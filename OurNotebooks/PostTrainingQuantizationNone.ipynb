{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"PostTrainingQuantizationNone.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-z8E8R3kgRGr","executionInfo":{"status":"ok","timestamp":1607461476633,"user_tz":300,"elapsed":4035,"user":{"displayName":"Michele L","photoUrl":"","userId":"03726718545613636685"}},"outputId":"806a26f9-5edb-4c39-e6b2-213a2e08d2ad"},"source":["!git clone https://github.com/mueedurrehman/distiller.git\r\n","%cd distiller\r\n","!pip3 install -e ."],"execution_count":1,"outputs":[{"output_type":"stream","text":["fatal: destination path 'distiller' already exists and is not an empty directory.\n","/content/distiller\n","Obtaining file:///content/distiller\n","Requirement already satisfied: pillow<7 in /usr/local/lib/python3.6/dist-packages (from distiller==0.4.0rc0) (6.2.2)\n","Requirement already satisfied: torch==1.3.1 in /usr/local/lib/python3.6/dist-packages (from distiller==0.4.0rc0) (1.3.1)\n","Requirement already satisfied: numpy>=1.16 in /usr/local/lib/python3.6/dist-packages (from distiller==0.4.0rc0) (1.18.5)\n","Requirement already satisfied: torchvision==0.4.2 in /usr/local/lib/python3.6/dist-packages (from distiller==0.4.0rc0) (0.4.2)\n","Requirement already satisfied: scipy>=1.3.0 in /usr/local/lib/python3.6/dist-packages (from distiller==0.4.0rc0) (1.4.1)\n","Requirement already satisfied: gitpython==3.1.0 in /usr/local/lib/python3.6/dist-packages (from distiller==0.4.0rc0) (3.1.0)\n","Requirement already satisfied: torchnet==0.0.4 in /usr/local/lib/python3.6/dist-packages (from distiller==0.4.0rc0) (0.0.4)\n","Requirement already satisfied: tensorflow~=1.14 in /usr/local/lib/python3.6/dist-packages (from distiller==0.4.0rc0) (1.15.4)\n","Requirement already satisfied: pydot==1.4.1 in /usr/local/lib/python3.6/dist-packages (from distiller==0.4.0rc0) (1.4.1)\n","Requirement already satisfied: tabulate==0.8.3 in /usr/local/lib/python3.6/dist-packages (from distiller==0.4.0rc0) (0.8.3)\n","Requirement already satisfied: pandas>=0.22.0 in /usr/local/lib/python3.6/dist-packages (from distiller==0.4.0rc0) (1.1.4)\n","Requirement already satisfied: jupyter>=1.0.0 in /usr/local/lib/python3.6/dist-packages (from distiller==0.4.0rc0) (1.0.0)\n","Requirement already satisfied: matplotlib~=3.0 in /usr/local/lib/python3.6/dist-packages (from distiller==0.4.0rc0) (3.2.2)\n","Requirement already satisfied: qgrid==1.1.1 in /usr/local/lib/python3.6/dist-packages (from distiller==0.4.0rc0) (1.1.1)\n","Requirement already satisfied: graphviz==0.10.1 in /usr/local/lib/python3.6/dist-packages (from distiller==0.4.0rc0) (0.10.1)\n","Requirement already satisfied: ipywidgets==7.4.2 in /usr/local/lib/python3.6/dist-packages (from distiller==0.4.0rc0) (7.4.2)\n","Requirement already satisfied: bqplot==0.11.5 in /usr/local/lib/python3.6/dist-packages (from distiller==0.4.0rc0) (0.11.5)\n","Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from distiller==0.4.0rc0) (3.13)\n","Requirement already satisfied: pytest~=4.6.1 in /usr/local/lib/python3.6/dist-packages (from distiller==0.4.0rc0) (4.6.11)\n","Requirement already satisfied: xlsxwriter>=1.2.2 in /usr/local/lib/python3.6/dist-packages (from distiller==0.4.0rc0) (1.3.7)\n","Requirement already satisfied: pretrainedmodels==0.7.4 in /usr/local/lib/python3.6/dist-packages (from distiller==0.4.0rc0) (0.7.4)\n","Requirement already satisfied: scikit-learn==0.21.2 in /usr/local/lib/python3.6/dist-packages (from distiller==0.4.0rc0) (0.21.2)\n","Requirement already satisfied: gym==0.12.5 in /usr/local/lib/python3.6/dist-packages (from distiller==0.4.0rc0) (0.12.5)\n","Requirement already satisfied: tqdm==4.33.0 in /usr/local/lib/python3.6/dist-packages (from distiller==0.4.0rc0) (4.33.0)\n","Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from torchvision==0.4.2->distiller==0.4.0rc0) (1.15.0)\n","Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.6/dist-packages (from gitpython==3.1.0->distiller==0.4.0rc0) (4.0.5)\n","Requirement already satisfied: visdom in /usr/local/lib/python3.6/dist-packages (from torchnet==0.0.4->distiller==0.4.0rc0) (0.1.8.9)\n","Requirement already satisfied: keras-applications>=1.0.8 in /usr/local/lib/python3.6/dist-packages (from tensorflow~=1.14->distiller==0.4.0rc0) (1.0.8)\n","Requirement already satisfied: google-pasta>=0.1.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow~=1.14->distiller==0.4.0rc0) (0.2.0)\n","Requirement already satisfied: gast==0.2.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow~=1.14->distiller==0.4.0rc0) (0.2.2)\n","Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow~=1.14->distiller==0.4.0rc0) (0.8.1)\n","Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow~=1.14->distiller==0.4.0rc0) (1.1.0)\n","Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow~=1.14->distiller==0.4.0rc0) (0.10.0)\n","Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow~=1.14->distiller==0.4.0rc0) (1.12.1)\n","Requirement already satisfied: wheel>=0.26; python_version >= \"3\" in /usr/local/lib/python3.6/dist-packages (from tensorflow~=1.14->distiller==0.4.0rc0) (0.35.1)\n","Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow~=1.14->distiller==0.4.0rc0) (1.1.2)\n","Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow~=1.14->distiller==0.4.0rc0) (3.3.0)\n","Requirement already satisfied: tensorflow-estimator==1.15.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow~=1.14->distiller==0.4.0rc0) (1.15.1)\n","Requirement already satisfied: tensorboard<1.16.0,>=1.15.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow~=1.14->distiller==0.4.0rc0) (1.15.0)\n","Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow~=1.14->distiller==0.4.0rc0) (1.33.2)\n","Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow~=1.14->distiller==0.4.0rc0) (3.12.4)\n","Requirement already satisfied: pyparsing>=2.1.4 in /usr/local/lib/python3.6/dist-packages (from pydot==1.4.1->distiller==0.4.0rc0) (2.4.7)\n","Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.6/dist-packages (from pandas>=0.22.0->distiller==0.4.0rc0) (2.8.1)\n","Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas>=0.22.0->distiller==0.4.0rc0) (2018.9)\n","Requirement already satisfied: jupyter-console in /usr/local/lib/python3.6/dist-packages (from jupyter>=1.0.0->distiller==0.4.0rc0) (5.2.0)\n","Requirement already satisfied: nbconvert in /usr/local/lib/python3.6/dist-packages (from jupyter>=1.0.0->distiller==0.4.0rc0) (5.6.1)\n","Requirement already satisfied: qtconsole in /usr/local/lib/python3.6/dist-packages (from jupyter>=1.0.0->distiller==0.4.0rc0) (5.0.1)\n","Requirement already satisfied: notebook in /usr/local/lib/python3.6/dist-packages (from jupyter>=1.0.0->distiller==0.4.0rc0) (5.3.1)\n","Requirement already satisfied: ipykernel in /usr/local/lib/python3.6/dist-packages (from jupyter>=1.0.0->distiller==0.4.0rc0) (4.10.1)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib~=3.0->distiller==0.4.0rc0) (0.10.0)\n","Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib~=3.0->distiller==0.4.0rc0) (1.3.1)\n","Requirement already satisfied: traitlets>=4.3.1 in /usr/local/lib/python3.6/dist-packages (from ipywidgets==7.4.2->distiller==0.4.0rc0) (4.3.3)\n","Requirement already satisfied: ipython>=4.0.0; python_version >= \"3.3\" in /usr/local/lib/python3.6/dist-packages (from ipywidgets==7.4.2->distiller==0.4.0rc0) (5.5.0)\n","Requirement already satisfied: nbformat>=4.2.0 in /usr/local/lib/python3.6/dist-packages (from ipywidgets==7.4.2->distiller==0.4.0rc0) (5.0.8)\n","Requirement already satisfied: widgetsnbextension~=3.4.0 in /usr/local/lib/python3.6/dist-packages (from ipywidgets==7.4.2->distiller==0.4.0rc0) (3.4.2)\n","Requirement already satisfied: traittypes>=0.0.6 in /usr/local/lib/python3.6/dist-packages (from bqplot==0.11.5->distiller==0.4.0rc0) (0.2.1)\n","Requirement already satisfied: atomicwrites>=1.0 in /usr/local/lib/python3.6/dist-packages (from pytest~=4.6.1->distiller==0.4.0rc0) (1.4.0)\n","Requirement already satisfied: wcwidth in /usr/local/lib/python3.6/dist-packages (from pytest~=4.6.1->distiller==0.4.0rc0) (0.2.5)\n","Requirement already satisfied: importlib-metadata>=0.12; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from pytest~=4.6.1->distiller==0.4.0rc0) (2.0.0)\n","Requirement already satisfied: py>=1.5.0 in /usr/local/lib/python3.6/dist-packages (from pytest~=4.6.1->distiller==0.4.0rc0) (1.9.0)\n","Requirement already satisfied: more-itertools>=4.0.0; python_version > \"2.7\" in /usr/local/lib/python3.6/dist-packages (from pytest~=4.6.1->distiller==0.4.0rc0) (8.6.0)\n","Requirement already satisfied: attrs>=17.4.0 in /usr/local/lib/python3.6/dist-packages (from pytest~=4.6.1->distiller==0.4.0rc0) (20.3.0)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from pytest~=4.6.1->distiller==0.4.0rc0) (20.4)\n","Requirement already satisfied: pluggy<1.0,>=0.12 in /usr/local/lib/python3.6/dist-packages (from pytest~=4.6.1->distiller==0.4.0rc0) (0.13.1)\n","Requirement already satisfied: munch in /usr/local/lib/python3.6/dist-packages (from pretrainedmodels==0.7.4->distiller==0.4.0rc0) (2.5.0)\n","Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn==0.21.2->distiller==0.4.0rc0) (0.17.0)\n","Requirement already satisfied: pyglet>=1.2.0 in /usr/local/lib/python3.6/dist-packages (from gym==0.12.5->distiller==0.4.0rc0) (1.5.0)\n","Requirement already satisfied: smmap<4,>=3.0.1 in /usr/local/lib/python3.6/dist-packages (from gitdb<5,>=4.0.1->gitpython==3.1.0->distiller==0.4.0rc0) (3.0.4)\n","Requirement already satisfied: pyzmq in /usr/local/lib/python3.6/dist-packages (from visdom->torchnet==0.0.4->distiller==0.4.0rc0) (20.0.0)\n","Requirement already satisfied: torchfile in /usr/local/lib/python3.6/dist-packages (from visdom->torchnet==0.0.4->distiller==0.4.0rc0) (0.1.0)\n","Requirement already satisfied: jsonpatch in /usr/local/lib/python3.6/dist-packages (from visdom->torchnet==0.0.4->distiller==0.4.0rc0) (1.28)\n","Requirement already satisfied: websocket-client in /usr/local/lib/python3.6/dist-packages (from visdom->torchnet==0.0.4->distiller==0.4.0rc0) (0.57.0)\n","Requirement already satisfied: tornado in /usr/local/lib/python3.6/dist-packages (from visdom->torchnet==0.0.4->distiller==0.4.0rc0) (5.1.1)\n","Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from visdom->torchnet==0.0.4->distiller==0.4.0rc0) (2.23.0)\n","Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras-applications>=1.0.8->tensorflow~=1.14->distiller==0.4.0rc0) (2.10.0)\n","Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow~=1.14->distiller==0.4.0rc0) (3.3.3)\n","Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow~=1.14->distiller==0.4.0rc0) (50.3.2)\n","Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow~=1.14->distiller==0.4.0rc0) (1.0.1)\n","Requirement already satisfied: pygments in /usr/local/lib/python3.6/dist-packages (from jupyter-console->jupyter>=1.0.0->distiller==0.4.0rc0) (2.6.1)\n","Requirement already satisfied: jupyter-client in /usr/local/lib/python3.6/dist-packages (from jupyter-console->jupyter>=1.0.0->distiller==0.4.0rc0) (5.3.5)\n","Requirement already satisfied: prompt-toolkit<2.0.0,>=1.0.0 in /usr/local/lib/python3.6/dist-packages (from jupyter-console->jupyter>=1.0.0->distiller==0.4.0rc0) (1.0.18)\n","Requirement already satisfied: jupyter-core in /usr/local/lib/python3.6/dist-packages (from nbconvert->jupyter>=1.0.0->distiller==0.4.0rc0) (4.7.0)\n","Requirement already satisfied: pandocfilters>=1.4.1 in /usr/local/lib/python3.6/dist-packages (from nbconvert->jupyter>=1.0.0->distiller==0.4.0rc0) (1.4.3)\n","Requirement already satisfied: defusedxml in /usr/local/lib/python3.6/dist-packages (from nbconvert->jupyter>=1.0.0->distiller==0.4.0rc0) (0.6.0)\n","Requirement already satisfied: jinja2>=2.4 in /usr/local/lib/python3.6/dist-packages (from nbconvert->jupyter>=1.0.0->distiller==0.4.0rc0) (2.11.2)\n","Requirement already satisfied: entrypoints>=0.2.2 in /usr/local/lib/python3.6/dist-packages (from nbconvert->jupyter>=1.0.0->distiller==0.4.0rc0) (0.3)\n","Requirement already satisfied: bleach in /usr/local/lib/python3.6/dist-packages (from nbconvert->jupyter>=1.0.0->distiller==0.4.0rc0) (3.2.1)\n","Requirement already satisfied: mistune<2,>=0.8.1 in /usr/local/lib/python3.6/dist-packages (from nbconvert->jupyter>=1.0.0->distiller==0.4.0rc0) (0.8.4)\n","Requirement already satisfied: testpath in /usr/local/lib/python3.6/dist-packages (from nbconvert->jupyter>=1.0.0->distiller==0.4.0rc0) (0.4.4)\n","Requirement already satisfied: qtpy in /usr/local/lib/python3.6/dist-packages (from qtconsole->jupyter>=1.0.0->distiller==0.4.0rc0) (1.9.0)\n","Requirement already satisfied: ipython-genutils in /usr/local/lib/python3.6/dist-packages (from qtconsole->jupyter>=1.0.0->distiller==0.4.0rc0) (0.2.0)\n","Requirement already satisfied: Send2Trash in /usr/local/lib/python3.6/dist-packages (from notebook->jupyter>=1.0.0->distiller==0.4.0rc0) (1.5.0)\n","Requirement already satisfied: terminado>=0.8.1 in /usr/local/lib/python3.6/dist-packages (from notebook->jupyter>=1.0.0->distiller==0.4.0rc0) (0.9.1)\n","Requirement already satisfied: decorator in /usr/local/lib/python3.6/dist-packages (from traitlets>=4.3.1->ipywidgets==7.4.2->distiller==0.4.0rc0) (4.4.2)\n","Requirement already satisfied: pexpect; sys_platform != \"win32\" in /usr/local/lib/python3.6/dist-packages (from ipython>=4.0.0; python_version >= \"3.3\"->ipywidgets==7.4.2->distiller==0.4.0rc0) (4.8.0)\n","Requirement already satisfied: pickleshare in /usr/local/lib/python3.6/dist-packages (from ipython>=4.0.0; python_version >= \"3.3\"->ipywidgets==7.4.2->distiller==0.4.0rc0) (0.7.5)\n","Requirement already satisfied: simplegeneric>0.8 in /usr/local/lib/python3.6/dist-packages (from ipython>=4.0.0; python_version >= \"3.3\"->ipywidgets==7.4.2->distiller==0.4.0rc0) (0.8.1)\n","Requirement already satisfied: jsonschema!=2.5.0,>=2.4 in /usr/local/lib/python3.6/dist-packages (from nbformat>=4.2.0->ipywidgets==7.4.2->distiller==0.4.0rc0) (2.6.0)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata>=0.12; python_version < \"3.8\"->pytest~=4.6.1->distiller==0.4.0rc0) (3.4.0)\n","Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from pyglet>=1.2.0->gym==0.12.5->distiller==0.4.0rc0) (0.16.0)\n","Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.6/dist-packages (from jsonpatch->visdom->torchnet==0.0.4->distiller==0.4.0rc0) (2.0)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->visdom->torchnet==0.0.4->distiller==0.4.0rc0) (2.10)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->visdom->torchnet==0.0.4->distiller==0.4.0rc0) (3.0.4)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->visdom->torchnet==0.0.4->distiller==0.4.0rc0) (2020.11.8)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->visdom->torchnet==0.0.4->distiller==0.4.0rc0) (1.24.3)\n","Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.6/dist-packages (from jinja2>=2.4->nbconvert->jupyter>=1.0.0->distiller==0.4.0rc0) (1.1.1)\n","Requirement already satisfied: webencodings in /usr/local/lib/python3.6/dist-packages (from bleach->nbconvert->jupyter>=1.0.0->distiller==0.4.0rc0) (0.5.1)\n","Requirement already satisfied: ptyprocess; os_name != \"nt\" in /usr/local/lib/python3.6/dist-packages (from terminado>=0.8.1->notebook->jupyter>=1.0.0->distiller==0.4.0rc0) (0.6.0)\n","Installing collected packages: distiller\n","  Found existing installation: distiller 0.4.0rc0\n","    Can't uninstall 'distiller'. No files were found to uninstall.\n","  Running setup.py develop for distiller\n","Successfully installed distiller\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"fcNpF9g2gtVx","executionInfo":{"status":"ok","timestamp":1607461476634,"user_tz":300,"elapsed":4028,"user":{"displayName":"Michele L","photoUrl":"","userId":"03726718545613636685"}},"outputId":"132833b5-a703-4f6a-f419-7d820418e6fd"},"source":["from google.colab import drive\r\n","drive.mount('/content/drive')"],"execution_count":2,"outputs":[{"output_type":"stream","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"PQvtIAXWoZFD","executionInfo":{"status":"ok","timestamp":1607461479463,"user_tz":300,"elapsed":6852,"user":{"displayName":"Michele L","photoUrl":"","userId":"03726718545613636685"}}},"source":["import torch\r\n","import torchvision\r\n","import torchvision.transforms as transforms\r\n","import torchvision.models as models\r\n","from torchsummary import summary\r\n","import matplotlib.pyplot as plt\r\n","import numpy as np\r\n","import torch.nn as nn\r\n","import torch.nn.functional as F\r\n","import time\r\n","import math\r\n","import yaml\r\n","import distiller\r\n","from collections import OrderedDict\r\n","import os\r\n","import pandas as pd"],"execution_count":3,"outputs":[]},{"cell_type":"code","metadata":{"id":"DU9QPjMtgucZ","executionInfo":{"status":"ok","timestamp":1607461482372,"user_tz":300,"elapsed":9756,"user":{"displayName":"Michele L","photoUrl":"","userId":"03726718545613636685"}}},"source":["!cp \"/content/drive/MyDrive/Colab Notebooks/6787 Notebooks/Google Colab Scripts/Baseline Models/baseResnet56\" .\r\n","# !cp ../../../drive/MyDrive/CS6787\\ -\\ Final\\ Project/Google\\ Colab\\ Scripts/Quantization\\ Models/Resnet56\\ Quantization\\ Stats/resnet56_quant_stats.yaml ."],"execution_count":4,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"wHDu0n7ExuwU"},"source":["Asymmetric U"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"A7Iupur823Fw","executionInfo":{"status":"ok","timestamp":1607461510493,"user_tz":300,"elapsed":37874,"user":{"displayName":"Michele L","photoUrl":"","userId":"03726718545613636685"}},"outputId":"2871094d-7b9d-4749-f360-0946570e8359"},"source":["!python3 \"/content/distiller/examples/classifier_compression/compress_classifier.py\" --arch resnet56_cifar -p 10 ./data --resume=\"baseResnet56\" --out-dir \"/content/drive/MyDrive/Colab Notebooks/6787 Notebooks/Google Colab Scripts/Schedules/Quantization Schedules/PostTrainingResults\" --evaluate --quantize-eval --qe-config-file \"/content/drive/MyDrive/Colab Notebooks/6787 Notebooks/Google Colab Scripts/Schedules/Quantization Schedules/PostTrainingSchedules/None/4bitAsymmetricUPost.yaml\" -o \"/content/drive/MyDrive/Colab Notebooks/6787 Notebooks/Google Colab Scripts/Schedules/Quantization Schedules/PostTrainingResults\""],"execution_count":5,"outputs":[{"output_type":"stream","text":["Log file for this run: /content/drive/.shortcut-targets-by-id/14_4ehU2lLHHu6HAFmEenl_iXGrCYtNmi/Google Colab Scripts/Schedules/Quantization Schedules/PostTrainingResults/2020.12.08-210446/2020.12.08-210446.log\n","Random seed: 0\n","\n","--------------------------------------------------------\n","Logging to TensorBoard - remember to execute the server:\n","> tensorboard --logdir='./logs'\n","\n","=> created a resnet56_cifar model with the cifar10 dataset\n","The \"--resume\" flag is deprecated. Please use \"--resume-from=YOUR_PATH\" instead.\n","If you wish to also reset the optimizer, call with: --reset-optimizer\n","=> loading checkpoint baseResnet56\n","=> Checkpoint contents:\n","+----------------------+--------+----------------+\n","| Key                  | Type   | Value          |\n","|----------------------+--------+----------------|\n","| arch                 | str    | resnet56_cifar |\n","| compression_sched    | dict   |                |\n","| dataset              | str    | cifar10        |\n","| epoch                | int    | 127            |\n","| extras               | dict   |                |\n","| is_parallel          | bool   | True           |\n","| optimizer            | type   | SGD            |\n","| optimizer_state_dict | dict   |                |\n","| state_dict           | dict   |                |\n","+----------------------+--------+----------------+\n","\n","=> Checkpoint['extras'] contents:\n","+--------------+--------+---------+\n","| Key          | Type   |   Value |\n","|--------------+--------+---------|\n","| best_epoch   | int    |  127    |\n","| best_top1    | float  |   92.94 |\n","| current_top1 | float  |   92.94 |\n","+--------------+--------+---------+\n","\n","Loaded compression schedule from checkpoint (epoch 127)\n","Optimizer could not be loaded from checkpoint.\n","=> loaded checkpoint 'baseResnet56' (epoch 127)\n","Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./data/cifar-10-python.tar.gz\n","170500096it [00:03, 45572616.47it/s]                   \n","Extracting ./data/cifar-10-python.tar.gz to ./data\n","Dataset sizes:\n","\ttest=10000\n","Reading configuration from: /content/drive/MyDrive/Colab Notebooks/6787 Notebooks/Google Colab Scripts/Schedules/Quantization Schedules/PostTrainingSchedules/None/4bitAsymmetricUPost.yaml\n","Found component of class PostTrainLinearQuantizer: Name: linear_quantizer ; Section: quantizers\n","Loading activation stats from: /content/drive/MyDrive/Colab Notebooks/6787 Notebooks/Google Colab Scripts/Schedules/Quantization Schedules/acts_quantization_stats.yaml\n","Preparing model for quantization using PostTrainLinearQuantizer\n","Applying batch-norm folding ahead of post-training quantization\n","Propagating output statistics from BN modules to folded modules\n","Optimizing output statistics for modules followed by ReLU/Tanh/Sigmoid\n","Updated stats saved to /content/drive/MyDrive/Colab Notebooks/6787 Notebooks/Google Colab Scripts/Schedules/Quantization Schedules/PostTrainingResults/2020.12.08-210446/quant_stats_after_prepare_model.yaml\n","Per-layer quantization parameters saved to /content/drive/MyDrive/Colab Notebooks/6787 Notebooks/Google Colab Scripts/Schedules/Quantization Schedules/PostTrainingResults/2020.12.08-210446/layer_quant_params.yaml\n","--- test ---------------------\n","10000 samples (256 per mini-batch)\n","Test: [   10/   39]    Loss 4.855318    Top1 38.867188    Top5 82.617188    \n","Test: [   20/   39]    Loss 4.733092    Top1 40.234375    Top5 83.613281    \n","Test: [   30/   39]    Loss 4.701374    Top1 40.859375    Top5 83.763021    \n","Test: [   40/   39]    Loss 4.650493    Top1 40.930000    Top5 83.900000    \n","==> Top1: 40.930    Top5: 83.900    Loss: 4.650\n","\n","Saving checkpoint to: /content/drive/MyDrive/Colab Notebooks/6787 Notebooks/Google Colab Scripts/Schedules/Quantization Schedules/PostTrainingResults/2020.12.08-210446/quantized_checkpoint.pth.tar\n","\n","Log file for this run: /content/drive/.shortcut-targets-by-id/14_4ehU2lLHHu6HAFmEenl_iXGrCYtNmi/Google Colab Scripts/Schedules/Quantization Schedules/PostTrainingResults/2020.12.08-210446/2020.12.08-210446.log\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"M5TkS-1O29ZZ","executionInfo":{"status":"ok","timestamp":1607461531842,"user_tz":300,"elapsed":59220,"user":{"displayName":"Michele L","photoUrl":"","userId":"03726718545613636685"}},"outputId":"f7d76aba-b2a7-453c-9f63-81c02bb14c22"},"source":["!python3 \"/content/distiller/examples/classifier_compression/compress_classifier.py\" --arch resnet56_cifar -p 10 ./data --resume=\"baseResnet56\" --out-dir \"/content/drive/MyDrive/Colab Notebooks/6787 Notebooks/Google Colab Scripts/Schedules/Quantization Schedules/PostTrainingResults\" --evaluate --quantize-eval --qe-config-file \"/content/drive/MyDrive/Colab Notebooks/6787 Notebooks/Google Colab Scripts/Schedules/Quantization Schedules/PostTrainingSchedules/None/6bitAsymmetricUPost.yaml\" -o \"/content/drive/MyDrive/Colab Notebooks/6787 Notebooks/Google Colab Scripts/Schedules/Quantization Schedules/PostTrainingResults\""],"execution_count":6,"outputs":[{"output_type":"stream","text":["Log file for this run: /content/drive/.shortcut-targets-by-id/14_4ehU2lLHHu6HAFmEenl_iXGrCYtNmi/Google Colab Scripts/Schedules/Quantization Schedules/PostTrainingResults/2020.12.08-210514/2020.12.08-210514.log\n","Random seed: 0\n","\n","--------------------------------------------------------\n","Logging to TensorBoard - remember to execute the server:\n","> tensorboard --logdir='./logs'\n","\n","=> created a resnet56_cifar model with the cifar10 dataset\n","The \"--resume\" flag is deprecated. Please use \"--resume-from=YOUR_PATH\" instead.\n","If you wish to also reset the optimizer, call with: --reset-optimizer\n","=> loading checkpoint baseResnet56\n","=> Checkpoint contents:\n","+----------------------+--------+----------------+\n","| Key                  | Type   | Value          |\n","|----------------------+--------+----------------|\n","| arch                 | str    | resnet56_cifar |\n","| compression_sched    | dict   |                |\n","| dataset              | str    | cifar10        |\n","| epoch                | int    | 127            |\n","| extras               | dict   |                |\n","| is_parallel          | bool   | True           |\n","| optimizer            | type   | SGD            |\n","| optimizer_state_dict | dict   |                |\n","| state_dict           | dict   |                |\n","+----------------------+--------+----------------+\n","\n","=> Checkpoint['extras'] contents:\n","+--------------+--------+---------+\n","| Key          | Type   |   Value |\n","|--------------+--------+---------|\n","| best_epoch   | int    |  127    |\n","| best_top1    | float  |   92.94 |\n","| current_top1 | float  |   92.94 |\n","+--------------+--------+---------+\n","\n","Loaded compression schedule from checkpoint (epoch 127)\n","Optimizer could not be loaded from checkpoint.\n","=> loaded checkpoint 'baseResnet56' (epoch 127)\n","Files already downloaded and verified\n","Dataset sizes:\n","\ttest=10000\n","Reading configuration from: /content/drive/MyDrive/Colab Notebooks/6787 Notebooks/Google Colab Scripts/Schedules/Quantization Schedules/PostTrainingSchedules/None/6bitAsymmetricUPost.yaml\n","Found component of class PostTrainLinearQuantizer: Name: linear_quantizer ; Section: quantizers\n","Loading activation stats from: /content/drive/MyDrive/Colab Notebooks/6787 Notebooks/Google Colab Scripts/Schedules/Quantization Schedules/acts_quantization_stats.yaml\n","Preparing model for quantization using PostTrainLinearQuantizer\n","Applying batch-norm folding ahead of post-training quantization\n","Propagating output statistics from BN modules to folded modules\n","Optimizing output statistics for modules followed by ReLU/Tanh/Sigmoid\n","Updated stats saved to /content/drive/MyDrive/Colab Notebooks/6787 Notebooks/Google Colab Scripts/Schedules/Quantization Schedules/PostTrainingResults/2020.12.08-210514/quant_stats_after_prepare_model.yaml\n","Per-layer quantization parameters saved to /content/drive/MyDrive/Colab Notebooks/6787 Notebooks/Google Colab Scripts/Schedules/Quantization Schedules/PostTrainingResults/2020.12.08-210514/layer_quant_params.yaml\n","--- test ---------------------\n","10000 samples (256 per mini-batch)\n","Test: [   10/   39]    Loss 0.547736    Top1 89.609375    Top5 99.609375    \n","Test: [   20/   39]    Loss 0.565324    Top1 89.121094    Top5 99.570312    \n","Test: [   30/   39]    Loss 0.537696    Top1 89.661458    Top5 99.544271    \n","Test: [   40/   39]    Loss 0.533306    Top1 89.740000    Top5 99.520000    \n","==> Top1: 89.740    Top5: 99.520    Loss: 0.533\n","\n","Saving checkpoint to: /content/drive/MyDrive/Colab Notebooks/6787 Notebooks/Google Colab Scripts/Schedules/Quantization Schedules/PostTrainingResults/2020.12.08-210514/quantized_checkpoint.pth.tar\n","\n","Log file for this run: /content/drive/.shortcut-targets-by-id/14_4ehU2lLHHu6HAFmEenl_iXGrCYtNmi/Google Colab Scripts/Schedules/Quantization Schedules/PostTrainingResults/2020.12.08-210514/2020.12.08-210514.log\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"XNsDkA6a2-Sk","executionInfo":{"status":"ok","timestamp":1607461553140,"user_tz":300,"elapsed":80515,"user":{"displayName":"Michele L","photoUrl":"","userId":"03726718545613636685"}},"outputId":"431e00ec-60a3-4a5c-8f49-1a92ae29ec8f"},"source":["!python3 \"/content/distiller/examples/classifier_compression/compress_classifier.py\" --arch resnet56_cifar -p 10 ./data --resume=\"baseResnet56\" --out-dir \"/content/drive/MyDrive/Colab Notebooks/6787 Notebooks/Google Colab Scripts/Schedules/Quantization Schedules/PostTrainingResults\" --evaluate --quantize-eval --qe-config-file \"/content/drive/MyDrive/Colab Notebooks/6787 Notebooks/Google Colab Scripts/Schedules/Quantization Schedules/PostTrainingSchedules/None/8bitAsymmetricUPost.yaml\" -o \"/content/drive/MyDrive/Colab Notebooks/6787 Notebooks/Google Colab Scripts/Schedules/Quantization Schedules/PostTrainingResults\""],"execution_count":7,"outputs":[{"output_type":"stream","text":["Log file for this run: /content/drive/.shortcut-targets-by-id/14_4ehU2lLHHu6HAFmEenl_iXGrCYtNmi/Google Colab Scripts/Schedules/Quantization Schedules/PostTrainingResults/2020.12.08-210535/2020.12.08-210535.log\n","Random seed: 0\n","\n","--------------------------------------------------------\n","Logging to TensorBoard - remember to execute the server:\n","> tensorboard --logdir='./logs'\n","\n","=> created a resnet56_cifar model with the cifar10 dataset\n","The \"--resume\" flag is deprecated. Please use \"--resume-from=YOUR_PATH\" instead.\n","If you wish to also reset the optimizer, call with: --reset-optimizer\n","=> loading checkpoint baseResnet56\n","=> Checkpoint contents:\n","+----------------------+--------+----------------+\n","| Key                  | Type   | Value          |\n","|----------------------+--------+----------------|\n","| arch                 | str    | resnet56_cifar |\n","| compression_sched    | dict   |                |\n","| dataset              | str    | cifar10        |\n","| epoch                | int    | 127            |\n","| extras               | dict   |                |\n","| is_parallel          | bool   | True           |\n","| optimizer            | type   | SGD            |\n","| optimizer_state_dict | dict   |                |\n","| state_dict           | dict   |                |\n","+----------------------+--------+----------------+\n","\n","=> Checkpoint['extras'] contents:\n","+--------------+--------+---------+\n","| Key          | Type   |   Value |\n","|--------------+--------+---------|\n","| best_epoch   | int    |  127    |\n","| best_top1    | float  |   92.94 |\n","| current_top1 | float  |   92.94 |\n","+--------------+--------+---------+\n","\n","Loaded compression schedule from checkpoint (epoch 127)\n","Optimizer could not be loaded from checkpoint.\n","=> loaded checkpoint 'baseResnet56' (epoch 127)\n","Files already downloaded and verified\n","Dataset sizes:\n","\ttest=10000\n","Reading configuration from: /content/drive/MyDrive/Colab Notebooks/6787 Notebooks/Google Colab Scripts/Schedules/Quantization Schedules/PostTrainingSchedules/None/8bitAsymmetricUPost.yaml\n","Found component of class PostTrainLinearQuantizer: Name: linear_quantizer ; Section: quantizers\n","Loading activation stats from: /content/drive/MyDrive/Colab Notebooks/6787 Notebooks/Google Colab Scripts/Schedules/Quantization Schedules/acts_quantization_stats.yaml\n","Preparing model for quantization using PostTrainLinearQuantizer\n","Applying batch-norm folding ahead of post-training quantization\n","Propagating output statistics from BN modules to folded modules\n","Optimizing output statistics for modules followed by ReLU/Tanh/Sigmoid\n","Updated stats saved to /content/drive/MyDrive/Colab Notebooks/6787 Notebooks/Google Colab Scripts/Schedules/Quantization Schedules/PostTrainingResults/2020.12.08-210535/quant_stats_after_prepare_model.yaml\n","Per-layer quantization parameters saved to /content/drive/MyDrive/Colab Notebooks/6787 Notebooks/Google Colab Scripts/Schedules/Quantization Schedules/PostTrainingResults/2020.12.08-210535/layer_quant_params.yaml\n","--- test ---------------------\n","10000 samples (256 per mini-batch)\n","Test: [   10/   39]    Loss 0.376151    Top1 92.148438    Top5 99.882812    \n","Test: [   20/   39]    Loss 0.370723    Top1 92.226562    Top5 99.843750    \n","Test: [   30/   39]    Loss 0.350093    Top1 92.721354    Top5 99.804688    \n","Test: [   40/   39]    Loss 0.347792    Top1 92.790000    Top5 99.760000    \n","==> Top1: 92.790    Top5: 99.760    Loss: 0.348\n","\n","Saving checkpoint to: /content/drive/MyDrive/Colab Notebooks/6787 Notebooks/Google Colab Scripts/Schedules/Quantization Schedules/PostTrainingResults/2020.12.08-210535/quantized_checkpoint.pth.tar\n","\n","Log file for this run: /content/drive/.shortcut-targets-by-id/14_4ehU2lLHHu6HAFmEenl_iXGrCYtNmi/Google Colab Scripts/Schedules/Quantization Schedules/PostTrainingResults/2020.12.08-210535/2020.12.08-210535.log\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"9D3UOg412-aj","executionInfo":{"status":"ok","timestamp":1607461574595,"user_tz":300,"elapsed":101967,"user":{"displayName":"Michele L","photoUrl":"","userId":"03726718545613636685"}},"outputId":"b6395990-d580-4f7d-dedf-d8fed00ab19e"},"source":["!python3 \"/content/distiller/examples/classifier_compression/compress_classifier.py\" --arch resnet56_cifar -p 10 ./data --resume=\"baseResnet56\" --out-dir \"/content/drive/MyDrive/Colab Notebooks/6787 Notebooks/Google Colab Scripts/Schedules/Quantization Schedules/PostTrainingResults\" --evaluate --quantize-eval --qe-config-file \"/content/drive/MyDrive/Colab Notebooks/6787 Notebooks/Google Colab Scripts/Schedules/Quantization Schedules/PostTrainingSchedules/None/10bitAsymmetricUPost.yaml\" -o \"/content/drive/MyDrive/Colab Notebooks/6787 Notebooks/Google Colab Scripts/Schedules/Quantization Schedules/PostTrainingResults\""],"execution_count":8,"outputs":[{"output_type":"stream","text":["Log file for this run: /content/drive/.shortcut-targets-by-id/14_4ehU2lLHHu6HAFmEenl_iXGrCYtNmi/Google Colab Scripts/Schedules/Quantization Schedules/PostTrainingResults/2020.12.08-210556/2020.12.08-210556.log\n","Random seed: 0\n","\n","--------------------------------------------------------\n","Logging to TensorBoard - remember to execute the server:\n","> tensorboard --logdir='./logs'\n","\n","=> created a resnet56_cifar model with the cifar10 dataset\n","The \"--resume\" flag is deprecated. Please use \"--resume-from=YOUR_PATH\" instead.\n","If you wish to also reset the optimizer, call with: --reset-optimizer\n","=> loading checkpoint baseResnet56\n","=> Checkpoint contents:\n","+----------------------+--------+----------------+\n","| Key                  | Type   | Value          |\n","|----------------------+--------+----------------|\n","| arch                 | str    | resnet56_cifar |\n","| compression_sched    | dict   |                |\n","| dataset              | str    | cifar10        |\n","| epoch                | int    | 127            |\n","| extras               | dict   |                |\n","| is_parallel          | bool   | True           |\n","| optimizer            | type   | SGD            |\n","| optimizer_state_dict | dict   |                |\n","| state_dict           | dict   |                |\n","+----------------------+--------+----------------+\n","\n","=> Checkpoint['extras'] contents:\n","+--------------+--------+---------+\n","| Key          | Type   |   Value |\n","|--------------+--------+---------|\n","| best_epoch   | int    |  127    |\n","| best_top1    | float  |   92.94 |\n","| current_top1 | float  |   92.94 |\n","+--------------+--------+---------+\n","\n","Loaded compression schedule from checkpoint (epoch 127)\n","Optimizer could not be loaded from checkpoint.\n","=> loaded checkpoint 'baseResnet56' (epoch 127)\n","Files already downloaded and verified\n","Dataset sizes:\n","\ttest=10000\n","Reading configuration from: /content/drive/MyDrive/Colab Notebooks/6787 Notebooks/Google Colab Scripts/Schedules/Quantization Schedules/PostTrainingSchedules/None/10bitAsymmetricUPost.yaml\n","Found component of class PostTrainLinearQuantizer: Name: linear_quantizer ; Section: quantizers\n","Loading activation stats from: /content/drive/MyDrive/Colab Notebooks/6787 Notebooks/Google Colab Scripts/Schedules/Quantization Schedules/acts_quantization_stats.yaml\n","Preparing model for quantization using PostTrainLinearQuantizer\n","Applying batch-norm folding ahead of post-training quantization\n","Propagating output statistics from BN modules to folded modules\n","Optimizing output statistics for modules followed by ReLU/Tanh/Sigmoid\n","Updated stats saved to /content/drive/MyDrive/Colab Notebooks/6787 Notebooks/Google Colab Scripts/Schedules/Quantization Schedules/PostTrainingResults/2020.12.08-210556/quant_stats_after_prepare_model.yaml\n","Per-layer quantization parameters saved to /content/drive/MyDrive/Colab Notebooks/6787 Notebooks/Google Colab Scripts/Schedules/Quantization Schedules/PostTrainingResults/2020.12.08-210556/layer_quant_params.yaml\n","--- test ---------------------\n","10000 samples (256 per mini-batch)\n","Test: [   10/   39]    Loss 0.369538    Top1 92.070312    Top5 99.882812    \n","Test: [   20/   39]    Loss 0.361437    Top1 92.324219    Top5 99.843750    \n","Test: [   30/   39]    Loss 0.342093    Top1 92.838542    Top5 99.830729    \n","Test: [   40/   39]    Loss 0.339033    Top1 92.900000    Top5 99.830000    \n","==> Top1: 92.900    Top5: 99.830    Loss: 0.339\n","\n","Saving checkpoint to: /content/drive/MyDrive/Colab Notebooks/6787 Notebooks/Google Colab Scripts/Schedules/Quantization Schedules/PostTrainingResults/2020.12.08-210556/quantized_checkpoint.pth.tar\n","\n","Log file for this run: /content/drive/.shortcut-targets-by-id/14_4ehU2lLHHu6HAFmEenl_iXGrCYtNmi/Google Colab Scripts/Schedules/Quantization Schedules/PostTrainingResults/2020.12.08-210556/2020.12.08-210556.log\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"F5s0UIn83GXu","executionInfo":{"status":"ok","timestamp":1607461595731,"user_tz":300,"elapsed":123100,"user":{"displayName":"Michele L","photoUrl":"","userId":"03726718545613636685"}},"outputId":"8d93088a-3022-48a5-8985-03752d2dc450"},"source":["!python3 \"/content/distiller/examples/classifier_compression/compress_classifier.py\" --arch resnet56_cifar -p 10 ./data --resume=\"baseResnet56\" --out-dir \"/content/drive/MyDrive/Colab Notebooks/6787 Notebooks/Google Colab Scripts/Schedules/Quantization Schedules/PostTrainingResults\" --evaluate --quantize-eval --qe-config-file \"/content/drive/MyDrive/Colab Notebooks/6787 Notebooks/Google Colab Scripts/Schedules/Quantization Schedules/PostTrainingSchedules/None/12bitAsymmetricUPost.yaml\" -o \"/content/drive/MyDrive/Colab Notebooks/6787 Notebooks/Google Colab Scripts/Schedules/Quantization Schedules/PostTrainingResults\""],"execution_count":9,"outputs":[{"output_type":"stream","text":["Log file for this run: /content/drive/.shortcut-targets-by-id/14_4ehU2lLHHu6HAFmEenl_iXGrCYtNmi/Google Colab Scripts/Schedules/Quantization Schedules/PostTrainingResults/2020.12.08-210618/2020.12.08-210618.log\n","Random seed: 0\n","\n","--------------------------------------------------------\n","Logging to TensorBoard - remember to execute the server:\n","> tensorboard --logdir='./logs'\n","\n","=> created a resnet56_cifar model with the cifar10 dataset\n","The \"--resume\" flag is deprecated. Please use \"--resume-from=YOUR_PATH\" instead.\n","If you wish to also reset the optimizer, call with: --reset-optimizer\n","=> loading checkpoint baseResnet56\n","=> Checkpoint contents:\n","+----------------------+--------+----------------+\n","| Key                  | Type   | Value          |\n","|----------------------+--------+----------------|\n","| arch                 | str    | resnet56_cifar |\n","| compression_sched    | dict   |                |\n","| dataset              | str    | cifar10        |\n","| epoch                | int    | 127            |\n","| extras               | dict   |                |\n","| is_parallel          | bool   | True           |\n","| optimizer            | type   | SGD            |\n","| optimizer_state_dict | dict   |                |\n","| state_dict           | dict   |                |\n","+----------------------+--------+----------------+\n","\n","=> Checkpoint['extras'] contents:\n","+--------------+--------+---------+\n","| Key          | Type   |   Value |\n","|--------------+--------+---------|\n","| best_epoch   | int    |  127    |\n","| best_top1    | float  |   92.94 |\n","| current_top1 | float  |   92.94 |\n","+--------------+--------+---------+\n","\n","Loaded compression schedule from checkpoint (epoch 127)\n","Optimizer could not be loaded from checkpoint.\n","=> loaded checkpoint 'baseResnet56' (epoch 127)\n","Files already downloaded and verified\n","Dataset sizes:\n","\ttest=10000\n","Reading configuration from: /content/drive/MyDrive/Colab Notebooks/6787 Notebooks/Google Colab Scripts/Schedules/Quantization Schedules/PostTrainingSchedules/None/12bitAsymmetricUPost.yaml\n","Found component of class PostTrainLinearQuantizer: Name: linear_quantizer ; Section: quantizers\n","Loading activation stats from: /content/drive/MyDrive/Colab Notebooks/6787 Notebooks/Google Colab Scripts/Schedules/Quantization Schedules/acts_quantization_stats.yaml\n","Preparing model for quantization using PostTrainLinearQuantizer\n","Applying batch-norm folding ahead of post-training quantization\n","Propagating output statistics from BN modules to folded modules\n","Optimizing output statistics for modules followed by ReLU/Tanh/Sigmoid\n","Updated stats saved to /content/drive/MyDrive/Colab Notebooks/6787 Notebooks/Google Colab Scripts/Schedules/Quantization Schedules/PostTrainingResults/2020.12.08-210618/quant_stats_after_prepare_model.yaml\n","Per-layer quantization parameters saved to /content/drive/MyDrive/Colab Notebooks/6787 Notebooks/Google Colab Scripts/Schedules/Quantization Schedules/PostTrainingResults/2020.12.08-210618/layer_quant_params.yaml\n","--- test ---------------------\n","10000 samples (256 per mini-batch)\n","Test: [   10/   39]    Loss 0.369708    Top1 92.265625    Top5 99.882812    \n","Test: [   20/   39]    Loss 0.361629    Top1 92.421875    Top5 99.863281    \n","Test: [   30/   39]    Loss 0.342078    Top1 92.877604    Top5 99.843750    \n","Test: [   40/   39]    Loss 0.339154    Top1 92.940000    Top5 99.830000    \n","==> Top1: 92.940    Top5: 99.830    Loss: 0.339\n","\n","Saving checkpoint to: /content/drive/MyDrive/Colab Notebooks/6787 Notebooks/Google Colab Scripts/Schedules/Quantization Schedules/PostTrainingResults/2020.12.08-210618/quantized_checkpoint.pth.tar\n","\n","Log file for this run: /content/drive/.shortcut-targets-by-id/14_4ehU2lLHHu6HAFmEenl_iXGrCYtNmi/Google Colab Scripts/Schedules/Quantization Schedules/PostTrainingResults/2020.12.08-210618/2020.12.08-210618.log\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"MIY3OFU-3Lmk","executionInfo":{"status":"ok","timestamp":1607461617248,"user_tz":300,"elapsed":144614,"user":{"displayName":"Michele L","photoUrl":"","userId":"03726718545613636685"}},"outputId":"6537a9d2-cebc-4011-acef-bced8df173fe"},"source":["!python3 \"/content/distiller/examples/classifier_compression/compress_classifier.py\" --arch resnet56_cifar -p 10 ./data --resume=\"baseResnet56\" --out-dir \"/content/drive/MyDrive/Colab Notebooks/6787 Notebooks/Google Colab Scripts/Schedules/Quantization Schedules/PostTrainingResults\" --evaluate --quantize-eval --qe-config-file \"/content/drive/MyDrive/Colab Notebooks/6787 Notebooks/Google Colab Scripts/Schedules/Quantization Schedules/PostTrainingSchedules/None/14bitAsymmetricUPost.yaml\" -o \"/content/drive/MyDrive/Colab Notebooks/6787 Notebooks/Google Colab Scripts/Schedules/Quantization Schedules/PostTrainingResults\""],"execution_count":10,"outputs":[{"output_type":"stream","text":["Log file for this run: /content/drive/.shortcut-targets-by-id/14_4ehU2lLHHu6HAFmEenl_iXGrCYtNmi/Google Colab Scripts/Schedules/Quantization Schedules/PostTrainingResults/2020.12.08-210639/2020.12.08-210639.log\n","Random seed: 0\n","\n","--------------------------------------------------------\n","Logging to TensorBoard - remember to execute the server:\n","> tensorboard --logdir='./logs'\n","\n","=> created a resnet56_cifar model with the cifar10 dataset\n","The \"--resume\" flag is deprecated. Please use \"--resume-from=YOUR_PATH\" instead.\n","If you wish to also reset the optimizer, call with: --reset-optimizer\n","=> loading checkpoint baseResnet56\n","=> Checkpoint contents:\n","+----------------------+--------+----------------+\n","| Key                  | Type   | Value          |\n","|----------------------+--------+----------------|\n","| arch                 | str    | resnet56_cifar |\n","| compression_sched    | dict   |                |\n","| dataset              | str    | cifar10        |\n","| epoch                | int    | 127            |\n","| extras               | dict   |                |\n","| is_parallel          | bool   | True           |\n","| optimizer            | type   | SGD            |\n","| optimizer_state_dict | dict   |                |\n","| state_dict           | dict   |                |\n","+----------------------+--------+----------------+\n","\n","=> Checkpoint['extras'] contents:\n","+--------------+--------+---------+\n","| Key          | Type   |   Value |\n","|--------------+--------+---------|\n","| best_epoch   | int    |  127    |\n","| best_top1    | float  |   92.94 |\n","| current_top1 | float  |   92.94 |\n","+--------------+--------+---------+\n","\n","Loaded compression schedule from checkpoint (epoch 127)\n","Optimizer could not be loaded from checkpoint.\n","=> loaded checkpoint 'baseResnet56' (epoch 127)\n","Files already downloaded and verified\n","Dataset sizes:\n","\ttest=10000\n","Reading configuration from: /content/drive/MyDrive/Colab Notebooks/6787 Notebooks/Google Colab Scripts/Schedules/Quantization Schedules/PostTrainingSchedules/None/14bitAsymmetricUPost.yaml\n","Found component of class PostTrainLinearQuantizer: Name: linear_quantizer ; Section: quantizers\n","Loading activation stats from: /content/drive/MyDrive/Colab Notebooks/6787 Notebooks/Google Colab Scripts/Schedules/Quantization Schedules/acts_quantization_stats.yaml\n","Preparing model for quantization using PostTrainLinearQuantizer\n","Applying batch-norm folding ahead of post-training quantization\n","Propagating output statistics from BN modules to folded modules\n","Optimizing output statistics for modules followed by ReLU/Tanh/Sigmoid\n","Updated stats saved to /content/drive/MyDrive/Colab Notebooks/6787 Notebooks/Google Colab Scripts/Schedules/Quantization Schedules/PostTrainingResults/2020.12.08-210639/quant_stats_after_prepare_model.yaml\n","Per-layer quantization parameters saved to /content/drive/MyDrive/Colab Notebooks/6787 Notebooks/Google Colab Scripts/Schedules/Quantization Schedules/PostTrainingResults/2020.12.08-210639/layer_quant_params.yaml\n","--- test ---------------------\n","10000 samples (256 per mini-batch)\n","Test: [   10/   39]    Loss 0.371905    Top1 92.226562    Top5 99.882812    \n","Test: [   20/   39]    Loss 0.363359    Top1 92.402344    Top5 99.843750    \n","Test: [   30/   39]    Loss 0.343024    Top1 92.903646    Top5 99.830729    \n","Test: [   40/   39]    Loss 0.339956    Top1 92.980000    Top5 99.830000    \n","==> Top1: 92.980    Top5: 99.830    Loss: 0.340\n","\n","Saving checkpoint to: /content/drive/MyDrive/Colab Notebooks/6787 Notebooks/Google Colab Scripts/Schedules/Quantization Schedules/PostTrainingResults/2020.12.08-210639/quantized_checkpoint.pth.tar\n","\n","Log file for this run: /content/drive/.shortcut-targets-by-id/14_4ehU2lLHHu6HAFmEenl_iXGrCYtNmi/Google Colab Scripts/Schedules/Quantization Schedules/PostTrainingResults/2020.12.08-210639/2020.12.08-210639.log\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"R6ZJGnEM3IAA","executionInfo":{"status":"ok","timestamp":1607461638498,"user_tz":300,"elapsed":165862,"user":{"displayName":"Michele L","photoUrl":"","userId":"03726718545613636685"}},"outputId":"7c38cd96-b33c-4d78-c051-15ee4e536c61"},"source":["!python3 \"/content/distiller/examples/classifier_compression/compress_classifier.py\" --arch resnet56_cifar -p 10 ./data --resume=\"baseResnet56\" --out-dir \"/content/drive/MyDrive/Colab Notebooks/6787 Notebooks/Google Colab Scripts/Schedules/Quantization Schedules/PostTrainingResults\" --evaluate --quantize-eval --qe-config-file \"/content/drive/MyDrive/Colab Notebooks/6787 Notebooks/Google Colab Scripts/Schedules/Quantization Schedules/PostTrainingSchedules/None/16bitAsymmetricUPost.yaml\" -o \"/content/drive/MyDrive/Colab Notebooks/6787 Notebooks/Google Colab Scripts/Schedules/Quantization Schedules/PostTrainingResults\""],"execution_count":11,"outputs":[{"output_type":"stream","text":["Log file for this run: /content/drive/.shortcut-targets-by-id/14_4ehU2lLHHu6HAFmEenl_iXGrCYtNmi/Google Colab Scripts/Schedules/Quantization Schedules/PostTrainingResults/2020.12.08-210700/2020.12.08-210700.log\n","Random seed: 0\n","\n","--------------------------------------------------------\n","Logging to TensorBoard - remember to execute the server:\n","> tensorboard --logdir='./logs'\n","\n","=> created a resnet56_cifar model with the cifar10 dataset\n","The \"--resume\" flag is deprecated. Please use \"--resume-from=YOUR_PATH\" instead.\n","If you wish to also reset the optimizer, call with: --reset-optimizer\n","=> loading checkpoint baseResnet56\n","=> Checkpoint contents:\n","+----------------------+--------+----------------+\n","| Key                  | Type   | Value          |\n","|----------------------+--------+----------------|\n","| arch                 | str    | resnet56_cifar |\n","| compression_sched    | dict   |                |\n","| dataset              | str    | cifar10        |\n","| epoch                | int    | 127            |\n","| extras               | dict   |                |\n","| is_parallel          | bool   | True           |\n","| optimizer            | type   | SGD            |\n","| optimizer_state_dict | dict   |                |\n","| state_dict           | dict   |                |\n","+----------------------+--------+----------------+\n","\n","=> Checkpoint['extras'] contents:\n","+--------------+--------+---------+\n","| Key          | Type   |   Value |\n","|--------------+--------+---------|\n","| best_epoch   | int    |  127    |\n","| best_top1    | float  |   92.94 |\n","| current_top1 | float  |   92.94 |\n","+--------------+--------+---------+\n","\n","Loaded compression schedule from checkpoint (epoch 127)\n","Optimizer could not be loaded from checkpoint.\n","=> loaded checkpoint 'baseResnet56' (epoch 127)\n","Files already downloaded and verified\n","Dataset sizes:\n","\ttest=10000\n","Reading configuration from: /content/drive/MyDrive/Colab Notebooks/6787 Notebooks/Google Colab Scripts/Schedules/Quantization Schedules/PostTrainingSchedules/None/16bitAsymmetricUPost.yaml\n","Found component of class PostTrainLinearQuantizer: Name: linear_quantizer ; Section: quantizers\n","Loading activation stats from: /content/drive/MyDrive/Colab Notebooks/6787 Notebooks/Google Colab Scripts/Schedules/Quantization Schedules/acts_quantization_stats.yaml\n","Preparing model for quantization using PostTrainLinearQuantizer\n","Applying batch-norm folding ahead of post-training quantization\n","Propagating output statistics from BN modules to folded modules\n","Optimizing output statistics for modules followed by ReLU/Tanh/Sigmoid\n","Updated stats saved to /content/drive/MyDrive/Colab Notebooks/6787 Notebooks/Google Colab Scripts/Schedules/Quantization Schedules/PostTrainingResults/2020.12.08-210700/quant_stats_after_prepare_model.yaml\n","Per-layer quantization parameters saved to /content/drive/MyDrive/Colab Notebooks/6787 Notebooks/Google Colab Scripts/Schedules/Quantization Schedules/PostTrainingResults/2020.12.08-210700/layer_quant_params.yaml\n","--- test ---------------------\n","10000 samples (256 per mini-batch)\n","Test: [   10/   39]    Loss 0.599946    Top1 84.609375    Top5 99.296875    \n","Test: [   20/   39]    Loss 0.591747    Top1 85.058594    Top5 99.257812    \n","Test: [   30/   39]    Loss 0.555601    Top1 85.755208    Top5 99.283854    \n","Test: [   40/   39]    Loss 0.544684    Top1 85.880000    Top5 99.290000    \n","==> Top1: 85.880    Top5: 99.290    Loss: 0.545\n","\n","Saving checkpoint to: /content/drive/MyDrive/Colab Notebooks/6787 Notebooks/Google Colab Scripts/Schedules/Quantization Schedules/PostTrainingResults/2020.12.08-210700/quantized_checkpoint.pth.tar\n","\n","Log file for this run: /content/drive/.shortcut-targets-by-id/14_4ehU2lLHHu6HAFmEenl_iXGrCYtNmi/Google Colab Scripts/Schedules/Quantization Schedules/PostTrainingResults/2020.12.08-210700/2020.12.08-210700.log\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"zBVfYUf_1PKM"},"source":["Asymetric S"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"nI5gRrst3OLJ","executionInfo":{"status":"ok","timestamp":1607461659692,"user_tz":300,"elapsed":187053,"user":{"displayName":"Michele L","photoUrl":"","userId":"03726718545613636685"}},"outputId":"6e7b6682-c079-4045-b4ef-1920b7efd034"},"source":["!python3 \"/content/distiller/examples/classifier_compression/compress_classifier.py\" --arch resnet56_cifar -p 10 ./data --resume=\"baseResnet56\" --out-dir \"/content/drive/MyDrive/Colab Notebooks/6787 Notebooks/Google Colab Scripts/Schedules/Quantization Schedules/PostTrainingResults\" --evaluate --quantize-eval --qe-config-file \"/content/drive/MyDrive/Colab Notebooks/6787 Notebooks/Google Colab Scripts/Schedules/Quantization Schedules/PostTrainingSchedules/None/4bitAsymmetricSPost.yaml\" -o \"/content/drive/MyDrive/Colab Notebooks/6787 Notebooks/Google Colab Scripts/Schedules/Quantization Schedules/PostTrainingResults\""],"execution_count":12,"outputs":[{"output_type":"stream","text":["Log file for this run: /content/drive/.shortcut-targets-by-id/14_4ehU2lLHHu6HAFmEenl_iXGrCYtNmi/Google Colab Scripts/Schedules/Quantization Schedules/PostTrainingResults/2020.12.08-210722/2020.12.08-210722.log\n","Random seed: 0\n","\n","--------------------------------------------------------\n","Logging to TensorBoard - remember to execute the server:\n","> tensorboard --logdir='./logs'\n","\n","=> created a resnet56_cifar model with the cifar10 dataset\n","The \"--resume\" flag is deprecated. Please use \"--resume-from=YOUR_PATH\" instead.\n","If you wish to also reset the optimizer, call with: --reset-optimizer\n","=> loading checkpoint baseResnet56\n","=> Checkpoint contents:\n","+----------------------+--------+----------------+\n","| Key                  | Type   | Value          |\n","|----------------------+--------+----------------|\n","| arch                 | str    | resnet56_cifar |\n","| compression_sched    | dict   |                |\n","| dataset              | str    | cifar10        |\n","| epoch                | int    | 127            |\n","| extras               | dict   |                |\n","| is_parallel          | bool   | True           |\n","| optimizer            | type   | SGD            |\n","| optimizer_state_dict | dict   |                |\n","| state_dict           | dict   |                |\n","+----------------------+--------+----------------+\n","\n","=> Checkpoint['extras'] contents:\n","+--------------+--------+---------+\n","| Key          | Type   |   Value |\n","|--------------+--------+---------|\n","| best_epoch   | int    |  127    |\n","| best_top1    | float  |   92.94 |\n","| current_top1 | float  |   92.94 |\n","+--------------+--------+---------+\n","\n","Loaded compression schedule from checkpoint (epoch 127)\n","Optimizer could not be loaded from checkpoint.\n","=> loaded checkpoint 'baseResnet56' (epoch 127)\n","Files already downloaded and verified\n","Dataset sizes:\n","\ttest=10000\n","Reading configuration from: /content/drive/MyDrive/Colab Notebooks/6787 Notebooks/Google Colab Scripts/Schedules/Quantization Schedules/PostTrainingSchedules/None/4bitAsymmetricSPost.yaml\n","Found component of class PostTrainLinearQuantizer: Name: linear_quantizer ; Section: quantizers\n","Loading activation stats from: /content/drive/MyDrive/Colab Notebooks/6787 Notebooks/Google Colab Scripts/Schedules/Quantization Schedules/acts_quantization_stats.yaml\n","Preparing model for quantization using PostTrainLinearQuantizer\n","Applying batch-norm folding ahead of post-training quantization\n","Propagating output statistics from BN modules to folded modules\n","Optimizing output statistics for modules followed by ReLU/Tanh/Sigmoid\n","Updated stats saved to /content/drive/MyDrive/Colab Notebooks/6787 Notebooks/Google Colab Scripts/Schedules/Quantization Schedules/PostTrainingResults/2020.12.08-210722/quant_stats_after_prepare_model.yaml\n","Per-layer quantization parameters saved to /content/drive/MyDrive/Colab Notebooks/6787 Notebooks/Google Colab Scripts/Schedules/Quantization Schedules/PostTrainingResults/2020.12.08-210722/layer_quant_params.yaml\n","--- test ---------------------\n","10000 samples (256 per mini-batch)\n","Test: [   10/   39]    Loss 4.866349    Top1 38.828125    Top5 82.695312    \n","Test: [   20/   39]    Loss 4.744760    Top1 40.078125    Top5 83.730469    \n","Test: [   30/   39]    Loss 4.707649    Top1 40.820312    Top5 83.932292    \n","Test: [   40/   39]    Loss 4.655525    Top1 40.960000    Top5 84.030000    \n","==> Top1: 40.960    Top5: 84.030    Loss: 4.656\n","\n","Saving checkpoint to: /content/drive/MyDrive/Colab Notebooks/6787 Notebooks/Google Colab Scripts/Schedules/Quantization Schedules/PostTrainingResults/2020.12.08-210722/quantized_checkpoint.pth.tar\n","\n","Log file for this run: /content/drive/.shortcut-targets-by-id/14_4ehU2lLHHu6HAFmEenl_iXGrCYtNmi/Google Colab Scripts/Schedules/Quantization Schedules/PostTrainingResults/2020.12.08-210722/2020.12.08-210722.log\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"oxMatIUv3SEh","executionInfo":{"status":"ok","timestamp":1607461681078,"user_tz":300,"elapsed":208436,"user":{"displayName":"Michele L","photoUrl":"","userId":"03726718545613636685"}},"outputId":"a0c4164e-67ac-41d1-c6ab-9842edaf2837"},"source":["!python3 \"/content/distiller/examples/classifier_compression/compress_classifier.py\" --arch resnet56_cifar -p 10 ./data --resume=\"baseResnet56\" --out-dir \"/content/drive/MyDrive/Colab Notebooks/6787 Notebooks/Google Colab Scripts/Schedules/Quantization Schedules/PostTrainingResults\" --evaluate --quantize-eval --qe-config-file \"/content/drive/MyDrive/Colab Notebooks/6787 Notebooks/Google Colab Scripts/Schedules/Quantization Schedules/PostTrainingSchedules/None/6bitAsymmetricSPost.yaml\" -o \"/content/drive/MyDrive/Colab Notebooks/6787 Notebooks/Google Colab Scripts/Schedules/Quantization Schedules/PostTrainingResults\""],"execution_count":13,"outputs":[{"output_type":"stream","text":["Log file for this run: /content/drive/.shortcut-targets-by-id/14_4ehU2lLHHu6HAFmEenl_iXGrCYtNmi/Google Colab Scripts/Schedules/Quantization Schedules/PostTrainingResults/2020.12.08-210743/2020.12.08-210743.log\n","Random seed: 0\n","\n","--------------------------------------------------------\n","Logging to TensorBoard - remember to execute the server:\n","> tensorboard --logdir='./logs'\n","\n","=> created a resnet56_cifar model with the cifar10 dataset\n","The \"--resume\" flag is deprecated. Please use \"--resume-from=YOUR_PATH\" instead.\n","If you wish to also reset the optimizer, call with: --reset-optimizer\n","=> loading checkpoint baseResnet56\n","=> Checkpoint contents:\n","+----------------------+--------+----------------+\n","| Key                  | Type   | Value          |\n","|----------------------+--------+----------------|\n","| arch                 | str    | resnet56_cifar |\n","| compression_sched    | dict   |                |\n","| dataset              | str    | cifar10        |\n","| epoch                | int    | 127            |\n","| extras               | dict   |                |\n","| is_parallel          | bool   | True           |\n","| optimizer            | type   | SGD            |\n","| optimizer_state_dict | dict   |                |\n","| state_dict           | dict   |                |\n","+----------------------+--------+----------------+\n","\n","=> Checkpoint['extras'] contents:\n","+--------------+--------+---------+\n","| Key          | Type   |   Value |\n","|--------------+--------+---------|\n","| best_epoch   | int    |  127    |\n","| best_top1    | float  |   92.94 |\n","| current_top1 | float  |   92.94 |\n","+--------------+--------+---------+\n","\n","Loaded compression schedule from checkpoint (epoch 127)\n","Optimizer could not be loaded from checkpoint.\n","=> loaded checkpoint 'baseResnet56' (epoch 127)\n","Files already downloaded and verified\n","Dataset sizes:\n","\ttest=10000\n","Reading configuration from: /content/drive/MyDrive/Colab Notebooks/6787 Notebooks/Google Colab Scripts/Schedules/Quantization Schedules/PostTrainingSchedules/None/6bitAsymmetricSPost.yaml\n","Found component of class PostTrainLinearQuantizer: Name: linear_quantizer ; Section: quantizers\n","Loading activation stats from: /content/drive/MyDrive/Colab Notebooks/6787 Notebooks/Google Colab Scripts/Schedules/Quantization Schedules/acts_quantization_stats.yaml\n","Preparing model for quantization using PostTrainLinearQuantizer\n","Applying batch-norm folding ahead of post-training quantization\n","Propagating output statistics from BN modules to folded modules\n","Optimizing output statistics for modules followed by ReLU/Tanh/Sigmoid\n","Updated stats saved to /content/drive/MyDrive/Colab Notebooks/6787 Notebooks/Google Colab Scripts/Schedules/Quantization Schedules/PostTrainingResults/2020.12.08-210743/quant_stats_after_prepare_model.yaml\n","Per-layer quantization parameters saved to /content/drive/MyDrive/Colab Notebooks/6787 Notebooks/Google Colab Scripts/Schedules/Quantization Schedules/PostTrainingResults/2020.12.08-210743/layer_quant_params.yaml\n","--- test ---------------------\n","10000 samples (256 per mini-batch)\n","Test: [   10/   39]    Loss 0.547638    Top1 89.570312    Top5 99.609375    \n","Test: [   20/   39]    Loss 0.565536    Top1 89.101562    Top5 99.570312    \n","Test: [   30/   39]    Loss 0.538331    Top1 89.648438    Top5 99.544271    \n","Test: [   40/   39]    Loss 0.534226    Top1 89.730000    Top5 99.520000    \n","==> Top1: 89.730    Top5: 99.520    Loss: 0.534\n","\n","Saving checkpoint to: /content/drive/MyDrive/Colab Notebooks/6787 Notebooks/Google Colab Scripts/Schedules/Quantization Schedules/PostTrainingResults/2020.12.08-210743/quantized_checkpoint.pth.tar\n","\n","Log file for this run: /content/drive/.shortcut-targets-by-id/14_4ehU2lLHHu6HAFmEenl_iXGrCYtNmi/Google Colab Scripts/Schedules/Quantization Schedules/PostTrainingResults/2020.12.08-210743/2020.12.08-210743.log\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-1-q7Mr53SJV","executionInfo":{"status":"ok","timestamp":1607461702542,"user_tz":300,"elapsed":229897,"user":{"displayName":"Michele L","photoUrl":"","userId":"03726718545613636685"}},"outputId":"9f4dfd53-7909-47ff-b504-16fa8a5b94a7"},"source":["!python3 \"/content/distiller/examples/classifier_compression/compress_classifier.py\" --arch resnet56_cifar -p 10 ./data --resume=\"baseResnet56\" --out-dir \"/content/drive/MyDrive/Colab Notebooks/6787 Notebooks/Google Colab Scripts/Schedules/Quantization Schedules/PostTrainingResults\" --evaluate --quantize-eval --qe-config-file \"/content/drive/MyDrive/Colab Notebooks/6787 Notebooks/Google Colab Scripts/Schedules/Quantization Schedules/PostTrainingSchedules/None/8bitAsymmetricSPost.yaml\" -o \"/content/drive/MyDrive/Colab Notebooks/6787 Notebooks/Google Colab Scripts/Schedules/Quantization Schedules/PostTrainingResults\""],"execution_count":14,"outputs":[{"output_type":"stream","text":["Log file for this run: /content/drive/.shortcut-targets-by-id/14_4ehU2lLHHu6HAFmEenl_iXGrCYtNmi/Google Colab Scripts/Schedules/Quantization Schedules/PostTrainingResults/2020.12.08-210804/2020.12.08-210804.log\n","Random seed: 0\n","\n","--------------------------------------------------------\n","Logging to TensorBoard - remember to execute the server:\n","> tensorboard --logdir='./logs'\n","\n","=> created a resnet56_cifar model with the cifar10 dataset\n","The \"--resume\" flag is deprecated. Please use \"--resume-from=YOUR_PATH\" instead.\n","If you wish to also reset the optimizer, call with: --reset-optimizer\n","=> loading checkpoint baseResnet56\n","=> Checkpoint contents:\n","+----------------------+--------+----------------+\n","| Key                  | Type   | Value          |\n","|----------------------+--------+----------------|\n","| arch                 | str    | resnet56_cifar |\n","| compression_sched    | dict   |                |\n","| dataset              | str    | cifar10        |\n","| epoch                | int    | 127            |\n","| extras               | dict   |                |\n","| is_parallel          | bool   | True           |\n","| optimizer            | type   | SGD            |\n","| optimizer_state_dict | dict   |                |\n","| state_dict           | dict   |                |\n","+----------------------+--------+----------------+\n","\n","=> Checkpoint['extras'] contents:\n","+--------------+--------+---------+\n","| Key          | Type   |   Value |\n","|--------------+--------+---------|\n","| best_epoch   | int    |  127    |\n","| best_top1    | float  |   92.94 |\n","| current_top1 | float  |   92.94 |\n","+--------------+--------+---------+\n","\n","Loaded compression schedule from checkpoint (epoch 127)\n","Optimizer could not be loaded from checkpoint.\n","=> loaded checkpoint 'baseResnet56' (epoch 127)\n","Files already downloaded and verified\n","Dataset sizes:\n","\ttest=10000\n","Reading configuration from: /content/drive/MyDrive/Colab Notebooks/6787 Notebooks/Google Colab Scripts/Schedules/Quantization Schedules/PostTrainingSchedules/None/8bitAsymmetricSPost.yaml\n","Found component of class PostTrainLinearQuantizer: Name: linear_quantizer ; Section: quantizers\n","Loading activation stats from: /content/drive/MyDrive/Colab Notebooks/6787 Notebooks/Google Colab Scripts/Schedules/Quantization Schedules/acts_quantization_stats.yaml\n","Preparing model for quantization using PostTrainLinearQuantizer\n","Applying batch-norm folding ahead of post-training quantization\n","Propagating output statistics from BN modules to folded modules\n","Optimizing output statistics for modules followed by ReLU/Tanh/Sigmoid\n","Updated stats saved to /content/drive/MyDrive/Colab Notebooks/6787 Notebooks/Google Colab Scripts/Schedules/Quantization Schedules/PostTrainingResults/2020.12.08-210804/quant_stats_after_prepare_model.yaml\n","Per-layer quantization parameters saved to /content/drive/MyDrive/Colab Notebooks/6787 Notebooks/Google Colab Scripts/Schedules/Quantization Schedules/PostTrainingResults/2020.12.08-210804/layer_quant_params.yaml\n","--- test ---------------------\n","10000 samples (256 per mini-batch)\n","Test: [   10/   39]    Loss 0.376268    Top1 92.304688    Top5 99.882812    \n","Test: [   20/   39]    Loss 0.370125    Top1 92.207031    Top5 99.824219    \n","Test: [   30/   39]    Loss 0.349117    Top1 92.682292    Top5 99.791667    \n","Test: [   40/   39]    Loss 0.347420    Top1 92.750000    Top5 99.760000    \n","==> Top1: 92.750    Top5: 99.760    Loss: 0.347\n","\n","Saving checkpoint to: /content/drive/MyDrive/Colab Notebooks/6787 Notebooks/Google Colab Scripts/Schedules/Quantization Schedules/PostTrainingResults/2020.12.08-210804/quantized_checkpoint.pth.tar\n","\n","Log file for this run: /content/drive/.shortcut-targets-by-id/14_4ehU2lLHHu6HAFmEenl_iXGrCYtNmi/Google Colab Scripts/Schedules/Quantization Schedules/PostTrainingResults/2020.12.08-210804/2020.12.08-210804.log\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"R5HtqpaE3SM1","executionInfo":{"status":"ok","timestamp":1607461723660,"user_tz":300,"elapsed":251011,"user":{"displayName":"Michele L","photoUrl":"","userId":"03726718545613636685"}},"outputId":"7907c362-32f3-4b57-9850-7f1b2fed4d3b"},"source":["!python3 \"/content/distiller/examples/classifier_compression/compress_classifier.py\" --arch resnet56_cifar -p 10 ./data --resume=\"baseResnet56\" --out-dir \"/content/drive/MyDrive/Colab Notebooks/6787 Notebooks/Google Colab Scripts/Schedules/Quantization Schedules/PostTrainingResults\" --evaluate --quantize-eval --qe-config-file \"/content/drive/MyDrive/Colab Notebooks/6787 Notebooks/Google Colab Scripts/Schedules/Quantization Schedules/PostTrainingSchedules/None/10bitAsymmetricSPost.yaml\" -o \"/content/drive/MyDrive/Colab Notebooks/6787 Notebooks/Google Colab Scripts/Schedules/Quantization Schedules/PostTrainingResults\""],"execution_count":15,"outputs":[{"output_type":"stream","text":["Log file for this run: /content/drive/.shortcut-targets-by-id/14_4ehU2lLHHu6HAFmEenl_iXGrCYtNmi/Google Colab Scripts/Schedules/Quantization Schedules/PostTrainingResults/2020.12.08-210826/2020.12.08-210826.log\n","Random seed: 0\n","\n","--------------------------------------------------------\n","Logging to TensorBoard - remember to execute the server:\n","> tensorboard --logdir='./logs'\n","\n","=> created a resnet56_cifar model with the cifar10 dataset\n","The \"--resume\" flag is deprecated. Please use \"--resume-from=YOUR_PATH\" instead.\n","If you wish to also reset the optimizer, call with: --reset-optimizer\n","=> loading checkpoint baseResnet56\n","=> Checkpoint contents:\n","+----------------------+--------+----------------+\n","| Key                  | Type   | Value          |\n","|----------------------+--------+----------------|\n","| arch                 | str    | resnet56_cifar |\n","| compression_sched    | dict   |                |\n","| dataset              | str    | cifar10        |\n","| epoch                | int    | 127            |\n","| extras               | dict   |                |\n","| is_parallel          | bool   | True           |\n","| optimizer            | type   | SGD            |\n","| optimizer_state_dict | dict   |                |\n","| state_dict           | dict   |                |\n","+----------------------+--------+----------------+\n","\n","=> Checkpoint['extras'] contents:\n","+--------------+--------+---------+\n","| Key          | Type   |   Value |\n","|--------------+--------+---------|\n","| best_epoch   | int    |  127    |\n","| best_top1    | float  |   92.94 |\n","| current_top1 | float  |   92.94 |\n","+--------------+--------+---------+\n","\n","Loaded compression schedule from checkpoint (epoch 127)\n","Optimizer could not be loaded from checkpoint.\n","=> loaded checkpoint 'baseResnet56' (epoch 127)\n","Files already downloaded and verified\n","Dataset sizes:\n","\ttest=10000\n","Reading configuration from: /content/drive/MyDrive/Colab Notebooks/6787 Notebooks/Google Colab Scripts/Schedules/Quantization Schedules/PostTrainingSchedules/None/10bitAsymmetricSPost.yaml\n","Found component of class PostTrainLinearQuantizer: Name: linear_quantizer ; Section: quantizers\n","Loading activation stats from: /content/drive/MyDrive/Colab Notebooks/6787 Notebooks/Google Colab Scripts/Schedules/Quantization Schedules/acts_quantization_stats.yaml\n","Preparing model for quantization using PostTrainLinearQuantizer\n","Applying batch-norm folding ahead of post-training quantization\n","Propagating output statistics from BN modules to folded modules\n","Optimizing output statistics for modules followed by ReLU/Tanh/Sigmoid\n","Updated stats saved to /content/drive/MyDrive/Colab Notebooks/6787 Notebooks/Google Colab Scripts/Schedules/Quantization Schedules/PostTrainingResults/2020.12.08-210826/quant_stats_after_prepare_model.yaml\n","Per-layer quantization parameters saved to /content/drive/MyDrive/Colab Notebooks/6787 Notebooks/Google Colab Scripts/Schedules/Quantization Schedules/PostTrainingResults/2020.12.08-210826/layer_quant_params.yaml\n","--- test ---------------------\n","10000 samples (256 per mini-batch)\n","Test: [   10/   39]    Loss 0.369344    Top1 92.031250    Top5 99.882812    \n","Test: [   20/   39]    Loss 0.361097    Top1 92.304688    Top5 99.843750    \n","Test: [   30/   39]    Loss 0.342004    Top1 92.812500    Top5 99.830729    \n","Test: [   40/   39]    Loss 0.338995    Top1 92.920000    Top5 99.830000    \n","==> Top1: 92.920    Top5: 99.830    Loss: 0.339\n","\n","Saving checkpoint to: /content/drive/MyDrive/Colab Notebooks/6787 Notebooks/Google Colab Scripts/Schedules/Quantization Schedules/PostTrainingResults/2020.12.08-210826/quantized_checkpoint.pth.tar\n","\n","Log file for this run: /content/drive/.shortcut-targets-by-id/14_4ehU2lLHHu6HAFmEenl_iXGrCYtNmi/Google Colab Scripts/Schedules/Quantization Schedules/PostTrainingResults/2020.12.08-210826/2020.12.08-210826.log\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"sVCV7ath3SRB","executionInfo":{"status":"ok","timestamp":1607461744806,"user_tz":300,"elapsed":272154,"user":{"displayName":"Michele L","photoUrl":"","userId":"03726718545613636685"}},"outputId":"27a90cb5-0401-4b70-8cdb-41cf116a79c3"},"source":["!python3 \"/content/distiller/examples/classifier_compression/compress_classifier.py\" --arch resnet56_cifar -p 10 ./data --resume=\"baseResnet56\" --out-dir \"/content/drive/MyDrive/Colab Notebooks/6787 Notebooks/Google Colab Scripts/Schedules/Quantization Schedules/PostTrainingResults\" --evaluate --quantize-eval --qe-config-file \"/content/drive/MyDrive/Colab Notebooks/6787 Notebooks/Google Colab Scripts/Schedules/Quantization Schedules/PostTrainingSchedules/None/12bitAsymmetricSPost.yaml\" -o \"/content/drive/MyDrive/Colab Notebooks/6787 Notebooks/Google Colab Scripts/Schedules/Quantization Schedules/PostTrainingResults\" -o \"/content/drive/MyDrive/Colab Notebooks/6787 Notebooks/Google Colab Scripts/Schedules/Quantization Schedules/PostTrainingResults\""],"execution_count":16,"outputs":[{"output_type":"stream","text":["Log file for this run: /content/drive/.shortcut-targets-by-id/14_4ehU2lLHHu6HAFmEenl_iXGrCYtNmi/Google Colab Scripts/Schedules/Quantization Schedules/PostTrainingResults/2020.12.08-210847/2020.12.08-210847.log\n","Random seed: 0\n","\n","--------------------------------------------------------\n","Logging to TensorBoard - remember to execute the server:\n","> tensorboard --logdir='./logs'\n","\n","=> created a resnet56_cifar model with the cifar10 dataset\n","The \"--resume\" flag is deprecated. Please use \"--resume-from=YOUR_PATH\" instead.\n","If you wish to also reset the optimizer, call with: --reset-optimizer\n","=> loading checkpoint baseResnet56\n","=> Checkpoint contents:\n","+----------------------+--------+----------------+\n","| Key                  | Type   | Value          |\n","|----------------------+--------+----------------|\n","| arch                 | str    | resnet56_cifar |\n","| compression_sched    | dict   |                |\n","| dataset              | str    | cifar10        |\n","| epoch                | int    | 127            |\n","| extras               | dict   |                |\n","| is_parallel          | bool   | True           |\n","| optimizer            | type   | SGD            |\n","| optimizer_state_dict | dict   |                |\n","| state_dict           | dict   |                |\n","+----------------------+--------+----------------+\n","\n","=> Checkpoint['extras'] contents:\n","+--------------+--------+---------+\n","| Key          | Type   |   Value |\n","|--------------+--------+---------|\n","| best_epoch   | int    |  127    |\n","| best_top1    | float  |   92.94 |\n","| current_top1 | float  |   92.94 |\n","+--------------+--------+---------+\n","\n","Loaded compression schedule from checkpoint (epoch 127)\n","Optimizer could not be loaded from checkpoint.\n","=> loaded checkpoint 'baseResnet56' (epoch 127)\n","Files already downloaded and verified\n","Dataset sizes:\n","\ttest=10000\n","Reading configuration from: /content/drive/MyDrive/Colab Notebooks/6787 Notebooks/Google Colab Scripts/Schedules/Quantization Schedules/PostTrainingSchedules/None/12bitAsymmetricSPost.yaml\n","Found component of class PostTrainLinearQuantizer: Name: linear_quantizer ; Section: quantizers\n","Loading activation stats from: /content/drive/MyDrive/Colab Notebooks/6787 Notebooks/Google Colab Scripts/Schedules/Quantization Schedules/acts_quantization_stats.yaml\n","Preparing model for quantization using PostTrainLinearQuantizer\n","Applying batch-norm folding ahead of post-training quantization\n","Propagating output statistics from BN modules to folded modules\n","Optimizing output statistics for modules followed by ReLU/Tanh/Sigmoid\n","Updated stats saved to /content/drive/MyDrive/Colab Notebooks/6787 Notebooks/Google Colab Scripts/Schedules/Quantization Schedules/PostTrainingResults/2020.12.08-210847/quant_stats_after_prepare_model.yaml\n","Per-layer quantization parameters saved to /content/drive/MyDrive/Colab Notebooks/6787 Notebooks/Google Colab Scripts/Schedules/Quantization Schedules/PostTrainingResults/2020.12.08-210847/layer_quant_params.yaml\n","--- test ---------------------\n","10000 samples (256 per mini-batch)\n","Test: [   10/   39]    Loss 0.369841    Top1 92.265625    Top5 99.882812    \n","Test: [   20/   39]    Loss 0.361635    Top1 92.421875    Top5 99.863281    \n","Test: [   30/   39]    Loss 0.342060    Top1 92.890625    Top5 99.843750    \n","Test: [   40/   39]    Loss 0.339106    Top1 92.960000    Top5 99.840000    \n","==> Top1: 92.960    Top5: 99.840    Loss: 0.339\n","\n","Saving checkpoint to: /content/drive/MyDrive/Colab Notebooks/6787 Notebooks/Google Colab Scripts/Schedules/Quantization Schedules/PostTrainingResults/2020.12.08-210847/quantized_checkpoint.pth.tar\n","\n","Log file for this run: /content/drive/.shortcut-targets-by-id/14_4ehU2lLHHu6HAFmEenl_iXGrCYtNmi/Google Colab Scripts/Schedules/Quantization Schedules/PostTrainingResults/2020.12.08-210847/2020.12.08-210847.log\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"3LmG2Vbf3SUS","executionInfo":{"status":"ok","timestamp":1607461766100,"user_tz":300,"elapsed":293445,"user":{"displayName":"Michele L","photoUrl":"","userId":"03726718545613636685"}},"outputId":"10e39b7b-8be6-4f5f-a4a7-43e25ef1ee3f"},"source":["!python3 \"/content/distiller/examples/classifier_compression/compress_classifier.py\" --arch resnet56_cifar -p 10 ./data --resume=\"baseResnet56\" --out-dir \"/content/drive/MyDrive/Colab Notebooks/6787 Notebooks/Google Colab Scripts/Schedules/Quantization Schedules/PostTrainingResults\" --evaluate --quantize-eval --qe-config-file \"/content/drive/MyDrive/Colab Notebooks/6787 Notebooks/Google Colab Scripts/Schedules/Quantization Schedules/PostTrainingSchedules/None/14bitAsymmetricSPost.yaml\" -o \"/content/drive/MyDrive/Colab Notebooks/6787 Notebooks/Google Colab Scripts/Schedules/Quantization Schedules/PostTrainingResults\""],"execution_count":17,"outputs":[{"output_type":"stream","text":["Log file for this run: /content/drive/.shortcut-targets-by-id/14_4ehU2lLHHu6HAFmEenl_iXGrCYtNmi/Google Colab Scripts/Schedules/Quantization Schedules/PostTrainingResults/2020.12.08-210908/2020.12.08-210908.log\n","Random seed: 0\n","\n","--------------------------------------------------------\n","Logging to TensorBoard - remember to execute the server:\n","> tensorboard --logdir='./logs'\n","\n","=> created a resnet56_cifar model with the cifar10 dataset\n","The \"--resume\" flag is deprecated. Please use \"--resume-from=YOUR_PATH\" instead.\n","If you wish to also reset the optimizer, call with: --reset-optimizer\n","=> loading checkpoint baseResnet56\n","=> Checkpoint contents:\n","+----------------------+--------+----------------+\n","| Key                  | Type   | Value          |\n","|----------------------+--------+----------------|\n","| arch                 | str    | resnet56_cifar |\n","| compression_sched    | dict   |                |\n","| dataset              | str    | cifar10        |\n","| epoch                | int    | 127            |\n","| extras               | dict   |                |\n","| is_parallel          | bool   | True           |\n","| optimizer            | type   | SGD            |\n","| optimizer_state_dict | dict   |                |\n","| state_dict           | dict   |                |\n","+----------------------+--------+----------------+\n","\n","=> Checkpoint['extras'] contents:\n","+--------------+--------+---------+\n","| Key          | Type   |   Value |\n","|--------------+--------+---------|\n","| best_epoch   | int    |  127    |\n","| best_top1    | float  |   92.94 |\n","| current_top1 | float  |   92.94 |\n","+--------------+--------+---------+\n","\n","Loaded compression schedule from checkpoint (epoch 127)\n","Optimizer could not be loaded from checkpoint.\n","=> loaded checkpoint 'baseResnet56' (epoch 127)\n","Files already downloaded and verified\n","Dataset sizes:\n","\ttest=10000\n","Reading configuration from: /content/drive/MyDrive/Colab Notebooks/6787 Notebooks/Google Colab Scripts/Schedules/Quantization Schedules/PostTrainingSchedules/None/14bitAsymmetricSPost.yaml\n","Found component of class PostTrainLinearQuantizer: Name: linear_quantizer ; Section: quantizers\n","Loading activation stats from: /content/drive/MyDrive/Colab Notebooks/6787 Notebooks/Google Colab Scripts/Schedules/Quantization Schedules/acts_quantization_stats.yaml\n","Preparing model for quantization using PostTrainLinearQuantizer\n","Applying batch-norm folding ahead of post-training quantization\n","Propagating output statistics from BN modules to folded modules\n","Optimizing output statistics for modules followed by ReLU/Tanh/Sigmoid\n","Updated stats saved to /content/drive/MyDrive/Colab Notebooks/6787 Notebooks/Google Colab Scripts/Schedules/Quantization Schedules/PostTrainingResults/2020.12.08-210908/quant_stats_after_prepare_model.yaml\n","Per-layer quantization parameters saved to /content/drive/MyDrive/Colab Notebooks/6787 Notebooks/Google Colab Scripts/Schedules/Quantization Schedules/PostTrainingResults/2020.12.08-210908/layer_quant_params.yaml\n","--- test ---------------------\n","10000 samples (256 per mini-batch)\n","Test: [   10/   39]    Loss 0.371894    Top1 92.187500    Top5 99.882812    \n","Test: [   20/   39]    Loss 0.363394    Top1 92.382812    Top5 99.843750    \n","Test: [   30/   39]    Loss 0.343048    Top1 92.890625    Top5 99.830729    \n","Test: [   40/   39]    Loss 0.339983    Top1 92.960000    Top5 99.830000    \n","==> Top1: 92.960    Top5: 99.830    Loss: 0.340\n","\n","Saving checkpoint to: /content/drive/MyDrive/Colab Notebooks/6787 Notebooks/Google Colab Scripts/Schedules/Quantization Schedules/PostTrainingResults/2020.12.08-210908/quantized_checkpoint.pth.tar\n","\n","Log file for this run: /content/drive/.shortcut-targets-by-id/14_4ehU2lLHHu6HAFmEenl_iXGrCYtNmi/Google Colab Scripts/Schedules/Quantization Schedules/PostTrainingResults/2020.12.08-210908/2020.12.08-210908.log\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"fgavtpql3SXL","executionInfo":{"status":"ok","timestamp":1607461787513,"user_tz":300,"elapsed":314855,"user":{"displayName":"Michele L","photoUrl":"","userId":"03726718545613636685"}},"outputId":"cbbb8a4b-f248-4daf-ad43-85f289beb500"},"source":["!python3 \"/content/distiller/examples/classifier_compression/compress_classifier.py\" --arch resnet56_cifar -p 10 ./data --resume=\"baseResnet56\" --out-dir \"/content/drive/MyDrive/Colab Notebooks/6787 Notebooks/Google Colab Scripts/Schedules/Quantization Schedules/PostTrainingResults\" --evaluate --quantize-eval --qe-config-file \"/content/drive/MyDrive/Colab Notebooks/6787 Notebooks/Google Colab Scripts/Schedules/Quantization Schedules/PostTrainingSchedules/None/16bitAsymmetricSPost.yaml\" -o \"/content/drive/MyDrive/Colab Notebooks/6787 Notebooks/Google Colab Scripts/Schedules/Quantization Schedules/PostTrainingResults\""],"execution_count":18,"outputs":[{"output_type":"stream","text":["Log file for this run: /content/drive/.shortcut-targets-by-id/14_4ehU2lLHHu6HAFmEenl_iXGrCYtNmi/Google Colab Scripts/Schedules/Quantization Schedules/PostTrainingResults/2020.12.08-210929/2020.12.08-210929.log\n","Random seed: 0\n","\n","--------------------------------------------------------\n","Logging to TensorBoard - remember to execute the server:\n","> tensorboard --logdir='./logs'\n","\n","=> created a resnet56_cifar model with the cifar10 dataset\n","The \"--resume\" flag is deprecated. Please use \"--resume-from=YOUR_PATH\" instead.\n","If you wish to also reset the optimizer, call with: --reset-optimizer\n","=> loading checkpoint baseResnet56\n","=> Checkpoint contents:\n","+----------------------+--------+----------------+\n","| Key                  | Type   | Value          |\n","|----------------------+--------+----------------|\n","| arch                 | str    | resnet56_cifar |\n","| compression_sched    | dict   |                |\n","| dataset              | str    | cifar10        |\n","| epoch                | int    | 127            |\n","| extras               | dict   |                |\n","| is_parallel          | bool   | True           |\n","| optimizer            | type   | SGD            |\n","| optimizer_state_dict | dict   |                |\n","| state_dict           | dict   |                |\n","+----------------------+--------+----------------+\n","\n","=> Checkpoint['extras'] contents:\n","+--------------+--------+---------+\n","| Key          | Type   |   Value |\n","|--------------+--------+---------|\n","| best_epoch   | int    |  127    |\n","| best_top1    | float  |   92.94 |\n","| current_top1 | float  |   92.94 |\n","+--------------+--------+---------+\n","\n","Loaded compression schedule from checkpoint (epoch 127)\n","Optimizer could not be loaded from checkpoint.\n","=> loaded checkpoint 'baseResnet56' (epoch 127)\n","Files already downloaded and verified\n","Dataset sizes:\n","\ttest=10000\n","Reading configuration from: /content/drive/MyDrive/Colab Notebooks/6787 Notebooks/Google Colab Scripts/Schedules/Quantization Schedules/PostTrainingSchedules/None/16bitAsymmetricSPost.yaml\n","Found component of class PostTrainLinearQuantizer: Name: linear_quantizer ; Section: quantizers\n","Loading activation stats from: /content/drive/MyDrive/Colab Notebooks/6787 Notebooks/Google Colab Scripts/Schedules/Quantization Schedules/acts_quantization_stats.yaml\n","Preparing model for quantization using PostTrainLinearQuantizer\n","Applying batch-norm folding ahead of post-training quantization\n","Propagating output statistics from BN modules to folded modules\n","Optimizing output statistics for modules followed by ReLU/Tanh/Sigmoid\n","Updated stats saved to /content/drive/MyDrive/Colab Notebooks/6787 Notebooks/Google Colab Scripts/Schedules/Quantization Schedules/PostTrainingResults/2020.12.08-210929/quant_stats_after_prepare_model.yaml\n","Per-layer quantization parameters saved to /content/drive/MyDrive/Colab Notebooks/6787 Notebooks/Google Colab Scripts/Schedules/Quantization Schedules/PostTrainingResults/2020.12.08-210929/layer_quant_params.yaml\n","--- test ---------------------\n","10000 samples (256 per mini-batch)\n","Test: [   10/   39]    Loss 0.599930    Top1 84.609375    Top5 99.296875    \n","Test: [   20/   39]    Loss 0.591735    Top1 85.078125    Top5 99.257812    \n","Test: [   30/   39]    Loss 0.555593    Top1 85.781250    Top5 99.283854    \n","Test: [   40/   39]    Loss 0.544678    Top1 85.900000    Top5 99.290000    \n","==> Top1: 85.900    Top5: 99.290    Loss: 0.545\n","\n","Saving checkpoint to: /content/drive/MyDrive/Colab Notebooks/6787 Notebooks/Google Colab Scripts/Schedules/Quantization Schedules/PostTrainingResults/2020.12.08-210929/quantized_checkpoint.pth.tar\n","\n","Log file for this run: /content/drive/.shortcut-targets-by-id/14_4ehU2lLHHu6HAFmEenl_iXGrCYtNmi/Google Colab Scripts/Schedules/Quantization Schedules/PostTrainingResults/2020.12.08-210929/2020.12.08-210929.log\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"nqOGl_1M1S1t"},"source":["Symetric"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ViSIBA_P3aCC","executionInfo":{"status":"ok","timestamp":1607461808716,"user_tz":300,"elapsed":336056,"user":{"displayName":"Michele L","photoUrl":"","userId":"03726718545613636685"}},"outputId":"5a2fc0cb-3a9a-4267-b66f-bb611f5fce0a"},"source":["!python3 \"/content/distiller/examples/classifier_compression/compress_classifier.py\" --arch resnet56_cifar -p 10 ./data --resume=\"baseResnet56\" --out-dir \"/content/drive/MyDrive/Colab Notebooks/6787 Notebooks/Google Colab Scripts/Schedules/Quantization Schedules/PostTrainingResults\" --evaluate --quantize-eval --qe-config-file \"/content/drive/MyDrive/Colab Notebooks/6787 Notebooks/Google Colab Scripts/Schedules/Quantization Schedules/PostTrainingSchedules/None/4bitSymmetricPost.yaml\" -o \"/content/drive/MyDrive/Colab Notebooks/6787 Notebooks/Google Colab Scripts/Schedules/Quantization Schedules/PostTrainingResults\""],"execution_count":19,"outputs":[{"output_type":"stream","text":["Log file for this run: /content/drive/.shortcut-targets-by-id/14_4ehU2lLHHu6HAFmEenl_iXGrCYtNmi/Google Colab Scripts/Schedules/Quantization Schedules/PostTrainingResults/2020.12.08-210950/2020.12.08-210950.log\n","Random seed: 0\n","\n","--------------------------------------------------------\n","Logging to TensorBoard - remember to execute the server:\n","> tensorboard --logdir='./logs'\n","\n","=> created a resnet56_cifar model with the cifar10 dataset\n","The \"--resume\" flag is deprecated. Please use \"--resume-from=YOUR_PATH\" instead.\n","If you wish to also reset the optimizer, call with: --reset-optimizer\n","=> loading checkpoint baseResnet56\n","=> Checkpoint contents:\n","+----------------------+--------+----------------+\n","| Key                  | Type   | Value          |\n","|----------------------+--------+----------------|\n","| arch                 | str    | resnet56_cifar |\n","| compression_sched    | dict   |                |\n","| dataset              | str    | cifar10        |\n","| epoch                | int    | 127            |\n","| extras               | dict   |                |\n","| is_parallel          | bool   | True           |\n","| optimizer            | type   | SGD            |\n","| optimizer_state_dict | dict   |                |\n","| state_dict           | dict   |                |\n","+----------------------+--------+----------------+\n","\n","=> Checkpoint['extras'] contents:\n","+--------------+--------+---------+\n","| Key          | Type   |   Value |\n","|--------------+--------+---------|\n","| best_epoch   | int    |  127    |\n","| best_top1    | float  |   92.94 |\n","| current_top1 | float  |   92.94 |\n","+--------------+--------+---------+\n","\n","Loaded compression schedule from checkpoint (epoch 127)\n","Optimizer could not be loaded from checkpoint.\n","=> loaded checkpoint 'baseResnet56' (epoch 127)\n","Files already downloaded and verified\n","Dataset sizes:\n","\ttest=10000\n","Reading configuration from: /content/drive/MyDrive/Colab Notebooks/6787 Notebooks/Google Colab Scripts/Schedules/Quantization Schedules/PostTrainingSchedules/None/4bitSymmetricPost.yaml\n","Found component of class PostTrainLinearQuantizer: Name: linear_quantizer ; Section: quantizers\n","Loading activation stats from: /content/drive/MyDrive/Colab Notebooks/6787 Notebooks/Google Colab Scripts/Schedules/Quantization Schedules/acts_quantization_stats.yaml\n","Preparing model for quantization using PostTrainLinearQuantizer\n","Applying batch-norm folding ahead of post-training quantization\n","Propagating output statistics from BN modules to folded modules\n","Optimizing output statistics for modules followed by ReLU/Tanh/Sigmoid\n","Updated stats saved to /content/drive/MyDrive/Colab Notebooks/6787 Notebooks/Google Colab Scripts/Schedules/Quantization Schedules/PostTrainingResults/2020.12.08-210950/quant_stats_after_prepare_model.yaml\n","Per-layer quantization parameters saved to /content/drive/MyDrive/Colab Notebooks/6787 Notebooks/Google Colab Scripts/Schedules/Quantization Schedules/PostTrainingResults/2020.12.08-210950/layer_quant_params.yaml\n","--- test ---------------------\n","10000 samples (256 per mini-batch)\n","Test: [   10/   39]    Loss 14.905928    Top1 23.164063    Top5 72.656250    \n","Test: [   20/   39]    Loss 14.565973    Top1 24.121094    Top5 73.828125    \n","Test: [   30/   39]    Loss 14.536104    Top1 24.309896    Top5 73.684896    \n","Test: [   40/   39]    Loss 14.523672    Top1 24.370000    Top5 73.830000    \n","==> Top1: 24.370    Top5: 73.830    Loss: 14.524\n","\n","Saving checkpoint to: /content/drive/MyDrive/Colab Notebooks/6787 Notebooks/Google Colab Scripts/Schedules/Quantization Schedules/PostTrainingResults/2020.12.08-210950/quantized_checkpoint.pth.tar\n","\n","Log file for this run: /content/drive/.shortcut-targets-by-id/14_4ehU2lLHHu6HAFmEenl_iXGrCYtNmi/Google Colab Scripts/Schedules/Quantization Schedules/PostTrainingResults/2020.12.08-210950/2020.12.08-210950.log\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"FfHFPf8X3aEz","executionInfo":{"status":"ok","timestamp":1607461829856,"user_tz":300,"elapsed":357193,"user":{"displayName":"Michele L","photoUrl":"","userId":"03726718545613636685"}},"outputId":"372f75e2-c83a-4ced-e616-14417ffb038e"},"source":["!python3 \"/content/distiller/examples/classifier_compression/compress_classifier.py\" --arch resnet56_cifar -p 10 ./data --resume=\"baseResnet56\" --out-dir \"/content/drive/MyDrive/Colab Notebooks/6787 Notebooks/Google Colab Scripts/Schedules/Quantization Schedules/PostTrainingResults\" --evaluate --quantize-eval --qe-config-file \"/content/drive/MyDrive/Colab Notebooks/6787 Notebooks/Google Colab Scripts/Schedules/Quantization Schedules/PostTrainingSchedules/None/6bitSymmetricPost.yaml\" -o \"/content/drive/MyDrive/Colab Notebooks/6787 Notebooks/Google Colab Scripts/Schedules/Quantization Schedules/PostTrainingResults\""],"execution_count":20,"outputs":[{"output_type":"stream","text":["Log file for this run: /content/drive/.shortcut-targets-by-id/14_4ehU2lLHHu6HAFmEenl_iXGrCYtNmi/Google Colab Scripts/Schedules/Quantization Schedules/PostTrainingResults/2020.12.08-211012/2020.12.08-211012.log\n","Random seed: 0\n","\n","--------------------------------------------------------\n","Logging to TensorBoard - remember to execute the server:\n","> tensorboard --logdir='./logs'\n","\n","=> created a resnet56_cifar model with the cifar10 dataset\n","The \"--resume\" flag is deprecated. Please use \"--resume-from=YOUR_PATH\" instead.\n","If you wish to also reset the optimizer, call with: --reset-optimizer\n","=> loading checkpoint baseResnet56\n","=> Checkpoint contents:\n","+----------------------+--------+----------------+\n","| Key                  | Type   | Value          |\n","|----------------------+--------+----------------|\n","| arch                 | str    | resnet56_cifar |\n","| compression_sched    | dict   |                |\n","| dataset              | str    | cifar10        |\n","| epoch                | int    | 127            |\n","| extras               | dict   |                |\n","| is_parallel          | bool   | True           |\n","| optimizer            | type   | SGD            |\n","| optimizer_state_dict | dict   |                |\n","| state_dict           | dict   |                |\n","+----------------------+--------+----------------+\n","\n","=> Checkpoint['extras'] contents:\n","+--------------+--------+---------+\n","| Key          | Type   |   Value |\n","|--------------+--------+---------|\n","| best_epoch   | int    |  127    |\n","| best_top1    | float  |   92.94 |\n","| current_top1 | float  |   92.94 |\n","+--------------+--------+---------+\n","\n","Loaded compression schedule from checkpoint (epoch 127)\n","Optimizer could not be loaded from checkpoint.\n","=> loaded checkpoint 'baseResnet56' (epoch 127)\n","Files already downloaded and verified\n","Dataset sizes:\n","\ttest=10000\n","Reading configuration from: /content/drive/MyDrive/Colab Notebooks/6787 Notebooks/Google Colab Scripts/Schedules/Quantization Schedules/PostTrainingSchedules/None/6bitSymmetricPost.yaml\n","Found component of class PostTrainLinearQuantizer: Name: linear_quantizer ; Section: quantizers\n","Loading activation stats from: /content/drive/MyDrive/Colab Notebooks/6787 Notebooks/Google Colab Scripts/Schedules/Quantization Schedules/acts_quantization_stats.yaml\n","Preparing model for quantization using PostTrainLinearQuantizer\n","Applying batch-norm folding ahead of post-training quantization\n","Propagating output statistics from BN modules to folded modules\n","Optimizing output statistics for modules followed by ReLU/Tanh/Sigmoid\n","Updated stats saved to /content/drive/MyDrive/Colab Notebooks/6787 Notebooks/Google Colab Scripts/Schedules/Quantization Schedules/PostTrainingResults/2020.12.08-211012/quant_stats_after_prepare_model.yaml\n","Per-layer quantization parameters saved to /content/drive/MyDrive/Colab Notebooks/6787 Notebooks/Google Colab Scripts/Schedules/Quantization Schedules/PostTrainingResults/2020.12.08-211012/layer_quant_params.yaml\n","--- test ---------------------\n","10000 samples (256 per mini-batch)\n","Test: [   10/   39]    Loss 1.383684    Top1 75.898438    Top5 98.593750    \n","Test: [   20/   39]    Loss 1.355852    Top1 76.601562    Top5 98.652344    \n","Test: [   30/   39]    Loss 1.317972    Top1 77.369792    Top5 98.645833    \n","Test: [   40/   39]    Loss 1.343831    Top1 77.410000    Top5 98.650000    \n","==> Top1: 77.410    Top5: 98.650    Loss: 1.344\n","\n","Saving checkpoint to: /content/drive/MyDrive/Colab Notebooks/6787 Notebooks/Google Colab Scripts/Schedules/Quantization Schedules/PostTrainingResults/2020.12.08-211012/quantized_checkpoint.pth.tar\n","\n","Log file for this run: /content/drive/.shortcut-targets-by-id/14_4ehU2lLHHu6HAFmEenl_iXGrCYtNmi/Google Colab Scripts/Schedules/Quantization Schedules/PostTrainingResults/2020.12.08-211012/2020.12.08-211012.log\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"6lTRZRje3aHW","executionInfo":{"status":"ok","timestamp":1607461851060,"user_tz":300,"elapsed":378394,"user":{"displayName":"Michele L","photoUrl":"","userId":"03726718545613636685"}},"outputId":"74f0b166-82d4-40b0-d8a6-e375e1322a91"},"source":["!python3 \"/content/distiller/examples/classifier_compression/compress_classifier.py\" --arch resnet56_cifar -p 10 ./data --resume=\"baseResnet56\" --out-dir \"/content/drive/MyDrive/Colab Notebooks/6787 Notebooks/Google Colab Scripts/Schedules/Quantization Schedules/PostTrainingResults\" --evaluate --quantize-eval --qe-config-file \"/content/drive/MyDrive/Colab Notebooks/6787 Notebooks/Google Colab Scripts/Schedules/Quantization Schedules/PostTrainingSchedules/None/8bitSymmetricPost.yaml\" -o \"/content/drive/MyDrive/Colab Notebooks/6787 Notebooks/Google Colab Scripts/Schedules/Quantization Schedules/PostTrainingResults\""],"execution_count":21,"outputs":[{"output_type":"stream","text":["Log file for this run: /content/drive/.shortcut-targets-by-id/14_4ehU2lLHHu6HAFmEenl_iXGrCYtNmi/Google Colab Scripts/Schedules/Quantization Schedules/PostTrainingResults/2020.12.08-211033/2020.12.08-211033.log\n","Random seed: 0\n","\n","--------------------------------------------------------\n","Logging to TensorBoard - remember to execute the server:\n","> tensorboard --logdir='./logs'\n","\n","=> created a resnet56_cifar model with the cifar10 dataset\n","The \"--resume\" flag is deprecated. Please use \"--resume-from=YOUR_PATH\" instead.\n","If you wish to also reset the optimizer, call with: --reset-optimizer\n","=> loading checkpoint baseResnet56\n","=> Checkpoint contents:\n","+----------------------+--------+----------------+\n","| Key                  | Type   | Value          |\n","|----------------------+--------+----------------|\n","| arch                 | str    | resnet56_cifar |\n","| compression_sched    | dict   |                |\n","| dataset              | str    | cifar10        |\n","| epoch                | int    | 127            |\n","| extras               | dict   |                |\n","| is_parallel          | bool   | True           |\n","| optimizer            | type   | SGD            |\n","| optimizer_state_dict | dict   |                |\n","| state_dict           | dict   |                |\n","+----------------------+--------+----------------+\n","\n","=> Checkpoint['extras'] contents:\n","+--------------+--------+---------+\n","| Key          | Type   |   Value |\n","|--------------+--------+---------|\n","| best_epoch   | int    |  127    |\n","| best_top1    | float  |   92.94 |\n","| current_top1 | float  |   92.94 |\n","+--------------+--------+---------+\n","\n","Loaded compression schedule from checkpoint (epoch 127)\n","Optimizer could not be loaded from checkpoint.\n","=> loaded checkpoint 'baseResnet56' (epoch 127)\n","Files already downloaded and verified\n","Dataset sizes:\n","\ttest=10000\n","Reading configuration from: /content/drive/MyDrive/Colab Notebooks/6787 Notebooks/Google Colab Scripts/Schedules/Quantization Schedules/PostTrainingSchedules/None/8bitSymmetricPost.yaml\n","Found component of class PostTrainLinearQuantizer: Name: linear_quantizer ; Section: quantizers\n","Loading activation stats from: /content/drive/MyDrive/Colab Notebooks/6787 Notebooks/Google Colab Scripts/Schedules/Quantization Schedules/acts_quantization_stats.yaml\n","Preparing model for quantization using PostTrainLinearQuantizer\n","Applying batch-norm folding ahead of post-training quantization\n","Propagating output statistics from BN modules to folded modules\n","Optimizing output statistics for modules followed by ReLU/Tanh/Sigmoid\n","Updated stats saved to /content/drive/MyDrive/Colab Notebooks/6787 Notebooks/Google Colab Scripts/Schedules/Quantization Schedules/PostTrainingResults/2020.12.08-211033/quant_stats_after_prepare_model.yaml\n","Per-layer quantization parameters saved to /content/drive/MyDrive/Colab Notebooks/6787 Notebooks/Google Colab Scripts/Schedules/Quantization Schedules/PostTrainingResults/2020.12.08-211033/layer_quant_params.yaml\n","--- test ---------------------\n","10000 samples (256 per mini-batch)\n","Test: [   10/   39]    Loss 0.405259    Top1 91.992188    Top5 99.843750    \n","Test: [   20/   39]    Loss 0.386963    Top1 91.914062    Top5 99.804688    \n","Test: [   30/   39]    Loss 0.365428    Top1 92.460938    Top5 99.752604    \n","Test: [   40/   39]    Loss 0.364434    Top1 92.470000    Top5 99.730000    \n","==> Top1: 92.470    Top5: 99.730    Loss: 0.364\n","\n","Saving checkpoint to: /content/drive/MyDrive/Colab Notebooks/6787 Notebooks/Google Colab Scripts/Schedules/Quantization Schedules/PostTrainingResults/2020.12.08-211033/quantized_checkpoint.pth.tar\n","\n","Log file for this run: /content/drive/.shortcut-targets-by-id/14_4ehU2lLHHu6HAFmEenl_iXGrCYtNmi/Google Colab Scripts/Schedules/Quantization Schedules/PostTrainingResults/2020.12.08-211033/2020.12.08-211033.log\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"flS0WJAD3aMj","executionInfo":{"status":"ok","timestamp":1607461872367,"user_tz":300,"elapsed":399699,"user":{"displayName":"Michele L","photoUrl":"","userId":"03726718545613636685"}},"outputId":"735ed3fd-ca21-4e45-cd7d-76aa1f6076d6"},"source":["!python3 \"/content/distiller/examples/classifier_compression/compress_classifier.py\" --arch resnet56_cifar -p 10 ./data --resume=\"baseResnet56\" --out-dir \"/content/drive/MyDrive/Colab Notebooks/6787 Notebooks/Google Colab Scripts/Schedules/Quantization Schedules/PostTrainingResults\" --evaluate --quantize-eval --qe-config-file \"/content/drive/MyDrive/Colab Notebooks/6787 Notebooks/Google Colab Scripts/Schedules/Quantization Schedules/PostTrainingSchedules/None/10bitSymmetricPost.yaml\" -o \"/content/drive/MyDrive/Colab Notebooks/6787 Notebooks/Google Colab Scripts/Schedules/Quantization Schedules/PostTrainingResults\""],"execution_count":22,"outputs":[{"output_type":"stream","text":["Log file for this run: /content/drive/.shortcut-targets-by-id/14_4ehU2lLHHu6HAFmEenl_iXGrCYtNmi/Google Colab Scripts/Schedules/Quantization Schedules/PostTrainingResults/2020.12.08-211054/2020.12.08-211054.log\n","Random seed: 0\n","\n","--------------------------------------------------------\n","Logging to TensorBoard - remember to execute the server:\n","> tensorboard --logdir='./logs'\n","\n","=> created a resnet56_cifar model with the cifar10 dataset\n","The \"--resume\" flag is deprecated. Please use \"--resume-from=YOUR_PATH\" instead.\n","If you wish to also reset the optimizer, call with: --reset-optimizer\n","=> loading checkpoint baseResnet56\n","=> Checkpoint contents:\n","+----------------------+--------+----------------+\n","| Key                  | Type   | Value          |\n","|----------------------+--------+----------------|\n","| arch                 | str    | resnet56_cifar |\n","| compression_sched    | dict   |                |\n","| dataset              | str    | cifar10        |\n","| epoch                | int    | 127            |\n","| extras               | dict   |                |\n","| is_parallel          | bool   | True           |\n","| optimizer            | type   | SGD            |\n","| optimizer_state_dict | dict   |                |\n","| state_dict           | dict   |                |\n","+----------------------+--------+----------------+\n","\n","=> Checkpoint['extras'] contents:\n","+--------------+--------+---------+\n","| Key          | Type   |   Value |\n","|--------------+--------+---------|\n","| best_epoch   | int    |  127    |\n","| best_top1    | float  |   92.94 |\n","| current_top1 | float  |   92.94 |\n","+--------------+--------+---------+\n","\n","Loaded compression schedule from checkpoint (epoch 127)\n","Optimizer could not be loaded from checkpoint.\n","=> loaded checkpoint 'baseResnet56' (epoch 127)\n","Files already downloaded and verified\n","Dataset sizes:\n","\ttest=10000\n","Reading configuration from: /content/drive/MyDrive/Colab Notebooks/6787 Notebooks/Google Colab Scripts/Schedules/Quantization Schedules/PostTrainingSchedules/None/10bitSymmetricPost.yaml\n","Found component of class PostTrainLinearQuantizer: Name: linear_quantizer ; Section: quantizers\n","Loading activation stats from: /content/drive/MyDrive/Colab Notebooks/6787 Notebooks/Google Colab Scripts/Schedules/Quantization Schedules/acts_quantization_stats.yaml\n","Preparing model for quantization using PostTrainLinearQuantizer\n","Applying batch-norm folding ahead of post-training quantization\n","Propagating output statistics from BN modules to folded modules\n","Optimizing output statistics for modules followed by ReLU/Tanh/Sigmoid\n","Updated stats saved to /content/drive/MyDrive/Colab Notebooks/6787 Notebooks/Google Colab Scripts/Schedules/Quantization Schedules/PostTrainingResults/2020.12.08-211054/quant_stats_after_prepare_model.yaml\n","Per-layer quantization parameters saved to /content/drive/MyDrive/Colab Notebooks/6787 Notebooks/Google Colab Scripts/Schedules/Quantization Schedules/PostTrainingResults/2020.12.08-211054/layer_quant_params.yaml\n","--- test ---------------------\n","10000 samples (256 per mini-batch)\n","Test: [   10/   39]    Loss 0.370146    Top1 91.914062    Top5 99.882812    \n","Test: [   20/   39]    Loss 0.362761    Top1 92.246094    Top5 99.843750    \n","Test: [   30/   39]    Loss 0.343093    Top1 92.773438    Top5 99.830729    \n","Test: [   40/   39]    Loss 0.339368    Top1 92.880000    Top5 99.830000    \n","==> Top1: 92.880    Top5: 99.830    Loss: 0.339\n","\n","Saving checkpoint to: /content/drive/MyDrive/Colab Notebooks/6787 Notebooks/Google Colab Scripts/Schedules/Quantization Schedules/PostTrainingResults/2020.12.08-211054/quantized_checkpoint.pth.tar\n","\n","Log file for this run: /content/drive/.shortcut-targets-by-id/14_4ehU2lLHHu6HAFmEenl_iXGrCYtNmi/Google Colab Scripts/Schedules/Quantization Schedules/PostTrainingResults/2020.12.08-211054/2020.12.08-211054.log\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"m5winHdH3aO_","executionInfo":{"status":"ok","timestamp":1607461893629,"user_tz":300,"elapsed":420958,"user":{"displayName":"Michele L","photoUrl":"","userId":"03726718545613636685"}},"outputId":"329bae26-b29d-4c25-efde-f774360f4391"},"source":["!python3 \"/content/distiller/examples/classifier_compression/compress_classifier.py\" --arch resnet56_cifar -p 10 ./data --resume=\"baseResnet56\" --out-dir \"/content/drive/MyDrive/Colab Notebooks/6787 Notebooks/Google Colab Scripts/Schedules/Quantization Schedules/PostTrainingResults\" --evaluate --quantize-eval --qe-config-file \"/content/drive/MyDrive/Colab Notebooks/6787 Notebooks/Google Colab Scripts/Schedules/Quantization Schedules/PostTrainingSchedules/None/12bitSymmetricPost.yaml\" -o \"/content/drive/MyDrive/Colab Notebooks/6787 Notebooks/Google Colab Scripts/Schedules/Quantization Schedules/PostTrainingResults\""],"execution_count":23,"outputs":[{"output_type":"stream","text":["Log file for this run: /content/drive/.shortcut-targets-by-id/14_4ehU2lLHHu6HAFmEenl_iXGrCYtNmi/Google Colab Scripts/Schedules/Quantization Schedules/PostTrainingResults/2020.12.08-211115/2020.12.08-211115.log\n","Random seed: 0\n","\n","--------------------------------------------------------\n","Logging to TensorBoard - remember to execute the server:\n","> tensorboard --logdir='./logs'\n","\n","=> created a resnet56_cifar model with the cifar10 dataset\n","The \"--resume\" flag is deprecated. Please use \"--resume-from=YOUR_PATH\" instead.\n","If you wish to also reset the optimizer, call with: --reset-optimizer\n","=> loading checkpoint baseResnet56\n","=> Checkpoint contents:\n","+----------------------+--------+----------------+\n","| Key                  | Type   | Value          |\n","|----------------------+--------+----------------|\n","| arch                 | str    | resnet56_cifar |\n","| compression_sched    | dict   |                |\n","| dataset              | str    | cifar10        |\n","| epoch                | int    | 127            |\n","| extras               | dict   |                |\n","| is_parallel          | bool   | True           |\n","| optimizer            | type   | SGD            |\n","| optimizer_state_dict | dict   |                |\n","| state_dict           | dict   |                |\n","+----------------------+--------+----------------+\n","\n","=> Checkpoint['extras'] contents:\n","+--------------+--------+---------+\n","| Key          | Type   |   Value |\n","|--------------+--------+---------|\n","| best_epoch   | int    |  127    |\n","| best_top1    | float  |   92.94 |\n","| current_top1 | float  |   92.94 |\n","+--------------+--------+---------+\n","\n","Loaded compression schedule from checkpoint (epoch 127)\n","Optimizer could not be loaded from checkpoint.\n","=> loaded checkpoint 'baseResnet56' (epoch 127)\n","Files already downloaded and verified\n","Dataset sizes:\n","\ttest=10000\n","Reading configuration from: /content/drive/MyDrive/Colab Notebooks/6787 Notebooks/Google Colab Scripts/Schedules/Quantization Schedules/PostTrainingSchedules/None/12bitSymmetricPost.yaml\n","Found component of class PostTrainLinearQuantizer: Name: linear_quantizer ; Section: quantizers\n","Loading activation stats from: /content/drive/MyDrive/Colab Notebooks/6787 Notebooks/Google Colab Scripts/Schedules/Quantization Schedules/acts_quantization_stats.yaml\n","Preparing model for quantization using PostTrainLinearQuantizer\n","Applying batch-norm folding ahead of post-training quantization\n","Propagating output statistics from BN modules to folded modules\n","Optimizing output statistics for modules followed by ReLU/Tanh/Sigmoid\n","Updated stats saved to /content/drive/MyDrive/Colab Notebooks/6787 Notebooks/Google Colab Scripts/Schedules/Quantization Schedules/PostTrainingResults/2020.12.08-211115/quant_stats_after_prepare_model.yaml\n","Per-layer quantization parameters saved to /content/drive/MyDrive/Colab Notebooks/6787 Notebooks/Google Colab Scripts/Schedules/Quantization Schedules/PostTrainingResults/2020.12.08-211115/layer_quant_params.yaml\n","--- test ---------------------\n","10000 samples (256 per mini-batch)\n","Test: [   10/   39]    Loss 0.368570    Top1 92.226562    Top5 99.882812    \n","Test: [   20/   39]    Loss 0.360982    Top1 92.441406    Top5 99.863281    \n","Test: [   30/   39]    Loss 0.341476    Top1 92.903646    Top5 99.843750    \n","Test: [   40/   39]    Loss 0.338789    Top1 92.970000    Top5 99.840000    \n","==> Top1: 92.970    Top5: 99.840    Loss: 0.339\n","\n","Saving checkpoint to: /content/drive/MyDrive/Colab Notebooks/6787 Notebooks/Google Colab Scripts/Schedules/Quantization Schedules/PostTrainingResults/2020.12.08-211115/quantized_checkpoint.pth.tar\n","\n","Log file for this run: /content/drive/.shortcut-targets-by-id/14_4ehU2lLHHu6HAFmEenl_iXGrCYtNmi/Google Colab Scripts/Schedules/Quantization Schedules/PostTrainingResults/2020.12.08-211115/2020.12.08-211115.log\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"OTBrmnSD3aRz","executionInfo":{"status":"ok","timestamp":1607461914778,"user_tz":300,"elapsed":442104,"user":{"displayName":"Michele L","photoUrl":"","userId":"03726718545613636685"}},"outputId":"006d86c1-36f8-421e-9c12-4c58f6c971e2"},"source":["!python3 \"/content/distiller/examples/classifier_compression/compress_classifier.py\" --arch resnet56_cifar -p 10 ./data --resume=\"baseResnet56\" --out-dir \"/content/drive/MyDrive/Colab Notebooks/6787 Notebooks/Google Colab Scripts/Schedules/Quantization Schedules/PostTrainingResults\" --evaluate --quantize-eval --qe-config-file \"/content/drive/MyDrive/Colab Notebooks/6787 Notebooks/Google Colab Scripts/Schedules/Quantization Schedules/PostTrainingSchedules/None/14bitSymmetricPost.yaml\" -o \"/content/drive/MyDrive/Colab Notebooks/6787 Notebooks/Google Colab Scripts/Schedules/Quantization Schedules/PostTrainingResults\""],"execution_count":24,"outputs":[{"output_type":"stream","text":["Log file for this run: /content/drive/.shortcut-targets-by-id/14_4ehU2lLHHu6HAFmEenl_iXGrCYtNmi/Google Colab Scripts/Schedules/Quantization Schedules/PostTrainingResults/2020.12.08-211137/2020.12.08-211137.log\n","Random seed: 0\n","\n","--------------------------------------------------------\n","Logging to TensorBoard - remember to execute the server:\n","> tensorboard --logdir='./logs'\n","\n","=> created a resnet56_cifar model with the cifar10 dataset\n","The \"--resume\" flag is deprecated. Please use \"--resume-from=YOUR_PATH\" instead.\n","If you wish to also reset the optimizer, call with: --reset-optimizer\n","=> loading checkpoint baseResnet56\n","=> Checkpoint contents:\n","+----------------------+--------+----------------+\n","| Key                  | Type   | Value          |\n","|----------------------+--------+----------------|\n","| arch                 | str    | resnet56_cifar |\n","| compression_sched    | dict   |                |\n","| dataset              | str    | cifar10        |\n","| epoch                | int    | 127            |\n","| extras               | dict   |                |\n","| is_parallel          | bool   | True           |\n","| optimizer            | type   | SGD            |\n","| optimizer_state_dict | dict   |                |\n","| state_dict           | dict   |                |\n","+----------------------+--------+----------------+\n","\n","=> Checkpoint['extras'] contents:\n","+--------------+--------+---------+\n","| Key          | Type   |   Value |\n","|--------------+--------+---------|\n","| best_epoch   | int    |  127    |\n","| best_top1    | float  |   92.94 |\n","| current_top1 | float  |   92.94 |\n","+--------------+--------+---------+\n","\n","Loaded compression schedule from checkpoint (epoch 127)\n","Optimizer could not be loaded from checkpoint.\n","=> loaded checkpoint 'baseResnet56' (epoch 127)\n","Files already downloaded and verified\n","Dataset sizes:\n","\ttest=10000\n","Reading configuration from: /content/drive/MyDrive/Colab Notebooks/6787 Notebooks/Google Colab Scripts/Schedules/Quantization Schedules/PostTrainingSchedules/None/14bitSymmetricPost.yaml\n","Found component of class PostTrainLinearQuantizer: Name: linear_quantizer ; Section: quantizers\n","Loading activation stats from: /content/drive/MyDrive/Colab Notebooks/6787 Notebooks/Google Colab Scripts/Schedules/Quantization Schedules/acts_quantization_stats.yaml\n","Preparing model for quantization using PostTrainLinearQuantizer\n","Applying batch-norm folding ahead of post-training quantization\n","Propagating output statistics from BN modules to folded modules\n","Optimizing output statistics for modules followed by ReLU/Tanh/Sigmoid\n","Updated stats saved to /content/drive/MyDrive/Colab Notebooks/6787 Notebooks/Google Colab Scripts/Schedules/Quantization Schedules/PostTrainingResults/2020.12.08-211137/quant_stats_after_prepare_model.yaml\n","Per-layer quantization parameters saved to /content/drive/MyDrive/Colab Notebooks/6787 Notebooks/Google Colab Scripts/Schedules/Quantization Schedules/PostTrainingResults/2020.12.08-211137/layer_quant_params.yaml\n","--- test ---------------------\n","10000 samples (256 per mini-batch)\n","Test: [   10/   39]    Loss 0.371328    Top1 92.226562    Top5 99.882812    \n","Test: [   20/   39]    Loss 0.363057    Top1 92.402344    Top5 99.843750    \n","Test: [   30/   39]    Loss 0.342819    Top1 92.903646    Top5 99.830729    \n","Test: [   40/   39]    Loss 0.339822    Top1 92.990000    Top5 99.830000    \n","==> Top1: 92.990    Top5: 99.830    Loss: 0.340\n","\n","Saving checkpoint to: /content/drive/MyDrive/Colab Notebooks/6787 Notebooks/Google Colab Scripts/Schedules/Quantization Schedules/PostTrainingResults/2020.12.08-211137/quantized_checkpoint.pth.tar\n","\n","Log file for this run: /content/drive/.shortcut-targets-by-id/14_4ehU2lLHHu6HAFmEenl_iXGrCYtNmi/Google Colab Scripts/Schedules/Quantization Schedules/PostTrainingResults/2020.12.08-211137/2020.12.08-211137.log\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Y9UKi4Ju3aUD","executionInfo":{"status":"ok","timestamp":1607461936014,"user_tz":300,"elapsed":463336,"user":{"displayName":"Michele L","photoUrl":"","userId":"03726718545613636685"}},"outputId":"f5346f37-9d22-435b-ce13-1ae56994eaa7"},"source":["!python3 \"/content/distiller/examples/classifier_compression/compress_classifier.py\" --arch resnet56_cifar -p 10 ./data --resume=\"baseResnet56\" --out-dir \"/content/drive/MyDrive/Colab Notebooks/6787 Notebooks/Google Colab Scripts/Schedules/Quantization Schedules/PostTrainingResults\" --evaluate --quantize-eval --qe-config-file \"/content/drive/MyDrive/Colab Notebooks/6787 Notebooks/Google Colab Scripts/Schedules/Quantization Schedules/PostTrainingSchedules/None/16bitSymmetricPost.yaml\" -o \"/content/drive/MyDrive/Colab Notebooks/6787 Notebooks/Google Colab Scripts/Schedules/Quantization Schedules/PostTrainingResults\""],"execution_count":25,"outputs":[{"output_type":"stream","text":["Log file for this run: /content/drive/.shortcut-targets-by-id/14_4ehU2lLHHu6HAFmEenl_iXGrCYtNmi/Google Colab Scripts/Schedules/Quantization Schedules/PostTrainingResults/2020.12.08-211158/2020.12.08-211158.log\n","Random seed: 0\n","\n","--------------------------------------------------------\n","Logging to TensorBoard - remember to execute the server:\n","> tensorboard --logdir='./logs'\n","\n","=> created a resnet56_cifar model with the cifar10 dataset\n","The \"--resume\" flag is deprecated. Please use \"--resume-from=YOUR_PATH\" instead.\n","If you wish to also reset the optimizer, call with: --reset-optimizer\n","=> loading checkpoint baseResnet56\n","=> Checkpoint contents:\n","+----------------------+--------+----------------+\n","| Key                  | Type   | Value          |\n","|----------------------+--------+----------------|\n","| arch                 | str    | resnet56_cifar |\n","| compression_sched    | dict   |                |\n","| dataset              | str    | cifar10        |\n","| epoch                | int    | 127            |\n","| extras               | dict   |                |\n","| is_parallel          | bool   | True           |\n","| optimizer            | type   | SGD            |\n","| optimizer_state_dict | dict   |                |\n","| state_dict           | dict   |                |\n","+----------------------+--------+----------------+\n","\n","=> Checkpoint['extras'] contents:\n","+--------------+--------+---------+\n","| Key          | Type   |   Value |\n","|--------------+--------+---------|\n","| best_epoch   | int    |  127    |\n","| best_top1    | float  |   92.94 |\n","| current_top1 | float  |   92.94 |\n","+--------------+--------+---------+\n","\n","Loaded compression schedule from checkpoint (epoch 127)\n","Optimizer could not be loaded from checkpoint.\n","=> loaded checkpoint 'baseResnet56' (epoch 127)\n","Files already downloaded and verified\n","Dataset sizes:\n","\ttest=10000\n","Reading configuration from: /content/drive/MyDrive/Colab Notebooks/6787 Notebooks/Google Colab Scripts/Schedules/Quantization Schedules/PostTrainingSchedules/None/16bitSymmetricPost.yaml\n","Found component of class PostTrainLinearQuantizer: Name: linear_quantizer ; Section: quantizers\n","Loading activation stats from: /content/drive/MyDrive/Colab Notebooks/6787 Notebooks/Google Colab Scripts/Schedules/Quantization Schedules/acts_quantization_stats.yaml\n","Preparing model for quantization using PostTrainLinearQuantizer\n","Applying batch-norm folding ahead of post-training quantization\n","Propagating output statistics from BN modules to folded modules\n","Optimizing output statistics for modules followed by ReLU/Tanh/Sigmoid\n","Updated stats saved to /content/drive/MyDrive/Colab Notebooks/6787 Notebooks/Google Colab Scripts/Schedules/Quantization Schedules/PostTrainingResults/2020.12.08-211158/quant_stats_after_prepare_model.yaml\n","Per-layer quantization parameters saved to /content/drive/MyDrive/Colab Notebooks/6787 Notebooks/Google Colab Scripts/Schedules/Quantization Schedules/PostTrainingResults/2020.12.08-211158/layer_quant_params.yaml\n","--- test ---------------------\n","10000 samples (256 per mini-batch)\n","Test: [   10/   39]    Loss 0.370293    Top1 92.031250    Top5 99.843750    \n","Test: [   20/   39]    Loss 0.364711    Top1 92.011719    Top5 99.804688    \n","Test: [   30/   39]    Loss 0.339707    Top1 92.630208    Top5 99.778646    \n","Test: [   40/   39]    Loss 0.338296    Top1 92.650000    Top5 99.790000    \n","==> Top1: 92.650    Top5: 99.790    Loss: 0.338\n","\n","Saving checkpoint to: /content/drive/MyDrive/Colab Notebooks/6787 Notebooks/Google Colab Scripts/Schedules/Quantization Schedules/PostTrainingResults/2020.12.08-211158/quantized_checkpoint.pth.tar\n","\n","Log file for this run: /content/drive/.shortcut-targets-by-id/14_4ehU2lLHHu6HAFmEenl_iXGrCYtNmi/Google Colab Scripts/Schedules/Quantization Schedules/PostTrainingResults/2020.12.08-211158/2020.12.08-211158.log\n"],"name":"stdout"}]}]}