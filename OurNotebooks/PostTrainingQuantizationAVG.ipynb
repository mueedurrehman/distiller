{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"PostTrainingQuantizationAVG.ipynb","provenance":[{"file_id":"1EnfgAuwJbnYoVe109usa0kmX0CPgoACD","timestamp":1607456449027}],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"-z8E8R3kgRGr","executionInfo":{"status":"ok","timestamp":1607470329374,"user_tz":300,"elapsed":220186,"user":{"displayName":"Michele L","photoUrl":"","userId":"03726718545613636685"}},"outputId":"9c4b58ef-64fe-4333-b019-5e2ff4ac9622"},"source":["!git clone https://github.com/mueedurrehman/distiller.git\r\n","%cd distiller\r\n","!pip3 install -e ."],"execution_count":1,"outputs":[{"output_type":"stream","text":["Cloning into 'distiller'...\n","remote: Enumerating objects: 11, done.\u001b[K\n","remote: Counting objects: 100% (11/11), done.\u001b[K\n","remote: Compressing objects: 100% (7/7), done.\u001b[K\n","remote: Total 6174 (delta 4), reused 6 (delta 4), pack-reused 6163\u001b[K\n","Receiving objects: 100% (6174/6174), 39.83 MiB | 32.24 MiB/s, done.\n","Resolving deltas: 100% (4327/4327), done.\n","/content/distiller\n","Obtaining file:///content/distiller\n","Collecting pillow<7\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/8a/fd/bbbc569f98f47813c50a116b539d97b3b17a86ac7a309f83b2022d26caf2/Pillow-6.2.2-cp36-cp36m-manylinux1_x86_64.whl (2.1MB)\n","\u001b[K     |████████████████████████████████| 2.1MB 25.0MB/s \n","\u001b[?25hCollecting torch==1.3.1\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/88/95/90e8c4c31cfc67248bf944ba42029295b77159982f532c5689bcfe4e9108/torch-1.3.1-cp36-cp36m-manylinux1_x86_64.whl (734.6MB)\n","\u001b[K     |████████████████████████████████| 734.6MB 25kB/s \n","\u001b[?25hRequirement already satisfied: numpy>=1.16 in /usr/local/lib/python3.6/dist-packages (from distiller==0.4.0rc0) (1.18.5)\n","Collecting torchvision==0.4.2\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/9b/e2/2b1f88a363ae37b2ba52cfb785ddfb3dd5f7e7ec9459e96fd8299b84ae39/torchvision-0.4.2-cp36-cp36m-manylinux1_x86_64.whl (10.2MB)\n","\u001b[K     |████████████████████████████████| 10.2MB 18.8MB/s \n","\u001b[?25hRequirement already satisfied: scipy>=1.3.0 in /usr/local/lib/python3.6/dist-packages (from distiller==0.4.0rc0) (1.4.1)\n","Collecting gitpython==3.1.0\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d3/2f/6a366d56c9b1355b0880be9ea66b166cb3536392638d8d91413ec66305ad/GitPython-3.1.0-py3-none-any.whl (450kB)\n","\u001b[K     |████████████████████████████████| 460kB 58.4MB/s \n","\u001b[?25hCollecting torchnet==0.0.4\n","  Downloading https://files.pythonhosted.org/packages/b7/b2/d7f70a85d3f6b0365517782632f150e3bbc2fb8e998cd69e27deba599aae/torchnet-0.0.4.tar.gz\n","Collecting tensorflow~=1.14\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/8e/64/7a19837dd54d3f53b1ce5ae346ab401dde9678e8f233220317000bfdb3e2/tensorflow-1.15.4-cp36-cp36m-manylinux2010_x86_64.whl (110.5MB)\n","\u001b[K     |████████████████████████████████| 110.5MB 35kB/s \n","\u001b[?25hCollecting pydot==1.4.1\n","  Downloading https://files.pythonhosted.org/packages/33/d1/b1479a770f66d962f545c2101630ce1d5592d90cb4f083d38862e93d16d2/pydot-1.4.1-py2.py3-none-any.whl\n","Collecting tabulate==0.8.3\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/c2/fd/202954b3f0eb896c53b7b6f07390851b1fd2ca84aa95880d7ae4f434c4ac/tabulate-0.8.3.tar.gz (46kB)\n","\u001b[K     |████████████████████████████████| 51kB 8.6MB/s \n","\u001b[?25hRequirement already satisfied: pandas>=0.22.0 in /usr/local/lib/python3.6/dist-packages (from distiller==0.4.0rc0) (1.1.4)\n","Requirement already satisfied: jupyter>=1.0.0 in /usr/local/lib/python3.6/dist-packages (from distiller==0.4.0rc0) (1.0.0)\n","Requirement already satisfied: matplotlib~=3.0 in /usr/local/lib/python3.6/dist-packages (from distiller==0.4.0rc0) (3.2.2)\n","Collecting qgrid==1.1.1\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/70/63/0e0827682889f1a4ee74191b8bebc2e6fca1d18927d8875af0e37044d2d3/qgrid-1.1.1.tar.gz (793kB)\n","\u001b[K     |████████████████████████████████| 798kB 42.6MB/s \n","\u001b[?25hRequirement already satisfied: graphviz==0.10.1 in /usr/local/lib/python3.6/dist-packages (from distiller==0.4.0rc0) (0.10.1)\n","Collecting ipywidgets==7.4.2\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/30/9a/a008c7b1183fac9e52066d80a379b3c64eab535bd9d86cdc29a0b766fd82/ipywidgets-7.4.2-py2.py3-none-any.whl (111kB)\n","\u001b[K     |████████████████████████████████| 112kB 53.9MB/s \n","\u001b[?25hCollecting bqplot==0.11.5\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/73/17/a792f7c92eee01286fbf3a729e90cce131af9d53dc1e6a96c24d2714e654/bqplot-0.11.5-py2.py3-none-any.whl (1.7MB)\n","\u001b[K     |████████████████████████████████| 1.7MB 36.5MB/s \n","\u001b[?25hRequirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from distiller==0.4.0rc0) (3.13)\n","Collecting pytest~=4.6.1\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/70/c7/e8cb4a537ee4fc497ac80a606a667fd1832f28ad3ddbfa25bf30473eae13/pytest-4.6.11-py2.py3-none-any.whl (231kB)\n","\u001b[K     |████████████████████████████████| 235kB 60.5MB/s \n","\u001b[?25hCollecting xlsxwriter>=1.2.2\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/6b/41/bf1aae04932d1eaffee1fc5f8b38ca47bbbf07d765129539bc4bcce1ce0c/XlsxWriter-1.3.7-py2.py3-none-any.whl (144kB)\n","\u001b[K     |████████████████████████████████| 153kB 57.1MB/s \n","\u001b[?25hCollecting pretrainedmodels==0.7.4\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/84/0e/be6a0e58447ac16c938799d49bfb5fb7a80ac35e137547fc6cee2c08c4cf/pretrainedmodels-0.7.4.tar.gz (58kB)\n","\u001b[K     |████████████████████████████████| 61kB 10.1MB/s \n","\u001b[?25hCollecting scikit-learn==0.21.2\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/85/04/49633f490f726da6e454fddc8e938bbb5bfed2001681118d3814c219b723/scikit_learn-0.21.2-cp36-cp36m-manylinux1_x86_64.whl (6.7MB)\n","\u001b[K     |████████████████████████████████| 6.7MB 50.1MB/s \n","\u001b[?25hCollecting gym==0.12.5\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/0c/c4/307107c687f75267d645415d57db8c0a6e29e20ac30d8f4a10e8030b6737/gym-0.12.5.tar.gz (1.5MB)\n","\u001b[K     |████████████████████████████████| 1.5MB 29.9MB/s \n","\u001b[?25hCollecting tqdm==4.33.0\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/02/56/60a5b1c2e634d8e4ff89c7bab47645604e19658f448050a21facffd43796/tqdm-4.33.0-py2.py3-none-any.whl (50kB)\n","\u001b[K     |████████████████████████████████| 51kB 7.6MB/s \n","\u001b[?25hRequirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from torchvision==0.4.2->distiller==0.4.0rc0) (1.15.0)\n","Collecting gitdb<5,>=4.0.1\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/48/11/d1800bca0a3bae820b84b7d813ad1eff15a48a64caea9c823fc8c1b119e8/gitdb-4.0.5-py3-none-any.whl (63kB)\n","\u001b[K     |████████████████████████████████| 71kB 10.9MB/s \n","\u001b[?25hCollecting visdom\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/c9/75/e078f5a2e1df7e0d3044749089fc2823e62d029cc027ed8ae5d71fafcbdc/visdom-0.1.8.9.tar.gz (676kB)\n","\u001b[K     |████████████████████████████████| 686kB 50.9MB/s \n","\u001b[?25hCollecting gast==0.2.2\n","  Downloading https://files.pythonhosted.org/packages/4e/35/11749bf99b2d4e3cceb4d55ca22590b0d7c2c62b9de38ac4a4a7f4687421/gast-0.2.2.tar.gz\n","Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow~=1.14->distiller==0.4.0rc0) (1.1.0)\n","Collecting tensorboard<1.16.0,>=1.15.0\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/1e/e9/d3d747a97f7188f48aa5eda486907f3b345cd409f0a0850468ba867db246/tensorboard-1.15.0-py3-none-any.whl (3.8MB)\n","\u001b[K     |████████████████████████████████| 3.8MB 44.7MB/s \n","\u001b[?25hCollecting tensorflow-estimator==1.15.1\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/de/62/2ee9cd74c9fa2fa450877847ba560b260f5d0fb70ee0595203082dafcc9d/tensorflow_estimator-1.15.1-py2.py3-none-any.whl (503kB)\n","\u001b[K     |████████████████████████████████| 512kB 57.8MB/s \n","\u001b[?25hRequirement already satisfied: wheel>=0.26; python_version >= \"3\" in /usr/local/lib/python3.6/dist-packages (from tensorflow~=1.14->distiller==0.4.0rc0) (0.35.1)\n","Collecting keras-applications>=1.0.8\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/71/e3/19762fdfc62877ae9102edf6342d71b28fbfd9dea3d2f96a882ce099b03f/Keras_Applications-1.0.8-py3-none-any.whl (50kB)\n","\u001b[K     |████████████████████████████████| 51kB 8.8MB/s \n","\u001b[?25hRequirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow~=1.14->distiller==0.4.0rc0) (0.10.0)\n","Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow~=1.14->distiller==0.4.0rc0) (3.3.0)\n","Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow~=1.14->distiller==0.4.0rc0) (1.33.2)\n","Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow~=1.14->distiller==0.4.0rc0) (3.12.4)\n","Requirement already satisfied: google-pasta>=0.1.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow~=1.14->distiller==0.4.0rc0) (0.2.0)\n","Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow~=1.14->distiller==0.4.0rc0) (0.8.1)\n","Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow~=1.14->distiller==0.4.0rc0) (1.12.1)\n","Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow~=1.14->distiller==0.4.0rc0) (1.1.2)\n","Requirement already satisfied: pyparsing>=2.1.4 in /usr/local/lib/python3.6/dist-packages (from pydot==1.4.1->distiller==0.4.0rc0) (2.4.7)\n","Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.6/dist-packages (from pandas>=0.22.0->distiller==0.4.0rc0) (2.8.1)\n","Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas>=0.22.0->distiller==0.4.0rc0) (2018.9)\n","Requirement already satisfied: notebook in /usr/local/lib/python3.6/dist-packages (from jupyter>=1.0.0->distiller==0.4.0rc0) (5.3.1)\n","Requirement already satisfied: jupyter-console in /usr/local/lib/python3.6/dist-packages (from jupyter>=1.0.0->distiller==0.4.0rc0) (5.2.0)\n","Requirement already satisfied: nbconvert in /usr/local/lib/python3.6/dist-packages (from jupyter>=1.0.0->distiller==0.4.0rc0) (5.6.1)\n","Requirement already satisfied: qtconsole in /usr/local/lib/python3.6/dist-packages (from jupyter>=1.0.0->distiller==0.4.0rc0) (5.0.1)\n","Requirement already satisfied: ipykernel in /usr/local/lib/python3.6/dist-packages (from jupyter>=1.0.0->distiller==0.4.0rc0) (4.10.1)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib~=3.0->distiller==0.4.0rc0) (0.10.0)\n","Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib~=3.0->distiller==0.4.0rc0) (1.3.1)\n","Requirement already satisfied: nbformat>=4.2.0 in /usr/local/lib/python3.6/dist-packages (from ipywidgets==7.4.2->distiller==0.4.0rc0) (5.0.8)\n","Requirement already satisfied: traitlets>=4.3.1 in /usr/local/lib/python3.6/dist-packages (from ipywidgets==7.4.2->distiller==0.4.0rc0) (4.3.3)\n","Requirement already satisfied: ipython>=4.0.0; python_version >= \"3.3\" in /usr/local/lib/python3.6/dist-packages (from ipywidgets==7.4.2->distiller==0.4.0rc0) (5.5.0)\n","Collecting widgetsnbextension~=3.4.0\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/8a/81/35789a3952afb48238289171728072d26d6e76649ddc8b3588657a2d78c1/widgetsnbextension-3.4.2-py2.py3-none-any.whl (2.2MB)\n","\u001b[K     |████████████████████████████████| 2.2MB 51.2MB/s \n","\u001b[?25hCollecting traittypes>=0.0.6\n","  Downloading https://files.pythonhosted.org/packages/9c/d1/8d5bd662703cc1764d986f6908a608777305946fa634d34c470cd4a1e729/traittypes-0.2.1-py2.py3-none-any.whl\n","Requirement already satisfied: atomicwrites>=1.0 in /usr/local/lib/python3.6/dist-packages (from pytest~=4.6.1->distiller==0.4.0rc0) (1.4.0)\n","Requirement already satisfied: importlib-metadata>=0.12; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from pytest~=4.6.1->distiller==0.4.0rc0) (2.0.0)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from pytest~=4.6.1->distiller==0.4.0rc0) (20.4)\n","Collecting pluggy<1.0,>=0.12\n","  Downloading https://files.pythonhosted.org/packages/a0/28/85c7aa31b80d150b772fbe4a229487bc6644da9ccb7e427dd8cc60cb8a62/pluggy-0.13.1-py2.py3-none-any.whl\n","Requirement already satisfied: wcwidth in /usr/local/lib/python3.6/dist-packages (from pytest~=4.6.1->distiller==0.4.0rc0) (0.2.5)\n","Requirement already satisfied: attrs>=17.4.0 in /usr/local/lib/python3.6/dist-packages (from pytest~=4.6.1->distiller==0.4.0rc0) (20.3.0)\n","Requirement already satisfied: more-itertools>=4.0.0; python_version > \"2.7\" in /usr/local/lib/python3.6/dist-packages (from pytest~=4.6.1->distiller==0.4.0rc0) (8.6.0)\n","Requirement already satisfied: py>=1.5.0 in /usr/local/lib/python3.6/dist-packages (from pytest~=4.6.1->distiller==0.4.0rc0) (1.9.0)\n","Collecting munch\n","  Downloading https://files.pythonhosted.org/packages/cc/ab/85d8da5c9a45e072301beb37ad7f833cd344e04c817d97e0cc75681d248f/munch-2.5.0-py2.py3-none-any.whl\n","Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn==0.21.2->distiller==0.4.0rc0) (0.17.0)\n","Requirement already satisfied: pyglet>=1.2.0 in /usr/local/lib/python3.6/dist-packages (from gym==0.12.5->distiller==0.4.0rc0) (1.5.0)\n","Collecting smmap<4,>=3.0.1\n","  Downloading https://files.pythonhosted.org/packages/b0/9a/4d409a6234eb940e6a78dfdfc66156e7522262f5f2fecca07dc55915952d/smmap-3.0.4-py2.py3-none-any.whl\n","Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from visdom->torchnet==0.0.4->distiller==0.4.0rc0) (2.23.0)\n","Requirement already satisfied: tornado in /usr/local/lib/python3.6/dist-packages (from visdom->torchnet==0.0.4->distiller==0.4.0rc0) (5.1.1)\n","Requirement already satisfied: pyzmq in /usr/local/lib/python3.6/dist-packages (from visdom->torchnet==0.0.4->distiller==0.4.0rc0) (20.0.0)\n","Collecting jsonpatch\n","  Downloading https://files.pythonhosted.org/packages/40/d5/6640ac6d1bdd20f44bb6b3c6e6f2f1c525bf0b7595f99c4f38917f995d6b/jsonpatch-1.28-py2.py3-none-any.whl\n","Collecting torchfile\n","  Downloading https://files.pythonhosted.org/packages/91/af/5b305f86f2d218091af657ddb53f984ecbd9518ca9fe8ef4103a007252c9/torchfile-0.1.0.tar.gz\n","Collecting websocket-client\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/4c/5f/f61b420143ed1c8dc69f9eaec5ff1ac36109d52c80de49d66e0c36c3dfdf/websocket_client-0.57.0-py2.py3-none-any.whl (200kB)\n","\u001b[K     |████████████████████████████████| 204kB 53.8MB/s \n","\u001b[?25hRequirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow~=1.14->distiller==0.4.0rc0) (50.3.2)\n","Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow~=1.14->distiller==0.4.0rc0) (1.0.1)\n","Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow~=1.14->distiller==0.4.0rc0) (3.3.3)\n","Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras-applications>=1.0.8->tensorflow~=1.14->distiller==0.4.0rc0) (2.10.0)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.6/dist-packages (from notebook->jupyter>=1.0.0->distiller==0.4.0rc0) (2.11.2)\n","Requirement already satisfied: jupyter-core>=4.4.0 in /usr/local/lib/python3.6/dist-packages (from notebook->jupyter>=1.0.0->distiller==0.4.0rc0) (4.7.0)\n","Requirement already satisfied: ipython-genutils in /usr/local/lib/python3.6/dist-packages (from notebook->jupyter>=1.0.0->distiller==0.4.0rc0) (0.2.0)\n","Requirement already satisfied: terminado>=0.8.1 in /usr/local/lib/python3.6/dist-packages (from notebook->jupyter>=1.0.0->distiller==0.4.0rc0) (0.9.1)\n","Requirement already satisfied: Send2Trash in /usr/local/lib/python3.6/dist-packages (from notebook->jupyter>=1.0.0->distiller==0.4.0rc0) (1.5.0)\n","Requirement already satisfied: jupyter-client>=5.2.0 in /usr/local/lib/python3.6/dist-packages (from notebook->jupyter>=1.0.0->distiller==0.4.0rc0) (5.3.5)\n","Requirement already satisfied: prompt-toolkit<2.0.0,>=1.0.0 in /usr/local/lib/python3.6/dist-packages (from jupyter-console->jupyter>=1.0.0->distiller==0.4.0rc0) (1.0.18)\n","Requirement already satisfied: pygments in /usr/local/lib/python3.6/dist-packages (from jupyter-console->jupyter>=1.0.0->distiller==0.4.0rc0) (2.6.1)\n","Requirement already satisfied: entrypoints>=0.2.2 in /usr/local/lib/python3.6/dist-packages (from nbconvert->jupyter>=1.0.0->distiller==0.4.0rc0) (0.3)\n","Requirement already satisfied: bleach in /usr/local/lib/python3.6/dist-packages (from nbconvert->jupyter>=1.0.0->distiller==0.4.0rc0) (3.2.1)\n","Requirement already satisfied: mistune<2,>=0.8.1 in /usr/local/lib/python3.6/dist-packages (from nbconvert->jupyter>=1.0.0->distiller==0.4.0rc0) (0.8.4)\n","Requirement already satisfied: defusedxml in /usr/local/lib/python3.6/dist-packages (from nbconvert->jupyter>=1.0.0->distiller==0.4.0rc0) (0.6.0)\n","Requirement already satisfied: pandocfilters>=1.4.1 in /usr/local/lib/python3.6/dist-packages (from nbconvert->jupyter>=1.0.0->distiller==0.4.0rc0) (1.4.3)\n","Requirement already satisfied: testpath in /usr/local/lib/python3.6/dist-packages (from nbconvert->jupyter>=1.0.0->distiller==0.4.0rc0) (0.4.4)\n","Requirement already satisfied: qtpy in /usr/local/lib/python3.6/dist-packages (from qtconsole->jupyter>=1.0.0->distiller==0.4.0rc0) (1.9.0)\n","Requirement already satisfied: jsonschema!=2.5.0,>=2.4 in /usr/local/lib/python3.6/dist-packages (from nbformat>=4.2.0->ipywidgets==7.4.2->distiller==0.4.0rc0) (2.6.0)\n","Requirement already satisfied: decorator in /usr/local/lib/python3.6/dist-packages (from traitlets>=4.3.1->ipywidgets==7.4.2->distiller==0.4.0rc0) (4.4.2)\n","Requirement already satisfied: simplegeneric>0.8 in /usr/local/lib/python3.6/dist-packages (from ipython>=4.0.0; python_version >= \"3.3\"->ipywidgets==7.4.2->distiller==0.4.0rc0) (0.8.1)\n","Requirement already satisfied: pexpect; sys_platform != \"win32\" in /usr/local/lib/python3.6/dist-packages (from ipython>=4.0.0; python_version >= \"3.3\"->ipywidgets==7.4.2->distiller==0.4.0rc0) (4.8.0)\n","Requirement already satisfied: pickleshare in /usr/local/lib/python3.6/dist-packages (from ipython>=4.0.0; python_version >= \"3.3\"->ipywidgets==7.4.2->distiller==0.4.0rc0) (0.7.5)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata>=0.12; python_version < \"3.8\"->pytest~=4.6.1->distiller==0.4.0rc0) (3.4.0)\n","Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from pyglet>=1.2.0->gym==0.12.5->distiller==0.4.0rc0) (0.16.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->visdom->torchnet==0.0.4->distiller==0.4.0rc0) (2020.11.8)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->visdom->torchnet==0.0.4->distiller==0.4.0rc0) (3.0.4)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->visdom->torchnet==0.0.4->distiller==0.4.0rc0) (1.24.3)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->visdom->torchnet==0.0.4->distiller==0.4.0rc0) (2.10)\n","Collecting jsonpointer>=1.9\n","  Downloading https://files.pythonhosted.org/packages/18/b0/a80d29577c08eea401659254dfaed87f1af45272899e1812d7e01b679bc5/jsonpointer-2.0-py2.py3-none-any.whl\n","Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.6/dist-packages (from jinja2->notebook->jupyter>=1.0.0->distiller==0.4.0rc0) (1.1.1)\n","Requirement already satisfied: ptyprocess; os_name != \"nt\" in /usr/local/lib/python3.6/dist-packages (from terminado>=0.8.1->notebook->jupyter>=1.0.0->distiller==0.4.0rc0) (0.6.0)\n","Requirement already satisfied: webencodings in /usr/local/lib/python3.6/dist-packages (from bleach->nbconvert->jupyter>=1.0.0->distiller==0.4.0rc0) (0.5.1)\n","Building wheels for collected packages: torchnet, tabulate, qgrid, pretrainedmodels, gym, visdom, gast, torchfile\n","  Building wheel for torchnet (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for torchnet: filename=torchnet-0.0.4-cp36-none-any.whl size=29747 sha256=ed9416b4fb8e5dc57e7dd8a3da8e730182e17c10ba6b56453b07baf2873bea36\n","  Stored in directory: /root/.cache/pip/wheels/e1/03/fb/1c212c2f20905cdf97fe39022946cf16b8e66ed754a6663400\n","  Building wheel for tabulate (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for tabulate: filename=tabulate-0.8.3-cp36-none-any.whl size=23377 sha256=7d62c899c7deebf8644d1d87485e5e64c1628762ed572f076569fc90114402f6\n","  Stored in directory: /root/.cache/pip/wheels/2b/67/89/414471314a2d15de625d184d8be6d38a03ae1e983dbda91e84\n","  Building wheel for qgrid (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for qgrid: filename=qgrid-1.1.1-py2.py3-none-any.whl size=1555709 sha256=373bbdc1171e7d20dd15484ad2f15c05b0dc1765f8e90e51f96e88f02da76565\n","  Stored in directory: /root/.cache/pip/wheels/97/71/37/8423045f66492c2b48ba9e968257ff7fdc7c941e2656380441\n","  Building wheel for pretrainedmodels (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for pretrainedmodels: filename=pretrainedmodels-0.7.4-cp36-none-any.whl size=60964 sha256=7f2e491b6f8dc77cc0d583aa1b912a6c1e2a7cec83f79efc51404b3bfd8e3513\n","  Stored in directory: /root/.cache/pip/wheels/69/df/63/62583c096289713f22db605aa2334de5b591d59861a02c2ecd\n","  Building wheel for gym (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for gym: filename=gym-0.12.5-cp36-none-any.whl size=1613802 sha256=6069a75dedefb58ec62ff8b3d3c94d53a59dc1101fd3158bfc54a612fccaeddd\n","  Stored in directory: /root/.cache/pip/wheels/cf/a5/c9/87967963aa32540d543e51bcf0d0fc19c5d68b8f49598d3b98\n","  Building wheel for visdom (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for visdom: filename=visdom-0.1.8.9-cp36-none-any.whl size=655251 sha256=b747734d0e0c0a2dd5e0ad12920cea43afcc10b4c03d108fda89631349688794\n","  Stored in directory: /root/.cache/pip/wheels/70/19/a7/6d589ed967f4dfefd33bc166d081257bd4ed0cb618dccfd62a\n","  Building wheel for gast (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for gast: filename=gast-0.2.2-cp36-none-any.whl size=7542 sha256=e820fa015ebcab17654796f77061aee7208fea25fdf13e8f6558efa377a95a7d\n","  Stored in directory: /root/.cache/pip/wheels/5c/2e/7e/a1d4d4fcebe6c381f378ce7743a3ced3699feb89bcfbdadadd\n","  Building wheel for torchfile (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for torchfile: filename=torchfile-0.1.0-cp36-none-any.whl size=5711 sha256=0f51786799ef77cc80a24079f9f9b826bbe79cf322eea646a83819163c0bc4f6\n","  Stored in directory: /root/.cache/pip/wheels/b1/c3/d6/9a1cc8f3a99a0fc1124cae20153f36af59a6e683daca0a0814\n","Successfully built torchnet tabulate qgrid pretrainedmodels gym visdom gast torchfile\n","\u001b[31mERROR: tensorflow-probability 0.11.0 has requirement gast>=0.3.2, but you'll have gast 0.2.2 which is incompatible.\u001b[0m\n","\u001b[31mERROR: spacy 2.2.4 has requirement tqdm<5.0.0,>=4.38.0, but you'll have tqdm 4.33.0 which is incompatible.\u001b[0m\n","\u001b[31mERROR: fbprophet 0.7.1 has requirement tqdm>=4.36.1, but you'll have tqdm 4.33.0 which is incompatible.\u001b[0m\n","\u001b[31mERROR: datascience 0.10.6 has requirement folium==0.2.1, but you'll have folium 0.8.3 which is incompatible.\u001b[0m\n","\u001b[31mERROR: albumentations 0.1.12 has requirement imgaug<0.2.7,>=0.2.5, but you'll have imgaug 0.2.9 which is incompatible.\u001b[0m\n","Installing collected packages: pillow, torch, torchvision, smmap, gitdb, gitpython, jsonpointer, jsonpatch, torchfile, websocket-client, visdom, torchnet, gast, tensorboard, tensorflow-estimator, keras-applications, tensorflow, pydot, tabulate, widgetsnbextension, ipywidgets, qgrid, traittypes, bqplot, pluggy, pytest, xlsxwriter, munch, tqdm, pretrainedmodels, scikit-learn, gym, distiller\n","  Found existing installation: Pillow 7.0.0\n","    Uninstalling Pillow-7.0.0:\n","      Successfully uninstalled Pillow-7.0.0\n","  Found existing installation: torch 1.7.0+cu101\n","    Uninstalling torch-1.7.0+cu101:\n","      Successfully uninstalled torch-1.7.0+cu101\n","  Found existing installation: torchvision 0.8.1+cu101\n","    Uninstalling torchvision-0.8.1+cu101:\n","      Successfully uninstalled torchvision-0.8.1+cu101\n","  Found existing installation: gast 0.3.3\n","    Uninstalling gast-0.3.3:\n","      Successfully uninstalled gast-0.3.3\n","  Found existing installation: tensorboard 2.3.0\n","    Uninstalling tensorboard-2.3.0:\n","      Successfully uninstalled tensorboard-2.3.0\n","  Found existing installation: tensorflow-estimator 2.3.0\n","    Uninstalling tensorflow-estimator-2.3.0:\n","      Successfully uninstalled tensorflow-estimator-2.3.0\n","  Found existing installation: tensorflow 2.3.0\n","    Uninstalling tensorflow-2.3.0:\n","      Successfully uninstalled tensorflow-2.3.0\n","  Found existing installation: pydot 1.3.0\n","    Uninstalling pydot-1.3.0:\n","      Successfully uninstalled pydot-1.3.0\n","  Found existing installation: tabulate 0.8.7\n","    Uninstalling tabulate-0.8.7:\n","      Successfully uninstalled tabulate-0.8.7\n","  Found existing installation: widgetsnbextension 3.5.1\n","    Uninstalling widgetsnbextension-3.5.1:\n","      Successfully uninstalled widgetsnbextension-3.5.1\n","  Found existing installation: ipywidgets 7.5.1\n","    Uninstalling ipywidgets-7.5.1:\n","      Successfully uninstalled ipywidgets-7.5.1\n","  Found existing installation: pluggy 0.7.1\n","    Uninstalling pluggy-0.7.1:\n","      Successfully uninstalled pluggy-0.7.1\n","  Found existing installation: pytest 3.6.4\n","    Uninstalling pytest-3.6.4:\n","      Successfully uninstalled pytest-3.6.4\n","  Found existing installation: tqdm 4.41.1\n","    Uninstalling tqdm-4.41.1:\n","      Successfully uninstalled tqdm-4.41.1\n","  Found existing installation: scikit-learn 0.22.2.post1\n","    Uninstalling scikit-learn-0.22.2.post1:\n","      Successfully uninstalled scikit-learn-0.22.2.post1\n","  Found existing installation: gym 0.17.3\n","    Uninstalling gym-0.17.3:\n","      Successfully uninstalled gym-0.17.3\n","  Running setup.py develop for distiller\n","Successfully installed bqplot-0.11.5 distiller gast-0.2.2 gitdb-4.0.5 gitpython-3.1.0 gym-0.12.5 ipywidgets-7.4.2 jsonpatch-1.28 jsonpointer-2.0 keras-applications-1.0.8 munch-2.5.0 pillow-6.2.2 pluggy-0.13.1 pretrainedmodels-0.7.4 pydot-1.4.1 pytest-4.6.11 qgrid-1.1.1 scikit-learn-0.21.2 smmap-3.0.4 tabulate-0.8.3 tensorboard-1.15.0 tensorflow-1.15.4 tensorflow-estimator-1.15.1 torch-1.3.1 torchfile-0.1.0 torchnet-0.0.4 torchvision-0.4.2 tqdm-4.33.0 traittypes-0.2.1 visdom-0.1.8.9 websocket-client-0.57.0 widgetsnbextension-3.4.2 xlsxwriter-1.3.7\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.colab-display-data+json":{"pip_warning":{"packages":["PIL","ipywidgets"]}}},"metadata":{"tags":[]}}]},{"cell_type":"code","metadata":{"id":"fcNpF9g2gtVx","colab":{"base_uri":"https://localhost:8080/"},"outputId":"2d6410a3-a92b-4464-d952-8fa08df9524d"},"source":["from google.colab import drive\r\n","drive.mount('/content/drive')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.activity.readonly&response_type=code\n","\n","Enter your authorization code:\n","4/1AY0e-g4peuNX2DH2sSuE0Pe8ZOITfjXK1zSOIVObBPfF4WATL6uuyAwUWK4\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"PQvtIAXWoZFD"},"source":["import torch\r\n","import torchvision\r\n","import torchvision.transforms as transforms\r\n","import torchvision.models as models\r\n","from torchsummary import summary\r\n","import matplotlib.pyplot as plt\r\n","import numpy as np\r\n","import torch.nn as nn\r\n","import torch.nn.functional as F\r\n","import time\r\n","import math\r\n","import yaml\r\n","import distiller\r\n","from collections import OrderedDict\r\n","import os\r\n","import pandas as pd"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"DU9QPjMtgucZ","executionInfo":{"status":"ok","timestamp":1607461435943,"user_tz":300,"elapsed":11303,"user":{"displayName":"Michele L","photoUrl":"","userId":"03726718545613636685"}}},"source":["!cp \"/content/drive/MyDrive/Colab Notebooks/6787 Notebooks/Google Colab Scripts/Baseline Models/baseResnet56\" .\r\n","# !cp ../../../drive/MyDrive/CS6787\\ -\\ Final\\ Project/Google\\ Colab\\ Scripts/Quantization\\ Models/Resnet56\\ Quantization\\ Stats/resnet56_quant_stats.yaml ."],"execution_count":4,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"wHDu0n7ExuwU"},"source":["Asymmetric U"]},{"cell_type":"code","metadata":{"id":"A7Iupur823Fw","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1607461465713,"user_tz":300,"elapsed":41069,"user":{"displayName":"Michele L","photoUrl":"","userId":"03726718545613636685"}},"outputId":"59eff24b-5f9d-4486-b4e0-df46b87599dc"},"source":["!python3 \"/content/distiller/examples/classifier_compression/compress_classifier.py\" --arch resnet56_cifar -p 10 ./data --resume=\"baseResnet56\" --out-dir \"/content/drive/MyDrive/Colab Notebooks/6787 Notebooks/Google Colab Scripts/Schedules/Quantization Schedules/PostTrainingResults\" --evaluate --quantize-eval --qe-config-file \"/content/drive/MyDrive/Colab Notebooks/6787 Notebooks/Google Colab Scripts/Schedules/Quantization Schedules/PostTrainingSchedules/AVG/4bitAsymmetricUPost.yaml\" -o \"/content/drive/MyDrive/Colab Notebooks/6787 Notebooks/Google Colab Scripts/Schedules/Quantization Schedules/PostTrainingResults\""],"execution_count":5,"outputs":[{"output_type":"stream","text":["Log file for this run: /content/drive/.shortcut-targets-by-id/14_4ehU2lLHHu6HAFmEenl_iXGrCYtNmi/Google Colab Scripts/Schedules/Quantization Schedules/PostTrainingResults/2020.12.08-210359/2020.12.08-210359.log\n","Random seed: 0\n","\n","--------------------------------------------------------\n","Logging to TensorBoard - remember to execute the server:\n","> tensorboard --logdir='./logs'\n","\n","=> created a resnet56_cifar model with the cifar10 dataset\n","The \"--resume\" flag is deprecated. Please use \"--resume-from=YOUR_PATH\" instead.\n","If you wish to also reset the optimizer, call with: --reset-optimizer\n","=> loading checkpoint baseResnet56\n","=> Checkpoint contents:\n","+----------------------+--------+----------------+\n","| Key                  | Type   | Value          |\n","|----------------------+--------+----------------|\n","| arch                 | str    | resnet56_cifar |\n","| compression_sched    | dict   |                |\n","| dataset              | str    | cifar10        |\n","| epoch                | int    | 127            |\n","| extras               | dict   |                |\n","| is_parallel          | bool   | True           |\n","| optimizer            | type   | SGD            |\n","| optimizer_state_dict | dict   |                |\n","| state_dict           | dict   |                |\n","+----------------------+--------+----------------+\n","\n","=> Checkpoint['extras'] contents:\n","+--------------+--------+---------+\n","| Key          | Type   |   Value |\n","|--------------+--------+---------|\n","| best_epoch   | int    |  127    |\n","| best_top1    | float  |   92.94 |\n","| current_top1 | float  |   92.94 |\n","+--------------+--------+---------+\n","\n","Loaded compression schedule from checkpoint (epoch 127)\n","Optimizer could not be loaded from checkpoint.\n","=> loaded checkpoint 'baseResnet56' (epoch 127)\n","Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./data/cifar-10-python.tar.gz\n","170500096it [00:03, 43953599.20it/s]                   \n","Extracting ./data/cifar-10-python.tar.gz to ./data\n","Dataset sizes:\n","\ttest=10000\n","Reading configuration from: /content/drive/MyDrive/Colab Notebooks/6787 Notebooks/Google Colab Scripts/Schedules/Quantization Schedules/PostTrainingSchedules/AVG/4bitAsymmetricUPost.yaml\n","Found component of class PostTrainLinearQuantizer: Name: linear_quantizer ; Section: quantizers\n","Loading activation stats from: /content/drive/MyDrive/Colab Notebooks/6787 Notebooks/Google Colab Scripts/Schedules/Quantization Schedules/acts_quantization_stats.yaml\n","Preparing model for quantization using PostTrainLinearQuantizer\n","Applying batch-norm folding ahead of post-training quantization\n","Propagating output statistics from BN modules to folded modules\n","Optimizing output statistics for modules followed by ReLU/Tanh/Sigmoid\n","Updated stats saved to /content/drive/MyDrive/Colab Notebooks/6787 Notebooks/Google Colab Scripts/Schedules/Quantization Schedules/PostTrainingResults/2020.12.08-210359/quant_stats_after_prepare_model.yaml\n","Per-layer quantization parameters saved to /content/drive/MyDrive/Colab Notebooks/6787 Notebooks/Google Colab Scripts/Schedules/Quantization Schedules/PostTrainingResults/2020.12.08-210359/layer_quant_params.yaml\n","--- test ---------------------\n","10000 samples (256 per mini-batch)\n","Test: [   10/   39]    Loss 1.785152    Top1 67.695312    Top5 96.289062    \n","Test: [   20/   39]    Loss 1.733676    Top1 68.398438    Top5 96.484375    \n","Test: [   30/   39]    Loss 1.687034    Top1 69.231771    Top5 96.588542    \n","Test: [   40/   39]    Loss 1.676022    Top1 69.540000    Top5 96.590000    \n","==> Top1: 69.540    Top5: 96.590    Loss: 1.676\n","\n","Saving checkpoint to: /content/drive/MyDrive/Colab Notebooks/6787 Notebooks/Google Colab Scripts/Schedules/Quantization Schedules/PostTrainingResults/2020.12.08-210359/quantized_checkpoint.pth.tar\n","\n","Log file for this run: /content/drive/.shortcut-targets-by-id/14_4ehU2lLHHu6HAFmEenl_iXGrCYtNmi/Google Colab Scripts/Schedules/Quantization Schedules/PostTrainingResults/2020.12.08-210359/2020.12.08-210359.log\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"M5TkS-1O29ZZ","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1607461487661,"user_tz":300,"elapsed":63013,"user":{"displayName":"Michele L","photoUrl":"","userId":"03726718545613636685"}},"outputId":"7eac8bab-97bf-4888-8258-4fa404f0c64c"},"source":["!python3 \"/content/distiller/examples/classifier_compression/compress_classifier.py\" --arch resnet56_cifar -p 10 ./data --resume=\"baseResnet56\" --out-dir \"/content/drive/MyDrive/Colab Notebooks/6787 Notebooks/Google Colab Scripts/Schedules/Quantization Schedules/PostTrainingResults\" --evaluate --quantize-eval --qe-config-file \"/content/drive/MyDrive/Colab Notebooks/6787 Notebooks/Google Colab Scripts/Schedules/Quantization Schedules/PostTrainingSchedules/AVG/6bitAsymmetricUPost.yaml\" -o \"/content/drive/MyDrive/Colab Notebooks/6787 Notebooks/Google Colab Scripts/Schedules/Quantization Schedules/PostTrainingResults\""],"execution_count":6,"outputs":[{"output_type":"stream","text":["Log file for this run: /content/drive/.shortcut-targets-by-id/14_4ehU2lLHHu6HAFmEenl_iXGrCYtNmi/Google Colab Scripts/Schedules/Quantization Schedules/PostTrainingResults/2020.12.08-210429/2020.12.08-210429.log\n","Random seed: 0\n","\n","--------------------------------------------------------\n","Logging to TensorBoard - remember to execute the server:\n","> tensorboard --logdir='./logs'\n","\n","=> created a resnet56_cifar model with the cifar10 dataset\n","The \"--resume\" flag is deprecated. Please use \"--resume-from=YOUR_PATH\" instead.\n","If you wish to also reset the optimizer, call with: --reset-optimizer\n","=> loading checkpoint baseResnet56\n","=> Checkpoint contents:\n","+----------------------+--------+----------------+\n","| Key                  | Type   | Value          |\n","|----------------------+--------+----------------|\n","| arch                 | str    | resnet56_cifar |\n","| compression_sched    | dict   |                |\n","| dataset              | str    | cifar10        |\n","| epoch                | int    | 127            |\n","| extras               | dict   |                |\n","| is_parallel          | bool   | True           |\n","| optimizer            | type   | SGD            |\n","| optimizer_state_dict | dict   |                |\n","| state_dict           | dict   |                |\n","+----------------------+--------+----------------+\n","\n","=> Checkpoint['extras'] contents:\n","+--------------+--------+---------+\n","| Key          | Type   |   Value |\n","|--------------+--------+---------|\n","| best_epoch   | int    |  127    |\n","| best_top1    | float  |   92.94 |\n","| current_top1 | float  |   92.94 |\n","+--------------+--------+---------+\n","\n","Loaded compression schedule from checkpoint (epoch 127)\n","Optimizer could not be loaded from checkpoint.\n","=> loaded checkpoint 'baseResnet56' (epoch 127)\n","Files already downloaded and verified\n","Dataset sizes:\n","\ttest=10000\n","Reading configuration from: /content/drive/MyDrive/Colab Notebooks/6787 Notebooks/Google Colab Scripts/Schedules/Quantization Schedules/PostTrainingSchedules/AVG/6bitAsymmetricUPost.yaml\n","Found component of class PostTrainLinearQuantizer: Name: linear_quantizer ; Section: quantizers\n","Loading activation stats from: /content/drive/MyDrive/Colab Notebooks/6787 Notebooks/Google Colab Scripts/Schedules/Quantization Schedules/acts_quantization_stats.yaml\n","Preparing model for quantization using PostTrainLinearQuantizer\n","Applying batch-norm folding ahead of post-training quantization\n","Propagating output statistics from BN modules to folded modules\n","Optimizing output statistics for modules followed by ReLU/Tanh/Sigmoid\n","Updated stats saved to /content/drive/MyDrive/Colab Notebooks/6787 Notebooks/Google Colab Scripts/Schedules/Quantization Schedules/PostTrainingResults/2020.12.08-210429/quant_stats_after_prepare_model.yaml\n","Per-layer quantization parameters saved to /content/drive/MyDrive/Colab Notebooks/6787 Notebooks/Google Colab Scripts/Schedules/Quantization Schedules/PostTrainingResults/2020.12.08-210429/layer_quant_params.yaml\n","--- test ---------------------\n","10000 samples (256 per mini-batch)\n","Test: [   10/   39]    Loss 0.405388    Top1 91.250000    Top5 99.765625    \n","Test: [   20/   39]    Loss 0.403066    Top1 91.503906    Top5 99.746094    \n","Test: [   30/   39]    Loss 0.373562    Top1 91.940104    Top5 99.713542    \n","Test: [   40/   39]    Loss 0.371684    Top1 91.990000    Top5 99.710000    \n","==> Top1: 91.990    Top5: 99.710    Loss: 0.372\n","\n","Saving checkpoint to: /content/drive/MyDrive/Colab Notebooks/6787 Notebooks/Google Colab Scripts/Schedules/Quantization Schedules/PostTrainingResults/2020.12.08-210429/quantized_checkpoint.pth.tar\n","\n","Log file for this run: /content/drive/.shortcut-targets-by-id/14_4ehU2lLHHu6HAFmEenl_iXGrCYtNmi/Google Colab Scripts/Schedules/Quantization Schedules/PostTrainingResults/2020.12.08-210429/2020.12.08-210429.log\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"XNsDkA6a2-Sk","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1607461509400,"user_tz":300,"elapsed":84748,"user":{"displayName":"Michele L","photoUrl":"","userId":"03726718545613636685"}},"outputId":"af5a8174-22fd-4c99-f343-085adde15baf"},"source":["!python3 \"/content/distiller/examples/classifier_compression/compress_classifier.py\" --arch resnet56_cifar -p 10 ./data --resume=\"baseResnet56\" --out-dir \"/content/drive/MyDrive/Colab Notebooks/6787 Notebooks/Google Colab Scripts/Schedules/Quantization Schedules/PostTrainingResults\" --evaluate --quantize-eval --qe-config-file \"/content/drive/MyDrive/Colab Notebooks/6787 Notebooks/Google Colab Scripts/Schedules/Quantization Schedules/PostTrainingSchedules/AVG/8bitAsymmetricUPost.yaml\" -o \"/content/drive/MyDrive/Colab Notebooks/6787 Notebooks/Google Colab Scripts/Schedules/Quantization Schedules/PostTrainingResults\""],"execution_count":7,"outputs":[{"output_type":"stream","text":["Log file for this run: /content/drive/.shortcut-targets-by-id/14_4ehU2lLHHu6HAFmEenl_iXGrCYtNmi/Google Colab Scripts/Schedules/Quantization Schedules/PostTrainingResults/2020.12.08-210451/2020.12.08-210451.log\n","Random seed: 0\n","\n","--------------------------------------------------------\n","Logging to TensorBoard - remember to execute the server:\n","> tensorboard --logdir='./logs'\n","\n","=> created a resnet56_cifar model with the cifar10 dataset\n","The \"--resume\" flag is deprecated. Please use \"--resume-from=YOUR_PATH\" instead.\n","If you wish to also reset the optimizer, call with: --reset-optimizer\n","=> loading checkpoint baseResnet56\n","=> Checkpoint contents:\n","+----------------------+--------+----------------+\n","| Key                  | Type   | Value          |\n","|----------------------+--------+----------------|\n","| arch                 | str    | resnet56_cifar |\n","| compression_sched    | dict   |                |\n","| dataset              | str    | cifar10        |\n","| epoch                | int    | 127            |\n","| extras               | dict   |                |\n","| is_parallel          | bool   | True           |\n","| optimizer            | type   | SGD            |\n","| optimizer_state_dict | dict   |                |\n","| state_dict           | dict   |                |\n","+----------------------+--------+----------------+\n","\n","=> Checkpoint['extras'] contents:\n","+--------------+--------+---------+\n","| Key          | Type   |   Value |\n","|--------------+--------+---------|\n","| best_epoch   | int    |  127    |\n","| best_top1    | float  |   92.94 |\n","| current_top1 | float  |   92.94 |\n","+--------------+--------+---------+\n","\n","Loaded compression schedule from checkpoint (epoch 127)\n","Optimizer could not be loaded from checkpoint.\n","=> loaded checkpoint 'baseResnet56' (epoch 127)\n","Files already downloaded and verified\n","Dataset sizes:\n","\ttest=10000\n","Reading configuration from: /content/drive/MyDrive/Colab Notebooks/6787 Notebooks/Google Colab Scripts/Schedules/Quantization Schedules/PostTrainingSchedules/AVG/8bitAsymmetricUPost.yaml\n","Found component of class PostTrainLinearQuantizer: Name: linear_quantizer ; Section: quantizers\n","Loading activation stats from: /content/drive/MyDrive/Colab Notebooks/6787 Notebooks/Google Colab Scripts/Schedules/Quantization Schedules/acts_quantization_stats.yaml\n","Preparing model for quantization using PostTrainLinearQuantizer\n","Applying batch-norm folding ahead of post-training quantization\n","Propagating output statistics from BN modules to folded modules\n","Optimizing output statistics for modules followed by ReLU/Tanh/Sigmoid\n","Updated stats saved to /content/drive/MyDrive/Colab Notebooks/6787 Notebooks/Google Colab Scripts/Schedules/Quantization Schedules/PostTrainingResults/2020.12.08-210451/quant_stats_after_prepare_model.yaml\n","Per-layer quantization parameters saved to /content/drive/MyDrive/Colab Notebooks/6787 Notebooks/Google Colab Scripts/Schedules/Quantization Schedules/PostTrainingResults/2020.12.08-210451/layer_quant_params.yaml\n","--- test ---------------------\n","10000 samples (256 per mini-batch)\n","Test: [   10/   39]    Loss 0.368234    Top1 92.148438    Top5 99.882812    \n","Test: [   20/   39]    Loss 0.362175    Top1 92.187500    Top5 99.843750    \n","Test: [   30/   39]    Loss 0.336519    Top1 92.747396    Top5 99.817708    \n","Test: [   40/   39]    Loss 0.332852    Top1 92.790000    Top5 99.820000    \n","==> Top1: 92.790    Top5: 99.820    Loss: 0.333\n","\n","Saving checkpoint to: /content/drive/MyDrive/Colab Notebooks/6787 Notebooks/Google Colab Scripts/Schedules/Quantization Schedules/PostTrainingResults/2020.12.08-210451/quantized_checkpoint.pth.tar\n","\n","Log file for this run: /content/drive/.shortcut-targets-by-id/14_4ehU2lLHHu6HAFmEenl_iXGrCYtNmi/Google Colab Scripts/Schedules/Quantization Schedules/PostTrainingResults/2020.12.08-210451/2020.12.08-210451.log\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"9D3UOg412-aj","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1607461531664,"user_tz":300,"elapsed":107009,"user":{"displayName":"Michele L","photoUrl":"","userId":"03726718545613636685"}},"outputId":"091bf383-e0bd-4c6b-f6c6-261324e78af4"},"source":["!python3 \"/content/distiller/examples/classifier_compression/compress_classifier.py\" --arch resnet56_cifar -p 10 ./data --resume=\"baseResnet56\" --out-dir \"/content/drive/MyDrive/Colab Notebooks/6787 Notebooks/Google Colab Scripts/Schedules/Quantization Schedules/PostTrainingResults\" --evaluate --quantize-eval --qe-config-file \"/content/drive/MyDrive/Colab Notebooks/6787 Notebooks/Google Colab Scripts/Schedules/Quantization Schedules/PostTrainingSchedules/AVG/10bitAsymmetricUPost.yaml\" -o \"/content/drive/MyDrive/Colab Notebooks/6787 Notebooks/Google Colab Scripts/Schedules/Quantization Schedules/PostTrainingResults\""],"execution_count":8,"outputs":[{"output_type":"stream","text":["Log file for this run: /content/drive/.shortcut-targets-by-id/14_4ehU2lLHHu6HAFmEenl_iXGrCYtNmi/Google Colab Scripts/Schedules/Quantization Schedules/PostTrainingResults/2020.12.08-210513/2020.12.08-210513.log\n","Random seed: 0\n","\n","--------------------------------------------------------\n","Logging to TensorBoard - remember to execute the server:\n","> tensorboard --logdir='./logs'\n","\n","=> created a resnet56_cifar model with the cifar10 dataset\n","The \"--resume\" flag is deprecated. Please use \"--resume-from=YOUR_PATH\" instead.\n","If you wish to also reset the optimizer, call with: --reset-optimizer\n","=> loading checkpoint baseResnet56\n","=> Checkpoint contents:\n","+----------------------+--------+----------------+\n","| Key                  | Type   | Value          |\n","|----------------------+--------+----------------|\n","| arch                 | str    | resnet56_cifar |\n","| compression_sched    | dict   |                |\n","| dataset              | str    | cifar10        |\n","| epoch                | int    | 127            |\n","| extras               | dict   |                |\n","| is_parallel          | bool   | True           |\n","| optimizer            | type   | SGD            |\n","| optimizer_state_dict | dict   |                |\n","| state_dict           | dict   |                |\n","+----------------------+--------+----------------+\n","\n","=> Checkpoint['extras'] contents:\n","+--------------+--------+---------+\n","| Key          | Type   |   Value |\n","|--------------+--------+---------|\n","| best_epoch   | int    |  127    |\n","| best_top1    | float  |   92.94 |\n","| current_top1 | float  |   92.94 |\n","+--------------+--------+---------+\n","\n","Loaded compression schedule from checkpoint (epoch 127)\n","Optimizer could not be loaded from checkpoint.\n","=> loaded checkpoint 'baseResnet56' (epoch 127)\n","Files already downloaded and verified\n","Dataset sizes:\n","\ttest=10000\n","Reading configuration from: /content/drive/MyDrive/Colab Notebooks/6787 Notebooks/Google Colab Scripts/Schedules/Quantization Schedules/PostTrainingSchedules/AVG/10bitAsymmetricUPost.yaml\n","Found component of class PostTrainLinearQuantizer: Name: linear_quantizer ; Section: quantizers\n","Loading activation stats from: /content/drive/MyDrive/Colab Notebooks/6787 Notebooks/Google Colab Scripts/Schedules/Quantization Schedules/acts_quantization_stats.yaml\n","Preparing model for quantization using PostTrainLinearQuantizer\n","Applying batch-norm folding ahead of post-training quantization\n","Propagating output statistics from BN modules to folded modules\n","Optimizing output statistics for modules followed by ReLU/Tanh/Sigmoid\n","Updated stats saved to /content/drive/MyDrive/Colab Notebooks/6787 Notebooks/Google Colab Scripts/Schedules/Quantization Schedules/PostTrainingResults/2020.12.08-210513/quant_stats_after_prepare_model.yaml\n","Per-layer quantization parameters saved to /content/drive/MyDrive/Colab Notebooks/6787 Notebooks/Google Colab Scripts/Schedules/Quantization Schedules/PostTrainingResults/2020.12.08-210513/layer_quant_params.yaml\n","--- test ---------------------\n","10000 samples (256 per mini-batch)\n","Test: [   10/   39]    Loss 0.366242    Top1 92.070312    Top5 99.843750    \n","Test: [   20/   39]    Loss 0.360968    Top1 92.167969    Top5 99.824219    \n","Test: [   30/   39]    Loss 0.334908    Top1 92.695312    Top5 99.804688    \n","Test: [   40/   39]    Loss 0.331230    Top1 92.750000    Top5 99.800000    \n","==> Top1: 92.750    Top5: 99.800    Loss: 0.331\n","\n","Saving checkpoint to: /content/drive/MyDrive/Colab Notebooks/6787 Notebooks/Google Colab Scripts/Schedules/Quantization Schedules/PostTrainingResults/2020.12.08-210513/quantized_checkpoint.pth.tar\n","\n","Log file for this run: /content/drive/.shortcut-targets-by-id/14_4ehU2lLHHu6HAFmEenl_iXGrCYtNmi/Google Colab Scripts/Schedules/Quantization Schedules/PostTrainingResults/2020.12.08-210513/2020.12.08-210513.log\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"F5s0UIn83GXu","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1607461554173,"user_tz":300,"elapsed":129514,"user":{"displayName":"Michele L","photoUrl":"","userId":"03726718545613636685"}},"outputId":"89a3a737-3aca-4834-e237-3b1cc3dfb429"},"source":["!python3 \"/content/distiller/examples/classifier_compression/compress_classifier.py\" --arch resnet56_cifar -p 10 ./data --resume=\"baseResnet56\" --out-dir \"/content/drive/MyDrive/Colab Notebooks/6787 Notebooks/Google Colab Scripts/Schedules/Quantization Schedules/PostTrainingResults\" --evaluate --quantize-eval --qe-config-file \"/content/drive/MyDrive/Colab Notebooks/6787 Notebooks/Google Colab Scripts/Schedules/Quantization Schedules/PostTrainingSchedules/AVG/12bitAsymmetricUPost.yaml\" -o \"/content/drive/MyDrive/Colab Notebooks/6787 Notebooks/Google Colab Scripts/Schedules/Quantization Schedules/PostTrainingResults\""],"execution_count":9,"outputs":[{"output_type":"stream","text":["Log file for this run: /content/drive/.shortcut-targets-by-id/14_4ehU2lLHHu6HAFmEenl_iXGrCYtNmi/Google Colab Scripts/Schedules/Quantization Schedules/PostTrainingResults/2020.12.08-210535/2020.12.08-210535.log\n","Random seed: 0\n","\n","--------------------------------------------------------\n","Logging to TensorBoard - remember to execute the server:\n","> tensorboard --logdir='./logs'\n","\n","=> created a resnet56_cifar model with the cifar10 dataset\n","The \"--resume\" flag is deprecated. Please use \"--resume-from=YOUR_PATH\" instead.\n","If you wish to also reset the optimizer, call with: --reset-optimizer\n","=> loading checkpoint baseResnet56\n","=> Checkpoint contents:\n","+----------------------+--------+----------------+\n","| Key                  | Type   | Value          |\n","|----------------------+--------+----------------|\n","| arch                 | str    | resnet56_cifar |\n","| compression_sched    | dict   |                |\n","| dataset              | str    | cifar10        |\n","| epoch                | int    | 127            |\n","| extras               | dict   |                |\n","| is_parallel          | bool   | True           |\n","| optimizer            | type   | SGD            |\n","| optimizer_state_dict | dict   |                |\n","| state_dict           | dict   |                |\n","+----------------------+--------+----------------+\n","\n","=> Checkpoint['extras'] contents:\n","+--------------+--------+---------+\n","| Key          | Type   |   Value |\n","|--------------+--------+---------|\n","| best_epoch   | int    |  127    |\n","| best_top1    | float  |   92.94 |\n","| current_top1 | float  |   92.94 |\n","+--------------+--------+---------+\n","\n","Loaded compression schedule from checkpoint (epoch 127)\n","Optimizer could not be loaded from checkpoint.\n","=> loaded checkpoint 'baseResnet56' (epoch 127)\n","Files already downloaded and verified\n","Dataset sizes:\n","\ttest=10000\n","Reading configuration from: /content/drive/MyDrive/Colab Notebooks/6787 Notebooks/Google Colab Scripts/Schedules/Quantization Schedules/PostTrainingSchedules/AVG/12bitAsymmetricUPost.yaml\n","Found component of class PostTrainLinearQuantizer: Name: linear_quantizer ; Section: quantizers\n","Loading activation stats from: /content/drive/MyDrive/Colab Notebooks/6787 Notebooks/Google Colab Scripts/Schedules/Quantization Schedules/acts_quantization_stats.yaml\n","Preparing model for quantization using PostTrainLinearQuantizer\n","Applying batch-norm folding ahead of post-training quantization\n","Propagating output statistics from BN modules to folded modules\n","Optimizing output statistics for modules followed by ReLU/Tanh/Sigmoid\n","Updated stats saved to /content/drive/MyDrive/Colab Notebooks/6787 Notebooks/Google Colab Scripts/Schedules/Quantization Schedules/PostTrainingResults/2020.12.08-210535/quant_stats_after_prepare_model.yaml\n","Per-layer quantization parameters saved to /content/drive/MyDrive/Colab Notebooks/6787 Notebooks/Google Colab Scripts/Schedules/Quantization Schedules/PostTrainingResults/2020.12.08-210535/layer_quant_params.yaml\n","--- test ---------------------\n","10000 samples (256 per mini-batch)\n","Test: [   10/   39]    Loss 0.366625    Top1 92.109375    Top5 99.843750    \n","Test: [   20/   39]    Loss 0.361386    Top1 92.187500    Top5 99.843750    \n","Test: [   30/   39]    Loss 0.335171    Top1 92.682292    Top5 99.817708    \n","Test: [   40/   39]    Loss 0.331545    Top1 92.770000    Top5 99.820000    \n","==> Top1: 92.770    Top5: 99.820    Loss: 0.332\n","\n","Saving checkpoint to: /content/drive/MyDrive/Colab Notebooks/6787 Notebooks/Google Colab Scripts/Schedules/Quantization Schedules/PostTrainingResults/2020.12.08-210535/quantized_checkpoint.pth.tar\n","\n","Log file for this run: /content/drive/.shortcut-targets-by-id/14_4ehU2lLHHu6HAFmEenl_iXGrCYtNmi/Google Colab Scripts/Schedules/Quantization Schedules/PostTrainingResults/2020.12.08-210535/2020.12.08-210535.log\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"MIY3OFU-3Lmk","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1607461576334,"user_tz":300,"elapsed":151672,"user":{"displayName":"Michele L","photoUrl":"","userId":"03726718545613636685"}},"outputId":"8cd619a1-7501-4072-8781-786418bf2a14"},"source":["!python3 \"/content/distiller/examples/classifier_compression/compress_classifier.py\" --arch resnet56_cifar -p 10 ./data --resume=\"baseResnet56\" --out-dir \"/content/drive/MyDrive/Colab Notebooks/6787 Notebooks/Google Colab Scripts/Schedules/Quantization Schedules/PostTrainingResults\" --evaluate --quantize-eval --qe-config-file \"/content/drive/MyDrive/Colab Notebooks/6787 Notebooks/Google Colab Scripts/Schedules/Quantization Schedules/PostTrainingSchedules/AVG/14bitAsymmetricUPost.yaml\" -o \"/content/drive/MyDrive/Colab Notebooks/6787 Notebooks/Google Colab Scripts/Schedules/Quantization Schedules/PostTrainingResults\""],"execution_count":10,"outputs":[{"output_type":"stream","text":["Log file for this run: /content/drive/.shortcut-targets-by-id/14_4ehU2lLHHu6HAFmEenl_iXGrCYtNmi/Google Colab Scripts/Schedules/Quantization Schedules/PostTrainingResults/2020.12.08-210557/2020.12.08-210557.log\n","Random seed: 0\n","\n","--------------------------------------------------------\n","Logging to TensorBoard - remember to execute the server:\n","> tensorboard --logdir='./logs'\n","\n","=> created a resnet56_cifar model with the cifar10 dataset\n","The \"--resume\" flag is deprecated. Please use \"--resume-from=YOUR_PATH\" instead.\n","If you wish to also reset the optimizer, call with: --reset-optimizer\n","=> loading checkpoint baseResnet56\n","=> Checkpoint contents:\n","+----------------------+--------+----------------+\n","| Key                  | Type   | Value          |\n","|----------------------+--------+----------------|\n","| arch                 | str    | resnet56_cifar |\n","| compression_sched    | dict   |                |\n","| dataset              | str    | cifar10        |\n","| epoch                | int    | 127            |\n","| extras               | dict   |                |\n","| is_parallel          | bool   | True           |\n","| optimizer            | type   | SGD            |\n","| optimizer_state_dict | dict   |                |\n","| state_dict           | dict   |                |\n","+----------------------+--------+----------------+\n","\n","=> Checkpoint['extras'] contents:\n","+--------------+--------+---------+\n","| Key          | Type   |   Value |\n","|--------------+--------+---------|\n","| best_epoch   | int    |  127    |\n","| best_top1    | float  |   92.94 |\n","| current_top1 | float  |   92.94 |\n","+--------------+--------+---------+\n","\n","Loaded compression schedule from checkpoint (epoch 127)\n","Optimizer could not be loaded from checkpoint.\n","=> loaded checkpoint 'baseResnet56' (epoch 127)\n","Files already downloaded and verified\n","Dataset sizes:\n","\ttest=10000\n","Reading configuration from: /content/drive/MyDrive/Colab Notebooks/6787 Notebooks/Google Colab Scripts/Schedules/Quantization Schedules/PostTrainingSchedules/AVG/14bitAsymmetricUPost.yaml\n","Found component of class PostTrainLinearQuantizer: Name: linear_quantizer ; Section: quantizers\n","Loading activation stats from: /content/drive/MyDrive/Colab Notebooks/6787 Notebooks/Google Colab Scripts/Schedules/Quantization Schedules/acts_quantization_stats.yaml\n","Preparing model for quantization using PostTrainLinearQuantizer\n","Applying batch-norm folding ahead of post-training quantization\n","Propagating output statistics from BN modules to folded modules\n","Optimizing output statistics for modules followed by ReLU/Tanh/Sigmoid\n","Updated stats saved to /content/drive/MyDrive/Colab Notebooks/6787 Notebooks/Google Colab Scripts/Schedules/Quantization Schedules/PostTrainingResults/2020.12.08-210557/quant_stats_after_prepare_model.yaml\n","Per-layer quantization parameters saved to /content/drive/MyDrive/Colab Notebooks/6787 Notebooks/Google Colab Scripts/Schedules/Quantization Schedules/PostTrainingResults/2020.12.08-210557/layer_quant_params.yaml\n","--- test ---------------------\n","10000 samples (256 per mini-batch)\n","Test: [   10/   39]    Loss 0.368973    Top1 92.148438    Top5 99.843750    \n","Test: [   20/   39]    Loss 0.363456    Top1 92.226562    Top5 99.843750    \n","Test: [   30/   39]    Loss 0.336556    Top1 92.773438    Top5 99.817708    \n","Test: [   40/   39]    Loss 0.332657    Top1 92.820000    Top5 99.820000    \n","==> Top1: 92.820    Top5: 99.820    Loss: 0.333\n","\n","Saving checkpoint to: /content/drive/MyDrive/Colab Notebooks/6787 Notebooks/Google Colab Scripts/Schedules/Quantization Schedules/PostTrainingResults/2020.12.08-210557/quantized_checkpoint.pth.tar\n","\n","Log file for this run: /content/drive/.shortcut-targets-by-id/14_4ehU2lLHHu6HAFmEenl_iXGrCYtNmi/Google Colab Scripts/Schedules/Quantization Schedules/PostTrainingResults/2020.12.08-210557/2020.12.08-210557.log\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"R6ZJGnEM3IAA","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1607461598371,"user_tz":300,"elapsed":173706,"user":{"displayName":"Michele L","photoUrl":"","userId":"03726718545613636685"}},"outputId":"060b7c5c-b883-44c6-95bd-508cad9e4438"},"source":["!python3 \"/content/distiller/examples/classifier_compression/compress_classifier.py\" --arch resnet56_cifar -p 10 ./data --resume=\"baseResnet56\" --out-dir \"/content/drive/MyDrive/Colab Notebooks/6787 Notebooks/Google Colab Scripts/Schedules/Quantization Schedules/PostTrainingResults\" --evaluate --quantize-eval --qe-config-file \"/content/drive/MyDrive/Colab Notebooks/6787 Notebooks/Google Colab Scripts/Schedules/Quantization Schedules/PostTrainingSchedules/AVG/16bitAsymmetricUPost.yaml\" -o \"/content/drive/MyDrive/Colab Notebooks/6787 Notebooks/Google Colab Scripts/Schedules/Quantization Schedules/PostTrainingResults\""],"execution_count":11,"outputs":[{"output_type":"stream","text":["Log file for this run: /content/drive/.shortcut-targets-by-id/14_4ehU2lLHHu6HAFmEenl_iXGrCYtNmi/Google Colab Scripts/Schedules/Quantization Schedules/PostTrainingResults/2020.12.08-210620/2020.12.08-210620.log\n","Random seed: 0\n","\n","--------------------------------------------------------\n","Logging to TensorBoard - remember to execute the server:\n","> tensorboard --logdir='./logs'\n","\n","=> created a resnet56_cifar model with the cifar10 dataset\n","The \"--resume\" flag is deprecated. Please use \"--resume-from=YOUR_PATH\" instead.\n","If you wish to also reset the optimizer, call with: --reset-optimizer\n","=> loading checkpoint baseResnet56\n","=> Checkpoint contents:\n","+----------------------+--------+----------------+\n","| Key                  | Type   | Value          |\n","|----------------------+--------+----------------|\n","| arch                 | str    | resnet56_cifar |\n","| compression_sched    | dict   |                |\n","| dataset              | str    | cifar10        |\n","| epoch                | int    | 127            |\n","| extras               | dict   |                |\n","| is_parallel          | bool   | True           |\n","| optimizer            | type   | SGD            |\n","| optimizer_state_dict | dict   |                |\n","| state_dict           | dict   |                |\n","+----------------------+--------+----------------+\n","\n","=> Checkpoint['extras'] contents:\n","+--------------+--------+---------+\n","| Key          | Type   |   Value |\n","|--------------+--------+---------|\n","| best_epoch   | int    |  127    |\n","| best_top1    | float  |   92.94 |\n","| current_top1 | float  |   92.94 |\n","+--------------+--------+---------+\n","\n","Loaded compression schedule from checkpoint (epoch 127)\n","Optimizer could not be loaded from checkpoint.\n","=> loaded checkpoint 'baseResnet56' (epoch 127)\n","Files already downloaded and verified\n","Dataset sizes:\n","\ttest=10000\n","Reading configuration from: /content/drive/MyDrive/Colab Notebooks/6787 Notebooks/Google Colab Scripts/Schedules/Quantization Schedules/PostTrainingSchedules/AVG/16bitAsymmetricUPost.yaml\n","Found component of class PostTrainLinearQuantizer: Name: linear_quantizer ; Section: quantizers\n","Loading activation stats from: /content/drive/MyDrive/Colab Notebooks/6787 Notebooks/Google Colab Scripts/Schedules/Quantization Schedules/acts_quantization_stats.yaml\n","Preparing model for quantization using PostTrainLinearQuantizer\n","Applying batch-norm folding ahead of post-training quantization\n","Propagating output statistics from BN modules to folded modules\n","Optimizing output statistics for modules followed by ReLU/Tanh/Sigmoid\n","Updated stats saved to /content/drive/MyDrive/Colab Notebooks/6787 Notebooks/Google Colab Scripts/Schedules/Quantization Schedules/PostTrainingResults/2020.12.08-210620/quant_stats_after_prepare_model.yaml\n","Per-layer quantization parameters saved to /content/drive/MyDrive/Colab Notebooks/6787 Notebooks/Google Colab Scripts/Schedules/Quantization Schedules/PostTrainingResults/2020.12.08-210620/layer_quant_params.yaml\n","--- test ---------------------\n","10000 samples (256 per mini-batch)\n","Test: [   10/   39]    Loss 2.085341    Top1 29.765625    Top5 86.093750    \n","Test: [   20/   39]    Loss 2.071349    Top1 30.917969    Top5 86.562500    \n","Test: [   30/   39]    Loss 2.063255    Top1 31.302083    Top5 86.575521    \n","Test: [   40/   39]    Loss 2.045447    Top1 31.340000    Top5 86.760000    \n","==> Top1: 31.340    Top5: 86.760    Loss: 2.045\n","\n","Saving checkpoint to: /content/drive/MyDrive/Colab Notebooks/6787 Notebooks/Google Colab Scripts/Schedules/Quantization Schedules/PostTrainingResults/2020.12.08-210620/quantized_checkpoint.pth.tar\n","\n","Log file for this run: /content/drive/.shortcut-targets-by-id/14_4ehU2lLHHu6HAFmEenl_iXGrCYtNmi/Google Colab Scripts/Schedules/Quantization Schedules/PostTrainingResults/2020.12.08-210620/2020.12.08-210620.log\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"zBVfYUf_1PKM"},"source":["Asymetric S"]},{"cell_type":"code","metadata":{"id":"nI5gRrst3OLJ","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1607461620690,"user_tz":300,"elapsed":196022,"user":{"displayName":"Michele L","photoUrl":"","userId":"03726718545613636685"}},"outputId":"0e56bd81-b688-4182-c724-286426eed8dd"},"source":["!python3 \"/content/distiller/examples/classifier_compression/compress_classifier.py\" --arch resnet56_cifar -p 10 ./data --resume=\"baseResnet56\" --out-dir \"/content/drive/MyDrive/Colab Notebooks/6787 Notebooks/Google Colab Scripts/Schedules/Quantization Schedules/PostTrainingResults\" --evaluate --quantize-eval --qe-config-file \"/content/drive/MyDrive/Colab Notebooks/6787 Notebooks/Google Colab Scripts/Schedules/Quantization Schedules/PostTrainingSchedules/AVG/4bitAsymmetricSPost.yaml\" -o \"/content/drive/MyDrive/Colab Notebooks/6787 Notebooks/Google Colab Scripts/Schedules/Quantization Schedules/PostTrainingResults\""],"execution_count":12,"outputs":[{"output_type":"stream","text":["Log file for this run: /content/drive/.shortcut-targets-by-id/14_4ehU2lLHHu6HAFmEenl_iXGrCYtNmi/Google Colab Scripts/Schedules/Quantization Schedules/PostTrainingResults/2020.12.08-210642/2020.12.08-210642.log\n","Random seed: 0\n","\n","--------------------------------------------------------\n","Logging to TensorBoard - remember to execute the server:\n","> tensorboard --logdir='./logs'\n","\n","=> created a resnet56_cifar model with the cifar10 dataset\n","The \"--resume\" flag is deprecated. Please use \"--resume-from=YOUR_PATH\" instead.\n","If you wish to also reset the optimizer, call with: --reset-optimizer\n","=> loading checkpoint baseResnet56\n","=> Checkpoint contents:\n","+----------------------+--------+----------------+\n","| Key                  | Type   | Value          |\n","|----------------------+--------+----------------|\n","| arch                 | str    | resnet56_cifar |\n","| compression_sched    | dict   |                |\n","| dataset              | str    | cifar10        |\n","| epoch                | int    | 127            |\n","| extras               | dict   |                |\n","| is_parallel          | bool   | True           |\n","| optimizer            | type   | SGD            |\n","| optimizer_state_dict | dict   |                |\n","| state_dict           | dict   |                |\n","+----------------------+--------+----------------+\n","\n","=> Checkpoint['extras'] contents:\n","+--------------+--------+---------+\n","| Key          | Type   |   Value |\n","|--------------+--------+---------|\n","| best_epoch   | int    |  127    |\n","| best_top1    | float  |   92.94 |\n","| current_top1 | float  |   92.94 |\n","+--------------+--------+---------+\n","\n","Loaded compression schedule from checkpoint (epoch 127)\n","Optimizer could not be loaded from checkpoint.\n","=> loaded checkpoint 'baseResnet56' (epoch 127)\n","Files already downloaded and verified\n","Dataset sizes:\n","\ttest=10000\n","Reading configuration from: /content/drive/MyDrive/Colab Notebooks/6787 Notebooks/Google Colab Scripts/Schedules/Quantization Schedules/PostTrainingSchedules/AVG/4bitAsymmetricSPost.yaml\n","Found component of class PostTrainLinearQuantizer: Name: linear_quantizer ; Section: quantizers\n","Loading activation stats from: /content/drive/MyDrive/Colab Notebooks/6787 Notebooks/Google Colab Scripts/Schedules/Quantization Schedules/acts_quantization_stats.yaml\n","Preparing model for quantization using PostTrainLinearQuantizer\n","Applying batch-norm folding ahead of post-training quantization\n","Propagating output statistics from BN modules to folded modules\n","Optimizing output statistics for modules followed by ReLU/Tanh/Sigmoid\n","Updated stats saved to /content/drive/MyDrive/Colab Notebooks/6787 Notebooks/Google Colab Scripts/Schedules/Quantization Schedules/PostTrainingResults/2020.12.08-210642/quant_stats_after_prepare_model.yaml\n","Per-layer quantization parameters saved to /content/drive/MyDrive/Colab Notebooks/6787 Notebooks/Google Colab Scripts/Schedules/Quantization Schedules/PostTrainingResults/2020.12.08-210642/layer_quant_params.yaml\n","--- test ---------------------\n","10000 samples (256 per mini-batch)\n","Test: [   10/   39]    Loss 1.793450    Top1 67.812500    Top5 96.250000    \n","Test: [   20/   39]    Loss 1.737904    Top1 68.496094    Top5 96.445312    \n","Test: [   30/   39]    Loss 1.689005    Top1 69.322917    Top5 96.627604    \n","Test: [   40/   39]    Loss 1.679233    Top1 69.660000    Top5 96.590000    \n","==> Top1: 69.660    Top5: 96.590    Loss: 1.679\n","\n","Saving checkpoint to: /content/drive/MyDrive/Colab Notebooks/6787 Notebooks/Google Colab Scripts/Schedules/Quantization Schedules/PostTrainingResults/2020.12.08-210642/quantized_checkpoint.pth.tar\n","\n","Log file for this run: /content/drive/.shortcut-targets-by-id/14_4ehU2lLHHu6HAFmEenl_iXGrCYtNmi/Google Colab Scripts/Schedules/Quantization Schedules/PostTrainingResults/2020.12.08-210642/2020.12.08-210642.log\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"oxMatIUv3SEh","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1607461642571,"user_tz":300,"elapsed":217901,"user":{"displayName":"Michele L","photoUrl":"","userId":"03726718545613636685"}},"outputId":"ed0f84df-c8bf-4db6-feaf-5f075b02caa9"},"source":["!python3 \"/content/distiller/examples/classifier_compression/compress_classifier.py\" --arch resnet56_cifar -p 10 ./data --resume=\"baseResnet56\" --out-dir \"/content/drive/MyDrive/Colab Notebooks/6787 Notebooks/Google Colab Scripts/Schedules/Quantization Schedules/PostTrainingResults\" --evaluate --quantize-eval --qe-config-file \"/content/drive/MyDrive/Colab Notebooks/6787 Notebooks/Google Colab Scripts/Schedules/Quantization Schedules/PostTrainingSchedules/AVG/6bitAsymmetricSPost.yaml\" -o \"/content/drive/MyDrive/Colab Notebooks/6787 Notebooks/Google Colab Scripts/Schedules/Quantization Schedules/PostTrainingResults\""],"execution_count":13,"outputs":[{"output_type":"stream","text":["Log file for this run: /content/drive/.shortcut-targets-by-id/14_4ehU2lLHHu6HAFmEenl_iXGrCYtNmi/Google Colab Scripts/Schedules/Quantization Schedules/PostTrainingResults/2020.12.08-210704/2020.12.08-210704.log\n","Random seed: 0\n","\n","--------------------------------------------------------\n","Logging to TensorBoard - remember to execute the server:\n","> tensorboard --logdir='./logs'\n","\n","=> created a resnet56_cifar model with the cifar10 dataset\n","The \"--resume\" flag is deprecated. Please use \"--resume-from=YOUR_PATH\" instead.\n","If you wish to also reset the optimizer, call with: --reset-optimizer\n","=> loading checkpoint baseResnet56\n","=> Checkpoint contents:\n","+----------------------+--------+----------------+\n","| Key                  | Type   | Value          |\n","|----------------------+--------+----------------|\n","| arch                 | str    | resnet56_cifar |\n","| compression_sched    | dict   |                |\n","| dataset              | str    | cifar10        |\n","| epoch                | int    | 127            |\n","| extras               | dict   |                |\n","| is_parallel          | bool   | True           |\n","| optimizer            | type   | SGD            |\n","| optimizer_state_dict | dict   |                |\n","| state_dict           | dict   |                |\n","+----------------------+--------+----------------+\n","\n","=> Checkpoint['extras'] contents:\n","+--------------+--------+---------+\n","| Key          | Type   |   Value |\n","|--------------+--------+---------|\n","| best_epoch   | int    |  127    |\n","| best_top1    | float  |   92.94 |\n","| current_top1 | float  |   92.94 |\n","+--------------+--------+---------+\n","\n","Loaded compression schedule from checkpoint (epoch 127)\n","Optimizer could not be loaded from checkpoint.\n","=> loaded checkpoint 'baseResnet56' (epoch 127)\n","Files already downloaded and verified\n","Dataset sizes:\n","\ttest=10000\n","Reading configuration from: /content/drive/MyDrive/Colab Notebooks/6787 Notebooks/Google Colab Scripts/Schedules/Quantization Schedules/PostTrainingSchedules/AVG/6bitAsymmetricSPost.yaml\n","Found component of class PostTrainLinearQuantizer: Name: linear_quantizer ; Section: quantizers\n","Loading activation stats from: /content/drive/MyDrive/Colab Notebooks/6787 Notebooks/Google Colab Scripts/Schedules/Quantization Schedules/acts_quantization_stats.yaml\n","Preparing model for quantization using PostTrainLinearQuantizer\n","Applying batch-norm folding ahead of post-training quantization\n","Propagating output statistics from BN modules to folded modules\n","Optimizing output statistics for modules followed by ReLU/Tanh/Sigmoid\n","Updated stats saved to /content/drive/MyDrive/Colab Notebooks/6787 Notebooks/Google Colab Scripts/Schedules/Quantization Schedules/PostTrainingResults/2020.12.08-210704/quant_stats_after_prepare_model.yaml\n","Per-layer quantization parameters saved to /content/drive/MyDrive/Colab Notebooks/6787 Notebooks/Google Colab Scripts/Schedules/Quantization Schedules/PostTrainingResults/2020.12.08-210704/layer_quant_params.yaml\n","--- test ---------------------\n","10000 samples (256 per mini-batch)\n","Test: [   10/   39]    Loss 0.405499    Top1 91.132812    Top5 99.765625    \n","Test: [   20/   39]    Loss 0.402944    Top1 91.464844    Top5 99.765625    \n","Test: [   30/   39]    Loss 0.373307    Top1 91.888021    Top5 99.726562    \n","Test: [   40/   39]    Loss 0.371291    Top1 91.960000    Top5 99.720000    \n","==> Top1: 91.960    Top5: 99.720    Loss: 0.371\n","\n","Saving checkpoint to: /content/drive/MyDrive/Colab Notebooks/6787 Notebooks/Google Colab Scripts/Schedules/Quantization Schedules/PostTrainingResults/2020.12.08-210704/quantized_checkpoint.pth.tar\n","\n","Log file for this run: /content/drive/.shortcut-targets-by-id/14_4ehU2lLHHu6HAFmEenl_iXGrCYtNmi/Google Colab Scripts/Schedules/Quantization Schedules/PostTrainingResults/2020.12.08-210704/2020.12.08-210704.log\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"-1-q7Mr53SJV","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1607461664704,"user_tz":300,"elapsed":240031,"user":{"displayName":"Michele L","photoUrl":"","userId":"03726718545613636685"}},"outputId":"dca59c86-bf2e-490e-a979-2354893e7efe"},"source":["!python3 \"/content/distiller/examples/classifier_compression/compress_classifier.py\" --arch resnet56_cifar -p 10 ./data --resume=\"baseResnet56\" --out-dir \"/content/drive/MyDrive/Colab Notebooks/6787 Notebooks/Google Colab Scripts/Schedules/Quantization Schedules/PostTrainingResults\" --evaluate --quantize-eval --qe-config-file \"/content/drive/MyDrive/Colab Notebooks/6787 Notebooks/Google Colab Scripts/Schedules/Quantization Schedules/PostTrainingSchedules/AVG/8bitAsymmetricSPost.yaml\" -o \"/content/drive/MyDrive/Colab Notebooks/6787 Notebooks/Google Colab Scripts/Schedules/Quantization Schedules/PostTrainingResults\""],"execution_count":14,"outputs":[{"output_type":"stream","text":["Log file for this run: /content/drive/.shortcut-targets-by-id/14_4ehU2lLHHu6HAFmEenl_iXGrCYtNmi/Google Colab Scripts/Schedules/Quantization Schedules/PostTrainingResults/2020.12.08-210726/2020.12.08-210726.log\n","Random seed: 0\n","\n","--------------------------------------------------------\n","Logging to TensorBoard - remember to execute the server:\n","> tensorboard --logdir='./logs'\n","\n","=> created a resnet56_cifar model with the cifar10 dataset\n","The \"--resume\" flag is deprecated. Please use \"--resume-from=YOUR_PATH\" instead.\n","If you wish to also reset the optimizer, call with: --reset-optimizer\n","=> loading checkpoint baseResnet56\n","=> Checkpoint contents:\n","+----------------------+--------+----------------+\n","| Key                  | Type   | Value          |\n","|----------------------+--------+----------------|\n","| arch                 | str    | resnet56_cifar |\n","| compression_sched    | dict   |                |\n","| dataset              | str    | cifar10        |\n","| epoch                | int    | 127            |\n","| extras               | dict   |                |\n","| is_parallel          | bool   | True           |\n","| optimizer            | type   | SGD            |\n","| optimizer_state_dict | dict   |                |\n","| state_dict           | dict   |                |\n","+----------------------+--------+----------------+\n","\n","=> Checkpoint['extras'] contents:\n","+--------------+--------+---------+\n","| Key          | Type   |   Value |\n","|--------------+--------+---------|\n","| best_epoch   | int    |  127    |\n","| best_top1    | float  |   92.94 |\n","| current_top1 | float  |   92.94 |\n","+--------------+--------+---------+\n","\n","Loaded compression schedule from checkpoint (epoch 127)\n","Optimizer could not be loaded from checkpoint.\n","=> loaded checkpoint 'baseResnet56' (epoch 127)\n","Files already downloaded and verified\n","Dataset sizes:\n","\ttest=10000\n","Reading configuration from: /content/drive/MyDrive/Colab Notebooks/6787 Notebooks/Google Colab Scripts/Schedules/Quantization Schedules/PostTrainingSchedules/AVG/8bitAsymmetricSPost.yaml\n","Found component of class PostTrainLinearQuantizer: Name: linear_quantizer ; Section: quantizers\n","Loading activation stats from: /content/drive/MyDrive/Colab Notebooks/6787 Notebooks/Google Colab Scripts/Schedules/Quantization Schedules/acts_quantization_stats.yaml\n","Preparing model for quantization using PostTrainLinearQuantizer\n","Applying batch-norm folding ahead of post-training quantization\n","Propagating output statistics from BN modules to folded modules\n","Optimizing output statistics for modules followed by ReLU/Tanh/Sigmoid\n","Updated stats saved to /content/drive/MyDrive/Colab Notebooks/6787 Notebooks/Google Colab Scripts/Schedules/Quantization Schedules/PostTrainingResults/2020.12.08-210726/quant_stats_after_prepare_model.yaml\n","Per-layer quantization parameters saved to /content/drive/MyDrive/Colab Notebooks/6787 Notebooks/Google Colab Scripts/Schedules/Quantization Schedules/PostTrainingResults/2020.12.08-210726/layer_quant_params.yaml\n","--- test ---------------------\n","10000 samples (256 per mini-batch)\n","Test: [   10/   39]    Loss 0.367977    Top1 92.148438    Top5 99.882812    \n","Test: [   20/   39]    Loss 0.362160    Top1 92.226562    Top5 99.843750    \n","Test: [   30/   39]    Loss 0.336818    Top1 92.747396    Top5 99.804688    \n","Test: [   40/   39]    Loss 0.332717    Top1 92.790000    Top5 99.820000    \n","==> Top1: 92.790    Top5: 99.820    Loss: 0.333\n","\n","Saving checkpoint to: /content/drive/MyDrive/Colab Notebooks/6787 Notebooks/Google Colab Scripts/Schedules/Quantization Schedules/PostTrainingResults/2020.12.08-210726/quantized_checkpoint.pth.tar\n","\n","Log file for this run: /content/drive/.shortcut-targets-by-id/14_4ehU2lLHHu6HAFmEenl_iXGrCYtNmi/Google Colab Scripts/Schedules/Quantization Schedules/PostTrainingResults/2020.12.08-210726/2020.12.08-210726.log\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"R5HtqpaE3SM1","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1607461687201,"user_tz":300,"elapsed":262525,"user":{"displayName":"Michele L","photoUrl":"","userId":"03726718545613636685"}},"outputId":"4ac65b27-bd44-4629-abb3-90efc45ce3af"},"source":["!python3 \"/content/distiller/examples/classifier_compression/compress_classifier.py\" --arch resnet56_cifar -p 10 ./data --resume=\"baseResnet56\" --out-dir \"/content/drive/MyDrive/Colab Notebooks/6787 Notebooks/Google Colab Scripts/Schedules/Quantization Schedules/PostTrainingResults\" --evaluate --quantize-eval --qe-config-file \"/content/drive/MyDrive/Colab Notebooks/6787 Notebooks/Google Colab Scripts/Schedules/Quantization Schedules/PostTrainingSchedules/AVG/10bitAsymmetricSPost.yaml\" -o \"/content/drive/MyDrive/Colab Notebooks/6787 Notebooks/Google Colab Scripts/Schedules/Quantization Schedules/PostTrainingResults\""],"execution_count":15,"outputs":[{"output_type":"stream","text":["Log file for this run: /content/drive/.shortcut-targets-by-id/14_4ehU2lLHHu6HAFmEenl_iXGrCYtNmi/Google Colab Scripts/Schedules/Quantization Schedules/PostTrainingResults/2020.12.08-210748/2020.12.08-210748.log\n","Random seed: 0\n","\n","--------------------------------------------------------\n","Logging to TensorBoard - remember to execute the server:\n","> tensorboard --logdir='./logs'\n","\n","=> created a resnet56_cifar model with the cifar10 dataset\n","The \"--resume\" flag is deprecated. Please use \"--resume-from=YOUR_PATH\" instead.\n","If you wish to also reset the optimizer, call with: --reset-optimizer\n","=> loading checkpoint baseResnet56\n","=> Checkpoint contents:\n","+----------------------+--------+----------------+\n","| Key                  | Type   | Value          |\n","|----------------------+--------+----------------|\n","| arch                 | str    | resnet56_cifar |\n","| compression_sched    | dict   |                |\n","| dataset              | str    | cifar10        |\n","| epoch                | int    | 127            |\n","| extras               | dict   |                |\n","| is_parallel          | bool   | True           |\n","| optimizer            | type   | SGD            |\n","| optimizer_state_dict | dict   |                |\n","| state_dict           | dict   |                |\n","+----------------------+--------+----------------+\n","\n","=> Checkpoint['extras'] contents:\n","+--------------+--------+---------+\n","| Key          | Type   |   Value |\n","|--------------+--------+---------|\n","| best_epoch   | int    |  127    |\n","| best_top1    | float  |   92.94 |\n","| current_top1 | float  |   92.94 |\n","+--------------+--------+---------+\n","\n","Loaded compression schedule from checkpoint (epoch 127)\n","Optimizer could not be loaded from checkpoint.\n","=> loaded checkpoint 'baseResnet56' (epoch 127)\n","Files already downloaded and verified\n","Dataset sizes:\n","\ttest=10000\n","Reading configuration from: /content/drive/MyDrive/Colab Notebooks/6787 Notebooks/Google Colab Scripts/Schedules/Quantization Schedules/PostTrainingSchedules/AVG/10bitAsymmetricSPost.yaml\n","Found component of class PostTrainLinearQuantizer: Name: linear_quantizer ; Section: quantizers\n","Loading activation stats from: /content/drive/MyDrive/Colab Notebooks/6787 Notebooks/Google Colab Scripts/Schedules/Quantization Schedules/acts_quantization_stats.yaml\n","Preparing model for quantization using PostTrainLinearQuantizer\n","Applying batch-norm folding ahead of post-training quantization\n","Propagating output statistics from BN modules to folded modules\n","Optimizing output statistics for modules followed by ReLU/Tanh/Sigmoid\n","Updated stats saved to /content/drive/MyDrive/Colab Notebooks/6787 Notebooks/Google Colab Scripts/Schedules/Quantization Schedules/PostTrainingResults/2020.12.08-210748/quant_stats_after_prepare_model.yaml\n","Per-layer quantization parameters saved to /content/drive/MyDrive/Colab Notebooks/6787 Notebooks/Google Colab Scripts/Schedules/Quantization Schedules/PostTrainingResults/2020.12.08-210748/layer_quant_params.yaml\n","--- test ---------------------\n","10000 samples (256 per mini-batch)\n","Test: [   10/   39]    Loss 0.366260    Top1 92.070312    Top5 99.843750    \n","Test: [   20/   39]    Loss 0.361041    Top1 92.167969    Top5 99.824219    \n","Test: [   30/   39]    Loss 0.334998    Top1 92.695312    Top5 99.804688    \n","Test: [   40/   39]    Loss 0.331274    Top1 92.750000    Top5 99.800000    \n","==> Top1: 92.750    Top5: 99.800    Loss: 0.331\n","\n","Saving checkpoint to: /content/drive/MyDrive/Colab Notebooks/6787 Notebooks/Google Colab Scripts/Schedules/Quantization Schedules/PostTrainingResults/2020.12.08-210748/quantized_checkpoint.pth.tar\n","\n","Log file for this run: /content/drive/.shortcut-targets-by-id/14_4ehU2lLHHu6HAFmEenl_iXGrCYtNmi/Google Colab Scripts/Schedules/Quantization Schedules/PostTrainingResults/2020.12.08-210748/2020.12.08-210748.log\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"sVCV7ath3SRB","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1607461710314,"user_tz":300,"elapsed":285635,"user":{"displayName":"Michele L","photoUrl":"","userId":"03726718545613636685"}},"outputId":"034d56d9-a247-43f4-8bf6-2886c18f100e"},"source":["!python3 \"/content/distiller/examples/classifier_compression/compress_classifier.py\" --arch resnet56_cifar -p 10 ./data --resume=\"baseResnet56\" --out-dir \"/content/drive/MyDrive/Colab Notebooks/6787 Notebooks/Google Colab Scripts/Schedules/Quantization Schedules/PostTrainingResults\" --evaluate --quantize-eval --qe-config-file \"/content/drive/MyDrive/Colab Notebooks/6787 Notebooks/Google Colab Scripts/Schedules/Quantization Schedules/PostTrainingSchedules/AVG/12bitAsymmetricSPost.yaml\" -o \"/content/drive/MyDrive/Colab Notebooks/6787 Notebooks/Google Colab Scripts/Schedules/Quantization Schedules/PostTrainingResults\""],"execution_count":16,"outputs":[{"output_type":"stream","text":["Log file for this run: /content/drive/.shortcut-targets-by-id/14_4ehU2lLHHu6HAFmEenl_iXGrCYtNmi/Google Colab Scripts/Schedules/Quantization Schedules/PostTrainingResults/2020.12.08-210811/2020.12.08-210811.log\n","Random seed: 0\n","\n","--------------------------------------------------------\n","Logging to TensorBoard - remember to execute the server:\n","> tensorboard --logdir='./logs'\n","\n","=> created a resnet56_cifar model with the cifar10 dataset\n","The \"--resume\" flag is deprecated. Please use \"--resume-from=YOUR_PATH\" instead.\n","If you wish to also reset the optimizer, call with: --reset-optimizer\n","=> loading checkpoint baseResnet56\n","=> Checkpoint contents:\n","+----------------------+--------+----------------+\n","| Key                  | Type   | Value          |\n","|----------------------+--------+----------------|\n","| arch                 | str    | resnet56_cifar |\n","| compression_sched    | dict   |                |\n","| dataset              | str    | cifar10        |\n","| epoch                | int    | 127            |\n","| extras               | dict   |                |\n","| is_parallel          | bool   | True           |\n","| optimizer            | type   | SGD            |\n","| optimizer_state_dict | dict   |                |\n","| state_dict           | dict   |                |\n","+----------------------+--------+----------------+\n","\n","=> Checkpoint['extras'] contents:\n","+--------------+--------+---------+\n","| Key          | Type   |   Value |\n","|--------------+--------+---------|\n","| best_epoch   | int    |  127    |\n","| best_top1    | float  |   92.94 |\n","| current_top1 | float  |   92.94 |\n","+--------------+--------+---------+\n","\n","Loaded compression schedule from checkpoint (epoch 127)\n","Optimizer could not be loaded from checkpoint.\n","=> loaded checkpoint 'baseResnet56' (epoch 127)\n","Files already downloaded and verified\n","Dataset sizes:\n","\ttest=10000\n","Reading configuration from: /content/drive/MyDrive/Colab Notebooks/6787 Notebooks/Google Colab Scripts/Schedules/Quantization Schedules/PostTrainingSchedules/AVG/12bitAsymmetricSPost.yaml\n","Found component of class PostTrainLinearQuantizer: Name: linear_quantizer ; Section: quantizers\n","Loading activation stats from: /content/drive/MyDrive/Colab Notebooks/6787 Notebooks/Google Colab Scripts/Schedules/Quantization Schedules/acts_quantization_stats.yaml\n","Preparing model for quantization using PostTrainLinearQuantizer\n","Applying batch-norm folding ahead of post-training quantization\n","Propagating output statistics from BN modules to folded modules\n","Optimizing output statistics for modules followed by ReLU/Tanh/Sigmoid\n","Updated stats saved to /content/drive/MyDrive/Colab Notebooks/6787 Notebooks/Google Colab Scripts/Schedules/Quantization Schedules/PostTrainingResults/2020.12.08-210811/quant_stats_after_prepare_model.yaml\n","Per-layer quantization parameters saved to /content/drive/MyDrive/Colab Notebooks/6787 Notebooks/Google Colab Scripts/Schedules/Quantization Schedules/PostTrainingResults/2020.12.08-210811/layer_quant_params.yaml\n","--- test ---------------------\n","10000 samples (256 per mini-batch)\n","Test: [   10/   39]    Loss 0.366677    Top1 92.109375    Top5 99.843750    \n","Test: [   20/   39]    Loss 0.361436    Top1 92.187500    Top5 99.843750    \n","Test: [   30/   39]    Loss 0.335204    Top1 92.708333    Top5 99.817708    \n","Test: [   40/   39]    Loss 0.331565    Top1 92.790000    Top5 99.820000    \n","==> Top1: 92.790    Top5: 99.820    Loss: 0.332\n","\n","Saving checkpoint to: /content/drive/MyDrive/Colab Notebooks/6787 Notebooks/Google Colab Scripts/Schedules/Quantization Schedules/PostTrainingResults/2020.12.08-210811/quantized_checkpoint.pth.tar\n","\n","Log file for this run: /content/drive/.shortcut-targets-by-id/14_4ehU2lLHHu6HAFmEenl_iXGrCYtNmi/Google Colab Scripts/Schedules/Quantization Schedules/PostTrainingResults/2020.12.08-210811/2020.12.08-210811.log\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"3LmG2Vbf3SUS","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1607461732921,"user_tz":300,"elapsed":308237,"user":{"displayName":"Michele L","photoUrl":"","userId":"03726718545613636685"}},"outputId":"c46e9c56-ae12-4a1b-8c0e-14ab1e315c64"},"source":["!python3 \"/content/distiller/examples/classifier_compression/compress_classifier.py\" --arch resnet56_cifar -p 10 ./data --resume=\"baseResnet56\" --out-dir \"/content/drive/MyDrive/Colab Notebooks/6787 Notebooks/Google Colab Scripts/Schedules/Quantization Schedules/PostTrainingResults\" --evaluate --quantize-eval --qe-config-file \"/content/drive/MyDrive/Colab Notebooks/6787 Notebooks/Google Colab Scripts/Schedules/Quantization Schedules/PostTrainingSchedules/AVG/14bitAsymmetricSPost.yaml\" -o \"/content/drive/MyDrive/Colab Notebooks/6787 Notebooks/Google Colab Scripts/Schedules/Quantization Schedules/PostTrainingResults\""],"execution_count":17,"outputs":[{"output_type":"stream","text":["Log file for this run: /content/drive/.shortcut-targets-by-id/14_4ehU2lLHHu6HAFmEenl_iXGrCYtNmi/Google Colab Scripts/Schedules/Quantization Schedules/PostTrainingResults/2020.12.08-210834/2020.12.08-210834.log\n","Random seed: 0\n","\n","--------------------------------------------------------\n","Logging to TensorBoard - remember to execute the server:\n","> tensorboard --logdir='./logs'\n","\n","=> created a resnet56_cifar model with the cifar10 dataset\n","The \"--resume\" flag is deprecated. Please use \"--resume-from=YOUR_PATH\" instead.\n","If you wish to also reset the optimizer, call with: --reset-optimizer\n","=> loading checkpoint baseResnet56\n","=> Checkpoint contents:\n","+----------------------+--------+----------------+\n","| Key                  | Type   | Value          |\n","|----------------------+--------+----------------|\n","| arch                 | str    | resnet56_cifar |\n","| compression_sched    | dict   |                |\n","| dataset              | str    | cifar10        |\n","| epoch                | int    | 127            |\n","| extras               | dict   |                |\n","| is_parallel          | bool   | True           |\n","| optimizer            | type   | SGD            |\n","| optimizer_state_dict | dict   |                |\n","| state_dict           | dict   |                |\n","+----------------------+--------+----------------+\n","\n","=> Checkpoint['extras'] contents:\n","+--------------+--------+---------+\n","| Key          | Type   |   Value |\n","|--------------+--------+---------|\n","| best_epoch   | int    |  127    |\n","| best_top1    | float  |   92.94 |\n","| current_top1 | float  |   92.94 |\n","+--------------+--------+---------+\n","\n","Loaded compression schedule from checkpoint (epoch 127)\n","Optimizer could not be loaded from checkpoint.\n","=> loaded checkpoint 'baseResnet56' (epoch 127)\n","Files already downloaded and verified\n","Dataset sizes:\n","\ttest=10000\n","Reading configuration from: /content/drive/MyDrive/Colab Notebooks/6787 Notebooks/Google Colab Scripts/Schedules/Quantization Schedules/PostTrainingSchedules/AVG/14bitAsymmetricSPost.yaml\n","Found component of class PostTrainLinearQuantizer: Name: linear_quantizer ; Section: quantizers\n","Loading activation stats from: /content/drive/MyDrive/Colab Notebooks/6787 Notebooks/Google Colab Scripts/Schedules/Quantization Schedules/acts_quantization_stats.yaml\n","Preparing model for quantization using PostTrainLinearQuantizer\n","Applying batch-norm folding ahead of post-training quantization\n","Propagating output statistics from BN modules to folded modules\n","Optimizing output statistics for modules followed by ReLU/Tanh/Sigmoid\n","Updated stats saved to /content/drive/MyDrive/Colab Notebooks/6787 Notebooks/Google Colab Scripts/Schedules/Quantization Schedules/PostTrainingResults/2020.12.08-210834/quant_stats_after_prepare_model.yaml\n","Per-layer quantization parameters saved to /content/drive/MyDrive/Colab Notebooks/6787 Notebooks/Google Colab Scripts/Schedules/Quantization Schedules/PostTrainingResults/2020.12.08-210834/layer_quant_params.yaml\n","--- test ---------------------\n","10000 samples (256 per mini-batch)\n","Test: [   10/   39]    Loss 0.368946    Top1 92.148438    Top5 99.843750    \n","Test: [   20/   39]    Loss 0.363455    Top1 92.226562    Top5 99.843750    \n","Test: [   30/   39]    Loss 0.336549    Top1 92.773438    Top5 99.817708    \n","Test: [   40/   39]    Loss 0.332643    Top1 92.820000    Top5 99.820000    \n","==> Top1: 92.820    Top5: 99.820    Loss: 0.333\n","\n","Saving checkpoint to: /content/drive/MyDrive/Colab Notebooks/6787 Notebooks/Google Colab Scripts/Schedules/Quantization Schedules/PostTrainingResults/2020.12.08-210834/quantized_checkpoint.pth.tar\n","\n","Log file for this run: /content/drive/.shortcut-targets-by-id/14_4ehU2lLHHu6HAFmEenl_iXGrCYtNmi/Google Colab Scripts/Schedules/Quantization Schedules/PostTrainingResults/2020.12.08-210834/2020.12.08-210834.log\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"fgavtpql3SXL","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1607461755118,"user_tz":300,"elapsed":330431,"user":{"displayName":"Michele L","photoUrl":"","userId":"03726718545613636685"}},"outputId":"1ddeaa60-d78d-4c82-eed3-4ef24648d9ac"},"source":["!python3 \"/content/distiller/examples/classifier_compression/compress_classifier.py\" --arch resnet56_cifar -p 10 ./data --resume=\"baseResnet56\" --out-dir \"/content/drive/MyDrive/Colab Notebooks/6787 Notebooks/Google Colab Scripts/Schedules/Quantization Schedules/PostTrainingResults\" --evaluate --quantize-eval --qe-config-file \"/content/drive/MyDrive/Colab Notebooks/6787 Notebooks/Google Colab Scripts/Schedules/Quantization Schedules/PostTrainingSchedules/AVG/16bitAsymmetricSPost.yaml\" -o \"/content/drive/MyDrive/Colab Notebooks/6787 Notebooks/Google Colab Scripts/Schedules/Quantization Schedules/PostTrainingResults\""],"execution_count":18,"outputs":[{"output_type":"stream","text":["Log file for this run: /content/drive/.shortcut-targets-by-id/14_4ehU2lLHHu6HAFmEenl_iXGrCYtNmi/Google Colab Scripts/Schedules/Quantization Schedules/PostTrainingResults/2020.12.08-210856/2020.12.08-210856.log\n","Random seed: 0\n","\n","--------------------------------------------------------\n","Logging to TensorBoard - remember to execute the server:\n","> tensorboard --logdir='./logs'\n","\n","=> created a resnet56_cifar model with the cifar10 dataset\n","The \"--resume\" flag is deprecated. Please use \"--resume-from=YOUR_PATH\" instead.\n","If you wish to also reset the optimizer, call with: --reset-optimizer\n","=> loading checkpoint baseResnet56\n","=> Checkpoint contents:\n","+----------------------+--------+----------------+\n","| Key                  | Type   | Value          |\n","|----------------------+--------+----------------|\n","| arch                 | str    | resnet56_cifar |\n","| compression_sched    | dict   |                |\n","| dataset              | str    | cifar10        |\n","| epoch                | int    | 127            |\n","| extras               | dict   |                |\n","| is_parallel          | bool   | True           |\n","| optimizer            | type   | SGD            |\n","| optimizer_state_dict | dict   |                |\n","| state_dict           | dict   |                |\n","+----------------------+--------+----------------+\n","\n","=> Checkpoint['extras'] contents:\n","+--------------+--------+---------+\n","| Key          | Type   |   Value |\n","|--------------+--------+---------|\n","| best_epoch   | int    |  127    |\n","| best_top1    | float  |   92.94 |\n","| current_top1 | float  |   92.94 |\n","+--------------+--------+---------+\n","\n","Loaded compression schedule from checkpoint (epoch 127)\n","Optimizer could not be loaded from checkpoint.\n","=> loaded checkpoint 'baseResnet56' (epoch 127)\n","Files already downloaded and verified\n","Dataset sizes:\n","\ttest=10000\n","Reading configuration from: /content/drive/MyDrive/Colab Notebooks/6787 Notebooks/Google Colab Scripts/Schedules/Quantization Schedules/PostTrainingSchedules/AVG/16bitAsymmetricSPost.yaml\n","Found component of class PostTrainLinearQuantizer: Name: linear_quantizer ; Section: quantizers\n","Loading activation stats from: /content/drive/MyDrive/Colab Notebooks/6787 Notebooks/Google Colab Scripts/Schedules/Quantization Schedules/acts_quantization_stats.yaml\n","Preparing model for quantization using PostTrainLinearQuantizer\n","Applying batch-norm folding ahead of post-training quantization\n","Propagating output statistics from BN modules to folded modules\n","Optimizing output statistics for modules followed by ReLU/Tanh/Sigmoid\n","Updated stats saved to /content/drive/MyDrive/Colab Notebooks/6787 Notebooks/Google Colab Scripts/Schedules/Quantization Schedules/PostTrainingResults/2020.12.08-210856/quant_stats_after_prepare_model.yaml\n","Per-layer quantization parameters saved to /content/drive/MyDrive/Colab Notebooks/6787 Notebooks/Google Colab Scripts/Schedules/Quantization Schedules/PostTrainingResults/2020.12.08-210856/layer_quant_params.yaml\n","--- test ---------------------\n","10000 samples (256 per mini-batch)\n","Test: [   10/   39]    Loss 2.085351    Top1 29.765625    Top5 86.093750    \n","Test: [   20/   39]    Loss 2.071353    Top1 30.917969    Top5 86.562500    \n","Test: [   30/   39]    Loss 2.063256    Top1 31.302083    Top5 86.575521    \n","Test: [   40/   39]    Loss 2.045448    Top1 31.340000    Top5 86.760000    \n","==> Top1: 31.340    Top5: 86.760    Loss: 2.045\n","\n","Saving checkpoint to: /content/drive/MyDrive/Colab Notebooks/6787 Notebooks/Google Colab Scripts/Schedules/Quantization Schedules/PostTrainingResults/2020.12.08-210856/quantized_checkpoint.pth.tar\n","\n","Log file for this run: /content/drive/.shortcut-targets-by-id/14_4ehU2lLHHu6HAFmEenl_iXGrCYtNmi/Google Colab Scripts/Schedules/Quantization Schedules/PostTrainingResults/2020.12.08-210856/2020.12.08-210856.log\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"nqOGl_1M1S1t"},"source":["Symetric"]},{"cell_type":"code","metadata":{"id":"ViSIBA_P3aCC","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1607461777565,"user_tz":300,"elapsed":352875,"user":{"displayName":"Michele L","photoUrl":"","userId":"03726718545613636685"}},"outputId":"4c7da2fe-7f65-44aa-933f-5fc6f218cb74"},"source":["!python3 \"/content/distiller/examples/classifier_compression/compress_classifier.py\" --arch resnet56_cifar -p 10 ./data --resume=\"baseResnet56\" --out-dir \"/content/drive/MyDrive/Colab Notebooks/6787 Notebooks/Google Colab Scripts/Schedules/Quantization Schedules/PostTrainingResults\" --evaluate --quantize-eval --qe-config-file \"/content/drive/MyDrive/Colab Notebooks/6787 Notebooks/Google Colab Scripts/Schedules/Quantization Schedules/PostTrainingSchedules/AVG/4bitSymmetricPost.yaml\" -o \"/content/drive/MyDrive/Colab Notebooks/6787 Notebooks/Google Colab Scripts/Schedules/Quantization Schedules/PostTrainingResults\""],"execution_count":19,"outputs":[{"output_type":"stream","text":["Log file for this run: /content/drive/.shortcut-targets-by-id/14_4ehU2lLHHu6HAFmEenl_iXGrCYtNmi/Google Colab Scripts/Schedules/Quantization Schedules/PostTrainingResults/2020.12.08-210918/2020.12.08-210918.log\n","Random seed: 0\n","\n","--------------------------------------------------------\n","Logging to TensorBoard - remember to execute the server:\n","> tensorboard --logdir='./logs'\n","\n","=> created a resnet56_cifar model with the cifar10 dataset\n","The \"--resume\" flag is deprecated. Please use \"--resume-from=YOUR_PATH\" instead.\n","If you wish to also reset the optimizer, call with: --reset-optimizer\n","=> loading checkpoint baseResnet56\n","=> Checkpoint contents:\n","+----------------------+--------+----------------+\n","| Key                  | Type   | Value          |\n","|----------------------+--------+----------------|\n","| arch                 | str    | resnet56_cifar |\n","| compression_sched    | dict   |                |\n","| dataset              | str    | cifar10        |\n","| epoch                | int    | 127            |\n","| extras               | dict   |                |\n","| is_parallel          | bool   | True           |\n","| optimizer            | type   | SGD            |\n","| optimizer_state_dict | dict   |                |\n","| state_dict           | dict   |                |\n","+----------------------+--------+----------------+\n","\n","=> Checkpoint['extras'] contents:\n","+--------------+--------+---------+\n","| Key          | Type   |   Value |\n","|--------------+--------+---------|\n","| best_epoch   | int    |  127    |\n","| best_top1    | float  |   92.94 |\n","| current_top1 | float  |   92.94 |\n","+--------------+--------+---------+\n","\n","Loaded compression schedule from checkpoint (epoch 127)\n","Optimizer could not be loaded from checkpoint.\n","=> loaded checkpoint 'baseResnet56' (epoch 127)\n","Files already downloaded and verified\n","Dataset sizes:\n","\ttest=10000\n","Reading configuration from: /content/drive/MyDrive/Colab Notebooks/6787 Notebooks/Google Colab Scripts/Schedules/Quantization Schedules/PostTrainingSchedules/AVG/4bitSymmetricPost.yaml\n","Found component of class PostTrainLinearQuantizer: Name: linear_quantizer ; Section: quantizers\n","Loading activation stats from: /content/drive/MyDrive/Colab Notebooks/6787 Notebooks/Google Colab Scripts/Schedules/Quantization Schedules/acts_quantization_stats.yaml\n","Preparing model for quantization using PostTrainLinearQuantizer\n","Applying batch-norm folding ahead of post-training quantization\n","Propagating output statistics from BN modules to folded modules\n","Optimizing output statistics for modules followed by ReLU/Tanh/Sigmoid\n","Updated stats saved to /content/drive/MyDrive/Colab Notebooks/6787 Notebooks/Google Colab Scripts/Schedules/Quantization Schedules/PostTrainingResults/2020.12.08-210918/quant_stats_after_prepare_model.yaml\n","Per-layer quantization parameters saved to /content/drive/MyDrive/Colab Notebooks/6787 Notebooks/Google Colab Scripts/Schedules/Quantization Schedules/PostTrainingResults/2020.12.08-210918/layer_quant_params.yaml\n","--- test ---------------------\n","10000 samples (256 per mini-batch)\n","Test: [   10/   39]    Loss 5.224966    Top1 36.992187    Top5 84.218750    \n","Test: [   20/   39]    Loss 5.096616    Top1 37.851562    Top5 85.078125    \n","Test: [   30/   39]    Loss 5.057178    Top1 38.346354    Top5 85.000000    \n","Test: [   40/   39]    Loss 5.032738    Top1 38.760000    Top5 85.120000    \n","==> Top1: 38.760    Top5: 85.120    Loss: 5.033\n","\n","Saving checkpoint to: /content/drive/MyDrive/Colab Notebooks/6787 Notebooks/Google Colab Scripts/Schedules/Quantization Schedules/PostTrainingResults/2020.12.08-210918/quantized_checkpoint.pth.tar\n","\n","Log file for this run: /content/drive/.shortcut-targets-by-id/14_4ehU2lLHHu6HAFmEenl_iXGrCYtNmi/Google Colab Scripts/Schedules/Quantization Schedules/PostTrainingResults/2020.12.08-210918/2020.12.08-210918.log\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"FfHFPf8X3aEz","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1607461800139,"user_tz":300,"elapsed":375447,"user":{"displayName":"Michele L","photoUrl":"","userId":"03726718545613636685"}},"outputId":"0be0b879-6d55-4223-98d2-0e2a87bd83d7"},"source":["!python3 \"/content/distiller/examples/classifier_compression/compress_classifier.py\" --arch resnet56_cifar -p 10 ./data --resume=\"baseResnet56\" --out-dir \"/content/drive/MyDrive/Colab Notebooks/6787 Notebooks/Google Colab Scripts/Schedules/Quantization Schedules/PostTrainingResults\" --evaluate --quantize-eval --qe-config-file \"/content/drive/MyDrive/Colab Notebooks/6787 Notebooks/Google Colab Scripts/Schedules/Quantization Schedules/PostTrainingSchedules/AVG/6bitSymmetricPost.yaml\" -o \"/content/drive/MyDrive/Colab Notebooks/6787 Notebooks/Google Colab Scripts/Schedules/Quantization Schedules/PostTrainingResults\""],"execution_count":20,"outputs":[{"output_type":"stream","text":["Log file for this run: /content/drive/.shortcut-targets-by-id/14_4ehU2lLHHu6HAFmEenl_iXGrCYtNmi/Google Colab Scripts/Schedules/Quantization Schedules/PostTrainingResults/2020.12.08-210941/2020.12.08-210941.log\n","Random seed: 0\n","\n","--------------------------------------------------------\n","Logging to TensorBoard - remember to execute the server:\n","> tensorboard --logdir='./logs'\n","\n","=> created a resnet56_cifar model with the cifar10 dataset\n","The \"--resume\" flag is deprecated. Please use \"--resume-from=YOUR_PATH\" instead.\n","If you wish to also reset the optimizer, call with: --reset-optimizer\n","=> loading checkpoint baseResnet56\n","=> Checkpoint contents:\n","+----------------------+--------+----------------+\n","| Key                  | Type   | Value          |\n","|----------------------+--------+----------------|\n","| arch                 | str    | resnet56_cifar |\n","| compression_sched    | dict   |                |\n","| dataset              | str    | cifar10        |\n","| epoch                | int    | 127            |\n","| extras               | dict   |                |\n","| is_parallel          | bool   | True           |\n","| optimizer            | type   | SGD            |\n","| optimizer_state_dict | dict   |                |\n","| state_dict           | dict   |                |\n","+----------------------+--------+----------------+\n","\n","=> Checkpoint['extras'] contents:\n","+--------------+--------+---------+\n","| Key          | Type   |   Value |\n","|--------------+--------+---------|\n","| best_epoch   | int    |  127    |\n","| best_top1    | float  |   92.94 |\n","| current_top1 | float  |   92.94 |\n","+--------------+--------+---------+\n","\n","Loaded compression schedule from checkpoint (epoch 127)\n","Optimizer could not be loaded from checkpoint.\n","=> loaded checkpoint 'baseResnet56' (epoch 127)\n","Files already downloaded and verified\n","Dataset sizes:\n","\ttest=10000\n","Reading configuration from: /content/drive/MyDrive/Colab Notebooks/6787 Notebooks/Google Colab Scripts/Schedules/Quantization Schedules/PostTrainingSchedules/AVG/6bitSymmetricPost.yaml\n","Found component of class PostTrainLinearQuantizer: Name: linear_quantizer ; Section: quantizers\n","Loading activation stats from: /content/drive/MyDrive/Colab Notebooks/6787 Notebooks/Google Colab Scripts/Schedules/Quantization Schedules/acts_quantization_stats.yaml\n","Preparing model for quantization using PostTrainLinearQuantizer\n","Applying batch-norm folding ahead of post-training quantization\n","Propagating output statistics from BN modules to folded modules\n","Optimizing output statistics for modules followed by ReLU/Tanh/Sigmoid\n","Updated stats saved to /content/drive/MyDrive/Colab Notebooks/6787 Notebooks/Google Colab Scripts/Schedules/Quantization Schedules/PostTrainingResults/2020.12.08-210941/quant_stats_after_prepare_model.yaml\n","Per-layer quantization parameters saved to /content/drive/MyDrive/Colab Notebooks/6787 Notebooks/Google Colab Scripts/Schedules/Quantization Schedules/PostTrainingResults/2020.12.08-210941/layer_quant_params.yaml\n","--- test ---------------------\n","10000 samples (256 per mini-batch)\n","Test: [   10/   39]    Loss 0.562670    Top1 89.218750    Top5 99.609375    \n","Test: [   20/   39]    Loss 0.559146    Top1 89.042969    Top5 99.667969    \n","Test: [   30/   39]    Loss 0.515619    Top1 89.778646    Top5 99.609375    \n","Test: [   40/   39]    Loss 0.501701    Top1 89.800000    Top5 99.600000    \n","==> Top1: 89.800    Top5: 99.600    Loss: 0.502\n","\n","Saving checkpoint to: /content/drive/MyDrive/Colab Notebooks/6787 Notebooks/Google Colab Scripts/Schedules/Quantization Schedules/PostTrainingResults/2020.12.08-210941/quantized_checkpoint.pth.tar\n","\n","Log file for this run: /content/drive/.shortcut-targets-by-id/14_4ehU2lLHHu6HAFmEenl_iXGrCYtNmi/Google Colab Scripts/Schedules/Quantization Schedules/PostTrainingResults/2020.12.08-210941/2020.12.08-210941.log\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"6lTRZRje3aHW","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1607461822671,"user_tz":300,"elapsed":397976,"user":{"displayName":"Michele L","photoUrl":"","userId":"03726718545613636685"}},"outputId":"dabd10d8-9ea7-4034-fdbc-efd6425fa727"},"source":["!python3 \"/content/distiller/examples/classifier_compression/compress_classifier.py\" --arch resnet56_cifar -p 10 ./data --resume=\"baseResnet56\" --out-dir \"/content/drive/MyDrive/Colab Notebooks/6787 Notebooks/Google Colab Scripts/Schedules/Quantization Schedules/PostTrainingResults\" --evaluate --quantize-eval --qe-config-file \"/content/drive/MyDrive/Colab Notebooks/6787 Notebooks/Google Colab Scripts/Schedules/Quantization Schedules/PostTrainingSchedules/AVG/8bitSymmetricPost.yaml\" -o \"/content/drive/MyDrive/Colab Notebooks/6787 Notebooks/Google Colab Scripts/Schedules/Quantization Schedules/PostTrainingResults\""],"execution_count":21,"outputs":[{"output_type":"stream","text":["Log file for this run: /content/drive/.shortcut-targets-by-id/14_4ehU2lLHHu6HAFmEenl_iXGrCYtNmi/Google Colab Scripts/Schedules/Quantization Schedules/PostTrainingResults/2020.12.08-211003/2020.12.08-211003.log\n","Random seed: 0\n","\n","--------------------------------------------------------\n","Logging to TensorBoard - remember to execute the server:\n","> tensorboard --logdir='./logs'\n","\n","=> created a resnet56_cifar model with the cifar10 dataset\n","The \"--resume\" flag is deprecated. Please use \"--resume-from=YOUR_PATH\" instead.\n","If you wish to also reset the optimizer, call with: --reset-optimizer\n","=> loading checkpoint baseResnet56\n","=> Checkpoint contents:\n","+----------------------+--------+----------------+\n","| Key                  | Type   | Value          |\n","|----------------------+--------+----------------|\n","| arch                 | str    | resnet56_cifar |\n","| compression_sched    | dict   |                |\n","| dataset              | str    | cifar10        |\n","| epoch                | int    | 127            |\n","| extras               | dict   |                |\n","| is_parallel          | bool   | True           |\n","| optimizer            | type   | SGD            |\n","| optimizer_state_dict | dict   |                |\n","| state_dict           | dict   |                |\n","+----------------------+--------+----------------+\n","\n","=> Checkpoint['extras'] contents:\n","+--------------+--------+---------+\n","| Key          | Type   |   Value |\n","|--------------+--------+---------|\n","| best_epoch   | int    |  127    |\n","| best_top1    | float  |   92.94 |\n","| current_top1 | float  |   92.94 |\n","+--------------+--------+---------+\n","\n","Loaded compression schedule from checkpoint (epoch 127)\n","Optimizer could not be loaded from checkpoint.\n","=> loaded checkpoint 'baseResnet56' (epoch 127)\n","Files already downloaded and verified\n","Dataset sizes:\n","\ttest=10000\n","Reading configuration from: /content/drive/MyDrive/Colab Notebooks/6787 Notebooks/Google Colab Scripts/Schedules/Quantization Schedules/PostTrainingSchedules/AVG/8bitSymmetricPost.yaml\n","Found component of class PostTrainLinearQuantizer: Name: linear_quantizer ; Section: quantizers\n","Loading activation stats from: /content/drive/MyDrive/Colab Notebooks/6787 Notebooks/Google Colab Scripts/Schedules/Quantization Schedules/acts_quantization_stats.yaml\n","Preparing model for quantization using PostTrainLinearQuantizer\n","Applying batch-norm folding ahead of post-training quantization\n","Propagating output statistics from BN modules to folded modules\n","Optimizing output statistics for modules followed by ReLU/Tanh/Sigmoid\n","Updated stats saved to /content/drive/MyDrive/Colab Notebooks/6787 Notebooks/Google Colab Scripts/Schedules/Quantization Schedules/PostTrainingResults/2020.12.08-211003/quant_stats_after_prepare_model.yaml\n","Per-layer quantization parameters saved to /content/drive/MyDrive/Colab Notebooks/6787 Notebooks/Google Colab Scripts/Schedules/Quantization Schedules/PostTrainingResults/2020.12.08-211003/layer_quant_params.yaml\n","--- test ---------------------\n","10000 samples (256 per mini-batch)\n","Test: [   10/   39]    Loss 0.369613    Top1 92.187500    Top5 99.843750    \n","Test: [   20/   39]    Loss 0.365107    Top1 92.011719    Top5 99.824219    \n","Test: [   30/   39]    Loss 0.339584    Top1 92.500000    Top5 99.804688    \n","Test: [   40/   39]    Loss 0.336499    Top1 92.570000    Top5 99.790000    \n","==> Top1: 92.570    Top5: 99.790    Loss: 0.336\n","\n","Saving checkpoint to: /content/drive/MyDrive/Colab Notebooks/6787 Notebooks/Google Colab Scripts/Schedules/Quantization Schedules/PostTrainingResults/2020.12.08-211003/quantized_checkpoint.pth.tar\n","\n","Log file for this run: /content/drive/.shortcut-targets-by-id/14_4ehU2lLHHu6HAFmEenl_iXGrCYtNmi/Google Colab Scripts/Schedules/Quantization Schedules/PostTrainingResults/2020.12.08-211003/2020.12.08-211003.log\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"flS0WJAD3aMj","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1607461845184,"user_tz":300,"elapsed":420485,"user":{"displayName":"Michele L","photoUrl":"","userId":"03726718545613636685"}},"outputId":"3eea21fb-f236-458a-eb0b-7ee68cf642f7"},"source":["!python3 \"/content/distiller/examples/classifier_compression/compress_classifier.py\" --arch resnet56_cifar -p 10 ./data --resume=\"baseResnet56\" --out-dir \"/content/drive/MyDrive/Colab Notebooks/6787 Notebooks/Google Colab Scripts/Schedules/Quantization Schedules/PostTrainingResults\" --evaluate --quantize-eval --qe-config-file \"/content/drive/MyDrive/Colab Notebooks/6787 Notebooks/Google Colab Scripts/Schedules/Quantization Schedules/PostTrainingSchedules/AVG/10bitSymmetricPost.yaml\" -o \"/content/drive/MyDrive/Colab Notebooks/6787 Notebooks/Google Colab Scripts/Schedules/Quantization Schedules/PostTrainingResults\""],"execution_count":22,"outputs":[{"output_type":"stream","text":["Log file for this run: /content/drive/.shortcut-targets-by-id/14_4ehU2lLHHu6HAFmEenl_iXGrCYtNmi/Google Colab Scripts/Schedules/Quantization Schedules/PostTrainingResults/2020.12.08-211026/2020.12.08-211026.log\n","Random seed: 0\n","\n","--------------------------------------------------------\n","Logging to TensorBoard - remember to execute the server:\n","> tensorboard --logdir='./logs'\n","\n","=> created a resnet56_cifar model with the cifar10 dataset\n","The \"--resume\" flag is deprecated. Please use \"--resume-from=YOUR_PATH\" instead.\n","If you wish to also reset the optimizer, call with: --reset-optimizer\n","=> loading checkpoint baseResnet56\n","=> Checkpoint contents:\n","+----------------------+--------+----------------+\n","| Key                  | Type   | Value          |\n","|----------------------+--------+----------------|\n","| arch                 | str    | resnet56_cifar |\n","| compression_sched    | dict   |                |\n","| dataset              | str    | cifar10        |\n","| epoch                | int    | 127            |\n","| extras               | dict   |                |\n","| is_parallel          | bool   | True           |\n","| optimizer            | type   | SGD            |\n","| optimizer_state_dict | dict   |                |\n","| state_dict           | dict   |                |\n","+----------------------+--------+----------------+\n","\n","=> Checkpoint['extras'] contents:\n","+--------------+--------+---------+\n","| Key          | Type   |   Value |\n","|--------------+--------+---------|\n","| best_epoch   | int    |  127    |\n","| best_top1    | float  |   92.94 |\n","| current_top1 | float  |   92.94 |\n","+--------------+--------+---------+\n","\n","Loaded compression schedule from checkpoint (epoch 127)\n","Optimizer could not be loaded from checkpoint.\n","=> loaded checkpoint 'baseResnet56' (epoch 127)\n","Files already downloaded and verified\n","Dataset sizes:\n","\ttest=10000\n","Reading configuration from: /content/drive/MyDrive/Colab Notebooks/6787 Notebooks/Google Colab Scripts/Schedules/Quantization Schedules/PostTrainingSchedules/AVG/10bitSymmetricPost.yaml\n","Found component of class PostTrainLinearQuantizer: Name: linear_quantizer ; Section: quantizers\n","Loading activation stats from: /content/drive/MyDrive/Colab Notebooks/6787 Notebooks/Google Colab Scripts/Schedules/Quantization Schedules/acts_quantization_stats.yaml\n","Preparing model for quantization using PostTrainLinearQuantizer\n","Applying batch-norm folding ahead of post-training quantization\n","Propagating output statistics from BN modules to folded modules\n","Optimizing output statistics for modules followed by ReLU/Tanh/Sigmoid\n","Updated stats saved to /content/drive/MyDrive/Colab Notebooks/6787 Notebooks/Google Colab Scripts/Schedules/Quantization Schedules/PostTrainingResults/2020.12.08-211026/quant_stats_after_prepare_model.yaml\n","Per-layer quantization parameters saved to /content/drive/MyDrive/Colab Notebooks/6787 Notebooks/Google Colab Scripts/Schedules/Quantization Schedules/PostTrainingResults/2020.12.08-211026/layer_quant_params.yaml\n","--- test ---------------------\n","10000 samples (256 per mini-batch)\n","Test: [   10/   39]    Loss 0.365781    Top1 92.226562    Top5 99.843750    \n","Test: [   20/   39]    Loss 0.359407    Top1 92.226562    Top5 99.843750    \n","Test: [   30/   39]    Loss 0.334976    Top1 92.721354    Top5 99.804688    \n","Test: [   40/   39]    Loss 0.331741    Top1 92.790000    Top5 99.800000    \n","==> Top1: 92.790    Top5: 99.800    Loss: 0.332\n","\n","Saving checkpoint to: /content/drive/MyDrive/Colab Notebooks/6787 Notebooks/Google Colab Scripts/Schedules/Quantization Schedules/PostTrainingResults/2020.12.08-211026/quantized_checkpoint.pth.tar\n","\n","Log file for this run: /content/drive/.shortcut-targets-by-id/14_4ehU2lLHHu6HAFmEenl_iXGrCYtNmi/Google Colab Scripts/Schedules/Quantization Schedules/PostTrainingResults/2020.12.08-211026/2020.12.08-211026.log\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"m5winHdH3aO_","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1607461867756,"user_tz":300,"elapsed":443055,"user":{"displayName":"Michele L","photoUrl":"","userId":"03726718545613636685"}},"outputId":"f19a6bc9-6bbe-46fc-e691-36d130436b81"},"source":["!python3 \"/content/distiller/examples/classifier_compression/compress_classifier.py\" --arch resnet56_cifar -p 10 ./data --resume=\"baseResnet56\" --out-dir \"/content/drive/MyDrive/Colab Notebooks/6787 Notebooks/Google Colab Scripts/Schedules/Quantization Schedules/PostTrainingResults\" --evaluate --quantize-eval --qe-config-file \"/content/drive/MyDrive/Colab Notebooks/6787 Notebooks/Google Colab Scripts/Schedules/Quantization Schedules/PostTrainingSchedules/AVG/12bitSymmetricPost.yaml\" -o \"/content/drive/MyDrive/Colab Notebooks/6787 Notebooks/Google Colab Scripts/Schedules/Quantization Schedules/PostTrainingResults\""],"execution_count":23,"outputs":[{"output_type":"stream","text":["Log file for this run: /content/drive/.shortcut-targets-by-id/14_4ehU2lLHHu6HAFmEenl_iXGrCYtNmi/Google Colab Scripts/Schedules/Quantization Schedules/PostTrainingResults/2020.12.08-211049/2020.12.08-211049.log\n","Random seed: 0\n","\n","--------------------------------------------------------\n","Logging to TensorBoard - remember to execute the server:\n","> tensorboard --logdir='./logs'\n","\n","=> created a resnet56_cifar model with the cifar10 dataset\n","The \"--resume\" flag is deprecated. Please use \"--resume-from=YOUR_PATH\" instead.\n","If you wish to also reset the optimizer, call with: --reset-optimizer\n","=> loading checkpoint baseResnet56\n","=> Checkpoint contents:\n","+----------------------+--------+----------------+\n","| Key                  | Type   | Value          |\n","|----------------------+--------+----------------|\n","| arch                 | str    | resnet56_cifar |\n","| compression_sched    | dict   |                |\n","| dataset              | str    | cifar10        |\n","| epoch                | int    | 127            |\n","| extras               | dict   |                |\n","| is_parallel          | bool   | True           |\n","| optimizer            | type   | SGD            |\n","| optimizer_state_dict | dict   |                |\n","| state_dict           | dict   |                |\n","+----------------------+--------+----------------+\n","\n","=> Checkpoint['extras'] contents:\n","+--------------+--------+---------+\n","| Key          | Type   |   Value |\n","|--------------+--------+---------|\n","| best_epoch   | int    |  127    |\n","| best_top1    | float  |   92.94 |\n","| current_top1 | float  |   92.94 |\n","+--------------+--------+---------+\n","\n","Loaded compression schedule from checkpoint (epoch 127)\n","Optimizer could not be loaded from checkpoint.\n","=> loaded checkpoint 'baseResnet56' (epoch 127)\n","Files already downloaded and verified\n","Dataset sizes:\n","\ttest=10000\n","Reading configuration from: /content/drive/MyDrive/Colab Notebooks/6787 Notebooks/Google Colab Scripts/Schedules/Quantization Schedules/PostTrainingSchedules/AVG/12bitSymmetricPost.yaml\n","Found component of class PostTrainLinearQuantizer: Name: linear_quantizer ; Section: quantizers\n","Loading activation stats from: /content/drive/MyDrive/Colab Notebooks/6787 Notebooks/Google Colab Scripts/Schedules/Quantization Schedules/acts_quantization_stats.yaml\n","Preparing model for quantization using PostTrainLinearQuantizer\n","Applying batch-norm folding ahead of post-training quantization\n","Propagating output statistics from BN modules to folded modules\n","Optimizing output statistics for modules followed by ReLU/Tanh/Sigmoid\n","Updated stats saved to /content/drive/MyDrive/Colab Notebooks/6787 Notebooks/Google Colab Scripts/Schedules/Quantization Schedules/PostTrainingResults/2020.12.08-211049/quant_stats_after_prepare_model.yaml\n","Per-layer quantization parameters saved to /content/drive/MyDrive/Colab Notebooks/6787 Notebooks/Google Colab Scripts/Schedules/Quantization Schedules/PostTrainingResults/2020.12.08-211049/layer_quant_params.yaml\n","--- test ---------------------\n","10000 samples (256 per mini-batch)\n","Test: [   10/   39]    Loss 0.365418    Top1 92.226562    Top5 99.843750    \n","Test: [   20/   39]    Loss 0.359970    Top1 92.226562    Top5 99.843750    \n","Test: [   30/   39]    Loss 0.335176    Top1 92.695312    Top5 99.817708    \n","Test: [   40/   39]    Loss 0.331781    Top1 92.760000    Top5 99.810000    \n","==> Top1: 92.760    Top5: 99.810    Loss: 0.332\n","\n","Saving checkpoint to: /content/drive/MyDrive/Colab Notebooks/6787 Notebooks/Google Colab Scripts/Schedules/Quantization Schedules/PostTrainingResults/2020.12.08-211049/quantized_checkpoint.pth.tar\n","\n","Log file for this run: /content/drive/.shortcut-targets-by-id/14_4ehU2lLHHu6HAFmEenl_iXGrCYtNmi/Google Colab Scripts/Schedules/Quantization Schedules/PostTrainingResults/2020.12.08-211049/2020.12.08-211049.log\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"OTBrmnSD3aRz","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1607461890232,"user_tz":300,"elapsed":465528,"user":{"displayName":"Michele L","photoUrl":"","userId":"03726718545613636685"}},"outputId":"6529fadb-8232-411d-f1db-b1c8779f8865"},"source":["!python3 \"/content/distiller/examples/classifier_compression/compress_classifier.py\" --arch resnet56_cifar -p 10 ./data --resume=\"baseResnet56\" --out-dir \"/content/drive/MyDrive/Colab Notebooks/6787 Notebooks/Google Colab Scripts/Schedules/Quantization Schedules/PostTrainingResults\" --evaluate --quantize-eval --qe-config-file \"/content/drive/MyDrive/Colab Notebooks/6787 Notebooks/Google Colab Scripts/Schedules/Quantization Schedules/PostTrainingSchedules/AVG/14bitSymmetricPost.yaml\" -o \"/content/drive/MyDrive/Colab Notebooks/6787 Notebooks/Google Colab Scripts/Schedules/Quantization Schedules/PostTrainingResults\""],"execution_count":24,"outputs":[{"output_type":"stream","text":["Log file for this run: /content/drive/.shortcut-targets-by-id/14_4ehU2lLHHu6HAFmEenl_iXGrCYtNmi/Google Colab Scripts/Schedules/Quantization Schedules/PostTrainingResults/2020.12.08-211111/2020.12.08-211111.log\n","Random seed: 0\n","\n","--------------------------------------------------------\n","Logging to TensorBoard - remember to execute the server:\n","> tensorboard --logdir='./logs'\n","\n","=> created a resnet56_cifar model with the cifar10 dataset\n","The \"--resume\" flag is deprecated. Please use \"--resume-from=YOUR_PATH\" instead.\n","If you wish to also reset the optimizer, call with: --reset-optimizer\n","=> loading checkpoint baseResnet56\n","=> Checkpoint contents:\n","+----------------------+--------+----------------+\n","| Key                  | Type   | Value          |\n","|----------------------+--------+----------------|\n","| arch                 | str    | resnet56_cifar |\n","| compression_sched    | dict   |                |\n","| dataset              | str    | cifar10        |\n","| epoch                | int    | 127            |\n","| extras               | dict   |                |\n","| is_parallel          | bool   | True           |\n","| optimizer            | type   | SGD            |\n","| optimizer_state_dict | dict   |                |\n","| state_dict           | dict   |                |\n","+----------------------+--------+----------------+\n","\n","=> Checkpoint['extras'] contents:\n","+--------------+--------+---------+\n","| Key          | Type   |   Value |\n","|--------------+--------+---------|\n","| best_epoch   | int    |  127    |\n","| best_top1    | float  |   92.94 |\n","| current_top1 | float  |   92.94 |\n","+--------------+--------+---------+\n","\n","Loaded compression schedule from checkpoint (epoch 127)\n","Optimizer could not be loaded from checkpoint.\n","=> loaded checkpoint 'baseResnet56' (epoch 127)\n","Files already downloaded and verified\n","Dataset sizes:\n","\ttest=10000\n","Reading configuration from: /content/drive/MyDrive/Colab Notebooks/6787 Notebooks/Google Colab Scripts/Schedules/Quantization Schedules/PostTrainingSchedules/AVG/14bitSymmetricPost.yaml\n","Found component of class PostTrainLinearQuantizer: Name: linear_quantizer ; Section: quantizers\n","Loading activation stats from: /content/drive/MyDrive/Colab Notebooks/6787 Notebooks/Google Colab Scripts/Schedules/Quantization Schedules/acts_quantization_stats.yaml\n","Preparing model for quantization using PostTrainLinearQuantizer\n","Applying batch-norm folding ahead of post-training quantization\n","Propagating output statistics from BN modules to folded modules\n","Optimizing output statistics for modules followed by ReLU/Tanh/Sigmoid\n","Updated stats saved to /content/drive/MyDrive/Colab Notebooks/6787 Notebooks/Google Colab Scripts/Schedules/Quantization Schedules/PostTrainingResults/2020.12.08-211111/quant_stats_after_prepare_model.yaml\n","Per-layer quantization parameters saved to /content/drive/MyDrive/Colab Notebooks/6787 Notebooks/Google Colab Scripts/Schedules/Quantization Schedules/PostTrainingResults/2020.12.08-211111/layer_quant_params.yaml\n","--- test ---------------------\n","10000 samples (256 per mini-batch)\n","Test: [   10/   39]    Loss 0.368050    Top1 92.070312    Top5 99.843750    \n","Test: [   20/   39]    Loss 0.361883    Top1 92.207031    Top5 99.843750    \n","Test: [   30/   39]    Loss 0.336242    Top1 92.721354    Top5 99.817708    \n","Test: [   40/   39]    Loss 0.332636    Top1 92.810000    Top5 99.800000    \n","==> Top1: 92.810    Top5: 99.800    Loss: 0.333\n","\n","Saving checkpoint to: /content/drive/MyDrive/Colab Notebooks/6787 Notebooks/Google Colab Scripts/Schedules/Quantization Schedules/PostTrainingResults/2020.12.08-211111/quantized_checkpoint.pth.tar\n","\n","Log file for this run: /content/drive/.shortcut-targets-by-id/14_4ehU2lLHHu6HAFmEenl_iXGrCYtNmi/Google Colab Scripts/Schedules/Quantization Schedules/PostTrainingResults/2020.12.08-211111/2020.12.08-211111.log\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"Y9UKi4Ju3aUD","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1607461912764,"user_tz":300,"elapsed":488057,"user":{"displayName":"Michele L","photoUrl":"","userId":"03726718545613636685"}},"outputId":"4b4016cf-5136-429c-bfcf-6e024d0af112"},"source":["!python3 \"/content/distiller/examples/classifier_compression/compress_classifier.py\" --arch resnet56_cifar -p 10 ./data --resume=\"baseResnet56\" --out-dir \"/content/drive/MyDrive/Colab Notebooks/6787 Notebooks/Google Colab Scripts/Schedules/Quantization Schedules/PostTrainingResults\" --evaluate --quantize-eval --qe-config-file \"/content/drive/MyDrive/Colab Notebooks/6787 Notebooks/Google Colab Scripts/Schedules/Quantization Schedules/PostTrainingSchedules/AVG/16bitSymmetricPost.yaml\" -o \"/content/drive/MyDrive/Colab Notebooks/6787 Notebooks/Google Colab Scripts/Schedules/Quantization Schedules/PostTrainingResults\""],"execution_count":25,"outputs":[{"output_type":"stream","text":["Log file for this run: /content/drive/.shortcut-targets-by-id/14_4ehU2lLHHu6HAFmEenl_iXGrCYtNmi/Google Colab Scripts/Schedules/Quantization Schedules/PostTrainingResults/2020.12.08-211134/2020.12.08-211134.log\n","Random seed: 0\n","\n","--------------------------------------------------------\n","Logging to TensorBoard - remember to execute the server:\n","> tensorboard --logdir='./logs'\n","\n","=> created a resnet56_cifar model with the cifar10 dataset\n","The \"--resume\" flag is deprecated. Please use \"--resume-from=YOUR_PATH\" instead.\n","If you wish to also reset the optimizer, call with: --reset-optimizer\n","=> loading checkpoint baseResnet56\n","=> Checkpoint contents:\n","+----------------------+--------+----------------+\n","| Key                  | Type   | Value          |\n","|----------------------+--------+----------------|\n","| arch                 | str    | resnet56_cifar |\n","| compression_sched    | dict   |                |\n","| dataset              | str    | cifar10        |\n","| epoch                | int    | 127            |\n","| extras               | dict   |                |\n","| is_parallel          | bool   | True           |\n","| optimizer            | type   | SGD            |\n","| optimizer_state_dict | dict   |                |\n","| state_dict           | dict   |                |\n","+----------------------+--------+----------------+\n","\n","=> Checkpoint['extras'] contents:\n","+--------------+--------+---------+\n","| Key          | Type   |   Value |\n","|--------------+--------+---------|\n","| best_epoch   | int    |  127    |\n","| best_top1    | float  |   92.94 |\n","| current_top1 | float  |   92.94 |\n","+--------------+--------+---------+\n","\n","Loaded compression schedule from checkpoint (epoch 127)\n","Optimizer could not be loaded from checkpoint.\n","=> loaded checkpoint 'baseResnet56' (epoch 127)\n","Files already downloaded and verified\n","Dataset sizes:\n","\ttest=10000\n","Reading configuration from: /content/drive/MyDrive/Colab Notebooks/6787 Notebooks/Google Colab Scripts/Schedules/Quantization Schedules/PostTrainingSchedules/AVG/16bitSymmetricPost.yaml\n","Found component of class PostTrainLinearQuantizer: Name: linear_quantizer ; Section: quantizers\n","Loading activation stats from: /content/drive/MyDrive/Colab Notebooks/6787 Notebooks/Google Colab Scripts/Schedules/Quantization Schedules/acts_quantization_stats.yaml\n","Preparing model for quantization using PostTrainLinearQuantizer\n","Applying batch-norm folding ahead of post-training quantization\n","Propagating output statistics from BN modules to folded modules\n","Optimizing output statistics for modules followed by ReLU/Tanh/Sigmoid\n","Updated stats saved to /content/drive/MyDrive/Colab Notebooks/6787 Notebooks/Google Colab Scripts/Schedules/Quantization Schedules/PostTrainingResults/2020.12.08-211134/quant_stats_after_prepare_model.yaml\n","Per-layer quantization parameters saved to /content/drive/MyDrive/Colab Notebooks/6787 Notebooks/Google Colab Scripts/Schedules/Quantization Schedules/PostTrainingResults/2020.12.08-211134/layer_quant_params.yaml\n","--- test ---------------------\n","10000 samples (256 per mini-batch)\n","Test: [   10/   39]    Loss 0.522303    Top1 86.679688    Top5 99.296875    \n","Test: [   20/   39]    Loss 0.517373    Top1 86.875000    Top5 99.433594    \n","Test: [   30/   39]    Loss 0.480220    Top1 87.539062    Top5 99.440104    \n","Test: [   40/   39]    Loss 0.469752    Top1 87.560000    Top5 99.440000    \n","==> Top1: 87.560    Top5: 99.440    Loss: 0.470\n","\n","Saving checkpoint to: /content/drive/MyDrive/Colab Notebooks/6787 Notebooks/Google Colab Scripts/Schedules/Quantization Schedules/PostTrainingResults/2020.12.08-211134/quantized_checkpoint.pth.tar\n","\n","Log file for this run: /content/drive/.shortcut-targets-by-id/14_4ehU2lLHHu6HAFmEenl_iXGrCYtNmi/Google Colab Scripts/Schedules/Quantization Schedules/PostTrainingResults/2020.12.08-211134/2020.12.08-211134.log\n"],"name":"stdout"}]}]}