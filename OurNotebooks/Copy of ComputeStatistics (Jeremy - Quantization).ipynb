{"nbformat":4,"nbformat_minor":0,"metadata":{"accelerator":"GPU","colab":{"name":"ComputeStatistics (Jeremy - Quantization).ipynb","provenance":[],"collapsed_sections":["ENz2hDstFhJ_"]},"kernelspec":{"display_name":"Python 3","name":"python3"}},"cells":[{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"xv-HxDm9GWzV","executionInfo":{"elapsed":4613,"status":"ok","timestamp":1607492170718,"user":{"displayName":"Jeremy Wang","photoUrl":"","userId":"16277065741529505083"},"user_tz":300},"outputId":"81594dbe-fb28-467e-bd3f-08b5bc3339c0"},"source":["!git clone https://github.com/mueedurrehman/distiller.git\n","%cd distiller\n","!pip3 install -e ."],"execution_count":null,"outputs":[{"output_type":"stream","text":["fatal: destination path 'distiller' already exists and is not an empty directory.\n","/content/distiller\n","Obtaining file:///content/distiller\n","Requirement already satisfied: pillow<7 in /usr/local/lib/python3.6/dist-packages (from distiller==0.4.0rc0) (6.2.2)\n","Requirement already satisfied: torch==1.3.1 in /usr/local/lib/python3.6/dist-packages (from distiller==0.4.0rc0) (1.3.1)\n","Requirement already satisfied: numpy>=1.16 in /usr/local/lib/python3.6/dist-packages (from distiller==0.4.0rc0) (1.18.5)\n","Requirement already satisfied: torchvision==0.4.2 in /usr/local/lib/python3.6/dist-packages (from distiller==0.4.0rc0) (0.4.2)\n","Requirement already satisfied: scipy>=1.3.0 in /usr/local/lib/python3.6/dist-packages (from distiller==0.4.0rc0) (1.4.1)\n","Requirement already satisfied: gitpython==3.1.0 in /usr/local/lib/python3.6/dist-packages (from distiller==0.4.0rc0) (3.1.0)\n","Requirement already satisfied: torchnet==0.0.4 in /usr/local/lib/python3.6/dist-packages (from distiller==0.4.0rc0) (0.0.4)\n","Requirement already satisfied: tensorflow~=1.14 in /usr/local/lib/python3.6/dist-packages (from distiller==0.4.0rc0) (1.15.4)\n","Requirement already satisfied: pydot==1.4.1 in /usr/local/lib/python3.6/dist-packages (from distiller==0.4.0rc0) (1.4.1)\n","Requirement already satisfied: tabulate==0.8.3 in /usr/local/lib/python3.6/dist-packages (from distiller==0.4.0rc0) (0.8.3)\n","Requirement already satisfied: pandas>=0.22.0 in /usr/local/lib/python3.6/dist-packages (from distiller==0.4.0rc0) (1.1.4)\n","Requirement already satisfied: jupyter>=1.0.0 in /usr/local/lib/python3.6/dist-packages (from distiller==0.4.0rc0) (1.0.0)\n","Requirement already satisfied: matplotlib~=3.0 in /usr/local/lib/python3.6/dist-packages (from distiller==0.4.0rc0) (3.2.2)\n","Requirement already satisfied: qgrid==1.1.1 in /usr/local/lib/python3.6/dist-packages (from distiller==0.4.0rc0) (1.1.1)\n","Requirement already satisfied: graphviz==0.10.1 in /usr/local/lib/python3.6/dist-packages (from distiller==0.4.0rc0) (0.10.1)\n","Requirement already satisfied: ipywidgets==7.4.2 in /usr/local/lib/python3.6/dist-packages (from distiller==0.4.0rc0) (7.4.2)\n","Requirement already satisfied: bqplot==0.11.5 in /usr/local/lib/python3.6/dist-packages (from distiller==0.4.0rc0) (0.11.5)\n","Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from distiller==0.4.0rc0) (3.13)\n","Requirement already satisfied: pytest~=4.6.1 in /usr/local/lib/python3.6/dist-packages (from distiller==0.4.0rc0) (4.6.11)\n","Requirement already satisfied: xlsxwriter>=1.2.2 in /usr/local/lib/python3.6/dist-packages (from distiller==0.4.0rc0) (1.3.7)\n","Requirement already satisfied: pretrainedmodels==0.7.4 in /usr/local/lib/python3.6/dist-packages (from distiller==0.4.0rc0) (0.7.4)\n","Requirement already satisfied: scikit-learn==0.21.2 in /usr/local/lib/python3.6/dist-packages (from distiller==0.4.0rc0) (0.21.2)\n","Requirement already satisfied: gym==0.12.5 in /usr/local/lib/python3.6/dist-packages (from distiller==0.4.0rc0) (0.12.5)\n","Requirement already satisfied: tqdm==4.33.0 in /usr/local/lib/python3.6/dist-packages (from distiller==0.4.0rc0) (4.33.0)\n","Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from torchvision==0.4.2->distiller==0.4.0rc0) (1.15.0)\n","Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.6/dist-packages (from gitpython==3.1.0->distiller==0.4.0rc0) (4.0.5)\n","Requirement already satisfied: visdom in /usr/local/lib/python3.6/dist-packages (from torchnet==0.0.4->distiller==0.4.0rc0) (0.1.8.9)\n","Requirement already satisfied: gast==0.2.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow~=1.14->distiller==0.4.0rc0) (0.2.2)\n","Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow~=1.14->distiller==0.4.0rc0) (3.12.4)\n","Requirement already satisfied: tensorboard<1.16.0,>=1.15.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow~=1.14->distiller==0.4.0rc0) (1.15.0)\n","Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow~=1.14->distiller==0.4.0rc0) (1.12.1)\n","Requirement already satisfied: tensorflow-estimator==1.15.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow~=1.14->distiller==0.4.0rc0) (1.15.1)\n","Requirement already satisfied: google-pasta>=0.1.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow~=1.14->distiller==0.4.0rc0) (0.2.0)\n","Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow~=1.14->distiller==0.4.0rc0) (1.1.2)\n","Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow~=1.14->distiller==0.4.0rc0) (0.10.0)\n","Requirement already satisfied: keras-applications>=1.0.8 in /usr/local/lib/python3.6/dist-packages (from tensorflow~=1.14->distiller==0.4.0rc0) (1.0.8)\n","Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow~=1.14->distiller==0.4.0rc0) (3.3.0)\n","Requirement already satisfied: wheel>=0.26; python_version >= \"3\" in /usr/local/lib/python3.6/dist-packages (from tensorflow~=1.14->distiller==0.4.0rc0) (0.35.1)\n","Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow~=1.14->distiller==0.4.0rc0) (1.1.0)\n","Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow~=1.14->distiller==0.4.0rc0) (1.33.2)\n","Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow~=1.14->distiller==0.4.0rc0) (0.8.1)\n","Requirement already satisfied: pyparsing>=2.1.4 in /usr/local/lib/python3.6/dist-packages (from pydot==1.4.1->distiller==0.4.0rc0) (2.4.7)\n","Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas>=0.22.0->distiller==0.4.0rc0) (2018.9)\n","Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.6/dist-packages (from pandas>=0.22.0->distiller==0.4.0rc0) (2.8.1)\n","Requirement already satisfied: qtconsole in /usr/local/lib/python3.6/dist-packages (from jupyter>=1.0.0->distiller==0.4.0rc0) (5.0.1)\n","Requirement already satisfied: ipykernel in /usr/local/lib/python3.6/dist-packages (from jupyter>=1.0.0->distiller==0.4.0rc0) (4.10.1)\n","Requirement already satisfied: notebook in /usr/local/lib/python3.6/dist-packages (from jupyter>=1.0.0->distiller==0.4.0rc0) (5.3.1)\n","Requirement already satisfied: nbconvert in /usr/local/lib/python3.6/dist-packages (from jupyter>=1.0.0->distiller==0.4.0rc0) (5.6.1)\n","Requirement already satisfied: jupyter-console in /usr/local/lib/python3.6/dist-packages (from jupyter>=1.0.0->distiller==0.4.0rc0) (5.2.0)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib~=3.0->distiller==0.4.0rc0) (0.10.0)\n","Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib~=3.0->distiller==0.4.0rc0) (1.3.1)\n","Requirement already satisfied: nbformat>=4.2.0 in /usr/local/lib/python3.6/dist-packages (from ipywidgets==7.4.2->distiller==0.4.0rc0) (5.0.8)\n","Requirement already satisfied: ipython>=4.0.0; python_version >= \"3.3\" in /usr/local/lib/python3.6/dist-packages (from ipywidgets==7.4.2->distiller==0.4.0rc0) (5.5.0)\n","Requirement already satisfied: widgetsnbextension~=3.4.0 in /usr/local/lib/python3.6/dist-packages (from ipywidgets==7.4.2->distiller==0.4.0rc0) (3.4.2)\n","Requirement already satisfied: traitlets>=4.3.1 in /usr/local/lib/python3.6/dist-packages (from ipywidgets==7.4.2->distiller==0.4.0rc0) (4.3.3)\n","Requirement already satisfied: traittypes>=0.0.6 in /usr/local/lib/python3.6/dist-packages (from bqplot==0.11.5->distiller==0.4.0rc0) (0.2.1)\n","Requirement already satisfied: importlib-metadata>=0.12; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from pytest~=4.6.1->distiller==0.4.0rc0) (2.0.0)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from pytest~=4.6.1->distiller==0.4.0rc0) (20.4)\n","Requirement already satisfied: atomicwrites>=1.0 in /usr/local/lib/python3.6/dist-packages (from pytest~=4.6.1->distiller==0.4.0rc0) (1.4.0)\n","Requirement already satisfied: wcwidth in /usr/local/lib/python3.6/dist-packages (from pytest~=4.6.1->distiller==0.4.0rc0) (0.2.5)\n","Requirement already satisfied: attrs>=17.4.0 in /usr/local/lib/python3.6/dist-packages (from pytest~=4.6.1->distiller==0.4.0rc0) (20.3.0)\n","Requirement already satisfied: more-itertools>=4.0.0; python_version > \"2.7\" in /usr/local/lib/python3.6/dist-packages (from pytest~=4.6.1->distiller==0.4.0rc0) (8.6.0)\n","Requirement already satisfied: pluggy<1.0,>=0.12 in /usr/local/lib/python3.6/dist-packages (from pytest~=4.6.1->distiller==0.4.0rc0) (0.13.1)\n","Requirement already satisfied: py>=1.5.0 in /usr/local/lib/python3.6/dist-packages (from pytest~=4.6.1->distiller==0.4.0rc0) (1.9.0)\n","Requirement already satisfied: munch in /usr/local/lib/python3.6/dist-packages (from pretrainedmodels==0.7.4->distiller==0.4.0rc0) (2.5.0)\n","Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn==0.21.2->distiller==0.4.0rc0) (0.17.0)\n","Requirement already satisfied: pyglet>=1.2.0 in /usr/local/lib/python3.6/dist-packages (from gym==0.12.5->distiller==0.4.0rc0) (1.5.0)\n","Requirement already satisfied: smmap<4,>=3.0.1 in /usr/local/lib/python3.6/dist-packages (from gitdb<5,>=4.0.1->gitpython==3.1.0->distiller==0.4.0rc0) (3.0.4)\n","Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from visdom->torchnet==0.0.4->distiller==0.4.0rc0) (2.23.0)\n","Requirement already satisfied: jsonpatch in /usr/local/lib/python3.6/dist-packages (from visdom->torchnet==0.0.4->distiller==0.4.0rc0) (1.28)\n","Requirement already satisfied: torchfile in /usr/local/lib/python3.6/dist-packages (from visdom->torchnet==0.0.4->distiller==0.4.0rc0) (0.1.0)\n","Requirement already satisfied: pyzmq in /usr/local/lib/python3.6/dist-packages (from visdom->torchnet==0.0.4->distiller==0.4.0rc0) (20.0.0)\n","Requirement already satisfied: tornado in /usr/local/lib/python3.6/dist-packages (from visdom->torchnet==0.0.4->distiller==0.4.0rc0) (5.1.1)\n","Requirement already satisfied: websocket-client in /usr/local/lib/python3.6/dist-packages (from visdom->torchnet==0.0.4->distiller==0.4.0rc0) (0.57.0)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.6.1->tensorflow~=1.14->distiller==0.4.0rc0) (50.3.2)\n","Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow~=1.14->distiller==0.4.0rc0) (1.0.1)\n","Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow~=1.14->distiller==0.4.0rc0) (3.3.3)\n","Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras-applications>=1.0.8->tensorflow~=1.14->distiller==0.4.0rc0) (2.10.0)\n","Requirement already satisfied: qtpy in /usr/local/lib/python3.6/dist-packages (from qtconsole->jupyter>=1.0.0->distiller==0.4.0rc0) (1.9.0)\n","Requirement already satisfied: jupyter-client>=4.1 in /usr/local/lib/python3.6/dist-packages (from qtconsole->jupyter>=1.0.0->distiller==0.4.0rc0) (5.3.5)\n","Requirement already satisfied: jupyter-core in /usr/local/lib/python3.6/dist-packages (from qtconsole->jupyter>=1.0.0->distiller==0.4.0rc0) (4.7.0)\n","Requirement already satisfied: pygments in /usr/local/lib/python3.6/dist-packages (from qtconsole->jupyter>=1.0.0->distiller==0.4.0rc0) (2.6.1)\n","Requirement already satisfied: ipython-genutils in /usr/local/lib/python3.6/dist-packages (from qtconsole->jupyter>=1.0.0->distiller==0.4.0rc0) (0.2.0)\n","Requirement already satisfied: terminado>=0.8.1 in /usr/local/lib/python3.6/dist-packages (from notebook->jupyter>=1.0.0->distiller==0.4.0rc0) (0.9.1)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.6/dist-packages (from notebook->jupyter>=1.0.0->distiller==0.4.0rc0) (2.11.2)\n","Requirement already satisfied: Send2Trash in /usr/local/lib/python3.6/dist-packages (from notebook->jupyter>=1.0.0->distiller==0.4.0rc0) (1.5.0)\n","Requirement already satisfied: testpath in /usr/local/lib/python3.6/dist-packages (from nbconvert->jupyter>=1.0.0->distiller==0.4.0rc0) (0.4.4)\n","Requirement already satisfied: mistune<2,>=0.8.1 in /usr/local/lib/python3.6/dist-packages (from nbconvert->jupyter>=1.0.0->distiller==0.4.0rc0) (0.8.4)\n","Requirement already satisfied: entrypoints>=0.2.2 in /usr/local/lib/python3.6/dist-packages (from nbconvert->jupyter>=1.0.0->distiller==0.4.0rc0) (0.3)\n","Requirement already satisfied: bleach in /usr/local/lib/python3.6/dist-packages (from nbconvert->jupyter>=1.0.0->distiller==0.4.0rc0) (3.2.1)\n","Requirement already satisfied: pandocfilters>=1.4.1 in /usr/local/lib/python3.6/dist-packages (from nbconvert->jupyter>=1.0.0->distiller==0.4.0rc0) (1.4.3)\n","Requirement already satisfied: defusedxml in /usr/local/lib/python3.6/dist-packages (from nbconvert->jupyter>=1.0.0->distiller==0.4.0rc0) (0.6.0)\n","Requirement already satisfied: prompt-toolkit<2.0.0,>=1.0.0 in /usr/local/lib/python3.6/dist-packages (from jupyter-console->jupyter>=1.0.0->distiller==0.4.0rc0) (1.0.18)\n","Requirement already satisfied: jsonschema!=2.5.0,>=2.4 in /usr/local/lib/python3.6/dist-packages (from nbformat>=4.2.0->ipywidgets==7.4.2->distiller==0.4.0rc0) (2.6.0)\n","Requirement already satisfied: simplegeneric>0.8 in /usr/local/lib/python3.6/dist-packages (from ipython>=4.0.0; python_version >= \"3.3\"->ipywidgets==7.4.2->distiller==0.4.0rc0) (0.8.1)\n","Requirement already satisfied: pexpect; sys_platform != \"win32\" in /usr/local/lib/python3.6/dist-packages (from ipython>=4.0.0; python_version >= \"3.3\"->ipywidgets==7.4.2->distiller==0.4.0rc0) (4.8.0)\n","Requirement already satisfied: decorator in /usr/local/lib/python3.6/dist-packages (from ipython>=4.0.0; python_version >= \"3.3\"->ipywidgets==7.4.2->distiller==0.4.0rc0) (4.4.2)\n","Requirement already satisfied: pickleshare in /usr/local/lib/python3.6/dist-packages (from ipython>=4.0.0; python_version >= \"3.3\"->ipywidgets==7.4.2->distiller==0.4.0rc0) (0.7.5)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata>=0.12; python_version < \"3.8\"->pytest~=4.6.1->distiller==0.4.0rc0) (3.4.0)\n","Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from pyglet>=1.2.0->gym==0.12.5->distiller==0.4.0rc0) (0.16.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->visdom->torchnet==0.0.4->distiller==0.4.0rc0) (2020.11.8)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->visdom->torchnet==0.0.4->distiller==0.4.0rc0) (3.0.4)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->visdom->torchnet==0.0.4->distiller==0.4.0rc0) (1.24.3)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->visdom->torchnet==0.0.4->distiller==0.4.0rc0) (2.10)\n","Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.6/dist-packages (from jsonpatch->visdom->torchnet==0.0.4->distiller==0.4.0rc0) (2.0)\n","Requirement already satisfied: ptyprocess; os_name != \"nt\" in /usr/local/lib/python3.6/dist-packages (from terminado>=0.8.1->notebook->jupyter>=1.0.0->distiller==0.4.0rc0) (0.6.0)\n","Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.6/dist-packages (from jinja2->notebook->jupyter>=1.0.0->distiller==0.4.0rc0) (1.1.1)\n","Requirement already satisfied: webencodings in /usr/local/lib/python3.6/dist-packages (from bleach->nbconvert->jupyter>=1.0.0->distiller==0.4.0rc0) (0.5.1)\n","Installing collected packages: distiller\n","  Found existing installation: distiller 0.4.0rc0\n","    Can't uninstall 'distiller'. No files were found to uninstall.\n","  Running setup.py develop for distiller\n","Successfully installed distiller\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"uwMes44EIz8D","executionInfo":{"elapsed":3461,"status":"ok","timestamp":1607492170720,"user":{"displayName":"Jeremy Wang","photoUrl":"","userId":"16277065741529505083"},"user_tz":300},"outputId":"39d9e3c5-74f7-4de4-f5ee-ac0f4eb398d4"},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"6pn4X8vY7gLm"},"source":["import torch\n","import torchvision\n","import torchvision.transforms as transforms\n","import torchvision.models as models\n","from torchsummary import summary\n","import matplotlib.pyplot as plt\n","import numpy as np\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import time\n","import math\n","import copy\n","import torchnet as tnt\n","from ipywidgets import widgets, interact\n","from copy import deepcopy\n","from collections import OrderedDict\n","\n","\n","from collections import OrderedDict\n","import os\n","import pandas as pd\n","import distiller.models\n","import distiller.quantization as quant\n","import distiller"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"60KmjoMLW8VE","executionInfo":{"elapsed":14554,"status":"ok","timestamp":1607492184755,"user":{"displayName":"Jeremy Wang","photoUrl":"","userId":"16277065741529505083"},"user_tz":300},"outputId":"4312933a-7607-4a09-9d09-4a6d1b3d1724"},"source":["#helper functions\n","\n","transformTest = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))])\n","\n","test = torchvision.datasets.CIFAR10(root='./data', train=False,\n","                                       download=True, transform = transformTest)\n","testLoader = torch.utils.data.DataLoader(test, batch_size=256,\n","                                         shuffle=False, num_workers=2)\n","                                         \n","baseModelCheckpoint = torch.load(\"/content/drive/MyDrive/CS6787 - Final Project/Google Colab Scripts/Baseline Models/baseResnet56\")\n","\n","baseModel = distiller.models.create_model(False, \"cifar10\", \"resnet56_cifar\", True, None)\n","baseModel.load_state_dict(baseModelCheckpoint[\"state_dict\"])\n","\n","# compute parameters for base model\n","# TODO: USE DISTILLER FOR COMPUTING SPARSITY. distiller.utils.model_sparsity(model)\n","# the below also gives correct counts\n","# def computeTotalParameters(model): \n","#   return sum(p.numel() for p in model.parameters() if p.dim() in [2,4])\n","\n","def to_sparse(x):\n","    \"\"\" converts dense tensor x to sparse format \"\"\"\n","    x_typename = torch.typename(x).split('.')[-1]\n","    sparse_tensortype = getattr(torch.sparse, x_typename)\n","\n","    indices = torch.nonzero(x)\n","    if len(indices.shape) == 0:  # if all elements are zeros\n","        return sparse_tensortype(*x.shape)\n","    indices = indices.t()\n","    values = x[tuple(indices[i] for i in range(indices.shape[0]))]\n","    return sparse_tensortype(indices, values, x.size())\n","\n","def computeStateSizes(state_dict, compressed = True):\n","  originalSize = 0\n","  compressedSize = 0\n","  torch.save(state_dict, \"./curStateDict\")\n","  totalSize = os.path.getsize(\"./curStateDict\")\n","  if compressed:\n","    for value in state_dict.values():\n","      torch.save(value, \"denseTensor\")\n","      sparse = to_sparse(value)\n","      torch.save(sparse.indices(), \"sparseTensorIndices\")\n","      torch.save(sparse.values(), \"sparseTensorValues\")\n","      torch.save(sparse.size(), \"sparseTensorSize\")\n","      originalSize += os.path.getsize(\"./denseTensor\")\n","      compressedSize += os.path.getsize(\"./sparseTensorIndices\") + os.path.getsize(\"./sparseTensorValues\") + os.path.getsize(\"./sparseTensorSize\")\n","    os.remove(\"./denseTensor\")\n","    os.remove(\"./sparseTensorIndices\")\n","    os.remove(\"./sparseTensorValues\")\n","    os.remove(\"./sparseTensorSize\")\n","    return (totalSize - originalSize + compressedSize) / (1024*1024)\n","  else:\n","    return totalSize\n","\n","# TODO: Use this for computing sparsity instead\n","# def computeTotalParameters(model):\n","#   return sum(p.numel() for p in model.parameters() if p.requires_grad)\n","\n","# def computeZeroParameters(model):\n","#   return sum(p.numel() - p.nonzero().size(0) for p in model.parameters() if p.requires_grad)\n","\n","# def computeSparsity(model):\n","#   return round(computeZeroParameters (model) / computeTotalParameters(model) * 100, 3)\n","\n","def computeSize(model):\n","  torch.save(model, \"./curModel\")\n","  size = os.path.getsize(\"./curModel\")\n","  os.remove(\"./curModel\")\n","  return size / (1024*1024)\n","\n","def computeCompressedModelSize(model):\n","  stateSize = computeStateSizes(model.state_dict(), True)\n","  return stateSize + computeSize(model) - computeStateSizes(model.state_dict(), False)\n","\n","def computeTotalParameters(model):\n","  return sum(p.nonzero().size(0) for p in model.parameters())\n","\n","def computeTotalTrainableParameters(model):\n","  return sum(p.nonzero().size(0) for p in model.parameters() if p.requires_grad)\n","\n","baseParameters = computeTotalParameters(baseModel)\n","baseTrainParameters = computeTotalTrainableParameters(baseModel)\n","baseSize = computeSize(baseModel)\n","\n","def computeIndexSavingRate(baseParameters, compressedParameters):\n","  return (baseParameters - compressedParameters)/compressedParameters\n","\n","def computeStatistics(compressedModel):\n","  modelParameters = computeTotalParameters(compressedModel)\n","  modelTrainParameters = computeTotalTrainableParameters(compressedModel)d\n","  modelSize = computeCompressedModelSize(compressedModel)\n","  indexSavingRate = computeIndexSavingRate(baseParameters, modelParameters)\n","  indexSavingRateTrain = computeIndexSavingRate(baseTrainParameters, modelTrainParameters)\n","  parameterCompressionRate = baseParameters / modelparameters\n","  parameterCompressionRateTrain =  baseTrainParameters / modelTrainParameters\n","  size = computeSize(compressedModel)\n","  sizeCompressionRate = baseSize / size\n","  return {\"Size Compression Rate\" : sizeCompressionRate, \"ParameterCompressionRate\" : parameterCompressionRate, \"IndexSavingRate\": indexSavingRate, \n","          \"Train Parameter Compression Rate\" : parameterCompressionRateTrain, \"Train Index Saving Rate\" : indexSavingRateTrain}\n","\n","def test(net):\n","    net.eval()\n","    test_loss = 0\n","    correct = 0\n","    total = 0\n","    criterion = nn.CrossEntropyLoss()\n","    with torch.no_grad():\n","        for batch_idx, (inputs, targets) in enumerate(testLoader):\n","            inputs, targets = inputs.to('cuda'), targets.to('cuda')\n","            outputs = net(inputs)\n","            loss = criterion(outputs, targets)\n","            test_loss += loss.item()\n","            _, predicted = outputs.max(1)\n","            total += targets.size(0)\n","            correct += predicted.eq(targets).sum().item()\n","    acc = 100.*correct/total\n","    return acc"],"execution_count":null,"outputs":[{"output_type":"stream","text":["  0%|          | 8192/170498071 [00:00<36:47, 77225.04it/s]"],"name":"stderr"},{"output_type":"stream","text":["Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./data/cifar-10-python.tar.gz\n"],"name":"stdout"},{"output_type":"stream","text":["170500096it [00:01, 97140725.72it/s]                               \n"],"name":"stderr"},{"output_type":"stream","text":["Extracting ./data/cifar-10-python.tar.gz to ./data\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"M7Hp88ydlv6R","executionInfo":{"elapsed":14518,"status":"ok","timestamp":1607459700159,"user":{"displayName":"Jeremy Wang","photoUrl":"","userId":"16277065741529505083"},"user_tz":300},"outputId":"1c381888-dc8f-42c5-93a9-0f158533a080"},"source":["test(baseModel)"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["92.94"]},"metadata":{"tags":[]},"execution_count":4}]},{"cell_type":"code","metadata":{"id":"Jc5PlmwWqGki"},"source":["def removeModule(checkpoint):\n","  state_dictionary = checkpoint[\"state_dict\"]\n","  newDict = {}\n","  for key,value in state_dictionary.items():\n","    newKey = key[7:]\n","    newDict[key] = value\n","  checkpoint[\"state_dict\"] = newDict\n","  return checkpoint"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ENz2hDstFhJ_"},"source":["# Seeing Layers"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"zdnKIavV593Y","executionInfo":{"elapsed":467,"status":"ok","timestamp":1607407047380,"user":{"displayName":"Jeremy Wang","photoUrl":"","userId":"16277065741529505083"},"user_tz":300},"outputId":"61585d7e-58e1-4984-d002-416cfc9c26bc"},"source":["# Structure Pruning\n","testere = torch.load(\"/content/drive/MyDrive/CS6787 - Final Project/Google Colab Scripts/Pruning Models/Structure Pruning/ActivationAPoZRankedFilterPruner/Averagepercentage of zeros (APoZ) V1/best.pth.tar\")\n","print(len(testere[\"state_dict\"].keys()))\n","testere[\"state_dict\"].keys()"],"execution_count":null,"outputs":[{"output_type":"stream","text":["344\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["odict_keys(['module.conv1.weight', 'module.bn1.weight', 'module.bn1.bias', 'module.bn1.running_mean', 'module.bn1.running_var', 'module.bn1.num_batches_tracked', 'module.layer1.0.conv1.weight', 'module.layer1.0.bn1.weight', 'module.layer1.0.bn1.bias', 'module.layer1.0.bn1.running_mean', 'module.layer1.0.bn1.running_var', 'module.layer1.0.bn1.num_batches_tracked', 'module.layer1.0.conv2.weight', 'module.layer1.0.bn2.weight', 'module.layer1.0.bn2.bias', 'module.layer1.0.bn2.running_mean', 'module.layer1.0.bn2.running_var', 'module.layer1.0.bn2.num_batches_tracked', 'module.layer1.1.conv1.weight', 'module.layer1.1.bn1.weight', 'module.layer1.1.bn1.bias', 'module.layer1.1.bn1.running_mean', 'module.layer1.1.bn1.running_var', 'module.layer1.1.bn1.num_batches_tracked', 'module.layer1.1.conv2.weight', 'module.layer1.1.bn2.weight', 'module.layer1.1.bn2.bias', 'module.layer1.1.bn2.running_mean', 'module.layer1.1.bn2.running_var', 'module.layer1.1.bn2.num_batches_tracked', 'module.layer1.2.conv1.weight', 'module.layer1.2.bn1.weight', 'module.layer1.2.bn1.bias', 'module.layer1.2.bn1.running_mean', 'module.layer1.2.bn1.running_var', 'module.layer1.2.bn1.num_batches_tracked', 'module.layer1.2.conv2.weight', 'module.layer1.2.bn2.weight', 'module.layer1.2.bn2.bias', 'module.layer1.2.bn2.running_mean', 'module.layer1.2.bn2.running_var', 'module.layer1.2.bn2.num_batches_tracked', 'module.layer1.3.conv1.weight', 'module.layer1.3.bn1.weight', 'module.layer1.3.bn1.bias', 'module.layer1.3.bn1.running_mean', 'module.layer1.3.bn1.running_var', 'module.layer1.3.bn1.num_batches_tracked', 'module.layer1.3.conv2.weight', 'module.layer1.3.bn2.weight', 'module.layer1.3.bn2.bias', 'module.layer1.3.bn2.running_mean', 'module.layer1.3.bn2.running_var', 'module.layer1.3.bn2.num_batches_tracked', 'module.layer1.4.conv1.weight', 'module.layer1.4.bn1.weight', 'module.layer1.4.bn1.bias', 'module.layer1.4.bn1.running_mean', 'module.layer1.4.bn1.running_var', 'module.layer1.4.bn1.num_batches_tracked', 'module.layer1.4.conv2.weight', 'module.layer1.4.bn2.weight', 'module.layer1.4.bn2.bias', 'module.layer1.4.bn2.running_mean', 'module.layer1.4.bn2.running_var', 'module.layer1.4.bn2.num_batches_tracked', 'module.layer1.5.conv1.weight', 'module.layer1.5.bn1.weight', 'module.layer1.5.bn1.bias', 'module.layer1.5.bn1.running_mean', 'module.layer1.5.bn1.running_var', 'module.layer1.5.bn1.num_batches_tracked', 'module.layer1.5.conv2.weight', 'module.layer1.5.bn2.weight', 'module.layer1.5.bn2.bias', 'module.layer1.5.bn2.running_mean', 'module.layer1.5.bn2.running_var', 'module.layer1.5.bn2.num_batches_tracked', 'module.layer1.6.conv1.weight', 'module.layer1.6.bn1.weight', 'module.layer1.6.bn1.bias', 'module.layer1.6.bn1.running_mean', 'module.layer1.6.bn1.running_var', 'module.layer1.6.bn1.num_batches_tracked', 'module.layer1.6.conv2.weight', 'module.layer1.6.bn2.weight', 'module.layer1.6.bn2.bias', 'module.layer1.6.bn2.running_mean', 'module.layer1.6.bn2.running_var', 'module.layer1.6.bn2.num_batches_tracked', 'module.layer1.7.conv1.weight', 'module.layer1.7.bn1.weight', 'module.layer1.7.bn1.bias', 'module.layer1.7.bn1.running_mean', 'module.layer1.7.bn1.running_var', 'module.layer1.7.bn1.num_batches_tracked', 'module.layer1.7.conv2.weight', 'module.layer1.7.bn2.weight', 'module.layer1.7.bn2.bias', 'module.layer1.7.bn2.running_mean', 'module.layer1.7.bn2.running_var', 'module.layer1.7.bn2.num_batches_tracked', 'module.layer1.8.conv1.weight', 'module.layer1.8.bn1.weight', 'module.layer1.8.bn1.bias', 'module.layer1.8.bn1.running_mean', 'module.layer1.8.bn1.running_var', 'module.layer1.8.bn1.num_batches_tracked', 'module.layer1.8.conv2.weight', 'module.layer1.8.bn2.weight', 'module.layer1.8.bn2.bias', 'module.layer1.8.bn2.running_mean', 'module.layer1.8.bn2.running_var', 'module.layer1.8.bn2.num_batches_tracked', 'module.layer2.0.conv1.weight', 'module.layer2.0.bn1.weight', 'module.layer2.0.bn1.bias', 'module.layer2.0.bn1.running_mean', 'module.layer2.0.bn1.running_var', 'module.layer2.0.bn1.num_batches_tracked', 'module.layer2.0.conv2.weight', 'module.layer2.0.bn2.weight', 'module.layer2.0.bn2.bias', 'module.layer2.0.bn2.running_mean', 'module.layer2.0.bn2.running_var', 'module.layer2.0.bn2.num_batches_tracked', 'module.layer2.0.downsample.0.weight', 'module.layer2.0.downsample.1.weight', 'module.layer2.0.downsample.1.bias', 'module.layer2.0.downsample.1.running_mean', 'module.layer2.0.downsample.1.running_var', 'module.layer2.0.downsample.1.num_batches_tracked', 'module.layer2.1.conv1.weight', 'module.layer2.1.bn1.weight', 'module.layer2.1.bn1.bias', 'module.layer2.1.bn1.running_mean', 'module.layer2.1.bn1.running_var', 'module.layer2.1.bn1.num_batches_tracked', 'module.layer2.1.conv2.weight', 'module.layer2.1.bn2.weight', 'module.layer2.1.bn2.bias', 'module.layer2.1.bn2.running_mean', 'module.layer2.1.bn2.running_var', 'module.layer2.1.bn2.num_batches_tracked', 'module.layer2.2.conv1.weight', 'module.layer2.2.bn1.weight', 'module.layer2.2.bn1.bias', 'module.layer2.2.bn1.running_mean', 'module.layer2.2.bn1.running_var', 'module.layer2.2.bn1.num_batches_tracked', 'module.layer2.2.conv2.weight', 'module.layer2.2.bn2.weight', 'module.layer2.2.bn2.bias', 'module.layer2.2.bn2.running_mean', 'module.layer2.2.bn2.running_var', 'module.layer2.2.bn2.num_batches_tracked', 'module.layer2.3.conv1.weight', 'module.layer2.3.bn1.weight', 'module.layer2.3.bn1.bias', 'module.layer2.3.bn1.running_mean', 'module.layer2.3.bn1.running_var', 'module.layer2.3.bn1.num_batches_tracked', 'module.layer2.3.conv2.weight', 'module.layer2.3.bn2.weight', 'module.layer2.3.bn2.bias', 'module.layer2.3.bn2.running_mean', 'module.layer2.3.bn2.running_var', 'module.layer2.3.bn2.num_batches_tracked', 'module.layer2.4.conv1.weight', 'module.layer2.4.bn1.weight', 'module.layer2.4.bn1.bias', 'module.layer2.4.bn1.running_mean', 'module.layer2.4.bn1.running_var', 'module.layer2.4.bn1.num_batches_tracked', 'module.layer2.4.conv2.weight', 'module.layer2.4.bn2.weight', 'module.layer2.4.bn2.bias', 'module.layer2.4.bn2.running_mean', 'module.layer2.4.bn2.running_var', 'module.layer2.4.bn2.num_batches_tracked', 'module.layer2.5.conv1.weight', 'module.layer2.5.bn1.weight', 'module.layer2.5.bn1.bias', 'module.layer2.5.bn1.running_mean', 'module.layer2.5.bn1.running_var', 'module.layer2.5.bn1.num_batches_tracked', 'module.layer2.5.conv2.weight', 'module.layer2.5.bn2.weight', 'module.layer2.5.bn2.bias', 'module.layer2.5.bn2.running_mean', 'module.layer2.5.bn2.running_var', 'module.layer2.5.bn2.num_batches_tracked', 'module.layer2.6.conv1.weight', 'module.layer2.6.bn1.weight', 'module.layer2.6.bn1.bias', 'module.layer2.6.bn1.running_mean', 'module.layer2.6.bn1.running_var', 'module.layer2.6.bn1.num_batches_tracked', 'module.layer2.6.conv2.weight', 'module.layer2.6.bn2.weight', 'module.layer2.6.bn2.bias', 'module.layer2.6.bn2.running_mean', 'module.layer2.6.bn2.running_var', 'module.layer2.6.bn2.num_batches_tracked', 'module.layer2.7.conv1.weight', 'module.layer2.7.bn1.weight', 'module.layer2.7.bn1.bias', 'module.layer2.7.bn1.running_mean', 'module.layer2.7.bn1.running_var', 'module.layer2.7.bn1.num_batches_tracked', 'module.layer2.7.conv2.weight', 'module.layer2.7.bn2.weight', 'module.layer2.7.bn2.bias', 'module.layer2.7.bn2.running_mean', 'module.layer2.7.bn2.running_var', 'module.layer2.7.bn2.num_batches_tracked', 'module.layer2.8.conv1.weight', 'module.layer2.8.bn1.weight', 'module.layer2.8.bn1.bias', 'module.layer2.8.bn1.running_mean', 'module.layer2.8.bn1.running_var', 'module.layer2.8.bn1.num_batches_tracked', 'module.layer2.8.conv2.weight', 'module.layer2.8.bn2.weight', 'module.layer2.8.bn2.bias', 'module.layer2.8.bn2.running_mean', 'module.layer2.8.bn2.running_var', 'module.layer2.8.bn2.num_batches_tracked', 'module.layer3.0.conv1.weight', 'module.layer3.0.bn1.weight', 'module.layer3.0.bn1.bias', 'module.layer3.0.bn1.running_mean', 'module.layer3.0.bn1.running_var', 'module.layer3.0.bn1.num_batches_tracked', 'module.layer3.0.conv2.weight', 'module.layer3.0.bn2.weight', 'module.layer3.0.bn2.bias', 'module.layer3.0.bn2.running_mean', 'module.layer3.0.bn2.running_var', 'module.layer3.0.bn2.num_batches_tracked', 'module.layer3.0.downsample.0.weight', 'module.layer3.0.downsample.1.weight', 'module.layer3.0.downsample.1.bias', 'module.layer3.0.downsample.1.running_mean', 'module.layer3.0.downsample.1.running_var', 'module.layer3.0.downsample.1.num_batches_tracked', 'module.layer3.1.conv1.weight', 'module.layer3.1.bn1.weight', 'module.layer3.1.bn1.bias', 'module.layer3.1.bn1.running_mean', 'module.layer3.1.bn1.running_var', 'module.layer3.1.bn1.num_batches_tracked', 'module.layer3.1.conv2.weight', 'module.layer3.1.bn2.weight', 'module.layer3.1.bn2.bias', 'module.layer3.1.bn2.running_mean', 'module.layer3.1.bn2.running_var', 'module.layer3.1.bn2.num_batches_tracked', 'module.layer3.2.conv1.weight', 'module.layer3.2.bn1.weight', 'module.layer3.2.bn1.bias', 'module.layer3.2.bn1.running_mean', 'module.layer3.2.bn1.running_var', 'module.layer3.2.bn1.num_batches_tracked', 'module.layer3.2.conv2.weight', 'module.layer3.2.bn2.weight', 'module.layer3.2.bn2.bias', 'module.layer3.2.bn2.running_mean', 'module.layer3.2.bn2.running_var', 'module.layer3.2.bn2.num_batches_tracked', 'module.layer3.3.conv1.weight', 'module.layer3.3.bn1.weight', 'module.layer3.3.bn1.bias', 'module.layer3.3.bn1.running_mean', 'module.layer3.3.bn1.running_var', 'module.layer3.3.bn1.num_batches_tracked', 'module.layer3.3.conv2.weight', 'module.layer3.3.bn2.weight', 'module.layer3.3.bn2.bias', 'module.layer3.3.bn2.running_mean', 'module.layer3.3.bn2.running_var', 'module.layer3.3.bn2.num_batches_tracked', 'module.layer3.4.conv1.weight', 'module.layer3.4.bn1.weight', 'module.layer3.4.bn1.bias', 'module.layer3.4.bn1.running_mean', 'module.layer3.4.bn1.running_var', 'module.layer3.4.bn1.num_batches_tracked', 'module.layer3.4.conv2.weight', 'module.layer3.4.bn2.weight', 'module.layer3.4.bn2.bias', 'module.layer3.4.bn2.running_mean', 'module.layer3.4.bn2.running_var', 'module.layer3.4.bn2.num_batches_tracked', 'module.layer3.5.conv1.weight', 'module.layer3.5.bn1.weight', 'module.layer3.5.bn1.bias', 'module.layer3.5.bn1.running_mean', 'module.layer3.5.bn1.running_var', 'module.layer3.5.bn1.num_batches_tracked', 'module.layer3.5.conv2.weight', 'module.layer3.5.bn2.weight', 'module.layer3.5.bn2.bias', 'module.layer3.5.bn2.running_mean', 'module.layer3.5.bn2.running_var', 'module.layer3.5.bn2.num_batches_tracked', 'module.layer3.6.conv1.weight', 'module.layer3.6.bn1.weight', 'module.layer3.6.bn1.bias', 'module.layer3.6.bn1.running_mean', 'module.layer3.6.bn1.running_var', 'module.layer3.6.bn1.num_batches_tracked', 'module.layer3.6.conv2.weight', 'module.layer3.6.bn2.weight', 'module.layer3.6.bn2.bias', 'module.layer3.6.bn2.running_mean', 'module.layer3.6.bn2.running_var', 'module.layer3.6.bn2.num_batches_tracked', 'module.layer3.7.conv1.weight', 'module.layer3.7.bn1.weight', 'module.layer3.7.bn1.bias', 'module.layer3.7.bn1.running_mean', 'module.layer3.7.bn1.running_var', 'module.layer3.7.bn1.num_batches_tracked', 'module.layer3.7.conv2.weight', 'module.layer3.7.bn2.weight', 'module.layer3.7.bn2.bias', 'module.layer3.7.bn2.running_mean', 'module.layer3.7.bn2.running_var', 'module.layer3.7.bn2.num_batches_tracked', 'module.layer3.8.conv1.weight', 'module.layer3.8.bn1.weight', 'module.layer3.8.bn1.bias', 'module.layer3.8.bn1.running_mean', 'module.layer3.8.bn1.running_var', 'module.layer3.8.bn1.num_batches_tracked', 'module.layer3.8.conv2.weight', 'module.layer3.8.bn2.weight', 'module.layer3.8.bn2.bias', 'module.layer3.8.bn2.running_mean', 'module.layer3.8.bn2.running_var', 'module.layer3.8.bn2.num_batches_tracked', 'module.fc.weight', 'module.fc.bias'])"]},"metadata":{"tags":[]},"execution_count":28}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"QM7JuskRs1t5","executionInfo":{"elapsed":375,"status":"ok","timestamp":1607407063591,"user":{"displayName":"Jeremy Wang","photoUrl":"","userId":"16277065741529505083"},"user_tz":300},"outputId":"21d33fa1-b0c3-4072-ff11-7b70443a9021"},"source":["# Base Model\n","print(len(baseModelCheckpoint[\"state_dict\"].keys()))\n","baseModelCheckpoint[\"state_dict\"].keys()"],"execution_count":null,"outputs":[{"output_type":"stream","text":["344\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["dict_keys(['module.conv1.weight', 'module.bn1.weight', 'module.bn1.bias', 'module.bn1.running_mean', 'module.bn1.running_var', 'module.bn1.num_batches_tracked', 'module.layer1.0.conv1.weight', 'module.layer1.0.bn1.weight', 'module.layer1.0.bn1.bias', 'module.layer1.0.bn1.running_mean', 'module.layer1.0.bn1.running_var', 'module.layer1.0.bn1.num_batches_tracked', 'module.layer1.0.conv2.weight', 'module.layer1.0.bn2.weight', 'module.layer1.0.bn2.bias', 'module.layer1.0.bn2.running_mean', 'module.layer1.0.bn2.running_var', 'module.layer1.0.bn2.num_batches_tracked', 'module.layer1.1.conv1.weight', 'module.layer1.1.bn1.weight', 'module.layer1.1.bn1.bias', 'module.layer1.1.bn1.running_mean', 'module.layer1.1.bn1.running_var', 'module.layer1.1.bn1.num_batches_tracked', 'module.layer1.1.conv2.weight', 'module.layer1.1.bn2.weight', 'module.layer1.1.bn2.bias', 'module.layer1.1.bn2.running_mean', 'module.layer1.1.bn2.running_var', 'module.layer1.1.bn2.num_batches_tracked', 'module.layer1.2.conv1.weight', 'module.layer1.2.bn1.weight', 'module.layer1.2.bn1.bias', 'module.layer1.2.bn1.running_mean', 'module.layer1.2.bn1.running_var', 'module.layer1.2.bn1.num_batches_tracked', 'module.layer1.2.conv2.weight', 'module.layer1.2.bn2.weight', 'module.layer1.2.bn2.bias', 'module.layer1.2.bn2.running_mean', 'module.layer1.2.bn2.running_var', 'module.layer1.2.bn2.num_batches_tracked', 'module.layer1.3.conv1.weight', 'module.layer1.3.bn1.weight', 'module.layer1.3.bn1.bias', 'module.layer1.3.bn1.running_mean', 'module.layer1.3.bn1.running_var', 'module.layer1.3.bn1.num_batches_tracked', 'module.layer1.3.conv2.weight', 'module.layer1.3.bn2.weight', 'module.layer1.3.bn2.bias', 'module.layer1.3.bn2.running_mean', 'module.layer1.3.bn2.running_var', 'module.layer1.3.bn2.num_batches_tracked', 'module.layer1.4.conv1.weight', 'module.layer1.4.bn1.weight', 'module.layer1.4.bn1.bias', 'module.layer1.4.bn1.running_mean', 'module.layer1.4.bn1.running_var', 'module.layer1.4.bn1.num_batches_tracked', 'module.layer1.4.conv2.weight', 'module.layer1.4.bn2.weight', 'module.layer1.4.bn2.bias', 'module.layer1.4.bn2.running_mean', 'module.layer1.4.bn2.running_var', 'module.layer1.4.bn2.num_batches_tracked', 'module.layer1.5.conv1.weight', 'module.layer1.5.bn1.weight', 'module.layer1.5.bn1.bias', 'module.layer1.5.bn1.running_mean', 'module.layer1.5.bn1.running_var', 'module.layer1.5.bn1.num_batches_tracked', 'module.layer1.5.conv2.weight', 'module.layer1.5.bn2.weight', 'module.layer1.5.bn2.bias', 'module.layer1.5.bn2.running_mean', 'module.layer1.5.bn2.running_var', 'module.layer1.5.bn2.num_batches_tracked', 'module.layer1.6.conv1.weight', 'module.layer1.6.bn1.weight', 'module.layer1.6.bn1.bias', 'module.layer1.6.bn1.running_mean', 'module.layer1.6.bn1.running_var', 'module.layer1.6.bn1.num_batches_tracked', 'module.layer1.6.conv2.weight', 'module.layer1.6.bn2.weight', 'module.layer1.6.bn2.bias', 'module.layer1.6.bn2.running_mean', 'module.layer1.6.bn2.running_var', 'module.layer1.6.bn2.num_batches_tracked', 'module.layer1.7.conv1.weight', 'module.layer1.7.bn1.weight', 'module.layer1.7.bn1.bias', 'module.layer1.7.bn1.running_mean', 'module.layer1.7.bn1.running_var', 'module.layer1.7.bn1.num_batches_tracked', 'module.layer1.7.conv2.weight', 'module.layer1.7.bn2.weight', 'module.layer1.7.bn2.bias', 'module.layer1.7.bn2.running_mean', 'module.layer1.7.bn2.running_var', 'module.layer1.7.bn2.num_batches_tracked', 'module.layer1.8.conv1.weight', 'module.layer1.8.bn1.weight', 'module.layer1.8.bn1.bias', 'module.layer1.8.bn1.running_mean', 'module.layer1.8.bn1.running_var', 'module.layer1.8.bn1.num_batches_tracked', 'module.layer1.8.conv2.weight', 'module.layer1.8.bn2.weight', 'module.layer1.8.bn2.bias', 'module.layer1.8.bn2.running_mean', 'module.layer1.8.bn2.running_var', 'module.layer1.8.bn2.num_batches_tracked', 'module.layer2.0.conv1.weight', 'module.layer2.0.bn1.weight', 'module.layer2.0.bn1.bias', 'module.layer2.0.bn1.running_mean', 'module.layer2.0.bn1.running_var', 'module.layer2.0.bn1.num_batches_tracked', 'module.layer2.0.conv2.weight', 'module.layer2.0.bn2.weight', 'module.layer2.0.bn2.bias', 'module.layer2.0.bn2.running_mean', 'module.layer2.0.bn2.running_var', 'module.layer2.0.bn2.num_batches_tracked', 'module.layer2.0.downsample.0.weight', 'module.layer2.0.downsample.1.weight', 'module.layer2.0.downsample.1.bias', 'module.layer2.0.downsample.1.running_mean', 'module.layer2.0.downsample.1.running_var', 'module.layer2.0.downsample.1.num_batches_tracked', 'module.layer2.1.conv1.weight', 'module.layer2.1.bn1.weight', 'module.layer2.1.bn1.bias', 'module.layer2.1.bn1.running_mean', 'module.layer2.1.bn1.running_var', 'module.layer2.1.bn1.num_batches_tracked', 'module.layer2.1.conv2.weight', 'module.layer2.1.bn2.weight', 'module.layer2.1.bn2.bias', 'module.layer2.1.bn2.running_mean', 'module.layer2.1.bn2.running_var', 'module.layer2.1.bn2.num_batches_tracked', 'module.layer2.2.conv1.weight', 'module.layer2.2.bn1.weight', 'module.layer2.2.bn1.bias', 'module.layer2.2.bn1.running_mean', 'module.layer2.2.bn1.running_var', 'module.layer2.2.bn1.num_batches_tracked', 'module.layer2.2.conv2.weight', 'module.layer2.2.bn2.weight', 'module.layer2.2.bn2.bias', 'module.layer2.2.bn2.running_mean', 'module.layer2.2.bn2.running_var', 'module.layer2.2.bn2.num_batches_tracked', 'module.layer2.3.conv1.weight', 'module.layer2.3.bn1.weight', 'module.layer2.3.bn1.bias', 'module.layer2.3.bn1.running_mean', 'module.layer2.3.bn1.running_var', 'module.layer2.3.bn1.num_batches_tracked', 'module.layer2.3.conv2.weight', 'module.layer2.3.bn2.weight', 'module.layer2.3.bn2.bias', 'module.layer2.3.bn2.running_mean', 'module.layer2.3.bn2.running_var', 'module.layer2.3.bn2.num_batches_tracked', 'module.layer2.4.conv1.weight', 'module.layer2.4.bn1.weight', 'module.layer2.4.bn1.bias', 'module.layer2.4.bn1.running_mean', 'module.layer2.4.bn1.running_var', 'module.layer2.4.bn1.num_batches_tracked', 'module.layer2.4.conv2.weight', 'module.layer2.4.bn2.weight', 'module.layer2.4.bn2.bias', 'module.layer2.4.bn2.running_mean', 'module.layer2.4.bn2.running_var', 'module.layer2.4.bn2.num_batches_tracked', 'module.layer2.5.conv1.weight', 'module.layer2.5.bn1.weight', 'module.layer2.5.bn1.bias', 'module.layer2.5.bn1.running_mean', 'module.layer2.5.bn1.running_var', 'module.layer2.5.bn1.num_batches_tracked', 'module.layer2.5.conv2.weight', 'module.layer2.5.bn2.weight', 'module.layer2.5.bn2.bias', 'module.layer2.5.bn2.running_mean', 'module.layer2.5.bn2.running_var', 'module.layer2.5.bn2.num_batches_tracked', 'module.layer2.6.conv1.weight', 'module.layer2.6.bn1.weight', 'module.layer2.6.bn1.bias', 'module.layer2.6.bn1.running_mean', 'module.layer2.6.bn1.running_var', 'module.layer2.6.bn1.num_batches_tracked', 'module.layer2.6.conv2.weight', 'module.layer2.6.bn2.weight', 'module.layer2.6.bn2.bias', 'module.layer2.6.bn2.running_mean', 'module.layer2.6.bn2.running_var', 'module.layer2.6.bn2.num_batches_tracked', 'module.layer2.7.conv1.weight', 'module.layer2.7.bn1.weight', 'module.layer2.7.bn1.bias', 'module.layer2.7.bn1.running_mean', 'module.layer2.7.bn1.running_var', 'module.layer2.7.bn1.num_batches_tracked', 'module.layer2.7.conv2.weight', 'module.layer2.7.bn2.weight', 'module.layer2.7.bn2.bias', 'module.layer2.7.bn2.running_mean', 'module.layer2.7.bn2.running_var', 'module.layer2.7.bn2.num_batches_tracked', 'module.layer2.8.conv1.weight', 'module.layer2.8.bn1.weight', 'module.layer2.8.bn1.bias', 'module.layer2.8.bn1.running_mean', 'module.layer2.8.bn1.running_var', 'module.layer2.8.bn1.num_batches_tracked', 'module.layer2.8.conv2.weight', 'module.layer2.8.bn2.weight', 'module.layer2.8.bn2.bias', 'module.layer2.8.bn2.running_mean', 'module.layer2.8.bn2.running_var', 'module.layer2.8.bn2.num_batches_tracked', 'module.layer3.0.conv1.weight', 'module.layer3.0.bn1.weight', 'module.layer3.0.bn1.bias', 'module.layer3.0.bn1.running_mean', 'module.layer3.0.bn1.running_var', 'module.layer3.0.bn1.num_batches_tracked', 'module.layer3.0.conv2.weight', 'module.layer3.0.bn2.weight', 'module.layer3.0.bn2.bias', 'module.layer3.0.bn2.running_mean', 'module.layer3.0.bn2.running_var', 'module.layer3.0.bn2.num_batches_tracked', 'module.layer3.0.downsample.0.weight', 'module.layer3.0.downsample.1.weight', 'module.layer3.0.downsample.1.bias', 'module.layer3.0.downsample.1.running_mean', 'module.layer3.0.downsample.1.running_var', 'module.layer3.0.downsample.1.num_batches_tracked', 'module.layer3.1.conv1.weight', 'module.layer3.1.bn1.weight', 'module.layer3.1.bn1.bias', 'module.layer3.1.bn1.running_mean', 'module.layer3.1.bn1.running_var', 'module.layer3.1.bn1.num_batches_tracked', 'module.layer3.1.conv2.weight', 'module.layer3.1.bn2.weight', 'module.layer3.1.bn2.bias', 'module.layer3.1.bn2.running_mean', 'module.layer3.1.bn2.running_var', 'module.layer3.1.bn2.num_batches_tracked', 'module.layer3.2.conv1.weight', 'module.layer3.2.bn1.weight', 'module.layer3.2.bn1.bias', 'module.layer3.2.bn1.running_mean', 'module.layer3.2.bn1.running_var', 'module.layer3.2.bn1.num_batches_tracked', 'module.layer3.2.conv2.weight', 'module.layer3.2.bn2.weight', 'module.layer3.2.bn2.bias', 'module.layer3.2.bn2.running_mean', 'module.layer3.2.bn2.running_var', 'module.layer3.2.bn2.num_batches_tracked', 'module.layer3.3.conv1.weight', 'module.layer3.3.bn1.weight', 'module.layer3.3.bn1.bias', 'module.layer3.3.bn1.running_mean', 'module.layer3.3.bn1.running_var', 'module.layer3.3.bn1.num_batches_tracked', 'module.layer3.3.conv2.weight', 'module.layer3.3.bn2.weight', 'module.layer3.3.bn2.bias', 'module.layer3.3.bn2.running_mean', 'module.layer3.3.bn2.running_var', 'module.layer3.3.bn2.num_batches_tracked', 'module.layer3.4.conv1.weight', 'module.layer3.4.bn1.weight', 'module.layer3.4.bn1.bias', 'module.layer3.4.bn1.running_mean', 'module.layer3.4.bn1.running_var', 'module.layer3.4.bn1.num_batches_tracked', 'module.layer3.4.conv2.weight', 'module.layer3.4.bn2.weight', 'module.layer3.4.bn2.bias', 'module.layer3.4.bn2.running_mean', 'module.layer3.4.bn2.running_var', 'module.layer3.4.bn2.num_batches_tracked', 'module.layer3.5.conv1.weight', 'module.layer3.5.bn1.weight', 'module.layer3.5.bn1.bias', 'module.layer3.5.bn1.running_mean', 'module.layer3.5.bn1.running_var', 'module.layer3.5.bn1.num_batches_tracked', 'module.layer3.5.conv2.weight', 'module.layer3.5.bn2.weight', 'module.layer3.5.bn2.bias', 'module.layer3.5.bn2.running_mean', 'module.layer3.5.bn2.running_var', 'module.layer3.5.bn2.num_batches_tracked', 'module.layer3.6.conv1.weight', 'module.layer3.6.bn1.weight', 'module.layer3.6.bn1.bias', 'module.layer3.6.bn1.running_mean', 'module.layer3.6.bn1.running_var', 'module.layer3.6.bn1.num_batches_tracked', 'module.layer3.6.conv2.weight', 'module.layer3.6.bn2.weight', 'module.layer3.6.bn2.bias', 'module.layer3.6.bn2.running_mean', 'module.layer3.6.bn2.running_var', 'module.layer3.6.bn2.num_batches_tracked', 'module.layer3.7.conv1.weight', 'module.layer3.7.bn1.weight', 'module.layer3.7.bn1.bias', 'module.layer3.7.bn1.running_mean', 'module.layer3.7.bn1.running_var', 'module.layer3.7.bn1.num_batches_tracked', 'module.layer3.7.conv2.weight', 'module.layer3.7.bn2.weight', 'module.layer3.7.bn2.bias', 'module.layer3.7.bn2.running_mean', 'module.layer3.7.bn2.running_var', 'module.layer3.7.bn2.num_batches_tracked', 'module.layer3.8.conv1.weight', 'module.layer3.8.bn1.weight', 'module.layer3.8.bn1.bias', 'module.layer3.8.bn1.running_mean', 'module.layer3.8.bn1.running_var', 'module.layer3.8.bn1.num_batches_tracked', 'module.layer3.8.conv2.weight', 'module.layer3.8.bn2.weight', 'module.layer3.8.bn2.bias', 'module.layer3.8.bn2.running_mean', 'module.layer3.8.bn2.running_var', 'module.layer3.8.bn2.num_batches_tracked', 'module.fc.weight', 'module.fc.bias'])"]},"metadata":{"tags":[]},"execution_count":31}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"YuYB9yaK6gl8","executionInfo":{"elapsed":646,"status":"ok","timestamp":1607407091521,"user":{"displayName":"Jeremy Wang","photoUrl":"","userId":"16277065741529505083"},"user_tz":300},"outputId":"390da396-7412-4f4b-c214-72b2ce0320fb"},"source":["# Resnet56_cifat10_post_train+retraining_10bit\n","testere = torch.load(\"/content/drive/MyDrive/CS6787 - Final Project/Google Colab Scripts/Quantization Models/Resnet56_cifat10_post_train+retraining_10bit/esterov=True_best.pth.tar\")\n","print(len(testere[\"state_dict\"].keys()))\n","testere[\"state_dict\"].keys()"],"execution_count":null,"outputs":[{"output_type":"stream","text":["969\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["odict_keys(['module.conv1.float_weight', 'module.conv1.weight', 'module.conv1.weight_scale', 'module.conv1.weight_zero_point', 'module.bn1.weight', 'module.bn1.bias', 'module.bn1.running_mean', 'module.bn1.running_var', 'module.bn1.num_batches_tracked', 'module.relu.fake_q.ema_decay', 'module.relu.fake_q.tracked_min_biased', 'module.relu.fake_q.tracked_min', 'module.relu.fake_q.tracked_max_biased', 'module.relu.fake_q.tracked_max', 'module.relu.fake_q.iter_count', 'module.relu.fake_q.scale', 'module.relu.fake_q.zero_point', 'module.layer1.0.conv1.float_weight', 'module.layer1.0.conv1.weight', 'module.layer1.0.conv1.weight_scale', 'module.layer1.0.conv1.weight_zero_point', 'module.layer1.0.bn1.weight', 'module.layer1.0.bn1.bias', 'module.layer1.0.bn1.running_mean', 'module.layer1.0.bn1.running_var', 'module.layer1.0.bn1.num_batches_tracked', 'module.layer1.0.relu1.fake_q.ema_decay', 'module.layer1.0.relu1.fake_q.tracked_min_biased', 'module.layer1.0.relu1.fake_q.tracked_min', 'module.layer1.0.relu1.fake_q.tracked_max_biased', 'module.layer1.0.relu1.fake_q.tracked_max', 'module.layer1.0.relu1.fake_q.iter_count', 'module.layer1.0.relu1.fake_q.scale', 'module.layer1.0.relu1.fake_q.zero_point', 'module.layer1.0.conv2.float_weight', 'module.layer1.0.conv2.weight', 'module.layer1.0.conv2.weight_scale', 'module.layer1.0.conv2.weight_zero_point', 'module.layer1.0.bn2.weight', 'module.layer1.0.bn2.bias', 'module.layer1.0.bn2.running_mean', 'module.layer1.0.bn2.running_var', 'module.layer1.0.bn2.num_batches_tracked', 'module.layer1.0.relu2.fake_q.ema_decay', 'module.layer1.0.relu2.fake_q.tracked_min_biased', 'module.layer1.0.relu2.fake_q.tracked_min', 'module.layer1.0.relu2.fake_q.tracked_max_biased', 'module.layer1.0.relu2.fake_q.tracked_max', 'module.layer1.0.relu2.fake_q.iter_count', 'module.layer1.0.relu2.fake_q.scale', 'module.layer1.0.relu2.fake_q.zero_point', 'module.layer1.1.conv1.float_weight', 'module.layer1.1.conv1.weight', 'module.layer1.1.conv1.weight_scale', 'module.layer1.1.conv1.weight_zero_point', 'module.layer1.1.bn1.weight', 'module.layer1.1.bn1.bias', 'module.layer1.1.bn1.running_mean', 'module.layer1.1.bn1.running_var', 'module.layer1.1.bn1.num_batches_tracked', 'module.layer1.1.relu1.fake_q.ema_decay', 'module.layer1.1.relu1.fake_q.tracked_min_biased', 'module.layer1.1.relu1.fake_q.tracked_min', 'module.layer1.1.relu1.fake_q.tracked_max_biased', 'module.layer1.1.relu1.fake_q.tracked_max', 'module.layer1.1.relu1.fake_q.iter_count', 'module.layer1.1.relu1.fake_q.scale', 'module.layer1.1.relu1.fake_q.zero_point', 'module.layer1.1.conv2.float_weight', 'module.layer1.1.conv2.weight', 'module.layer1.1.conv2.weight_scale', 'module.layer1.1.conv2.weight_zero_point', 'module.layer1.1.bn2.weight', 'module.layer1.1.bn2.bias', 'module.layer1.1.bn2.running_mean', 'module.layer1.1.bn2.running_var', 'module.layer1.1.bn2.num_batches_tracked', 'module.layer1.1.relu2.fake_q.ema_decay', 'module.layer1.1.relu2.fake_q.tracked_min_biased', 'module.layer1.1.relu2.fake_q.tracked_min', 'module.layer1.1.relu2.fake_q.tracked_max_biased', 'module.layer1.1.relu2.fake_q.tracked_max', 'module.layer1.1.relu2.fake_q.iter_count', 'module.layer1.1.relu2.fake_q.scale', 'module.layer1.1.relu2.fake_q.zero_point', 'module.layer1.2.conv1.float_weight', 'module.layer1.2.conv1.weight', 'module.layer1.2.conv1.weight_scale', 'module.layer1.2.conv1.weight_zero_point', 'module.layer1.2.bn1.weight', 'module.layer1.2.bn1.bias', 'module.layer1.2.bn1.running_mean', 'module.layer1.2.bn1.running_var', 'module.layer1.2.bn1.num_batches_tracked', 'module.layer1.2.relu1.fake_q.ema_decay', 'module.layer1.2.relu1.fake_q.tracked_min_biased', 'module.layer1.2.relu1.fake_q.tracked_min', 'module.layer1.2.relu1.fake_q.tracked_max_biased', 'module.layer1.2.relu1.fake_q.tracked_max', 'module.layer1.2.relu1.fake_q.iter_count', 'module.layer1.2.relu1.fake_q.scale', 'module.layer1.2.relu1.fake_q.zero_point', 'module.layer1.2.conv2.float_weight', 'module.layer1.2.conv2.weight', 'module.layer1.2.conv2.weight_scale', 'module.layer1.2.conv2.weight_zero_point', 'module.layer1.2.bn2.weight', 'module.layer1.2.bn2.bias', 'module.layer1.2.bn2.running_mean', 'module.layer1.2.bn2.running_var', 'module.layer1.2.bn2.num_batches_tracked', 'module.layer1.2.relu2.fake_q.ema_decay', 'module.layer1.2.relu2.fake_q.tracked_min_biased', 'module.layer1.2.relu2.fake_q.tracked_min', 'module.layer1.2.relu2.fake_q.tracked_max_biased', 'module.layer1.2.relu2.fake_q.tracked_max', 'module.layer1.2.relu2.fake_q.iter_count', 'module.layer1.2.relu2.fake_q.scale', 'module.layer1.2.relu2.fake_q.zero_point', 'module.layer1.3.conv1.float_weight', 'module.layer1.3.conv1.weight', 'module.layer1.3.conv1.weight_scale', 'module.layer1.3.conv1.weight_zero_point', 'module.layer1.3.bn1.weight', 'module.layer1.3.bn1.bias', 'module.layer1.3.bn1.running_mean', 'module.layer1.3.bn1.running_var', 'module.layer1.3.bn1.num_batches_tracked', 'module.layer1.3.relu1.fake_q.ema_decay', 'module.layer1.3.relu1.fake_q.tracked_min_biased', 'module.layer1.3.relu1.fake_q.tracked_min', 'module.layer1.3.relu1.fake_q.tracked_max_biased', 'module.layer1.3.relu1.fake_q.tracked_max', 'module.layer1.3.relu1.fake_q.iter_count', 'module.layer1.3.relu1.fake_q.scale', 'module.layer1.3.relu1.fake_q.zero_point', 'module.layer1.3.conv2.float_weight', 'module.layer1.3.conv2.weight', 'module.layer1.3.conv2.weight_scale', 'module.layer1.3.conv2.weight_zero_point', 'module.layer1.3.bn2.weight', 'module.layer1.3.bn2.bias', 'module.layer1.3.bn2.running_mean', 'module.layer1.3.bn2.running_var', 'module.layer1.3.bn2.num_batches_tracked', 'module.layer1.3.relu2.fake_q.ema_decay', 'module.layer1.3.relu2.fake_q.tracked_min_biased', 'module.layer1.3.relu2.fake_q.tracked_min', 'module.layer1.3.relu2.fake_q.tracked_max_biased', 'module.layer1.3.relu2.fake_q.tracked_max', 'module.layer1.3.relu2.fake_q.iter_count', 'module.layer1.3.relu2.fake_q.scale', 'module.layer1.3.relu2.fake_q.zero_point', 'module.layer1.4.conv1.float_weight', 'module.layer1.4.conv1.weight', 'module.layer1.4.conv1.weight_scale', 'module.layer1.4.conv1.weight_zero_point', 'module.layer1.4.bn1.weight', 'module.layer1.4.bn1.bias', 'module.layer1.4.bn1.running_mean', 'module.layer1.4.bn1.running_var', 'module.layer1.4.bn1.num_batches_tracked', 'module.layer1.4.relu1.fake_q.ema_decay', 'module.layer1.4.relu1.fake_q.tracked_min_biased', 'module.layer1.4.relu1.fake_q.tracked_min', 'module.layer1.4.relu1.fake_q.tracked_max_biased', 'module.layer1.4.relu1.fake_q.tracked_max', 'module.layer1.4.relu1.fake_q.iter_count', 'module.layer1.4.relu1.fake_q.scale', 'module.layer1.4.relu1.fake_q.zero_point', 'module.layer1.4.conv2.float_weight', 'module.layer1.4.conv2.weight', 'module.layer1.4.conv2.weight_scale', 'module.layer1.4.conv2.weight_zero_point', 'module.layer1.4.bn2.weight', 'module.layer1.4.bn2.bias', 'module.layer1.4.bn2.running_mean', 'module.layer1.4.bn2.running_var', 'module.layer1.4.bn2.num_batches_tracked', 'module.layer1.4.relu2.fake_q.ema_decay', 'module.layer1.4.relu2.fake_q.tracked_min_biased', 'module.layer1.4.relu2.fake_q.tracked_min', 'module.layer1.4.relu2.fake_q.tracked_max_biased', 'module.layer1.4.relu2.fake_q.tracked_max', 'module.layer1.4.relu2.fake_q.iter_count', 'module.layer1.4.relu2.fake_q.scale', 'module.layer1.4.relu2.fake_q.zero_point', 'module.layer1.5.conv1.float_weight', 'module.layer1.5.conv1.weight', 'module.layer1.5.conv1.weight_scale', 'module.layer1.5.conv1.weight_zero_point', 'module.layer1.5.bn1.weight', 'module.layer1.5.bn1.bias', 'module.layer1.5.bn1.running_mean', 'module.layer1.5.bn1.running_var', 'module.layer1.5.bn1.num_batches_tracked', 'module.layer1.5.relu1.fake_q.ema_decay', 'module.layer1.5.relu1.fake_q.tracked_min_biased', 'module.layer1.5.relu1.fake_q.tracked_min', 'module.layer1.5.relu1.fake_q.tracked_max_biased', 'module.layer1.5.relu1.fake_q.tracked_max', 'module.layer1.5.relu1.fake_q.iter_count', 'module.layer1.5.relu1.fake_q.scale', 'module.layer1.5.relu1.fake_q.zero_point', 'module.layer1.5.conv2.float_weight', 'module.layer1.5.conv2.weight', 'module.layer1.5.conv2.weight_scale', 'module.layer1.5.conv2.weight_zero_point', 'module.layer1.5.bn2.weight', 'module.layer1.5.bn2.bias', 'module.layer1.5.bn2.running_mean', 'module.layer1.5.bn2.running_var', 'module.layer1.5.bn2.num_batches_tracked', 'module.layer1.5.relu2.fake_q.ema_decay', 'module.layer1.5.relu2.fake_q.tracked_min_biased', 'module.layer1.5.relu2.fake_q.tracked_min', 'module.layer1.5.relu2.fake_q.tracked_max_biased', 'module.layer1.5.relu2.fake_q.tracked_max', 'module.layer1.5.relu2.fake_q.iter_count', 'module.layer1.5.relu2.fake_q.scale', 'module.layer1.5.relu2.fake_q.zero_point', 'module.layer1.6.conv1.float_weight', 'module.layer1.6.conv1.weight', 'module.layer1.6.conv1.weight_scale', 'module.layer1.6.conv1.weight_zero_point', 'module.layer1.6.bn1.weight', 'module.layer1.6.bn1.bias', 'module.layer1.6.bn1.running_mean', 'module.layer1.6.bn1.running_var', 'module.layer1.6.bn1.num_batches_tracked', 'module.layer1.6.relu1.fake_q.ema_decay', 'module.layer1.6.relu1.fake_q.tracked_min_biased', 'module.layer1.6.relu1.fake_q.tracked_min', 'module.layer1.6.relu1.fake_q.tracked_max_biased', 'module.layer1.6.relu1.fake_q.tracked_max', 'module.layer1.6.relu1.fake_q.iter_count', 'module.layer1.6.relu1.fake_q.scale', 'module.layer1.6.relu1.fake_q.zero_point', 'module.layer1.6.conv2.float_weight', 'module.layer1.6.conv2.weight', 'module.layer1.6.conv2.weight_scale', 'module.layer1.6.conv2.weight_zero_point', 'module.layer1.6.bn2.weight', 'module.layer1.6.bn2.bias', 'module.layer1.6.bn2.running_mean', 'module.layer1.6.bn2.running_var', 'module.layer1.6.bn2.num_batches_tracked', 'module.layer1.6.relu2.fake_q.ema_decay', 'module.layer1.6.relu2.fake_q.tracked_min_biased', 'module.layer1.6.relu2.fake_q.tracked_min', 'module.layer1.6.relu2.fake_q.tracked_max_biased', 'module.layer1.6.relu2.fake_q.tracked_max', 'module.layer1.6.relu2.fake_q.iter_count', 'module.layer1.6.relu2.fake_q.scale', 'module.layer1.6.relu2.fake_q.zero_point', 'module.layer1.7.conv1.float_weight', 'module.layer1.7.conv1.weight', 'module.layer1.7.conv1.weight_scale', 'module.layer1.7.conv1.weight_zero_point', 'module.layer1.7.bn1.weight', 'module.layer1.7.bn1.bias', 'module.layer1.7.bn1.running_mean', 'module.layer1.7.bn1.running_var', 'module.layer1.7.bn1.num_batches_tracked', 'module.layer1.7.relu1.fake_q.ema_decay', 'module.layer1.7.relu1.fake_q.tracked_min_biased', 'module.layer1.7.relu1.fake_q.tracked_min', 'module.layer1.7.relu1.fake_q.tracked_max_biased', 'module.layer1.7.relu1.fake_q.tracked_max', 'module.layer1.7.relu1.fake_q.iter_count', 'module.layer1.7.relu1.fake_q.scale', 'module.layer1.7.relu1.fake_q.zero_point', 'module.layer1.7.conv2.float_weight', 'module.layer1.7.conv2.weight', 'module.layer1.7.conv2.weight_scale', 'module.layer1.7.conv2.weight_zero_point', 'module.layer1.7.bn2.weight', 'module.layer1.7.bn2.bias', 'module.layer1.7.bn2.running_mean', 'module.layer1.7.bn2.running_var', 'module.layer1.7.bn2.num_batches_tracked', 'module.layer1.7.relu2.fake_q.ema_decay', 'module.layer1.7.relu2.fake_q.tracked_min_biased', 'module.layer1.7.relu2.fake_q.tracked_min', 'module.layer1.7.relu2.fake_q.tracked_max_biased', 'module.layer1.7.relu2.fake_q.tracked_max', 'module.layer1.7.relu2.fake_q.iter_count', 'module.layer1.7.relu2.fake_q.scale', 'module.layer1.7.relu2.fake_q.zero_point', 'module.layer1.8.conv1.float_weight', 'module.layer1.8.conv1.weight', 'module.layer1.8.conv1.weight_scale', 'module.layer1.8.conv1.weight_zero_point', 'module.layer1.8.bn1.weight', 'module.layer1.8.bn1.bias', 'module.layer1.8.bn1.running_mean', 'module.layer1.8.bn1.running_var', 'module.layer1.8.bn1.num_batches_tracked', 'module.layer1.8.relu1.fake_q.ema_decay', 'module.layer1.8.relu1.fake_q.tracked_min_biased', 'module.layer1.8.relu1.fake_q.tracked_min', 'module.layer1.8.relu1.fake_q.tracked_max_biased', 'module.layer1.8.relu1.fake_q.tracked_max', 'module.layer1.8.relu1.fake_q.iter_count', 'module.layer1.8.relu1.fake_q.scale', 'module.layer1.8.relu1.fake_q.zero_point', 'module.layer1.8.conv2.float_weight', 'module.layer1.8.conv2.weight', 'module.layer1.8.conv2.weight_scale', 'module.layer1.8.conv2.weight_zero_point', 'module.layer1.8.bn2.weight', 'module.layer1.8.bn2.bias', 'module.layer1.8.bn2.running_mean', 'module.layer1.8.bn2.running_var', 'module.layer1.8.bn2.num_batches_tracked', 'module.layer1.8.relu2.fake_q.ema_decay', 'module.layer1.8.relu2.fake_q.tracked_min_biased', 'module.layer1.8.relu2.fake_q.tracked_min', 'module.layer1.8.relu2.fake_q.tracked_max_biased', 'module.layer1.8.relu2.fake_q.tracked_max', 'module.layer1.8.relu2.fake_q.iter_count', 'module.layer1.8.relu2.fake_q.scale', 'module.layer1.8.relu2.fake_q.zero_point', 'module.layer2.0.conv1.float_weight', 'module.layer2.0.conv1.weight', 'module.layer2.0.conv1.weight_scale', 'module.layer2.0.conv1.weight_zero_point', 'module.layer2.0.bn1.weight', 'module.layer2.0.bn1.bias', 'module.layer2.0.bn1.running_mean', 'module.layer2.0.bn1.running_var', 'module.layer2.0.bn1.num_batches_tracked', 'module.layer2.0.relu1.fake_q.ema_decay', 'module.layer2.0.relu1.fake_q.tracked_min_biased', 'module.layer2.0.relu1.fake_q.tracked_min', 'module.layer2.0.relu1.fake_q.tracked_max_biased', 'module.layer2.0.relu1.fake_q.tracked_max', 'module.layer2.0.relu1.fake_q.iter_count', 'module.layer2.0.relu1.fake_q.scale', 'module.layer2.0.relu1.fake_q.zero_point', 'module.layer2.0.conv2.float_weight', 'module.layer2.0.conv2.weight', 'module.layer2.0.conv2.weight_scale', 'module.layer2.0.conv2.weight_zero_point', 'module.layer2.0.bn2.weight', 'module.layer2.0.bn2.bias', 'module.layer2.0.bn2.running_mean', 'module.layer2.0.bn2.running_var', 'module.layer2.0.bn2.num_batches_tracked', 'module.layer2.0.relu2.fake_q.ema_decay', 'module.layer2.0.relu2.fake_q.tracked_min_biased', 'module.layer2.0.relu2.fake_q.tracked_min', 'module.layer2.0.relu2.fake_q.tracked_max_biased', 'module.layer2.0.relu2.fake_q.tracked_max', 'module.layer2.0.relu2.fake_q.iter_count', 'module.layer2.0.relu2.fake_q.scale', 'module.layer2.0.relu2.fake_q.zero_point', 'module.layer2.0.downsample.0.float_weight', 'module.layer2.0.downsample.0.weight', 'module.layer2.0.downsample.0.weight_scale', 'module.layer2.0.downsample.0.weight_zero_point', 'module.layer2.0.downsample.1.weight', 'module.layer2.0.downsample.1.bias', 'module.layer2.0.downsample.1.running_mean', 'module.layer2.0.downsample.1.running_var', 'module.layer2.0.downsample.1.num_batches_tracked', 'module.layer2.1.conv1.float_weight', 'module.layer2.1.conv1.weight', 'module.layer2.1.conv1.weight_scale', 'module.layer2.1.conv1.weight_zero_point', 'module.layer2.1.bn1.weight', 'module.layer2.1.bn1.bias', 'module.layer2.1.bn1.running_mean', 'module.layer2.1.bn1.running_var', 'module.layer2.1.bn1.num_batches_tracked', 'module.layer2.1.relu1.fake_q.ema_decay', 'module.layer2.1.relu1.fake_q.tracked_min_biased', 'module.layer2.1.relu1.fake_q.tracked_min', 'module.layer2.1.relu1.fake_q.tracked_max_biased', 'module.layer2.1.relu1.fake_q.tracked_max', 'module.layer2.1.relu1.fake_q.iter_count', 'module.layer2.1.relu1.fake_q.scale', 'module.layer2.1.relu1.fake_q.zero_point', 'module.layer2.1.conv2.float_weight', 'module.layer2.1.conv2.weight', 'module.layer2.1.conv2.weight_scale', 'module.layer2.1.conv2.weight_zero_point', 'module.layer2.1.bn2.weight', 'module.layer2.1.bn2.bias', 'module.layer2.1.bn2.running_mean', 'module.layer2.1.bn2.running_var', 'module.layer2.1.bn2.num_batches_tracked', 'module.layer2.1.relu2.fake_q.ema_decay', 'module.layer2.1.relu2.fake_q.tracked_min_biased', 'module.layer2.1.relu2.fake_q.tracked_min', 'module.layer2.1.relu2.fake_q.tracked_max_biased', 'module.layer2.1.relu2.fake_q.tracked_max', 'module.layer2.1.relu2.fake_q.iter_count', 'module.layer2.1.relu2.fake_q.scale', 'module.layer2.1.relu2.fake_q.zero_point', 'module.layer2.2.conv1.float_weight', 'module.layer2.2.conv1.weight', 'module.layer2.2.conv1.weight_scale', 'module.layer2.2.conv1.weight_zero_point', 'module.layer2.2.bn1.weight', 'module.layer2.2.bn1.bias', 'module.layer2.2.bn1.running_mean', 'module.layer2.2.bn1.running_var', 'module.layer2.2.bn1.num_batches_tracked', 'module.layer2.2.relu1.fake_q.ema_decay', 'module.layer2.2.relu1.fake_q.tracked_min_biased', 'module.layer2.2.relu1.fake_q.tracked_min', 'module.layer2.2.relu1.fake_q.tracked_max_biased', 'module.layer2.2.relu1.fake_q.tracked_max', 'module.layer2.2.relu1.fake_q.iter_count', 'module.layer2.2.relu1.fake_q.scale', 'module.layer2.2.relu1.fake_q.zero_point', 'module.layer2.2.conv2.float_weight', 'module.layer2.2.conv2.weight', 'module.layer2.2.conv2.weight_scale', 'module.layer2.2.conv2.weight_zero_point', 'module.layer2.2.bn2.weight', 'module.layer2.2.bn2.bias', 'module.layer2.2.bn2.running_mean', 'module.layer2.2.bn2.running_var', 'module.layer2.2.bn2.num_batches_tracked', 'module.layer2.2.relu2.fake_q.ema_decay', 'module.layer2.2.relu2.fake_q.tracked_min_biased', 'module.layer2.2.relu2.fake_q.tracked_min', 'module.layer2.2.relu2.fake_q.tracked_max_biased', 'module.layer2.2.relu2.fake_q.tracked_max', 'module.layer2.2.relu2.fake_q.iter_count', 'module.layer2.2.relu2.fake_q.scale', 'module.layer2.2.relu2.fake_q.zero_point', 'module.layer2.3.conv1.float_weight', 'module.layer2.3.conv1.weight', 'module.layer2.3.conv1.weight_scale', 'module.layer2.3.conv1.weight_zero_point', 'module.layer2.3.bn1.weight', 'module.layer2.3.bn1.bias', 'module.layer2.3.bn1.running_mean', 'module.layer2.3.bn1.running_var', 'module.layer2.3.bn1.num_batches_tracked', 'module.layer2.3.relu1.fake_q.ema_decay', 'module.layer2.3.relu1.fake_q.tracked_min_biased', 'module.layer2.3.relu1.fake_q.tracked_min', 'module.layer2.3.relu1.fake_q.tracked_max_biased', 'module.layer2.3.relu1.fake_q.tracked_max', 'module.layer2.3.relu1.fake_q.iter_count', 'module.layer2.3.relu1.fake_q.scale', 'module.layer2.3.relu1.fake_q.zero_point', 'module.layer2.3.conv2.float_weight', 'module.layer2.3.conv2.weight', 'module.layer2.3.conv2.weight_scale', 'module.layer2.3.conv2.weight_zero_point', 'module.layer2.3.bn2.weight', 'module.layer2.3.bn2.bias', 'module.layer2.3.bn2.running_mean', 'module.layer2.3.bn2.running_var', 'module.layer2.3.bn2.num_batches_tracked', 'module.layer2.3.relu2.fake_q.ema_decay', 'module.layer2.3.relu2.fake_q.tracked_min_biased', 'module.layer2.3.relu2.fake_q.tracked_min', 'module.layer2.3.relu2.fake_q.tracked_max_biased', 'module.layer2.3.relu2.fake_q.tracked_max', 'module.layer2.3.relu2.fake_q.iter_count', 'module.layer2.3.relu2.fake_q.scale', 'module.layer2.3.relu2.fake_q.zero_point', 'module.layer2.4.conv1.float_weight', 'module.layer2.4.conv1.weight', 'module.layer2.4.conv1.weight_scale', 'module.layer2.4.conv1.weight_zero_point', 'module.layer2.4.bn1.weight', 'module.layer2.4.bn1.bias', 'module.layer2.4.bn1.running_mean', 'module.layer2.4.bn1.running_var', 'module.layer2.4.bn1.num_batches_tracked', 'module.layer2.4.relu1.fake_q.ema_decay', 'module.layer2.4.relu1.fake_q.tracked_min_biased', 'module.layer2.4.relu1.fake_q.tracked_min', 'module.layer2.4.relu1.fake_q.tracked_max_biased', 'module.layer2.4.relu1.fake_q.tracked_max', 'module.layer2.4.relu1.fake_q.iter_count', 'module.layer2.4.relu1.fake_q.scale', 'module.layer2.4.relu1.fake_q.zero_point', 'module.layer2.4.conv2.float_weight', 'module.layer2.4.conv2.weight', 'module.layer2.4.conv2.weight_scale', 'module.layer2.4.conv2.weight_zero_point', 'module.layer2.4.bn2.weight', 'module.layer2.4.bn2.bias', 'module.layer2.4.bn2.running_mean', 'module.layer2.4.bn2.running_var', 'module.layer2.4.bn2.num_batches_tracked', 'module.layer2.4.relu2.fake_q.ema_decay', 'module.layer2.4.relu2.fake_q.tracked_min_biased', 'module.layer2.4.relu2.fake_q.tracked_min', 'module.layer2.4.relu2.fake_q.tracked_max_biased', 'module.layer2.4.relu2.fake_q.tracked_max', 'module.layer2.4.relu2.fake_q.iter_count', 'module.layer2.4.relu2.fake_q.scale', 'module.layer2.4.relu2.fake_q.zero_point', 'module.layer2.5.conv1.float_weight', 'module.layer2.5.conv1.weight', 'module.layer2.5.conv1.weight_scale', 'module.layer2.5.conv1.weight_zero_point', 'module.layer2.5.bn1.weight', 'module.layer2.5.bn1.bias', 'module.layer2.5.bn1.running_mean', 'module.layer2.5.bn1.running_var', 'module.layer2.5.bn1.num_batches_tracked', 'module.layer2.5.relu1.fake_q.ema_decay', 'module.layer2.5.relu1.fake_q.tracked_min_biased', 'module.layer2.5.relu1.fake_q.tracked_min', 'module.layer2.5.relu1.fake_q.tracked_max_biased', 'module.layer2.5.relu1.fake_q.tracked_max', 'module.layer2.5.relu1.fake_q.iter_count', 'module.layer2.5.relu1.fake_q.scale', 'module.layer2.5.relu1.fake_q.zero_point', 'module.layer2.5.conv2.float_weight', 'module.layer2.5.conv2.weight', 'module.layer2.5.conv2.weight_scale', 'module.layer2.5.conv2.weight_zero_point', 'module.layer2.5.bn2.weight', 'module.layer2.5.bn2.bias', 'module.layer2.5.bn2.running_mean', 'module.layer2.5.bn2.running_var', 'module.layer2.5.bn2.num_batches_tracked', 'module.layer2.5.relu2.fake_q.ema_decay', 'module.layer2.5.relu2.fake_q.tracked_min_biased', 'module.layer2.5.relu2.fake_q.tracked_min', 'module.layer2.5.relu2.fake_q.tracked_max_biased', 'module.layer2.5.relu2.fake_q.tracked_max', 'module.layer2.5.relu2.fake_q.iter_count', 'module.layer2.5.relu2.fake_q.scale', 'module.layer2.5.relu2.fake_q.zero_point', 'module.layer2.6.conv1.float_weight', 'module.layer2.6.conv1.weight', 'module.layer2.6.conv1.weight_scale', 'module.layer2.6.conv1.weight_zero_point', 'module.layer2.6.bn1.weight', 'module.layer2.6.bn1.bias', 'module.layer2.6.bn1.running_mean', 'module.layer2.6.bn1.running_var', 'module.layer2.6.bn1.num_batches_tracked', 'module.layer2.6.relu1.fake_q.ema_decay', 'module.layer2.6.relu1.fake_q.tracked_min_biased', 'module.layer2.6.relu1.fake_q.tracked_min', 'module.layer2.6.relu1.fake_q.tracked_max_biased', 'module.layer2.6.relu1.fake_q.tracked_max', 'module.layer2.6.relu1.fake_q.iter_count', 'module.layer2.6.relu1.fake_q.scale', 'module.layer2.6.relu1.fake_q.zero_point', 'module.layer2.6.conv2.float_weight', 'module.layer2.6.conv2.weight', 'module.layer2.6.conv2.weight_scale', 'module.layer2.6.conv2.weight_zero_point', 'module.layer2.6.bn2.weight', 'module.layer2.6.bn2.bias', 'module.layer2.6.bn2.running_mean', 'module.layer2.6.bn2.running_var', 'module.layer2.6.bn2.num_batches_tracked', 'module.layer2.6.relu2.fake_q.ema_decay', 'module.layer2.6.relu2.fake_q.tracked_min_biased', 'module.layer2.6.relu2.fake_q.tracked_min', 'module.layer2.6.relu2.fake_q.tracked_max_biased', 'module.layer2.6.relu2.fake_q.tracked_max', 'module.layer2.6.relu2.fake_q.iter_count', 'module.layer2.6.relu2.fake_q.scale', 'module.layer2.6.relu2.fake_q.zero_point', 'module.layer2.7.conv1.float_weight', 'module.layer2.7.conv1.weight', 'module.layer2.7.conv1.weight_scale', 'module.layer2.7.conv1.weight_zero_point', 'module.layer2.7.bn1.weight', 'module.layer2.7.bn1.bias', 'module.layer2.7.bn1.running_mean', 'module.layer2.7.bn1.running_var', 'module.layer2.7.bn1.num_batches_tracked', 'module.layer2.7.relu1.fake_q.ema_decay', 'module.layer2.7.relu1.fake_q.tracked_min_biased', 'module.layer2.7.relu1.fake_q.tracked_min', 'module.layer2.7.relu1.fake_q.tracked_max_biased', 'module.layer2.7.relu1.fake_q.tracked_max', 'module.layer2.7.relu1.fake_q.iter_count', 'module.layer2.7.relu1.fake_q.scale', 'module.layer2.7.relu1.fake_q.zero_point', 'module.layer2.7.conv2.float_weight', 'module.layer2.7.conv2.weight', 'module.layer2.7.conv2.weight_scale', 'module.layer2.7.conv2.weight_zero_point', 'module.layer2.7.bn2.weight', 'module.layer2.7.bn2.bias', 'module.layer2.7.bn2.running_mean', 'module.layer2.7.bn2.running_var', 'module.layer2.7.bn2.num_batches_tracked', 'module.layer2.7.relu2.fake_q.ema_decay', 'module.layer2.7.relu2.fake_q.tracked_min_biased', 'module.layer2.7.relu2.fake_q.tracked_min', 'module.layer2.7.relu2.fake_q.tracked_max_biased', 'module.layer2.7.relu2.fake_q.tracked_max', 'module.layer2.7.relu2.fake_q.iter_count', 'module.layer2.7.relu2.fake_q.scale', 'module.layer2.7.relu2.fake_q.zero_point', 'module.layer2.8.conv1.float_weight', 'module.layer2.8.conv1.weight', 'module.layer2.8.conv1.weight_scale', 'module.layer2.8.conv1.weight_zero_point', 'module.layer2.8.bn1.weight', 'module.layer2.8.bn1.bias', 'module.layer2.8.bn1.running_mean', 'module.layer2.8.bn1.running_var', 'module.layer2.8.bn1.num_batches_tracked', 'module.layer2.8.relu1.fake_q.ema_decay', 'module.layer2.8.relu1.fake_q.tracked_min_biased', 'module.layer2.8.relu1.fake_q.tracked_min', 'module.layer2.8.relu1.fake_q.tracked_max_biased', 'module.layer2.8.relu1.fake_q.tracked_max', 'module.layer2.8.relu1.fake_q.iter_count', 'module.layer2.8.relu1.fake_q.scale', 'module.layer2.8.relu1.fake_q.zero_point', 'module.layer2.8.conv2.float_weight', 'module.layer2.8.conv2.weight', 'module.layer2.8.conv2.weight_scale', 'module.layer2.8.conv2.weight_zero_point', 'module.layer2.8.bn2.weight', 'module.layer2.8.bn2.bias', 'module.layer2.8.bn2.running_mean', 'module.layer2.8.bn2.running_var', 'module.layer2.8.bn2.num_batches_tracked', 'module.layer2.8.relu2.fake_q.ema_decay', 'module.layer2.8.relu2.fake_q.tracked_min_biased', 'module.layer2.8.relu2.fake_q.tracked_min', 'module.layer2.8.relu2.fake_q.tracked_max_biased', 'module.layer2.8.relu2.fake_q.tracked_max', 'module.layer2.8.relu2.fake_q.iter_count', 'module.layer2.8.relu2.fake_q.scale', 'module.layer2.8.relu2.fake_q.zero_point', 'module.layer3.0.conv1.float_weight', 'module.layer3.0.conv1.weight', 'module.layer3.0.conv1.weight_scale', 'module.layer3.0.conv1.weight_zero_point', 'module.layer3.0.bn1.weight', 'module.layer3.0.bn1.bias', 'module.layer3.0.bn1.running_mean', 'module.layer3.0.bn1.running_var', 'module.layer3.0.bn1.num_batches_tracked', 'module.layer3.0.relu1.fake_q.ema_decay', 'module.layer3.0.relu1.fake_q.tracked_min_biased', 'module.layer3.0.relu1.fake_q.tracked_min', 'module.layer3.0.relu1.fake_q.tracked_max_biased', 'module.layer3.0.relu1.fake_q.tracked_max', 'module.layer3.0.relu1.fake_q.iter_count', 'module.layer3.0.relu1.fake_q.scale', 'module.layer3.0.relu1.fake_q.zero_point', 'module.layer3.0.conv2.float_weight', 'module.layer3.0.conv2.weight', 'module.layer3.0.conv2.weight_scale', 'module.layer3.0.conv2.weight_zero_point', 'module.layer3.0.bn2.weight', 'module.layer3.0.bn2.bias', 'module.layer3.0.bn2.running_mean', 'module.layer3.0.bn2.running_var', 'module.layer3.0.bn2.num_batches_tracked', 'module.layer3.0.relu2.fake_q.ema_decay', 'module.layer3.0.relu2.fake_q.tracked_min_biased', 'module.layer3.0.relu2.fake_q.tracked_min', 'module.layer3.0.relu2.fake_q.tracked_max_biased', 'module.layer3.0.relu2.fake_q.tracked_max', 'module.layer3.0.relu2.fake_q.iter_count', 'module.layer3.0.relu2.fake_q.scale', 'module.layer3.0.relu2.fake_q.zero_point', 'module.layer3.0.downsample.0.float_weight', 'module.layer3.0.downsample.0.weight', 'module.layer3.0.downsample.0.weight_scale', 'module.layer3.0.downsample.0.weight_zero_point', 'module.layer3.0.downsample.1.weight', 'module.layer3.0.downsample.1.bias', 'module.layer3.0.downsample.1.running_mean', 'module.layer3.0.downsample.1.running_var', 'module.layer3.0.downsample.1.num_batches_tracked', 'module.layer3.1.conv1.float_weight', 'module.layer3.1.conv1.weight', 'module.layer3.1.conv1.weight_scale', 'module.layer3.1.conv1.weight_zero_point', 'module.layer3.1.bn1.weight', 'module.layer3.1.bn1.bias', 'module.layer3.1.bn1.running_mean', 'module.layer3.1.bn1.running_var', 'module.layer3.1.bn1.num_batches_tracked', 'module.layer3.1.relu1.fake_q.ema_decay', 'module.layer3.1.relu1.fake_q.tracked_min_biased', 'module.layer3.1.relu1.fake_q.tracked_min', 'module.layer3.1.relu1.fake_q.tracked_max_biased', 'module.layer3.1.relu1.fake_q.tracked_max', 'module.layer3.1.relu1.fake_q.iter_count', 'module.layer3.1.relu1.fake_q.scale', 'module.layer3.1.relu1.fake_q.zero_point', 'module.layer3.1.conv2.float_weight', 'module.layer3.1.conv2.weight', 'module.layer3.1.conv2.weight_scale', 'module.layer3.1.conv2.weight_zero_point', 'module.layer3.1.bn2.weight', 'module.layer3.1.bn2.bias', 'module.layer3.1.bn2.running_mean', 'module.layer3.1.bn2.running_var', 'module.layer3.1.bn2.num_batches_tracked', 'module.layer3.1.relu2.fake_q.ema_decay', 'module.layer3.1.relu2.fake_q.tracked_min_biased', 'module.layer3.1.relu2.fake_q.tracked_min', 'module.layer3.1.relu2.fake_q.tracked_max_biased', 'module.layer3.1.relu2.fake_q.tracked_max', 'module.layer3.1.relu2.fake_q.iter_count', 'module.layer3.1.relu2.fake_q.scale', 'module.layer3.1.relu2.fake_q.zero_point', 'module.layer3.2.conv1.float_weight', 'module.layer3.2.conv1.weight', 'module.layer3.2.conv1.weight_scale', 'module.layer3.2.conv1.weight_zero_point', 'module.layer3.2.bn1.weight', 'module.layer3.2.bn1.bias', 'module.layer3.2.bn1.running_mean', 'module.layer3.2.bn1.running_var', 'module.layer3.2.bn1.num_batches_tracked', 'module.layer3.2.relu1.fake_q.ema_decay', 'module.layer3.2.relu1.fake_q.tracked_min_biased', 'module.layer3.2.relu1.fake_q.tracked_min', 'module.layer3.2.relu1.fake_q.tracked_max_biased', 'module.layer3.2.relu1.fake_q.tracked_max', 'module.layer3.2.relu1.fake_q.iter_count', 'module.layer3.2.relu1.fake_q.scale', 'module.layer3.2.relu1.fake_q.zero_point', 'module.layer3.2.conv2.float_weight', 'module.layer3.2.conv2.weight', 'module.layer3.2.conv2.weight_scale', 'module.layer3.2.conv2.weight_zero_point', 'module.layer3.2.bn2.weight', 'module.layer3.2.bn2.bias', 'module.layer3.2.bn2.running_mean', 'module.layer3.2.bn2.running_var', 'module.layer3.2.bn2.num_batches_tracked', 'module.layer3.2.relu2.fake_q.ema_decay', 'module.layer3.2.relu2.fake_q.tracked_min_biased', 'module.layer3.2.relu2.fake_q.tracked_min', 'module.layer3.2.relu2.fake_q.tracked_max_biased', 'module.layer3.2.relu2.fake_q.tracked_max', 'module.layer3.2.relu2.fake_q.iter_count', 'module.layer3.2.relu2.fake_q.scale', 'module.layer3.2.relu2.fake_q.zero_point', 'module.layer3.3.conv1.float_weight', 'module.layer3.3.conv1.weight', 'module.layer3.3.conv1.weight_scale', 'module.layer3.3.conv1.weight_zero_point', 'module.layer3.3.bn1.weight', 'module.layer3.3.bn1.bias', 'module.layer3.3.bn1.running_mean', 'module.layer3.3.bn1.running_var', 'module.layer3.3.bn1.num_batches_tracked', 'module.layer3.3.relu1.fake_q.ema_decay', 'module.layer3.3.relu1.fake_q.tracked_min_biased', 'module.layer3.3.relu1.fake_q.tracked_min', 'module.layer3.3.relu1.fake_q.tracked_max_biased', 'module.layer3.3.relu1.fake_q.tracked_max', 'module.layer3.3.relu1.fake_q.iter_count', 'module.layer3.3.relu1.fake_q.scale', 'module.layer3.3.relu1.fake_q.zero_point', 'module.layer3.3.conv2.float_weight', 'module.layer3.3.conv2.weight', 'module.layer3.3.conv2.weight_scale', 'module.layer3.3.conv2.weight_zero_point', 'module.layer3.3.bn2.weight', 'module.layer3.3.bn2.bias', 'module.layer3.3.bn2.running_mean', 'module.layer3.3.bn2.running_var', 'module.layer3.3.bn2.num_batches_tracked', 'module.layer3.3.relu2.fake_q.ema_decay', 'module.layer3.3.relu2.fake_q.tracked_min_biased', 'module.layer3.3.relu2.fake_q.tracked_min', 'module.layer3.3.relu2.fake_q.tracked_max_biased', 'module.layer3.3.relu2.fake_q.tracked_max', 'module.layer3.3.relu2.fake_q.iter_count', 'module.layer3.3.relu2.fake_q.scale', 'module.layer3.3.relu2.fake_q.zero_point', 'module.layer3.4.conv1.float_weight', 'module.layer3.4.conv1.weight', 'module.layer3.4.conv1.weight_scale', 'module.layer3.4.conv1.weight_zero_point', 'module.layer3.4.bn1.weight', 'module.layer3.4.bn1.bias', 'module.layer3.4.bn1.running_mean', 'module.layer3.4.bn1.running_var', 'module.layer3.4.bn1.num_batches_tracked', 'module.layer3.4.relu1.fake_q.ema_decay', 'module.layer3.4.relu1.fake_q.tracked_min_biased', 'module.layer3.4.relu1.fake_q.tracked_min', 'module.layer3.4.relu1.fake_q.tracked_max_biased', 'module.layer3.4.relu1.fake_q.tracked_max', 'module.layer3.4.relu1.fake_q.iter_count', 'module.layer3.4.relu1.fake_q.scale', 'module.layer3.4.relu1.fake_q.zero_point', 'module.layer3.4.conv2.float_weight', 'module.layer3.4.conv2.weight', 'module.layer3.4.conv2.weight_scale', 'module.layer3.4.conv2.weight_zero_point', 'module.layer3.4.bn2.weight', 'module.layer3.4.bn2.bias', 'module.layer3.4.bn2.running_mean', 'module.layer3.4.bn2.running_var', 'module.layer3.4.bn2.num_batches_tracked', 'module.layer3.4.relu2.fake_q.ema_decay', 'module.layer3.4.relu2.fake_q.tracked_min_biased', 'module.layer3.4.relu2.fake_q.tracked_min', 'module.layer3.4.relu2.fake_q.tracked_max_biased', 'module.layer3.4.relu2.fake_q.tracked_max', 'module.layer3.4.relu2.fake_q.iter_count', 'module.layer3.4.relu2.fake_q.scale', 'module.layer3.4.relu2.fake_q.zero_point', 'module.layer3.5.conv1.float_weight', 'module.layer3.5.conv1.weight', 'module.layer3.5.conv1.weight_scale', 'module.layer3.5.conv1.weight_zero_point', 'module.layer3.5.bn1.weight', 'module.layer3.5.bn1.bias', 'module.layer3.5.bn1.running_mean', 'module.layer3.5.bn1.running_var', 'module.layer3.5.bn1.num_batches_tracked', 'module.layer3.5.relu1.fake_q.ema_decay', 'module.layer3.5.relu1.fake_q.tracked_min_biased', 'module.layer3.5.relu1.fake_q.tracked_min', 'module.layer3.5.relu1.fake_q.tracked_max_biased', 'module.layer3.5.relu1.fake_q.tracked_max', 'module.layer3.5.relu1.fake_q.iter_count', 'module.layer3.5.relu1.fake_q.scale', 'module.layer3.5.relu1.fake_q.zero_point', 'module.layer3.5.conv2.float_weight', 'module.layer3.5.conv2.weight', 'module.layer3.5.conv2.weight_scale', 'module.layer3.5.conv2.weight_zero_point', 'module.layer3.5.bn2.weight', 'module.layer3.5.bn2.bias', 'module.layer3.5.bn2.running_mean', 'module.layer3.5.bn2.running_var', 'module.layer3.5.bn2.num_batches_tracked', 'module.layer3.5.relu2.fake_q.ema_decay', 'module.layer3.5.relu2.fake_q.tracked_min_biased', 'module.layer3.5.relu2.fake_q.tracked_min', 'module.layer3.5.relu2.fake_q.tracked_max_biased', 'module.layer3.5.relu2.fake_q.tracked_max', 'module.layer3.5.relu2.fake_q.iter_count', 'module.layer3.5.relu2.fake_q.scale', 'module.layer3.5.relu2.fake_q.zero_point', 'module.layer3.6.conv1.float_weight', 'module.layer3.6.conv1.weight', 'module.layer3.6.conv1.weight_scale', 'module.layer3.6.conv1.weight_zero_point', 'module.layer3.6.bn1.weight', 'module.layer3.6.bn1.bias', 'module.layer3.6.bn1.running_mean', 'module.layer3.6.bn1.running_var', 'module.layer3.6.bn1.num_batches_tracked', 'module.layer3.6.relu1.fake_q.ema_decay', 'module.layer3.6.relu1.fake_q.tracked_min_biased', 'module.layer3.6.relu1.fake_q.tracked_min', 'module.layer3.6.relu1.fake_q.tracked_max_biased', 'module.layer3.6.relu1.fake_q.tracked_max', 'module.layer3.6.relu1.fake_q.iter_count', 'module.layer3.6.relu1.fake_q.scale', 'module.layer3.6.relu1.fake_q.zero_point', 'module.layer3.6.conv2.float_weight', 'module.layer3.6.conv2.weight', 'module.layer3.6.conv2.weight_scale', 'module.layer3.6.conv2.weight_zero_point', 'module.layer3.6.bn2.weight', 'module.layer3.6.bn2.bias', 'module.layer3.6.bn2.running_mean', 'module.layer3.6.bn2.running_var', 'module.layer3.6.bn2.num_batches_tracked', 'module.layer3.6.relu2.fake_q.ema_decay', 'module.layer3.6.relu2.fake_q.tracked_min_biased', 'module.layer3.6.relu2.fake_q.tracked_min', 'module.layer3.6.relu2.fake_q.tracked_max_biased', 'module.layer3.6.relu2.fake_q.tracked_max', 'module.layer3.6.relu2.fake_q.iter_count', 'module.layer3.6.relu2.fake_q.scale', 'module.layer3.6.relu2.fake_q.zero_point', 'module.layer3.7.conv1.float_weight', 'module.layer3.7.conv1.weight', 'module.layer3.7.conv1.weight_scale', 'module.layer3.7.conv1.weight_zero_point', 'module.layer3.7.bn1.weight', 'module.layer3.7.bn1.bias', 'module.layer3.7.bn1.running_mean', 'module.layer3.7.bn1.running_var', 'module.layer3.7.bn1.num_batches_tracked', 'module.layer3.7.relu1.fake_q.ema_decay', 'module.layer3.7.relu1.fake_q.tracked_min_biased', 'module.layer3.7.relu1.fake_q.tracked_min', 'module.layer3.7.relu1.fake_q.tracked_max_biased', 'module.layer3.7.relu1.fake_q.tracked_max', 'module.layer3.7.relu1.fake_q.iter_count', 'module.layer3.7.relu1.fake_q.scale', 'module.layer3.7.relu1.fake_q.zero_point', 'module.layer3.7.conv2.float_weight', 'module.layer3.7.conv2.weight', 'module.layer3.7.conv2.weight_scale', 'module.layer3.7.conv2.weight_zero_point', 'module.layer3.7.bn2.weight', 'module.layer3.7.bn2.bias', 'module.layer3.7.bn2.running_mean', 'module.layer3.7.bn2.running_var', 'module.layer3.7.bn2.num_batches_tracked', 'module.layer3.7.relu2.fake_q.ema_decay', 'module.layer3.7.relu2.fake_q.tracked_min_biased', 'module.layer3.7.relu2.fake_q.tracked_min', 'module.layer3.7.relu2.fake_q.tracked_max_biased', 'module.layer3.7.relu2.fake_q.tracked_max', 'module.layer3.7.relu2.fake_q.iter_count', 'module.layer3.7.relu2.fake_q.scale', 'module.layer3.7.relu2.fake_q.zero_point', 'module.layer3.8.conv1.float_weight', 'module.layer3.8.conv1.weight', 'module.layer3.8.conv1.weight_scale', 'module.layer3.8.conv1.weight_zero_point', 'module.layer3.8.bn1.weight', 'module.layer3.8.bn1.bias', 'module.layer3.8.bn1.running_mean', 'module.layer3.8.bn1.running_var', 'module.layer3.8.bn1.num_batches_tracked', 'module.layer3.8.relu1.fake_q.ema_decay', 'module.layer3.8.relu1.fake_q.tracked_min_biased', 'module.layer3.8.relu1.fake_q.tracked_min', 'module.layer3.8.relu1.fake_q.tracked_max_biased', 'module.layer3.8.relu1.fake_q.tracked_max', 'module.layer3.8.relu1.fake_q.iter_count', 'module.layer3.8.relu1.fake_q.scale', 'module.layer3.8.relu1.fake_q.zero_point', 'module.layer3.8.conv2.float_weight', 'module.layer3.8.conv2.weight', 'module.layer3.8.conv2.weight_scale', 'module.layer3.8.conv2.weight_zero_point', 'module.layer3.8.bn2.weight', 'module.layer3.8.bn2.bias', 'module.layer3.8.bn2.running_mean', 'module.layer3.8.bn2.running_var', 'module.layer3.8.bn2.num_batches_tracked', 'module.layer3.8.relu2.fake_q.ema_decay', 'module.layer3.8.relu2.fake_q.tracked_min_biased', 'module.layer3.8.relu2.fake_q.tracked_min', 'module.layer3.8.relu2.fake_q.tracked_max_biased', 'module.layer3.8.relu2.fake_q.tracked_max', 'module.layer3.8.relu2.fake_q.iter_count', 'module.layer3.8.relu2.fake_q.scale', 'module.layer3.8.relu2.fake_q.zero_point', 'module.fc.float_weight', 'module.fc.float_bias', 'module.fc.weight', 'module.fc.bias', 'module.fc.weight_scale', 'module.fc.weight_zero_point', 'module.fc.bias_scale', 'module.fc.bias_zero_point', 'module.inputs_quant.ema_decay', 'module.inputs_quant.tracked_min_biased', 'module.inputs_quant.tracked_min', 'module.inputs_quant.tracked_max_biased', 'module.inputs_quant.tracked_max', 'module.inputs_quant.iter_count', 'module.inputs_quant.scale', 'module.inputs_quant.zero_point'])"]},"metadata":{"tags":[]},"execution_count":33}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"qLMrmvFc5VtQ","executionInfo":{"elapsed":454,"status":"ok","timestamp":1607407112928,"user":{"displayName":"Jeremy Wang","photoUrl":"","userId":"16277065741529505083"},"user_tz":300},"outputId":"461dcc8b-c57f-406e-f9ed-74af70360051"},"source":["# Resnet56_cifar10_post_train_2\n","entry = torch.load(pather)\n","print(len(entry[\"state_dict\"].keys()))\n","entry[\"state_dict\"].keys()"],"execution_count":null,"outputs":[{"output_type":"stream","text":["858\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["odict_keys(['module.conv1.num_forwards', 'module.conv1.force_readjust', 'module.conv1.output_scale', 'module.conv1.output_zero_point', 'module.conv1.w_scale', 'module.conv1.w_zero_point', 'module.conv1.fp_bias', 'module.conv1.accum_scale', 'module.conv1.is_simulated_quant_weight_shifted', 'module.conv1.wrapped_module.weight', 'module.conv1.wrapped_module.bias', 'module.layer1.0.conv1.num_forwards', 'module.layer1.0.conv1.force_readjust', 'module.layer1.0.conv1.output_scale', 'module.layer1.0.conv1.output_zero_point', 'module.layer1.0.conv1.w_scale', 'module.layer1.0.conv1.w_zero_point', 'module.layer1.0.conv1.fp_bias', 'module.layer1.0.conv1.accum_scale', 'module.layer1.0.conv1.is_simulated_quant_weight_shifted', 'module.layer1.0.conv1.wrapped_module.weight', 'module.layer1.0.conv1.wrapped_module.bias', 'module.layer1.0.conv2.num_forwards', 'module.layer1.0.conv2.force_readjust', 'module.layer1.0.conv2.output_scale', 'module.layer1.0.conv2.output_zero_point', 'module.layer1.0.conv2.w_scale', 'module.layer1.0.conv2.w_zero_point', 'module.layer1.0.conv2.fp_bias', 'module.layer1.0.conv2.accum_scale', 'module.layer1.0.conv2.is_simulated_quant_weight_shifted', 'module.layer1.0.conv2.wrapped_module.weight', 'module.layer1.0.conv2.wrapped_module.bias', 'module.layer1.0.relu2.num_forwards', 'module.layer1.0.relu2.force_readjust', 'module.layer1.0.relu2.output_scale', 'module.layer1.0.relu2.output_zero_point', 'module.layer1.0.residual_eltwiseadd.num_forwards', 'module.layer1.0.residual_eltwiseadd.force_readjust', 'module.layer1.0.residual_eltwiseadd.output_scale', 'module.layer1.0.residual_eltwiseadd.output_zero_point', 'module.layer1.1.conv1.num_forwards', 'module.layer1.1.conv1.force_readjust', 'module.layer1.1.conv1.output_scale', 'module.layer1.1.conv1.output_zero_point', 'module.layer1.1.conv1.w_scale', 'module.layer1.1.conv1.w_zero_point', 'module.layer1.1.conv1.fp_bias', 'module.layer1.1.conv1.accum_scale', 'module.layer1.1.conv1.is_simulated_quant_weight_shifted', 'module.layer1.1.conv1.wrapped_module.weight', 'module.layer1.1.conv1.wrapped_module.bias', 'module.layer1.1.conv2.num_forwards', 'module.layer1.1.conv2.force_readjust', 'module.layer1.1.conv2.output_scale', 'module.layer1.1.conv2.output_zero_point', 'module.layer1.1.conv2.w_scale', 'module.layer1.1.conv2.w_zero_point', 'module.layer1.1.conv2.fp_bias', 'module.layer1.1.conv2.accum_scale', 'module.layer1.1.conv2.is_simulated_quant_weight_shifted', 'module.layer1.1.conv2.wrapped_module.weight', 'module.layer1.1.conv2.wrapped_module.bias', 'module.layer1.1.relu2.num_forwards', 'module.layer1.1.relu2.force_readjust', 'module.layer1.1.relu2.output_scale', 'module.layer1.1.relu2.output_zero_point', 'module.layer1.1.residual_eltwiseadd.num_forwards', 'module.layer1.1.residual_eltwiseadd.force_readjust', 'module.layer1.1.residual_eltwiseadd.output_scale', 'module.layer1.1.residual_eltwiseadd.output_zero_point', 'module.layer1.2.conv1.num_forwards', 'module.layer1.2.conv1.force_readjust', 'module.layer1.2.conv1.output_scale', 'module.layer1.2.conv1.output_zero_point', 'module.layer1.2.conv1.w_scale', 'module.layer1.2.conv1.w_zero_point', 'module.layer1.2.conv1.fp_bias', 'module.layer1.2.conv1.accum_scale', 'module.layer1.2.conv1.is_simulated_quant_weight_shifted', 'module.layer1.2.conv1.wrapped_module.weight', 'module.layer1.2.conv1.wrapped_module.bias', 'module.layer1.2.conv2.num_forwards', 'module.layer1.2.conv2.force_readjust', 'module.layer1.2.conv2.output_scale', 'module.layer1.2.conv2.output_zero_point', 'module.layer1.2.conv2.w_scale', 'module.layer1.2.conv2.w_zero_point', 'module.layer1.2.conv2.fp_bias', 'module.layer1.2.conv2.accum_scale', 'module.layer1.2.conv2.is_simulated_quant_weight_shifted', 'module.layer1.2.conv2.wrapped_module.weight', 'module.layer1.2.conv2.wrapped_module.bias', 'module.layer1.2.relu2.num_forwards', 'module.layer1.2.relu2.force_readjust', 'module.layer1.2.relu2.output_scale', 'module.layer1.2.relu2.output_zero_point', 'module.layer1.2.residual_eltwiseadd.num_forwards', 'module.layer1.2.residual_eltwiseadd.force_readjust', 'module.layer1.2.residual_eltwiseadd.output_scale', 'module.layer1.2.residual_eltwiseadd.output_zero_point', 'module.layer1.3.conv1.num_forwards', 'module.layer1.3.conv1.force_readjust', 'module.layer1.3.conv1.output_scale', 'module.layer1.3.conv1.output_zero_point', 'module.layer1.3.conv1.w_scale', 'module.layer1.3.conv1.w_zero_point', 'module.layer1.3.conv1.fp_bias', 'module.layer1.3.conv1.accum_scale', 'module.layer1.3.conv1.is_simulated_quant_weight_shifted', 'module.layer1.3.conv1.wrapped_module.weight', 'module.layer1.3.conv1.wrapped_module.bias', 'module.layer1.3.conv2.num_forwards', 'module.layer1.3.conv2.force_readjust', 'module.layer1.3.conv2.output_scale', 'module.layer1.3.conv2.output_zero_point', 'module.layer1.3.conv2.w_scale', 'module.layer1.3.conv2.w_zero_point', 'module.layer1.3.conv2.fp_bias', 'module.layer1.3.conv2.accum_scale', 'module.layer1.3.conv2.is_simulated_quant_weight_shifted', 'module.layer1.3.conv2.wrapped_module.weight', 'module.layer1.3.conv2.wrapped_module.bias', 'module.layer1.3.relu2.num_forwards', 'module.layer1.3.relu2.force_readjust', 'module.layer1.3.relu2.output_scale', 'module.layer1.3.relu2.output_zero_point', 'module.layer1.3.residual_eltwiseadd.num_forwards', 'module.layer1.3.residual_eltwiseadd.force_readjust', 'module.layer1.3.residual_eltwiseadd.output_scale', 'module.layer1.3.residual_eltwiseadd.output_zero_point', 'module.layer1.4.conv1.num_forwards', 'module.layer1.4.conv1.force_readjust', 'module.layer1.4.conv1.output_scale', 'module.layer1.4.conv1.output_zero_point', 'module.layer1.4.conv1.w_scale', 'module.layer1.4.conv1.w_zero_point', 'module.layer1.4.conv1.fp_bias', 'module.layer1.4.conv1.accum_scale', 'module.layer1.4.conv1.is_simulated_quant_weight_shifted', 'module.layer1.4.conv1.wrapped_module.weight', 'module.layer1.4.conv1.wrapped_module.bias', 'module.layer1.4.conv2.num_forwards', 'module.layer1.4.conv2.force_readjust', 'module.layer1.4.conv2.output_scale', 'module.layer1.4.conv2.output_zero_point', 'module.layer1.4.conv2.w_scale', 'module.layer1.4.conv2.w_zero_point', 'module.layer1.4.conv2.fp_bias', 'module.layer1.4.conv2.accum_scale', 'module.layer1.4.conv2.is_simulated_quant_weight_shifted', 'module.layer1.4.conv2.wrapped_module.weight', 'module.layer1.4.conv2.wrapped_module.bias', 'module.layer1.4.relu2.num_forwards', 'module.layer1.4.relu2.force_readjust', 'module.layer1.4.relu2.output_scale', 'module.layer1.4.relu2.output_zero_point', 'module.layer1.4.residual_eltwiseadd.num_forwards', 'module.layer1.4.residual_eltwiseadd.force_readjust', 'module.layer1.4.residual_eltwiseadd.output_scale', 'module.layer1.4.residual_eltwiseadd.output_zero_point', 'module.layer1.5.conv1.num_forwards', 'module.layer1.5.conv1.force_readjust', 'module.layer1.5.conv1.output_scale', 'module.layer1.5.conv1.output_zero_point', 'module.layer1.5.conv1.w_scale', 'module.layer1.5.conv1.w_zero_point', 'module.layer1.5.conv1.fp_bias', 'module.layer1.5.conv1.accum_scale', 'module.layer1.5.conv1.is_simulated_quant_weight_shifted', 'module.layer1.5.conv1.wrapped_module.weight', 'module.layer1.5.conv1.wrapped_module.bias', 'module.layer1.5.conv2.num_forwards', 'module.layer1.5.conv2.force_readjust', 'module.layer1.5.conv2.output_scale', 'module.layer1.5.conv2.output_zero_point', 'module.layer1.5.conv2.w_scale', 'module.layer1.5.conv2.w_zero_point', 'module.layer1.5.conv2.fp_bias', 'module.layer1.5.conv2.accum_scale', 'module.layer1.5.conv2.is_simulated_quant_weight_shifted', 'module.layer1.5.conv2.wrapped_module.weight', 'module.layer1.5.conv2.wrapped_module.bias', 'module.layer1.5.relu2.num_forwards', 'module.layer1.5.relu2.force_readjust', 'module.layer1.5.relu2.output_scale', 'module.layer1.5.relu2.output_zero_point', 'module.layer1.5.residual_eltwiseadd.num_forwards', 'module.layer1.5.residual_eltwiseadd.force_readjust', 'module.layer1.5.residual_eltwiseadd.output_scale', 'module.layer1.5.residual_eltwiseadd.output_zero_point', 'module.layer1.6.conv1.num_forwards', 'module.layer1.6.conv1.force_readjust', 'module.layer1.6.conv1.output_scale', 'module.layer1.6.conv1.output_zero_point', 'module.layer1.6.conv1.w_scale', 'module.layer1.6.conv1.w_zero_point', 'module.layer1.6.conv1.fp_bias', 'module.layer1.6.conv1.accum_scale', 'module.layer1.6.conv1.is_simulated_quant_weight_shifted', 'module.layer1.6.conv1.wrapped_module.weight', 'module.layer1.6.conv1.wrapped_module.bias', 'module.layer1.6.conv2.num_forwards', 'module.layer1.6.conv2.force_readjust', 'module.layer1.6.conv2.output_scale', 'module.layer1.6.conv2.output_zero_point', 'module.layer1.6.conv2.w_scale', 'module.layer1.6.conv2.w_zero_point', 'module.layer1.6.conv2.fp_bias', 'module.layer1.6.conv2.accum_scale', 'module.layer1.6.conv2.is_simulated_quant_weight_shifted', 'module.layer1.6.conv2.wrapped_module.weight', 'module.layer1.6.conv2.wrapped_module.bias', 'module.layer1.6.relu2.num_forwards', 'module.layer1.6.relu2.force_readjust', 'module.layer1.6.relu2.output_scale', 'module.layer1.6.relu2.output_zero_point', 'module.layer1.6.residual_eltwiseadd.num_forwards', 'module.layer1.6.residual_eltwiseadd.force_readjust', 'module.layer1.6.residual_eltwiseadd.output_scale', 'module.layer1.6.residual_eltwiseadd.output_zero_point', 'module.layer1.7.conv1.num_forwards', 'module.layer1.7.conv1.force_readjust', 'module.layer1.7.conv1.output_scale', 'module.layer1.7.conv1.output_zero_point', 'module.layer1.7.conv1.w_scale', 'module.layer1.7.conv1.w_zero_point', 'module.layer1.7.conv1.fp_bias', 'module.layer1.7.conv1.accum_scale', 'module.layer1.7.conv1.is_simulated_quant_weight_shifted', 'module.layer1.7.conv1.wrapped_module.weight', 'module.layer1.7.conv1.wrapped_module.bias', 'module.layer1.7.conv2.num_forwards', 'module.layer1.7.conv2.force_readjust', 'module.layer1.7.conv2.output_scale', 'module.layer1.7.conv2.output_zero_point', 'module.layer1.7.conv2.w_scale', 'module.layer1.7.conv2.w_zero_point', 'module.layer1.7.conv2.fp_bias', 'module.layer1.7.conv2.accum_scale', 'module.layer1.7.conv2.is_simulated_quant_weight_shifted', 'module.layer1.7.conv2.wrapped_module.weight', 'module.layer1.7.conv2.wrapped_module.bias', 'module.layer1.7.relu2.num_forwards', 'module.layer1.7.relu2.force_readjust', 'module.layer1.7.relu2.output_scale', 'module.layer1.7.relu2.output_zero_point', 'module.layer1.7.residual_eltwiseadd.num_forwards', 'module.layer1.7.residual_eltwiseadd.force_readjust', 'module.layer1.7.residual_eltwiseadd.output_scale', 'module.layer1.7.residual_eltwiseadd.output_zero_point', 'module.layer1.8.conv1.num_forwards', 'module.layer1.8.conv1.force_readjust', 'module.layer1.8.conv1.output_scale', 'module.layer1.8.conv1.output_zero_point', 'module.layer1.8.conv1.w_scale', 'module.layer1.8.conv1.w_zero_point', 'module.layer1.8.conv1.fp_bias', 'module.layer1.8.conv1.accum_scale', 'module.layer1.8.conv1.is_simulated_quant_weight_shifted', 'module.layer1.8.conv1.wrapped_module.weight', 'module.layer1.8.conv1.wrapped_module.bias', 'module.layer1.8.conv2.num_forwards', 'module.layer1.8.conv2.force_readjust', 'module.layer1.8.conv2.output_scale', 'module.layer1.8.conv2.output_zero_point', 'module.layer1.8.conv2.w_scale', 'module.layer1.8.conv2.w_zero_point', 'module.layer1.8.conv2.fp_bias', 'module.layer1.8.conv2.accum_scale', 'module.layer1.8.conv2.is_simulated_quant_weight_shifted', 'module.layer1.8.conv2.wrapped_module.weight', 'module.layer1.8.conv2.wrapped_module.bias', 'module.layer1.8.relu2.num_forwards', 'module.layer1.8.relu2.force_readjust', 'module.layer1.8.relu2.output_scale', 'module.layer1.8.relu2.output_zero_point', 'module.layer1.8.residual_eltwiseadd.num_forwards', 'module.layer1.8.residual_eltwiseadd.force_readjust', 'module.layer1.8.residual_eltwiseadd.output_scale', 'module.layer1.8.residual_eltwiseadd.output_zero_point', 'module.layer2.0.conv1.num_forwards', 'module.layer2.0.conv1.force_readjust', 'module.layer2.0.conv1.output_scale', 'module.layer2.0.conv1.output_zero_point', 'module.layer2.0.conv1.w_scale', 'module.layer2.0.conv1.w_zero_point', 'module.layer2.0.conv1.fp_bias', 'module.layer2.0.conv1.accum_scale', 'module.layer2.0.conv1.is_simulated_quant_weight_shifted', 'module.layer2.0.conv1.wrapped_module.weight', 'module.layer2.0.conv1.wrapped_module.bias', 'module.layer2.0.conv2.num_forwards', 'module.layer2.0.conv2.force_readjust', 'module.layer2.0.conv2.output_scale', 'module.layer2.0.conv2.output_zero_point', 'module.layer2.0.conv2.w_scale', 'module.layer2.0.conv2.w_zero_point', 'module.layer2.0.conv2.fp_bias', 'module.layer2.0.conv2.accum_scale', 'module.layer2.0.conv2.is_simulated_quant_weight_shifted', 'module.layer2.0.conv2.wrapped_module.weight', 'module.layer2.0.conv2.wrapped_module.bias', 'module.layer2.0.relu2.num_forwards', 'module.layer2.0.relu2.force_readjust', 'module.layer2.0.relu2.output_scale', 'module.layer2.0.relu2.output_zero_point', 'module.layer2.0.downsample.0.num_forwards', 'module.layer2.0.downsample.0.force_readjust', 'module.layer2.0.downsample.0.output_scale', 'module.layer2.0.downsample.0.output_zero_point', 'module.layer2.0.downsample.0.w_scale', 'module.layer2.0.downsample.0.w_zero_point', 'module.layer2.0.downsample.0.fp_bias', 'module.layer2.0.downsample.0.accum_scale', 'module.layer2.0.downsample.0.is_simulated_quant_weight_shifted', 'module.layer2.0.downsample.0.wrapped_module.weight', 'module.layer2.0.downsample.0.wrapped_module.bias', 'module.layer2.0.residual_eltwiseadd.num_forwards', 'module.layer2.0.residual_eltwiseadd.force_readjust', 'module.layer2.0.residual_eltwiseadd.output_scale', 'module.layer2.0.residual_eltwiseadd.output_zero_point', 'module.layer2.1.conv1.num_forwards', 'module.layer2.1.conv1.force_readjust', 'module.layer2.1.conv1.output_scale', 'module.layer2.1.conv1.output_zero_point', 'module.layer2.1.conv1.w_scale', 'module.layer2.1.conv1.w_zero_point', 'module.layer2.1.conv1.fp_bias', 'module.layer2.1.conv1.accum_scale', 'module.layer2.1.conv1.is_simulated_quant_weight_shifted', 'module.layer2.1.conv1.wrapped_module.weight', 'module.layer2.1.conv1.wrapped_module.bias', 'module.layer2.1.conv2.num_forwards', 'module.layer2.1.conv2.force_readjust', 'module.layer2.1.conv2.output_scale', 'module.layer2.1.conv2.output_zero_point', 'module.layer2.1.conv2.w_scale', 'module.layer2.1.conv2.w_zero_point', 'module.layer2.1.conv2.fp_bias', 'module.layer2.1.conv2.accum_scale', 'module.layer2.1.conv2.is_simulated_quant_weight_shifted', 'module.layer2.1.conv2.wrapped_module.weight', 'module.layer2.1.conv2.wrapped_module.bias', 'module.layer2.1.relu2.num_forwards', 'module.layer2.1.relu2.force_readjust', 'module.layer2.1.relu2.output_scale', 'module.layer2.1.relu2.output_zero_point', 'module.layer2.1.residual_eltwiseadd.num_forwards', 'module.layer2.1.residual_eltwiseadd.force_readjust', 'module.layer2.1.residual_eltwiseadd.output_scale', 'module.layer2.1.residual_eltwiseadd.output_zero_point', 'module.layer2.2.conv1.num_forwards', 'module.layer2.2.conv1.force_readjust', 'module.layer2.2.conv1.output_scale', 'module.layer2.2.conv1.output_zero_point', 'module.layer2.2.conv1.w_scale', 'module.layer2.2.conv1.w_zero_point', 'module.layer2.2.conv1.fp_bias', 'module.layer2.2.conv1.accum_scale', 'module.layer2.2.conv1.is_simulated_quant_weight_shifted', 'module.layer2.2.conv1.wrapped_module.weight', 'module.layer2.2.conv1.wrapped_module.bias', 'module.layer2.2.conv2.num_forwards', 'module.layer2.2.conv2.force_readjust', 'module.layer2.2.conv2.output_scale', 'module.layer2.2.conv2.output_zero_point', 'module.layer2.2.conv2.w_scale', 'module.layer2.2.conv2.w_zero_point', 'module.layer2.2.conv2.fp_bias', 'module.layer2.2.conv2.accum_scale', 'module.layer2.2.conv2.is_simulated_quant_weight_shifted', 'module.layer2.2.conv2.wrapped_module.weight', 'module.layer2.2.conv2.wrapped_module.bias', 'module.layer2.2.relu2.num_forwards', 'module.layer2.2.relu2.force_readjust', 'module.layer2.2.relu2.output_scale', 'module.layer2.2.relu2.output_zero_point', 'module.layer2.2.residual_eltwiseadd.num_forwards', 'module.layer2.2.residual_eltwiseadd.force_readjust', 'module.layer2.2.residual_eltwiseadd.output_scale', 'module.layer2.2.residual_eltwiseadd.output_zero_point', 'module.layer2.3.conv1.num_forwards', 'module.layer2.3.conv1.force_readjust', 'module.layer2.3.conv1.output_scale', 'module.layer2.3.conv1.output_zero_point', 'module.layer2.3.conv1.w_scale', 'module.layer2.3.conv1.w_zero_point', 'module.layer2.3.conv1.fp_bias', 'module.layer2.3.conv1.accum_scale', 'module.layer2.3.conv1.is_simulated_quant_weight_shifted', 'module.layer2.3.conv1.wrapped_module.weight', 'module.layer2.3.conv1.wrapped_module.bias', 'module.layer2.3.conv2.num_forwards', 'module.layer2.3.conv2.force_readjust', 'module.layer2.3.conv2.output_scale', 'module.layer2.3.conv2.output_zero_point', 'module.layer2.3.conv2.w_scale', 'module.layer2.3.conv2.w_zero_point', 'module.layer2.3.conv2.fp_bias', 'module.layer2.3.conv2.accum_scale', 'module.layer2.3.conv2.is_simulated_quant_weight_shifted', 'module.layer2.3.conv2.wrapped_module.weight', 'module.layer2.3.conv2.wrapped_module.bias', 'module.layer2.3.relu2.num_forwards', 'module.layer2.3.relu2.force_readjust', 'module.layer2.3.relu2.output_scale', 'module.layer2.3.relu2.output_zero_point', 'module.layer2.3.residual_eltwiseadd.num_forwards', 'module.layer2.3.residual_eltwiseadd.force_readjust', 'module.layer2.3.residual_eltwiseadd.output_scale', 'module.layer2.3.residual_eltwiseadd.output_zero_point', 'module.layer2.4.conv1.num_forwards', 'module.layer2.4.conv1.force_readjust', 'module.layer2.4.conv1.output_scale', 'module.layer2.4.conv1.output_zero_point', 'module.layer2.4.conv1.w_scale', 'module.layer2.4.conv1.w_zero_point', 'module.layer2.4.conv1.fp_bias', 'module.layer2.4.conv1.accum_scale', 'module.layer2.4.conv1.is_simulated_quant_weight_shifted', 'module.layer2.4.conv1.wrapped_module.weight', 'module.layer2.4.conv1.wrapped_module.bias', 'module.layer2.4.conv2.num_forwards', 'module.layer2.4.conv2.force_readjust', 'module.layer2.4.conv2.output_scale', 'module.layer2.4.conv2.output_zero_point', 'module.layer2.4.conv2.w_scale', 'module.layer2.4.conv2.w_zero_point', 'module.layer2.4.conv2.fp_bias', 'module.layer2.4.conv2.accum_scale', 'module.layer2.4.conv2.is_simulated_quant_weight_shifted', 'module.layer2.4.conv2.wrapped_module.weight', 'module.layer2.4.conv2.wrapped_module.bias', 'module.layer2.4.relu2.num_forwards', 'module.layer2.4.relu2.force_readjust', 'module.layer2.4.relu2.output_scale', 'module.layer2.4.relu2.output_zero_point', 'module.layer2.4.residual_eltwiseadd.num_forwards', 'module.layer2.4.residual_eltwiseadd.force_readjust', 'module.layer2.4.residual_eltwiseadd.output_scale', 'module.layer2.4.residual_eltwiseadd.output_zero_point', 'module.layer2.5.conv1.num_forwards', 'module.layer2.5.conv1.force_readjust', 'module.layer2.5.conv1.output_scale', 'module.layer2.5.conv1.output_zero_point', 'module.layer2.5.conv1.w_scale', 'module.layer2.5.conv1.w_zero_point', 'module.layer2.5.conv1.fp_bias', 'module.layer2.5.conv1.accum_scale', 'module.layer2.5.conv1.is_simulated_quant_weight_shifted', 'module.layer2.5.conv1.wrapped_module.weight', 'module.layer2.5.conv1.wrapped_module.bias', 'module.layer2.5.conv2.num_forwards', 'module.layer2.5.conv2.force_readjust', 'module.layer2.5.conv2.output_scale', 'module.layer2.5.conv2.output_zero_point', 'module.layer2.5.conv2.w_scale', 'module.layer2.5.conv2.w_zero_point', 'module.layer2.5.conv2.fp_bias', 'module.layer2.5.conv2.accum_scale', 'module.layer2.5.conv2.is_simulated_quant_weight_shifted', 'module.layer2.5.conv2.wrapped_module.weight', 'module.layer2.5.conv2.wrapped_module.bias', 'module.layer2.5.relu2.num_forwards', 'module.layer2.5.relu2.force_readjust', 'module.layer2.5.relu2.output_scale', 'module.layer2.5.relu2.output_zero_point', 'module.layer2.5.residual_eltwiseadd.num_forwards', 'module.layer2.5.residual_eltwiseadd.force_readjust', 'module.layer2.5.residual_eltwiseadd.output_scale', 'module.layer2.5.residual_eltwiseadd.output_zero_point', 'module.layer2.6.conv1.num_forwards', 'module.layer2.6.conv1.force_readjust', 'module.layer2.6.conv1.output_scale', 'module.layer2.6.conv1.output_zero_point', 'module.layer2.6.conv1.w_scale', 'module.layer2.6.conv1.w_zero_point', 'module.layer2.6.conv1.fp_bias', 'module.layer2.6.conv1.accum_scale', 'module.layer2.6.conv1.is_simulated_quant_weight_shifted', 'module.layer2.6.conv1.wrapped_module.weight', 'module.layer2.6.conv1.wrapped_module.bias', 'module.layer2.6.conv2.num_forwards', 'module.layer2.6.conv2.force_readjust', 'module.layer2.6.conv2.output_scale', 'module.layer2.6.conv2.output_zero_point', 'module.layer2.6.conv2.w_scale', 'module.layer2.6.conv2.w_zero_point', 'module.layer2.6.conv2.fp_bias', 'module.layer2.6.conv2.accum_scale', 'module.layer2.6.conv2.is_simulated_quant_weight_shifted', 'module.layer2.6.conv2.wrapped_module.weight', 'module.layer2.6.conv2.wrapped_module.bias', 'module.layer2.6.relu2.num_forwards', 'module.layer2.6.relu2.force_readjust', 'module.layer2.6.relu2.output_scale', 'module.layer2.6.relu2.output_zero_point', 'module.layer2.6.residual_eltwiseadd.num_forwards', 'module.layer2.6.residual_eltwiseadd.force_readjust', 'module.layer2.6.residual_eltwiseadd.output_scale', 'module.layer2.6.residual_eltwiseadd.output_zero_point', 'module.layer2.7.conv1.num_forwards', 'module.layer2.7.conv1.force_readjust', 'module.layer2.7.conv1.output_scale', 'module.layer2.7.conv1.output_zero_point', 'module.layer2.7.conv1.w_scale', 'module.layer2.7.conv1.w_zero_point', 'module.layer2.7.conv1.fp_bias', 'module.layer2.7.conv1.accum_scale', 'module.layer2.7.conv1.is_simulated_quant_weight_shifted', 'module.layer2.7.conv1.wrapped_module.weight', 'module.layer2.7.conv1.wrapped_module.bias', 'module.layer2.7.conv2.num_forwards', 'module.layer2.7.conv2.force_readjust', 'module.layer2.7.conv2.output_scale', 'module.layer2.7.conv2.output_zero_point', 'module.layer2.7.conv2.w_scale', 'module.layer2.7.conv2.w_zero_point', 'module.layer2.7.conv2.fp_bias', 'module.layer2.7.conv2.accum_scale', 'module.layer2.7.conv2.is_simulated_quant_weight_shifted', 'module.layer2.7.conv2.wrapped_module.weight', 'module.layer2.7.conv2.wrapped_module.bias', 'module.layer2.7.relu2.num_forwards', 'module.layer2.7.relu2.force_readjust', 'module.layer2.7.relu2.output_scale', 'module.layer2.7.relu2.output_zero_point', 'module.layer2.7.residual_eltwiseadd.num_forwards', 'module.layer2.7.residual_eltwiseadd.force_readjust', 'module.layer2.7.residual_eltwiseadd.output_scale', 'module.layer2.7.residual_eltwiseadd.output_zero_point', 'module.layer2.8.conv1.num_forwards', 'module.layer2.8.conv1.force_readjust', 'module.layer2.8.conv1.output_scale', 'module.layer2.8.conv1.output_zero_point', 'module.layer2.8.conv1.w_scale', 'module.layer2.8.conv1.w_zero_point', 'module.layer2.8.conv1.fp_bias', 'module.layer2.8.conv1.accum_scale', 'module.layer2.8.conv1.is_simulated_quant_weight_shifted', 'module.layer2.8.conv1.wrapped_module.weight', 'module.layer2.8.conv1.wrapped_module.bias', 'module.layer2.8.conv2.num_forwards', 'module.layer2.8.conv2.force_readjust', 'module.layer2.8.conv2.output_scale', 'module.layer2.8.conv2.output_zero_point', 'module.layer2.8.conv2.w_scale', 'module.layer2.8.conv2.w_zero_point', 'module.layer2.8.conv2.fp_bias', 'module.layer2.8.conv2.accum_scale', 'module.layer2.8.conv2.is_simulated_quant_weight_shifted', 'module.layer2.8.conv2.wrapped_module.weight', 'module.layer2.8.conv2.wrapped_module.bias', 'module.layer2.8.relu2.num_forwards', 'module.layer2.8.relu2.force_readjust', 'module.layer2.8.relu2.output_scale', 'module.layer2.8.relu2.output_zero_point', 'module.layer2.8.residual_eltwiseadd.num_forwards', 'module.layer2.8.residual_eltwiseadd.force_readjust', 'module.layer2.8.residual_eltwiseadd.output_scale', 'module.layer2.8.residual_eltwiseadd.output_zero_point', 'module.layer3.0.conv1.num_forwards', 'module.layer3.0.conv1.force_readjust', 'module.layer3.0.conv1.output_scale', 'module.layer3.0.conv1.output_zero_point', 'module.layer3.0.conv1.w_scale', 'module.layer3.0.conv1.w_zero_point', 'module.layer3.0.conv1.fp_bias', 'module.layer3.0.conv1.accum_scale', 'module.layer3.0.conv1.is_simulated_quant_weight_shifted', 'module.layer3.0.conv1.wrapped_module.weight', 'module.layer3.0.conv1.wrapped_module.bias', 'module.layer3.0.conv2.num_forwards', 'module.layer3.0.conv2.force_readjust', 'module.layer3.0.conv2.output_scale', 'module.layer3.0.conv2.output_zero_point', 'module.layer3.0.conv2.w_scale', 'module.layer3.0.conv2.w_zero_point', 'module.layer3.0.conv2.fp_bias', 'module.layer3.0.conv2.accum_scale', 'module.layer3.0.conv2.is_simulated_quant_weight_shifted', 'module.layer3.0.conv2.wrapped_module.weight', 'module.layer3.0.conv2.wrapped_module.bias', 'module.layer3.0.relu2.num_forwards', 'module.layer3.0.relu2.force_readjust', 'module.layer3.0.relu2.output_scale', 'module.layer3.0.relu2.output_zero_point', 'module.layer3.0.downsample.0.num_forwards', 'module.layer3.0.downsample.0.force_readjust', 'module.layer3.0.downsample.0.output_scale', 'module.layer3.0.downsample.0.output_zero_point', 'module.layer3.0.downsample.0.w_scale', 'module.layer3.0.downsample.0.w_zero_point', 'module.layer3.0.downsample.0.fp_bias', 'module.layer3.0.downsample.0.accum_scale', 'module.layer3.0.downsample.0.is_simulated_quant_weight_shifted', 'module.layer3.0.downsample.0.wrapped_module.weight', 'module.layer3.0.downsample.0.wrapped_module.bias', 'module.layer3.0.residual_eltwiseadd.num_forwards', 'module.layer3.0.residual_eltwiseadd.force_readjust', 'module.layer3.0.residual_eltwiseadd.output_scale', 'module.layer3.0.residual_eltwiseadd.output_zero_point', 'module.layer3.1.conv1.num_forwards', 'module.layer3.1.conv1.force_readjust', 'module.layer3.1.conv1.output_scale', 'module.layer3.1.conv1.output_zero_point', 'module.layer3.1.conv1.w_scale', 'module.layer3.1.conv1.w_zero_point', 'module.layer3.1.conv1.fp_bias', 'module.layer3.1.conv1.accum_scale', 'module.layer3.1.conv1.is_simulated_quant_weight_shifted', 'module.layer3.1.conv1.wrapped_module.weight', 'module.layer3.1.conv1.wrapped_module.bias', 'module.layer3.1.conv2.num_forwards', 'module.layer3.1.conv2.force_readjust', 'module.layer3.1.conv2.output_scale', 'module.layer3.1.conv2.output_zero_point', 'module.layer3.1.conv2.w_scale', 'module.layer3.1.conv2.w_zero_point', 'module.layer3.1.conv2.fp_bias', 'module.layer3.1.conv2.accum_scale', 'module.layer3.1.conv2.is_simulated_quant_weight_shifted', 'module.layer3.1.conv2.wrapped_module.weight', 'module.layer3.1.conv2.wrapped_module.bias', 'module.layer3.1.relu2.num_forwards', 'module.layer3.1.relu2.force_readjust', 'module.layer3.1.relu2.output_scale', 'module.layer3.1.relu2.output_zero_point', 'module.layer3.1.residual_eltwiseadd.num_forwards', 'module.layer3.1.residual_eltwiseadd.force_readjust', 'module.layer3.1.residual_eltwiseadd.output_scale', 'module.layer3.1.residual_eltwiseadd.output_zero_point', 'module.layer3.2.conv1.num_forwards', 'module.layer3.2.conv1.force_readjust', 'module.layer3.2.conv1.output_scale', 'module.layer3.2.conv1.output_zero_point', 'module.layer3.2.conv1.w_scale', 'module.layer3.2.conv1.w_zero_point', 'module.layer3.2.conv1.fp_bias', 'module.layer3.2.conv1.accum_scale', 'module.layer3.2.conv1.is_simulated_quant_weight_shifted', 'module.layer3.2.conv1.wrapped_module.weight', 'module.layer3.2.conv1.wrapped_module.bias', 'module.layer3.2.conv2.num_forwards', 'module.layer3.2.conv2.force_readjust', 'module.layer3.2.conv2.output_scale', 'module.layer3.2.conv2.output_zero_point', 'module.layer3.2.conv2.w_scale', 'module.layer3.2.conv2.w_zero_point', 'module.layer3.2.conv2.fp_bias', 'module.layer3.2.conv2.accum_scale', 'module.layer3.2.conv2.is_simulated_quant_weight_shifted', 'module.layer3.2.conv2.wrapped_module.weight', 'module.layer3.2.conv2.wrapped_module.bias', 'module.layer3.2.relu2.num_forwards', 'module.layer3.2.relu2.force_readjust', 'module.layer3.2.relu2.output_scale', 'module.layer3.2.relu2.output_zero_point', 'module.layer3.2.residual_eltwiseadd.num_forwards', 'module.layer3.2.residual_eltwiseadd.force_readjust', 'module.layer3.2.residual_eltwiseadd.output_scale', 'module.layer3.2.residual_eltwiseadd.output_zero_point', 'module.layer3.3.conv1.num_forwards', 'module.layer3.3.conv1.force_readjust', 'module.layer3.3.conv1.output_scale', 'module.layer3.3.conv1.output_zero_point', 'module.layer3.3.conv1.w_scale', 'module.layer3.3.conv1.w_zero_point', 'module.layer3.3.conv1.fp_bias', 'module.layer3.3.conv1.accum_scale', 'module.layer3.3.conv1.is_simulated_quant_weight_shifted', 'module.layer3.3.conv1.wrapped_module.weight', 'module.layer3.3.conv1.wrapped_module.bias', 'module.layer3.3.conv2.num_forwards', 'module.layer3.3.conv2.force_readjust', 'module.layer3.3.conv2.output_scale', 'module.layer3.3.conv2.output_zero_point', 'module.layer3.3.conv2.w_scale', 'module.layer3.3.conv2.w_zero_point', 'module.layer3.3.conv2.fp_bias', 'module.layer3.3.conv2.accum_scale', 'module.layer3.3.conv2.is_simulated_quant_weight_shifted', 'module.layer3.3.conv2.wrapped_module.weight', 'module.layer3.3.conv2.wrapped_module.bias', 'module.layer3.3.relu2.num_forwards', 'module.layer3.3.relu2.force_readjust', 'module.layer3.3.relu2.output_scale', 'module.layer3.3.relu2.output_zero_point', 'module.layer3.3.residual_eltwiseadd.num_forwards', 'module.layer3.3.residual_eltwiseadd.force_readjust', 'module.layer3.3.residual_eltwiseadd.output_scale', 'module.layer3.3.residual_eltwiseadd.output_zero_point', 'module.layer3.4.conv1.num_forwards', 'module.layer3.4.conv1.force_readjust', 'module.layer3.4.conv1.output_scale', 'module.layer3.4.conv1.output_zero_point', 'module.layer3.4.conv1.w_scale', 'module.layer3.4.conv1.w_zero_point', 'module.layer3.4.conv1.fp_bias', 'module.layer3.4.conv1.accum_scale', 'module.layer3.4.conv1.is_simulated_quant_weight_shifted', 'module.layer3.4.conv1.wrapped_module.weight', 'module.layer3.4.conv1.wrapped_module.bias', 'module.layer3.4.conv2.num_forwards', 'module.layer3.4.conv2.force_readjust', 'module.layer3.4.conv2.output_scale', 'module.layer3.4.conv2.output_zero_point', 'module.layer3.4.conv2.w_scale', 'module.layer3.4.conv2.w_zero_point', 'module.layer3.4.conv2.fp_bias', 'module.layer3.4.conv2.accum_scale', 'module.layer3.4.conv2.is_simulated_quant_weight_shifted', 'module.layer3.4.conv2.wrapped_module.weight', 'module.layer3.4.conv2.wrapped_module.bias', 'module.layer3.4.relu2.num_forwards', 'module.layer3.4.relu2.force_readjust', 'module.layer3.4.relu2.output_scale', 'module.layer3.4.relu2.output_zero_point', 'module.layer3.4.residual_eltwiseadd.num_forwards', 'module.layer3.4.residual_eltwiseadd.force_readjust', 'module.layer3.4.residual_eltwiseadd.output_scale', 'module.layer3.4.residual_eltwiseadd.output_zero_point', 'module.layer3.5.conv1.num_forwards', 'module.layer3.5.conv1.force_readjust', 'module.layer3.5.conv1.output_scale', 'module.layer3.5.conv1.output_zero_point', 'module.layer3.5.conv1.w_scale', 'module.layer3.5.conv1.w_zero_point', 'module.layer3.5.conv1.fp_bias', 'module.layer3.5.conv1.accum_scale', 'module.layer3.5.conv1.is_simulated_quant_weight_shifted', 'module.layer3.5.conv1.wrapped_module.weight', 'module.layer3.5.conv1.wrapped_module.bias', 'module.layer3.5.conv2.num_forwards', 'module.layer3.5.conv2.force_readjust', 'module.layer3.5.conv2.output_scale', 'module.layer3.5.conv2.output_zero_point', 'module.layer3.5.conv2.w_scale', 'module.layer3.5.conv2.w_zero_point', 'module.layer3.5.conv2.fp_bias', 'module.layer3.5.conv2.accum_scale', 'module.layer3.5.conv2.is_simulated_quant_weight_shifted', 'module.layer3.5.conv2.wrapped_module.weight', 'module.layer3.5.conv2.wrapped_module.bias', 'module.layer3.5.relu2.num_forwards', 'module.layer3.5.relu2.force_readjust', 'module.layer3.5.relu2.output_scale', 'module.layer3.5.relu2.output_zero_point', 'module.layer3.5.residual_eltwiseadd.num_forwards', 'module.layer3.5.residual_eltwiseadd.force_readjust', 'module.layer3.5.residual_eltwiseadd.output_scale', 'module.layer3.5.residual_eltwiseadd.output_zero_point', 'module.layer3.6.conv1.num_forwards', 'module.layer3.6.conv1.force_readjust', 'module.layer3.6.conv1.output_scale', 'module.layer3.6.conv1.output_zero_point', 'module.layer3.6.conv1.w_scale', 'module.layer3.6.conv1.w_zero_point', 'module.layer3.6.conv1.fp_bias', 'module.layer3.6.conv1.accum_scale', 'module.layer3.6.conv1.is_simulated_quant_weight_shifted', 'module.layer3.6.conv1.wrapped_module.weight', 'module.layer3.6.conv1.wrapped_module.bias', 'module.layer3.6.conv2.num_forwards', 'module.layer3.6.conv2.force_readjust', 'module.layer3.6.conv2.output_scale', 'module.layer3.6.conv2.output_zero_point', 'module.layer3.6.conv2.w_scale', 'module.layer3.6.conv2.w_zero_point', 'module.layer3.6.conv2.fp_bias', 'module.layer3.6.conv2.accum_scale', 'module.layer3.6.conv2.is_simulated_quant_weight_shifted', 'module.layer3.6.conv2.wrapped_module.weight', 'module.layer3.6.conv2.wrapped_module.bias', 'module.layer3.6.relu2.num_forwards', 'module.layer3.6.relu2.force_readjust', 'module.layer3.6.relu2.output_scale', 'module.layer3.6.relu2.output_zero_point', 'module.layer3.6.residual_eltwiseadd.num_forwards', 'module.layer3.6.residual_eltwiseadd.force_readjust', 'module.layer3.6.residual_eltwiseadd.output_scale', 'module.layer3.6.residual_eltwiseadd.output_zero_point', 'module.layer3.7.conv1.num_forwards', 'module.layer3.7.conv1.force_readjust', 'module.layer3.7.conv1.output_scale', 'module.layer3.7.conv1.output_zero_point', 'module.layer3.7.conv1.w_scale', 'module.layer3.7.conv1.w_zero_point', 'module.layer3.7.conv1.fp_bias', 'module.layer3.7.conv1.accum_scale', 'module.layer3.7.conv1.is_simulated_quant_weight_shifted', 'module.layer3.7.conv1.wrapped_module.weight', 'module.layer3.7.conv1.wrapped_module.bias', 'module.layer3.7.conv2.num_forwards', 'module.layer3.7.conv2.force_readjust', 'module.layer3.7.conv2.output_scale', 'module.layer3.7.conv2.output_zero_point', 'module.layer3.7.conv2.w_scale', 'module.layer3.7.conv2.w_zero_point', 'module.layer3.7.conv2.fp_bias', 'module.layer3.7.conv2.accum_scale', 'module.layer3.7.conv2.is_simulated_quant_weight_shifted', 'module.layer3.7.conv2.wrapped_module.weight', 'module.layer3.7.conv2.wrapped_module.bias', 'module.layer3.7.relu2.num_forwards', 'module.layer3.7.relu2.force_readjust', 'module.layer3.7.relu2.output_scale', 'module.layer3.7.relu2.output_zero_point', 'module.layer3.7.residual_eltwiseadd.num_forwards', 'module.layer3.7.residual_eltwiseadd.force_readjust', 'module.layer3.7.residual_eltwiseadd.output_scale', 'module.layer3.7.residual_eltwiseadd.output_zero_point', 'module.layer3.8.conv1.num_forwards', 'module.layer3.8.conv1.force_readjust', 'module.layer3.8.conv1.output_scale', 'module.layer3.8.conv1.output_zero_point', 'module.layer3.8.conv1.w_scale', 'module.layer3.8.conv1.w_zero_point', 'module.layer3.8.conv1.fp_bias', 'module.layer3.8.conv1.accum_scale', 'module.layer3.8.conv1.is_simulated_quant_weight_shifted', 'module.layer3.8.conv1.wrapped_module.weight', 'module.layer3.8.conv1.wrapped_module.bias', 'module.layer3.8.conv2.num_forwards', 'module.layer3.8.conv2.force_readjust', 'module.layer3.8.conv2.output_scale', 'module.layer3.8.conv2.output_zero_point', 'module.layer3.8.conv2.w_scale', 'module.layer3.8.conv2.w_zero_point', 'module.layer3.8.conv2.fp_bias', 'module.layer3.8.conv2.accum_scale', 'module.layer3.8.conv2.is_simulated_quant_weight_shifted', 'module.layer3.8.conv2.wrapped_module.weight', 'module.layer3.8.conv2.wrapped_module.bias', 'module.layer3.8.relu2.num_forwards', 'module.layer3.8.relu2.force_readjust', 'module.layer3.8.relu2.output_scale', 'module.layer3.8.relu2.output_zero_point', 'module.layer3.8.residual_eltwiseadd.num_forwards', 'module.layer3.8.residual_eltwiseadd.force_readjust', 'module.layer3.8.residual_eltwiseadd.output_scale', 'module.layer3.8.residual_eltwiseadd.output_zero_point', 'module.avgpool.num_forwards', 'module.avgpool.force_readjust', 'module.avgpool.output_scale', 'module.avgpool.output_zero_point', 'module.fc.num_forwards', 'module.fc.force_readjust', 'module.fc.output_scale', 'module.fc.output_zero_point', 'module.fc.w_scale', 'module.fc.w_zero_point', 'module.fc.fp_bias', 'module.fc.accum_scale', 'module.fc.is_simulated_quant_weight_shifted', 'module.fc.wrapped_module.weight', 'module.fc.wrapped_module.bias'])"]},"metadata":{"tags":[]},"execution_count":35}]},{"cell_type":"code","metadata":{"id":"At53PZkysrBm"},"source":["testentry = removeModule(torch.load(pather))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"xracYfF7tMFH","executionInfo":{"elapsed":3537,"status":"ok","timestamp":1607406129239,"user":{"displayName":"Jeremy Wang","photoUrl":"","userId":"16277065741529505083"},"user_tz":300},"outputId":"cd1d7c7f-fa2e-4b8a-f7a8-70fd138d5026"},"source":["entry[\"state_dict\"]"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["OrderedDict([('module.conv1.num_forwards', tensor([40], device='cuda:0')),\n","             ('module.conv1.force_readjust', tensor(False, device='cuda:0')),\n","             ('module.conv1.output_scale', tensor([11.0280], device='cuda:0')),\n","             ('module.conv1.output_zero_point', tensor([0.], device='cuda:0')),\n","             ('module.conv1.w_scale', tensor([[[[1.0050e+02]]],\n","              \n","              \n","                      [[[2.1752e+06]]],\n","              \n","              \n","                      [[[6.9460e+05]]],\n","              \n","              \n","                      [[[1.1469e+02]]],\n","              \n","              \n","                      [[[8.4651e+01]]],\n","              \n","              \n","                      [[[5.9710e+05]]],\n","              \n","              \n","                      [[[4.1348e+01]]],\n","              \n","              \n","                      [[[1.2563e+06]]],\n","              \n","              \n","                      [[[6.6465e+01]]],\n","              \n","              \n","                      [[[3.9228e+01]]],\n","              \n","              \n","                      [[[9.3445e+03]]],\n","              \n","              \n","                      [[[9.1344e+01]]],\n","              \n","              \n","                      [[[8.0979e+01]]],\n","              \n","              \n","                      [[[1.4984e+07]]],\n","              \n","              \n","                      [[[3.7370e+02]]],\n","              \n","              \n","                      [[[1.7669e+06]]]], device='cuda:0')),\n","             ('module.conv1.w_zero_point', tensor([[[[-29.]]],\n","              \n","              \n","                      [[[-47.]]],\n","              \n","              \n","                      [[[-21.]]],\n","              \n","              \n","                      [[[-28.]]],\n","              \n","              \n","                      [[[-30.]]],\n","              \n","              \n","                      [[[-59.]]],\n","              \n","              \n","                      [[[-20.]]],\n","              \n","              \n","                      [[[-51.]]],\n","              \n","              \n","                      [[[-21.]]],\n","              \n","              \n","                      [[[-13.]]],\n","              \n","              \n","                      [[[-10.]]],\n","              \n","              \n","                      [[[-28.]]],\n","              \n","              \n","                      [[[-53.]]],\n","              \n","              \n","                      [[[ -4.]]],\n","              \n","              \n","                      [[[-17.]]],\n","              \n","              \n","                      [[[-63.]]]], device='cuda:0')),\n","             ('module.conv1.fp_bias',\n","              tensor([ 6.7084e-01, -1.1652e-03, -3.5343e-03,  6.3502e-01,  7.3546e-01,\n","                      -2.7732e-03,  2.4089e+00, -1.0072e-03,  1.0231e+00,  1.5622e+00,\n","                       1.1219e-03,  1.0911e+00,  3.4948e-02, -2.4342e-03,  1.5152e-01,\n","                      -1.9359e-03], device='cuda:0')),\n","             ('module.conv1.accum_scale', tensor([[[1.4085e+03]],\n","              \n","                      [[3.0486e+07]],\n","              \n","                      [[9.7347e+06]],\n","              \n","                      [[1.6074e+03]],\n","              \n","                      [[1.1864e+03]],\n","              \n","                      [[8.3682e+06]],\n","              \n","                      [[5.7949e+02]],\n","              \n","                      [[1.7607e+07]],\n","              \n","                      [[9.3149e+02]],\n","              \n","                      [[5.4977e+02]],\n","              \n","                      [[1.3096e+05]],\n","              \n","                      [[1.2802e+03]],\n","              \n","                      [[1.1349e+03]],\n","              \n","                      [[2.0999e+08]],\n","              \n","                      [[5.2374e+03]],\n","              \n","                      [[2.4762e+07]]], device='cuda:0')),\n","             ('module.conv1.is_simulated_quant_weight_shifted',\n","              tensor(False, device='cuda:0')),\n","             ('module.conv1.wrapped_module.weight', tensor([[[[43., 54., 38.],\n","                        [30., 38., 25.],\n","                        [14., 20., 20.]],\n","              \n","                       [[58., 63., 33.],\n","                        [37., 41., 17.],\n","                        [33., 34., 19.]],\n","              \n","                       [[21., 12., 21.],\n","                        [ 5.,  0., 19.],\n","                        [22., 22., 38.]]],\n","              \n","              \n","                      [[[48., 28., 31.],\n","                        [52., 42., 45.],\n","                        [63., 46., 52.]],\n","              \n","                       [[27.,  7.,  6.],\n","                        [27., 13., 23.],\n","                        [36., 28., 32.]],\n","              \n","                       [[16.,  0.,  2.],\n","                        [20., 11., 15.],\n","                        [31., 18., 22.]]],\n","              \n","              \n","                      [[[35., 23., 37.],\n","                        [40., 32., 45.],\n","                        [48., 42., 63.]],\n","              \n","                       [[21., 18., 31.],\n","                        [34., 29., 39.],\n","                        [48., 43., 60.]],\n","              \n","                       [[14.,  0., 20.],\n","                        [24., 18., 42.],\n","                        [43., 42., 54.]]],\n","              \n","              \n","                      [[[23., 14., 18.],\n","                        [24., 32., 23.],\n","                        [20., 28., 31.]],\n","              \n","                       [[43., 44., 24.],\n","                        [50., 63., 29.],\n","                        [31., 37., 25.]],\n","              \n","                       [[44., 28., 14.],\n","                        [43., 30.,  0.],\n","                        [31., 16.,  2.]]],\n","              \n","              \n","                      [[[30.,  9., 24.],\n","                        [19.,  0., 12.],\n","                        [22., 13., 24.]],\n","              \n","                       [[31., 26., 35.],\n","                        [35., 33., 33.],\n","                        [34., 31., 32.]],\n","              \n","                       [[34., 44., 38.],\n","                        [46., 63., 49.],\n","                        [32., 41., 33.]]],\n","              \n","              \n","                      [[[17., 25., 45.],\n","                        [24., 21., 20.],\n","                        [14.,  0., 20.]],\n","              \n","                       [[27., 40., 56.],\n","                        [45., 46., 44.],\n","                        [28., 28., 62.]],\n","              \n","                       [[33., 48., 63.],\n","                        [50., 55., 45.],\n","                        [30., 31., 59.]]],\n","              \n","              \n","                      [[[13., 36., 11.],\n","                        [27.,  0., 15.],\n","                        [27., 25., 25.]],\n","              \n","                       [[ 9., 63., 19.],\n","                        [13.,  1., 10.],\n","                        [22., 12., 20.]],\n","              \n","                       [[13., 53., 23.],\n","                        [17., 26., 26.],\n","                        [14., 19., 16.]]],\n","              \n","              \n","                      [[[44., 53., 61.],\n","                        [26., 37., 39.],\n","                        [ 9., 27., 25.]],\n","              \n","                       [[28., 33., 57.],\n","                        [15., 41., 38.],\n","                        [ 0., 27., 30.]],\n","              \n","                       [[40., 45., 63.],\n","                        [27., 37., 43.],\n","                        [13., 28., 30.]]],\n","              \n","              \n","                      [[[ 6.,  0., 12.],\n","                        [12., 17., 17.],\n","                        [17., 22., 23.]],\n","              \n","                       [[36., 45., 32.],\n","                        [46., 63., 38.],\n","                        [32., 41., 23.]],\n","              \n","                       [[16.,  6., 20.],\n","                        [ 6.,  2., 13.],\n","                        [17.,  7., 15.]]],\n","              \n","              \n","                      [[[ 3., 24.,  9.],\n","                        [ 8., 63., 39.],\n","                        [ 6., 27., 12.]],\n","              \n","                       [[11.,  2.,  6.],\n","                        [ 0.,  3.,  8.],\n","                        [ 9.,  1., 14.]],\n","              \n","                       [[22., 14., 18.],\n","                        [20.,  6.,  0.],\n","                        [23., 10.,  9.]]],\n","              \n","              \n","                      [[[63., 50., 46.],\n","                        [44., 28., 23.],\n","                        [29., 18., 17.]],\n","              \n","                       [[38., 28., 29.],\n","                        [39., 24., 14.],\n","                        [29., 15.,  5.]],\n","              \n","                       [[41., 31., 29.],\n","                        [38., 22., 14.],\n","                        [27., 13.,  0.]]],\n","              \n","              \n","                      [[[29., 32., 23.],\n","                        [41., 52., 20.],\n","                        [34., 38., 28.]],\n","              \n","                       [[26., 31.,  8.],\n","                        [33., 39.,  0.],\n","                        [24., 19., 11.]],\n","              \n","                       [[27., 39., 20.],\n","                        [45., 63., 27.],\n","                        [26., 35., 24.]]],\n","              \n","              \n","                      [[[62., 60., 57.],\n","                        [60., 23., 50.],\n","                        [63., 56., 53.]],\n","              \n","                       [[49., 31., 55.],\n","                        [44.,  0., 48.],\n","                        [59., 47., 58.]],\n","              \n","                       [[60., 57., 57.],\n","                        [59., 29., 53.],\n","                        [56., 53., 52.]]],\n","              \n","              \n","                      [[[34., 41., 19.],\n","                        [40., 40., 24.],\n","                        [10., 28., 22.]],\n","              \n","                       [[32., 34., 13.],\n","                        [30., 14., 45.],\n","                        [ 0., 21., 12.]],\n","              \n","                       [[42., 38., 54.],\n","                        [62., 63., 59.],\n","                        [19., 20., 45.]]],\n","              \n","              \n","                      [[[22., 29., 27.],\n","                        [21., 41., 19.],\n","                        [ 0., 20., 22.]],\n","              \n","                       [[18., 38., 33.],\n","                        [30., 63., 31.],\n","                        [11., 36., 31.]],\n","              \n","                       [[13., 16., 12.],\n","                        [25., 33., 10.],\n","                        [15., 20., 19.]]],\n","              \n","              \n","                      [[[42., 18., 20.],\n","                        [18., 19., 15.],\n","                        [14., 23., 24.]],\n","              \n","                       [[23., 11.,  7.],\n","                        [ 7.,  5.,  4.],\n","                        [ 0., 11., 18.]],\n","              \n","                       [[21.,  8.,  6.],\n","                        [ 9., 13.,  6.],\n","                        [ 0., 15., 15.]]]], device='cuda:0')),\n","             ('module.conv1.wrapped_module.bias',\n","              tensor([ 9.4500e+02, -3.5521e+04, -3.4406e+04,  1.0210e+03,  8.7300e+02,\n","                      -2.3206e+04,  1.3960e+03, -1.7734e+04,  9.5300e+02,  8.5900e+02,\n","                       1.4700e+02,  1.3970e+03,  4.0000e+01, -5.1116e+05,  7.9400e+02,\n","                      -4.7937e+04], device='cuda:0')),\n","             ('module.layer1.0.conv1.num_forwards',\n","              tensor([40], device='cuda:0')),\n","             ('module.layer1.0.conv1.force_readjust',\n","              tensor(False, device='cuda:0')),\n","             ('module.layer1.0.conv1.output_scale',\n","              tensor([41.6379], device='cuda:0')),\n","             ('module.layer1.0.conv1.output_zero_point',\n","              tensor([0.], device='cuda:0')),\n","             ('module.layer1.0.conv1.w_scale', tensor([[[[1.8056e+05]]],\n","              \n","              \n","                      [[[2.8634e+02]]],\n","              \n","              \n","                      [[[9.4884e+02]]],\n","              \n","              \n","                      [[[2.8043e+02]]],\n","              \n","              \n","                      [[[2.4778e+02]]],\n","              \n","              \n","                      [[[3.5243e+02]]],\n","              \n","              \n","                      [[[4.4903e+02]]],\n","              \n","              \n","                      [[[5.9835e+02]]],\n","              \n","              \n","                      [[[3.8350e+02]]],\n","              \n","              \n","                      [[[5.0036e+02]]],\n","              \n","              \n","                      [[[9.8378e+02]]],\n","              \n","              \n","                      [[[3.4203e+02]]],\n","              \n","              \n","                      [[[2.4807e+06]]],\n","              \n","              \n","                      [[[3.5880e+02]]],\n","              \n","              \n","                      [[[1.1422e+05]]],\n","              \n","              \n","                      [[[4.4443e+02]]]], device='cuda:0')),\n","             ('module.layer1.0.conv1.w_zero_point', tensor([[[[-34.]]],\n","              \n","              \n","                      [[[-17.]]],\n","              \n","              \n","                      [[[-25.]]],\n","              \n","              \n","                      [[[-36.]]],\n","              \n","              \n","                      [[[-28.]]],\n","              \n","              \n","                      [[[-35.]]],\n","              \n","              \n","                      [[[-25.]]],\n","              \n","              \n","                      [[[-42.]]],\n","              \n","              \n","                      [[[-20.]]],\n","              \n","              \n","                      [[[-30.]]],\n","              \n","              \n","                      [[[-30.]]],\n","              \n","              \n","                      [[[-24.]]],\n","              \n","              \n","                      [[[-24.]]],\n","              \n","              \n","                      [[[-31.]]],\n","              \n","              \n","                      [[[-30.]]],\n","              \n","              \n","                      [[[-28.]]]], device='cuda:0')),\n","             ('module.layer1.0.conv1.fp_bias',\n","              tensor([ 3.9175e-04, -1.2039e+00, -2.6362e-01,  8.5549e-01,  8.8966e-01,\n","                      -4.0299e-01, -1.8411e+00,  4.7812e-01, -1.0780e+00, -5.6041e-02,\n","                      -1.6244e-01, -1.0612e-01, -3.8254e-03,  1.2814e+00, -4.4502e-03,\n","                       3.1543e-01], device='cuda:0')),\n","             ('module.layer1.0.conv1.accum_scale', tensor([[[1.9912e+06]],\n","              \n","                      [[3.1577e+03]],\n","              \n","                      [[1.0464e+04]],\n","              \n","                      [[3.0925e+03]],\n","              \n","                      [[2.7325e+03]],\n","              \n","                      [[3.8866e+03]],\n","              \n","                      [[4.9519e+03]],\n","              \n","                      [[6.5986e+03]],\n","              \n","                      [[4.2292e+03]],\n","              \n","                      [[5.5180e+03]],\n","              \n","                      [[1.0849e+04]],\n","              \n","                      [[3.7719e+03]],\n","              \n","                      [[2.7357e+07]],\n","              \n","                      [[3.9568e+03]],\n","              \n","                      [[1.2596e+06]],\n","              \n","                      [[4.9011e+03]]], device='cuda:0')),\n","             ('module.layer1.0.conv1.is_simulated_quant_weight_shifted',\n","              tensor(False, device='cuda:0')),\n","             ('module.layer1.0.conv1.wrapped_module.weight',\n","              tensor([[[[ 3., 11.,  9.],\n","                        [ 3., 17., 16.],\n","                        [ 0., 14., 18.]],\n","              \n","                       [[23., 27., 11.],\n","                        [21., 23., 14.],\n","                        [22., 33., 20.]],\n","              \n","                       [[17.,  9., 12.],\n","                        [18., 14., 18.],\n","                        [27., 26., 27.]],\n","              \n","                       ...,\n","              \n","                       [[40., 41., 36.],\n","                        [41., 45., 44.],\n","                        [38., 40., 39.]],\n","              \n","                       [[ 6., 20., 13.],\n","                        [ 8., 12., 16.],\n","                        [19., 29., 30.]],\n","              \n","                       [[ 5., 10.,  1.],\n","                        [11., 14.,  8.],\n","                        [19., 18., 24.]]],\n","              \n","              \n","                      [[[ 5., 10., 10.],\n","                        [ 1.,  9.,  5.],\n","                        [ 7., 15.,  8.]],\n","              \n","                       [[17., 17., 17.],\n","                        [17., 17., 17.],\n","                        [17., 17., 17.]],\n","              \n","                       [[17., 17., 17.],\n","                        [17., 17., 17.],\n","                        [17., 17., 17.]],\n","              \n","                       ...,\n","              \n","                       [[17., 17., 17.],\n","                        [17., 17., 17.],\n","                        [17., 17., 17.]],\n","              \n","                       [[11.,  8.,  9.],\n","                        [12.,  9., 11.],\n","                        [16., 14., 15.]],\n","              \n","                       [[17., 17., 17.],\n","                        [17., 17., 17.],\n","                        [17., 17., 17.]]],\n","              \n","              \n","                      [[[38., 38., 29.],\n","                        [19., 29., 26.],\n","                        [18., 33., 35.]],\n","              \n","                       [[26., 26., 26.],\n","                        [27., 26., 26.],\n","                        [26., 26., 26.]],\n","              \n","                       [[27., 26., 26.],\n","                        [27., 27., 26.],\n","                        [27., 27., 26.]],\n","              \n","                       ...,\n","              \n","                       [[25., 25., 25.],\n","                        [24., 25., 24.],\n","                        [24., 25., 25.]],\n","              \n","                       [[54., 59., 58.],\n","                        [45., 50., 50.],\n","                        [35., 36., 34.]],\n","              \n","                       [[27., 27., 26.],\n","                        [27., 27., 26.],\n","                        [27., 27., 26.]]],\n","              \n","              \n","                      ...,\n","              \n","              \n","                      [[[38., 40., 32.],\n","                        [35., 32., 28.],\n","                        [22., 16., 27.]],\n","              \n","                       [[31., 31., 31.],\n","                        [31., 31., 31.],\n","                        [31., 31., 31.]],\n","              \n","                       [[31., 31., 31.],\n","                        [31., 31., 31.],\n","                        [31., 31., 31.]],\n","              \n","                       ...,\n","              \n","                       [[31., 31., 31.],\n","                        [31., 31., 31.],\n","                        [31., 31., 31.]],\n","              \n","                       [[24., 21., 27.],\n","                        [21., 22., 26.],\n","                        [24., 25., 26.]],\n","              \n","                       [[31., 31., 31.],\n","                        [31., 31., 31.],\n","                        [31., 31., 31.]]],\n","              \n","              \n","                      [[[59., 60., 44.],\n","                        [48., 46., 34.],\n","                        [43., 44., 31.]],\n","              \n","                       [[42., 40., 44.],\n","                        [40., 32., 28.],\n","                        [22., 11., 18.]],\n","              \n","                       [[42., 30., 36.],\n","                        [43., 25., 31.],\n","                        [59., 41., 40.]],\n","              \n","                       ...,\n","              \n","                       [[17.,  6., 10.],\n","                        [15.,  6.,  8.],\n","                        [28., 13., 15.]],\n","              \n","                       [[53., 43., 29.],\n","                        [48., 46., 34.],\n","                        [62., 51., 38.]],\n","              \n","                       [[53., 42., 43.],\n","                        [48., 36., 29.],\n","                        [50., 35., 26.]]],\n","              \n","              \n","                      [[[51., 44., 31.],\n","                        [35., 25., 16.],\n","                        [32., 21., 19.]],\n","              \n","                       [[28., 28., 28.],\n","                        [28., 28., 28.],\n","                        [28., 28., 28.]],\n","              \n","                       [[28., 28., 28.],\n","                        [28., 28., 28.],\n","                        [28., 28., 28.]],\n","              \n","                       ...,\n","              \n","                       [[28., 28., 28.],\n","                        [28., 28., 28.],\n","                        [28., 28., 28.]],\n","              \n","                       [[29., 24., 29.],\n","                        [27., 23., 25.],\n","                        [27., 22., 23.]],\n","              \n","                       [[28., 28., 28.],\n","                        [28., 28., 28.],\n","                        [28., 28., 28.]]]], device='cuda:0')),\n","             ('module.layer1.0.conv1.wrapped_module.bias',\n","              tensor([    780.,   -3802.,   -2758.,    2646.,    2431.,   -1566.,   -9117.,\n","                         3155.,   -4559.,    -309.,   -1762.,    -400., -104651.,    5070.,\n","                        -5605.,    1546.], device='cuda:0')),\n","             ('module.layer1.0.conv2.num_forwards',\n","              tensor([40], device='cuda:0')),\n","             ('module.layer1.0.conv2.force_readjust',\n","              tensor(False, device='cuda:0')),\n","             ('module.layer1.0.conv2.output_scale',\n","              tensor([21.9046], device='cuda:0')),\n","             ('module.layer1.0.conv2.output_zero_point',\n","              tensor([-27.], device='cuda:0')),\n","             ('module.layer1.0.conv2.w_scale', tensor([[[[3.6573e+02]]],\n","              \n","              \n","                      [[[2.5748e+02]]],\n","              \n","              \n","                      [[[7.6190e+01]]],\n","              \n","              \n","                      [[[1.1425e+04]]],\n","              \n","              \n","                      [[[2.7531e+02]]],\n","              \n","              \n","                      [[[1.6563e+02]]],\n","              \n","              \n","                      [[[3.0155e+02]]],\n","              \n","              \n","                      [[[2.9383e+05]]],\n","              \n","              \n","                      [[[1.2029e+02]]],\n","              \n","              \n","                      [[[1.7827e+02]]],\n","              \n","              \n","                      [[[4.0190e+03]]],\n","              \n","              \n","                      [[[1.0339e+03]]],\n","              \n","              \n","                      [[[5.4239e+02]]],\n","              \n","              \n","                      [[[3.4067e+05]]],\n","              \n","              \n","                      [[[4.7482e+02]]],\n","              \n","              \n","                      [[[2.0942e+02]]]], device='cuda:0')),\n","             ('module.layer1.0.conv2.w_zero_point', tensor([[[[-33.]]],\n","              \n","              \n","                      [[[-24.]]],\n","              \n","              \n","                      [[[-25.]]],\n","              \n","              \n","                      [[[-28.]]],\n","              \n","              \n","                      [[[-25.]]],\n","              \n","              \n","                      [[[-28.]]],\n","              \n","              \n","                      [[[-26.]]],\n","              \n","              \n","                      [[[-36.]]],\n","              \n","              \n","                      [[[-36.]]],\n","              \n","              \n","                      [[[-23.]]],\n","              \n","              \n","                      [[[-32.]]],\n","              \n","              \n","                      [[[-36.]]],\n","              \n","              \n","                      [[[-23.]]],\n","              \n","              \n","                      [[[-27.]]],\n","              \n","              \n","                      [[[-31.]]],\n","              \n","              \n","                      [[[-38.]]]], device='cuda:0')),\n","             ('module.layer1.0.conv2.fp_bias',\n","              tensor([ 0.0511, -0.3457, -0.1257,  0.0648, -0.1589,  0.2921,  0.3049, -0.0050,\n","                      -0.2575, -0.2578, -0.0308,  0.0748,  0.0125, -0.0022,  0.1688,  0.6248],\n","                     device='cuda:0')),\n","             ('module.layer1.0.conv2.accum_scale', tensor([[[1.5228e+04]],\n","              \n","                      [[1.0721e+04]],\n","              \n","                      [[3.1724e+03]],\n","              \n","                      [[4.7570e+05]],\n","              \n","                      [[1.1463e+04]],\n","              \n","                      [[6.8964e+03]],\n","              \n","                      [[1.2556e+04]],\n","              \n","                      [[1.2235e+07]],\n","              \n","                      [[5.0087e+03]],\n","              \n","                      [[7.4228e+03]],\n","              \n","                      [[1.6734e+05]],\n","              \n","                      [[4.3048e+04]],\n","              \n","                      [[2.2584e+04]],\n","              \n","                      [[1.4185e+07]],\n","              \n","                      [[1.9771e+04]],\n","              \n","                      [[8.7200e+03]]], device='cuda:0')),\n","             ('module.layer1.0.conv2.is_simulated_quant_weight_shifted',\n","              tensor(False, device='cuda:0')),\n","             ('module.layer1.0.conv2.wrapped_module.weight',\n","              tensor([[[[33., 33., 33.],\n","                        [33., 33., 33.],\n","                        [33., 33., 33.]],\n","              \n","                       [[41., 39., 38.],\n","                        [37., 39., 37.],\n","                        [41., 36., 42.]],\n","              \n","                       [[50., 47., 45.],\n","                        [47., 43., 39.],\n","                        [46., 47., 44.]],\n","              \n","                       ...,\n","              \n","                       [[46., 44., 46.],\n","                        [40., 36., 33.],\n","                        [41., 29., 28.]],\n","              \n","                       [[33., 33., 33.],\n","                        [33., 33., 33.],\n","                        [33., 33., 33.]],\n","              \n","                       [[34., 41., 53.],\n","                        [26., 38., 43.],\n","                        [33., 47., 45.]]],\n","              \n","              \n","                      [[[24., 24., 24.],\n","                        [24., 24., 24.],\n","                        [24., 24., 24.]],\n","              \n","                       [[21., 20., 20.],\n","                        [20., 20., 17.],\n","                        [26., 26., 25.]],\n","              \n","                       [[14., 23., 30.],\n","                        [10., 21., 28.],\n","                        [ 5., 14., 22.]],\n","              \n","                       ...,\n","              \n","                       [[32., 35., 42.],\n","                        [29., 31., 31.],\n","                        [24., 16., 20.]],\n","              \n","                       [[24., 24., 24.],\n","                        [24., 24., 25.],\n","                        [24., 24., 24.]],\n","              \n","                       [[27., 26., 25.],\n","                        [28., 28., 19.],\n","                        [27., 22., 14.]]],\n","              \n","              \n","                      [[[25., 25., 25.],\n","                        [25., 25., 25.],\n","                        [25., 25., 25.]],\n","              \n","                       [[29., 25., 23.],\n","                        [27., 22., 16.],\n","                        [21., 19., 12.]],\n","              \n","                       [[23., 26., 28.],\n","                        [22., 25., 27.],\n","                        [20., 22., 23.]],\n","              \n","                       ...,\n","              \n","                       [[36., 36., 41.],\n","                        [25., 25., 26.],\n","                        [26., 25., 27.]],\n","              \n","                       [[25., 25., 25.],\n","                        [25., 25., 25.],\n","                        [25., 25., 25.]],\n","              \n","                       [[16., 18., 27.],\n","                        [16., 19., 25.],\n","                        [24., 25., 26.]]],\n","              \n","              \n","                      ...,\n","              \n","              \n","                      [[[19., 13.,  9.],\n","                        [40., 17., 34.],\n","                        [25., 36., 41.]],\n","              \n","                       [[20., 34., 33.],\n","                        [21., 30., 32.],\n","                        [ 5., 29., 27.]],\n","              \n","                       [[20., 20., 30.],\n","                        [ 4., 29., 29.],\n","                        [ 0., 18., 26.]],\n","              \n","                       ...,\n","              \n","                       [[21., 22., 27.],\n","                        [20., 30., 37.],\n","                        [18., 22., 28.]],\n","              \n","                       [[26., 36., 19.],\n","                        [13., 26., 33.],\n","                        [ 9., 31., 12.]],\n","              \n","                       [[ 5., 17., 12.],\n","                        [19., 29., 10.],\n","                        [32., 35., 13.]]],\n","              \n","              \n","                      [[[31., 31., 31.],\n","                        [31., 31., 31.],\n","                        [31., 31., 31.]],\n","              \n","                       [[46., 34., 34.],\n","                        [31., 25., 24.],\n","                        [28., 20., 20.]],\n","              \n","                       [[19., 17., 27.],\n","                        [24., 22., 29.],\n","                        [29., 34., 36.]],\n","              \n","                       ...,\n","              \n","                       [[40., 37., 48.],\n","                        [34., 37., 56.],\n","                        [31., 33., 45.]],\n","              \n","                       [[31., 31., 31.],\n","                        [31., 31., 31.],\n","                        [31., 31., 31.]],\n","              \n","                       [[31., 29., 38.],\n","                        [26., 24., 37.],\n","                        [25., 26., 44.]]],\n","              \n","              \n","                      [[[38., 38., 38.],\n","                        [38., 38., 38.],\n","                        [38., 38., 38.]],\n","              \n","                       [[32., 25., 22.],\n","                        [31., 24., 20.],\n","                        [39., 34., 30.]],\n","              \n","                       [[43., 49., 44.],\n","                        [52., 57., 52.],\n","                        [49., 47., 43.]],\n","              \n","                       ...,\n","              \n","                       [[42., 36., 20.],\n","                        [57., 47., 16.],\n","                        [55., 44., 11.]],\n","              \n","                       [[38., 38., 38.],\n","                        [38., 38., 38.],\n","                        [38., 38., 38.]],\n","              \n","                       [[37., 45., 39.],\n","                        [37., 41., 31.],\n","                        [40., 40., 28.]]]], device='cuda:0')),\n","             ('module.layer1.0.conv2.wrapped_module.bias',\n","              tensor([   777.,  -3706.,   -399.,  30830.,  -1822.,   2014.,   3828., -61221.,\n","                       -1290.,  -1913.,  -5158.,   3221.,    283., -30530.,   3338.,   5448.],\n","                     device='cuda:0')),\n","             ('module.layer1.0.relu2.num_forwards',\n","              tensor([40], device='cuda:0')),\n","             ('module.layer1.0.relu2.force_readjust',\n","              tensor(False, device='cuda:0')),\n","             ('module.layer1.0.relu2.output_scale',\n","              tensor([10.3858], device='cuda:0')),\n","             ('module.layer1.0.relu2.output_zero_point',\n","              tensor([0.], device='cuda:0')),\n","             ('module.layer1.0.residual_eltwiseadd.num_forwards',\n","              tensor([40], device='cuda:0')),\n","             ('module.layer1.0.residual_eltwiseadd.force_readjust',\n","              tensor(False, device='cuda:0')),\n","             ('module.layer1.0.residual_eltwiseadd.output_scale',\n","              tensor([10.3858], device='cuda:0')),\n","             ('module.layer1.0.residual_eltwiseadd.output_zero_point',\n","              tensor([0.], device='cuda:0')),\n","             ('module.layer1.1.conv1.num_forwards',\n","              tensor([40], device='cuda:0')),\n","             ('module.layer1.1.conv1.force_readjust',\n","              tensor(False, device='cuda:0')),\n","             ('module.layer1.1.conv1.output_scale',\n","              tensor([19.3049], device='cuda:0')),\n","             ('module.layer1.1.conv1.output_zero_point',\n","              tensor([0.], device='cuda:0')),\n","             ('module.layer1.1.conv1.w_scale', tensor([[[[2.1127e+02]]],\n","              \n","              \n","                      [[[2.2143e+02]]],\n","              \n","              \n","                      [[[3.0730e+02]]],\n","              \n","              \n","                      [[[1.0991e+03]]],\n","              \n","              \n","                      [[[1.9090e+02]]],\n","              \n","              \n","                      [[[4.2324e+02]]],\n","              \n","              \n","                      [[[2.5499e+02]]],\n","              \n","              \n","                      [[[2.1518e+02]]],\n","              \n","              \n","                      [[[1.6145e+02]]],\n","              \n","              \n","                      [[[7.6339e+01]]],\n","              \n","              \n","                      [[[3.0464e+02]]],\n","              \n","              \n","                      [[[3.6119e+06]]],\n","              \n","              \n","                      [[[1.1560e+03]]],\n","              \n","              \n","                      [[[1.3032e+06]]],\n","              \n","              \n","                      [[[1.2579e+02]]],\n","              \n","              \n","                      [[[3.4070e+02]]]], device='cuda:0')),\n","             ('module.layer1.1.conv1.w_zero_point', tensor([[[[-33.]]],\n","              \n","              \n","                      [[[-22.]]],\n","              \n","              \n","                      [[[-22.]]],\n","              \n","              \n","                      [[[-28.]]],\n","              \n","              \n","                      [[[-28.]]],\n","              \n","              \n","                      [[[-27.]]],\n","              \n","              \n","                      [[[-28.]]],\n","              \n","              \n","                      [[[-27.]]],\n","              \n","              \n","                      [[[-31.]]],\n","              \n","              \n","                      [[[-42.]]],\n","              \n","              \n","                      [[[-23.]]],\n","              \n","              \n","                      [[[-26.]]],\n","              \n","              \n","                      [[[-40.]]],\n","              \n","              \n","                      [[[-34.]]],\n","              \n","              \n","                      [[[-19.]]],\n","              \n","              \n","                      [[[-39.]]]], device='cuda:0')),\n","             ('module.layer1.1.conv1.fp_bias',\n","              tensor([ 1.2476e+00, -4.3928e-01, -1.5150e+00, -4.3638e-01,  3.9016e-01,\n","                      -4.0804e-01,  3.5084e-02, -7.0724e-01,  4.2889e-01,  1.6761e+00,\n","                      -4.9018e-01, -7.7723e-04,  6.2775e-01, -8.6198e-04,  1.0671e+00,\n","                       7.8780e-01], device='cuda:0')),\n","             ('module.layer1.1.conv1.accum_scale', tensor([[[2.1942e+03]],\n","              \n","                      [[2.2997e+03]],\n","              \n","                      [[3.1916e+03]],\n","              \n","                      [[1.1415e+04]],\n","              \n","                      [[1.9826e+03]],\n","              \n","                      [[4.3957e+03]],\n","              \n","                      [[2.6483e+03]],\n","              \n","                      [[2.2348e+03]],\n","              \n","                      [[1.6768e+03]],\n","              \n","                      [[7.9284e+02]],\n","              \n","                      [[3.1640e+03]],\n","              \n","                      [[3.7513e+07]],\n","              \n","                      [[1.2006e+04]],\n","              \n","                      [[1.3535e+07]],\n","              \n","                      [[1.3064e+03]],\n","              \n","                      [[3.5385e+03]]], device='cuda:0')),\n","             ('module.layer1.1.conv1.is_simulated_quant_weight_shifted',\n","              tensor(False, device='cuda:0')),\n","             ('module.layer1.1.conv1.wrapped_module.weight',\n","              tensor([[[[34., 28., 18.],\n","                        [47., 29.,  6.],\n","                        [39., 22.,  6.]],\n","              \n","                       [[30., 31., 32.],\n","                        [27., 29., 31.],\n","                        [26., 28., 30.]],\n","              \n","                       [[34., 37., 38.],\n","                        [38., 36., 34.],\n","                        [32., 24., 26.]],\n","              \n","                       ...,\n","              \n","                       [[33., 33., 33.],\n","                        [33., 33., 33.],\n","                        [33., 33., 33.]],\n","              \n","                       [[30., 27., 26.],\n","                        [33., 28., 25.],\n","                        [39., 36., 33.]],\n","              \n","                       [[32., 30., 31.],\n","                        [31., 30., 33.],\n","                        [34., 32., 33.]]],\n","              \n","              \n","                      [[[ 2., 21., 37.],\n","                        [12., 46., 63.],\n","                        [10., 39., 46.]],\n","              \n","                       [[29., 23., 19.],\n","                        [31., 24., 21.],\n","                        [29., 24., 21.]],\n","              \n","                       [[29., 21., 11.],\n","                        [35., 31., 21.],\n","                        [41., 44., 33.]],\n","              \n","                       ...,\n","              \n","                       [[22., 22., 22.],\n","                        [22., 22., 22.],\n","                        [22., 22., 22.]],\n","              \n","                       [[34., 36., 34.],\n","                        [33., 35., 33.],\n","                        [31., 32., 32.]],\n","              \n","                       [[22., 23., 24.],\n","                        [19., 19., 21.],\n","                        [22., 21., 23.]]],\n","              \n","              \n","                      [[[49., 54., 58.],\n","                        [35., 45., 54.],\n","                        [19., 30., 42.]],\n","              \n","                       [[22., 23., 20.],\n","                        [25., 25., 23.],\n","                        [26., 26., 24.]],\n","              \n","                       [[15., 13.,  8.],\n","                        [22., 22., 20.],\n","                        [28., 31., 29.]],\n","              \n","                       ...,\n","              \n","                       [[22., 22., 22.],\n","                        [22., 22., 22.],\n","                        [22., 22., 22.]],\n","              \n","                       [[39., 39., 33.],\n","                        [30., 32., 26.],\n","                        [20., 20., 14.]],\n","              \n","                       [[27., 24., 24.],\n","                        [27., 26., 27.],\n","                        [26., 24., 23.]]],\n","              \n","              \n","                      ...,\n","              \n","              \n","                      [[[29., 11., 13.],\n","                        [26., 15., 15.],\n","                        [31., 20., 11.]],\n","              \n","                       [[17.,  1., 11.],\n","                        [29., 14., 13.],\n","                        [27.,  9., 25.]],\n","              \n","                       [[28., 36., 14.],\n","                        [27., 20., 11.],\n","                        [35., 25., 13.]],\n","              \n","                       ...,\n","              \n","                       [[62., 63., 57.],\n","                        [42., 39., 48.],\n","                        [33., 49., 37.]],\n","              \n","                       [[35., 30., 18.],\n","                        [14., 14., 22.],\n","                        [19., 18., 24.]],\n","              \n","                       [[31., 26., 40.],\n","                        [44., 27., 30.],\n","                        [24., 22., 30.]]],\n","              \n","              \n","                      [[[24., 22., 24.],\n","                        [11., 11., 16.],\n","                        [ 8., 18., 22.]],\n","              \n","                       [[18., 20., 18.],\n","                        [19., 21., 19.],\n","                        [18., 20., 19.]],\n","              \n","                       [[20., 18., 15.],\n","                        [22., 20., 17.],\n","                        [17., 18., 17.]],\n","              \n","                       ...,\n","              \n","                       [[19., 19., 19.],\n","                        [19., 19., 19.],\n","                        [19., 19., 19.]],\n","              \n","                       [[20., 23., 22.],\n","                        [21., 27., 27.],\n","                        [22., 25., 26.]],\n","              \n","                       [[20., 21., 22.],\n","                        [19., 20., 22.],\n","                        [22., 21., 21.]]],\n","              \n","              \n","                      [[[46., 33., 30.],\n","                        [40., 27., 30.],\n","                        [21., 21., 35.]],\n","              \n","                       [[41., 42., 40.],\n","                        [40., 40., 38.],\n","                        [39., 40., 38.]],\n","              \n","                       [[44., 41., 35.],\n","                        [50., 45., 36.],\n","                        [47., 40., 32.]],\n","              \n","                       ...,\n","              \n","                       [[39., 39., 39.],\n","                        [39., 39., 39.],\n","                        [39., 39., 39.]],\n","              \n","                       [[34., 39., 44.],\n","                        [41., 46., 51.],\n","                        [45., 50., 53.]],\n","              \n","                       [[34., 37., 39.],\n","                        [38., 36., 38.],\n","                        [39., 36., 37.]]]], device='cuda:0')),\n","             ('module.layer1.1.conv1.wrapped_module.bias',\n","              tensor([  2737.,  -1010.,  -4835.,  -4981.,    774.,  -1794.,     93.,  -1581.,\n","                         719.,   1329.,  -1551., -29156.,   7537., -11667.,   1394.,   2788.],\n","                     device='cuda:0')),\n","             ('module.layer1.1.conv2.num_forwards',\n","              tensor([40], device='cuda:0')),\n","             ('module.layer1.1.conv2.force_readjust',\n","              tensor(False, device='cuda:0')),\n","             ('module.layer1.1.conv2.output_scale',\n","              tensor([7.1207], device='cuda:0')),\n","             ('module.layer1.1.conv2.output_zero_point',\n","              tensor([-33.], device='cuda:0')),\n","             ('module.layer1.1.conv2.w_scale', tensor([[[[1.0758e+02]]],\n","              \n","              \n","                      [[[1.7270e+03]]],\n","              \n","              \n","                      [[[3.1226e+02]]],\n","              \n","              \n","                      [[[1.8296e+02]]],\n","              \n","              \n","                      [[[2.2703e+02]]],\n","              \n","              \n","                      [[[1.7079e+02]]],\n","              \n","              \n","                      [[[5.2061e+01]]],\n","              \n","              \n","                      [[[4.0561e+05]]],\n","              \n","              \n","                      [[[1.4810e+02]]],\n","              \n","              \n","                      [[[9.0726e+01]]],\n","              \n","              \n","                      [[[1.1029e+04]]],\n","              \n","              \n","                      [[[2.8988e+02]]],\n","              \n","              \n","                      [[[1.9858e+02]]],\n","              \n","              \n","                      [[[6.8036e+05]]],\n","              \n","              \n","                      [[[5.3586e+01]]],\n","              \n","              \n","                      [[[1.8826e+02]]]], device='cuda:0')),\n","             ('module.layer1.1.conv2.w_zero_point', tensor([[[[-26.]]],\n","              \n","              \n","                      [[[-26.]]],\n","              \n","              \n","                      [[[-32.]]],\n","              \n","              \n","                      [[[-48.]]],\n","              \n","              \n","                      [[[-24.]]],\n","              \n","              \n","                      [[[-33.]]],\n","              \n","              \n","                      [[[-32.]]],\n","              \n","              \n","                      [[[-21.]]],\n","              \n","              \n","                      [[[-27.]]],\n","              \n","              \n","                      [[[-39.]]],\n","              \n","              \n","                      [[[-30.]]],\n","              \n","              \n","                      [[[-36.]]],\n","              \n","              \n","                      [[[-25.]]],\n","              \n","              \n","                      [[[-30.]]],\n","              \n","              \n","                      [[[-35.]]],\n","              \n","              \n","                      [[[-36.]]]], device='cuda:0')),\n","             ('module.layer1.1.conv2.fp_bias',\n","              tensor([-0.5288, -0.2127, -0.1348,  0.5942, -0.4085,  0.1393,  0.8161, -0.0033,\n","                       0.4911,  0.8536, -0.0766,  0.4875, -0.1539, -0.0015,  1.0717,  0.8257],\n","                     device='cuda:0')),\n","             ('module.layer1.1.conv2.accum_scale', tensor([[[2.0769e+03]],\n","              \n","                      [[3.3340e+04]],\n","              \n","                      [[6.0282e+03]],\n","              \n","                      [[3.5321e+03]],\n","              \n","                      [[4.3828e+03]],\n","              \n","                      [[3.2970e+03]],\n","              \n","                      [[1.0050e+03]],\n","              \n","                      [[7.8303e+06]],\n","              \n","                      [[2.8590e+03]],\n","              \n","                      [[1.7515e+03]],\n","              \n","                      [[2.1292e+05]],\n","              \n","                      [[5.5960e+03]],\n","              \n","                      [[3.8336e+03]],\n","              \n","                      [[1.3134e+07]],\n","              \n","                      [[1.0345e+03]],\n","              \n","                      [[3.6344e+03]]], device='cuda:0')),\n","             ('module.layer1.1.conv2.is_simulated_quant_weight_shifted',\n","              tensor(False, device='cuda:0')),\n","             ('module.layer1.1.conv2.wrapped_module.weight',\n","              tensor([[[[12., 38., 43.],\n","                        [25., 63., 56.],\n","                        [34., 57., 41.]],\n","              \n","                       [[40., 29., 16.],\n","                        [43., 13.,  0.],\n","                        [30.,  4.,  3.]],\n","              \n","                       [[35., 19., 17.],\n","                        [33., 20., 14.],\n","                        [28., 21., 16.]],\n","              \n","                       ...,\n","              \n","                       [[26., 26., 26.],\n","                        [26., 26., 26.],\n","                        [26., 26., 26.]],\n","              \n","                       [[30., 24., 29.],\n","                        [35., 17., 34.],\n","                        [36., 21., 15.]],\n","              \n","                       [[30., 23., 28.],\n","                        [25., 21., 27.],\n","                        [27., 25., 25.]]],\n","              \n","              \n","                      [[[30., 36., 19.],\n","                        [20., 25., 11.],\n","                        [23., 22., 11.]],\n","              \n","                       [[33., 23., 23.],\n","                        [24., 16., 19.],\n","                        [37., 30., 36.]],\n","              \n","                       [[27., 30., 37.],\n","                        [28., 33., 40.],\n","                        [28., 34., 43.]],\n","              \n","                       ...,\n","              \n","                       [[25., 25., 26.],\n","                        [26., 26., 26.],\n","                        [25., 26., 25.]],\n","              \n","                       [[18., 35., 28.],\n","                        [27., 43., 34.],\n","                        [44., 56., 63.]],\n","              \n","                       [[38., 25., 19.],\n","                        [41., 28., 18.],\n","                        [36., 35., 28.]]],\n","              \n","              \n","                      [[[41., 45., 37.],\n","                        [26., 30., 27.],\n","                        [35., 32., 28.]],\n","              \n","                       [[52., 61., 63.],\n","                        [40., 49., 47.],\n","                        [32., 34., 34.]],\n","              \n","                       [[29., 26., 26.],\n","                        [31., 27., 29.],\n","                        [30., 28., 30.]],\n","              \n","                       ...,\n","              \n","                       [[32., 32., 32.],\n","                        [32., 32., 32.],\n","                        [32., 32., 32.]],\n","              \n","                       [[53., 44., 48.],\n","                        [40., 31., 10.],\n","                        [36., 39., 27.]],\n","              \n","                       [[20., 27., 31.],\n","                        [23., 23., 22.],\n","                        [27., 33., 25.]]],\n","              \n","              \n","                      ...,\n","              \n","              \n","                      [[[15., 21., 24.],\n","                        [20., 17., 21.],\n","                        [24., 21., 20.]],\n","              \n","                       [[32., 30., 22.],\n","                        [25., 25., 24.],\n","                        [24., 23., 19.]],\n","              \n","                       [[57., 56., 60.],\n","                        [56., 63., 63.],\n","                        [50., 55., 59.]],\n","              \n","                       ...,\n","              \n","                       [[28., 27., 22.],\n","                        [16., 16., 19.],\n","                        [18., 15., 11.]],\n","              \n","                       [[41., 49., 34.],\n","                        [50., 54., 48.],\n","                        [51., 62., 49.]],\n","              \n","                       [[45., 37., 21.],\n","                        [43., 47., 37.],\n","                        [44., 42., 37.]]],\n","              \n","              \n","                      [[[34., 34., 37.],\n","                        [39., 40., 42.],\n","                        [40., 37., 38.]],\n","              \n","                       [[30., 35., 40.],\n","                        [32., 33., 35.],\n","                        [38., 35., 33.]],\n","              \n","                       [[32., 30., 29.],\n","                        [32., 36., 33.],\n","                        [27., 32., 32.]],\n","              \n","                       ...,\n","              \n","                       [[35., 35., 35.],\n","                        [35., 35., 35.],\n","                        [35., 35., 35.]],\n","              \n","                       [[41., 54., 19.],\n","                        [39., 46.,  0.],\n","                        [34., 30., 26.]],\n","              \n","                       [[42., 33., 29.],\n","                        [42., 25., 20.],\n","                        [37., 32., 26.]]],\n","              \n","              \n","                      [[[37., 36., 25.],\n","                        [44., 43., 21.],\n","                        [53., 51., 21.]],\n","              \n","                       [[46., 39., 34.],\n","                        [30., 21., 27.],\n","                        [30., 23., 28.]],\n","              \n","                       [[40., 31., 21.],\n","                        [41., 31., 20.],\n","                        [43., 31., 22.]],\n","              \n","                       ...,\n","              \n","                       [[36., 36., 36.],\n","                        [36., 36., 36.],\n","                        [36., 36., 36.]],\n","              \n","                       [[41., 49., 59.],\n","                        [42., 46., 63.],\n","                        [27., 25., 45.]],\n","              \n","                       [[41., 45., 32.],\n","                        [41., 57., 51.],\n","                        [33., 48., 43.]]]], device='cuda:0')),\n","             ('module.layer1.1.conv2.wrapped_module.bias',\n","              tensor([ -1098.,  -7090.,   -813.,   2099.,  -1790.,    459.,    820., -25568.,\n","                        1404.,   1495., -16319.,   2728.,   -590., -19384.,   1109.,   3001.],\n","                     device='cuda:0')),\n","             ('module.layer1.1.relu2.num_forwards',\n","              tensor([40], device='cuda:0')),\n","             ('module.layer1.1.relu2.force_readjust',\n","              tensor(False, device='cuda:0')),\n","             ('module.layer1.1.relu2.output_scale',\n","              tensor([7.1860], device='cuda:0')),\n","             ('module.layer1.1.relu2.output_zero_point',\n","              tensor([0.], device='cuda:0')),\n","             ('module.layer1.1.residual_eltwiseadd.num_forwards',\n","              tensor([40], device='cuda:0')),\n","             ('module.layer1.1.residual_eltwiseadd.force_readjust',\n","              tensor(False, device='cuda:0')),\n","             ('module.layer1.1.residual_eltwiseadd.output_scale',\n","              tensor([7.1860], device='cuda:0')),\n","             ('module.layer1.1.residual_eltwiseadd.output_zero_point',\n","              tensor([0.], device='cuda:0')),\n","             ('module.layer1.2.conv1.num_forwards',\n","              tensor([40], device='cuda:0')),\n","             ('module.layer1.2.conv1.force_readjust',\n","              tensor(False, device='cuda:0')),\n","             ('module.layer1.2.conv1.output_scale',\n","              tensor([28.1477], device='cuda:0')),\n","             ('module.layer1.2.conv1.output_zero_point',\n","              tensor([0.], device='cuda:0')),\n","             ('module.layer1.2.conv1.w_scale', tensor([[[[2.5775e+02]]],\n","              \n","              \n","                      [[[5.8208e+02]]],\n","              \n","              \n","                      [[[4.8310e+02]]],\n","              \n","              \n","                      [[[9.1351e+05]]],\n","              \n","              \n","                      [[[1.3793e+03]]],\n","              \n","              \n","                      [[[7.1311e+05]]],\n","              \n","              \n","                      [[[2.9178e+03]]],\n","              \n","              \n","                      [[[3.4126e+05]]],\n","              \n","              \n","                      [[[2.1687e+02]]],\n","              \n","              \n","                      [[[4.8863e+02]]],\n","              \n","              \n","                      [[[3.6754e+02]]],\n","              \n","              \n","                      [[[4.3408e+02]]],\n","              \n","              \n","                      [[[7.0983e+02]]],\n","              \n","              \n","                      [[[4.0007e+02]]],\n","              \n","              \n","                      [[[1.9481e+02]]],\n","              \n","              \n","                      [[[4.0499e+02]]]], device='cuda:0')),\n","             ('module.layer1.2.conv1.w_zero_point', tensor([[[[-36.]]],\n","              \n","              \n","                      [[[-41.]]],\n","              \n","              \n","                      [[[-21.]]],\n","              \n","              \n","                      [[[-20.]]],\n","              \n","              \n","                      [[[-36.]]],\n","              \n","              \n","                      [[[-31.]]],\n","              \n","              \n","                      [[[-32.]]],\n","              \n","              \n","                      [[[-34.]]],\n","              \n","              \n","                      [[[-29.]]],\n","              \n","              \n","                      [[[-30.]]],\n","              \n","              \n","                      [[[-27.]]],\n","              \n","              \n","                      [[[-35.]]],\n","              \n","              \n","                      [[[-34.]]],\n","              \n","              \n","                      [[[-30.]]],\n","              \n","              \n","                      [[[-22.]]],\n","              \n","              \n","                      [[[-32.]]]], device='cuda:0')),\n","             ('module.layer1.2.conv1.fp_bias',\n","              tensor([ 1.5662e-01,  9.0454e-01, -1.0476e-01, -3.4575e-03,  1.1974e-01,\n","                      -5.8092e-04,  5.7970e-02, -1.0339e-03,  4.8168e-01,  8.6120e-02,\n","                      -2.1244e-01,  1.7261e-01, -2.3331e-01, -2.6251e-01, -1.5355e-01,\n","                       6.2831e-02], device='cuda:0')),\n","             ('module.layer1.2.conv1.accum_scale', tensor([[[1.8522e+03]],\n","              \n","                      [[4.1828e+03]],\n","              \n","                      [[3.4716e+03]],\n","              \n","                      [[6.5645e+06]],\n","              \n","                      [[9.9119e+03]],\n","              \n","                      [[5.1245e+06]],\n","              \n","                      [[2.0967e+04]],\n","              \n","                      [[2.4523e+06]],\n","              \n","                      [[1.5584e+03]],\n","              \n","                      [[3.5113e+03]],\n","              \n","                      [[2.6412e+03]],\n","              \n","                      [[3.1193e+03]],\n","              \n","                      [[5.1009e+03]],\n","              \n","                      [[2.8749e+03]],\n","              \n","                      [[1.3999e+03]],\n","              \n","                      [[2.9103e+03]]], device='cuda:0')),\n","             ('module.layer1.2.conv1.is_simulated_quant_weight_shifted',\n","              tensor(False, device='cuda:0')),\n","             ('module.layer1.2.conv1.wrapped_module.weight',\n","              tensor([[[[42., 37., 32.],\n","                        [40., 34., 29.],\n","                        [39., 35., 29.]],\n","              \n","                       [[34., 35., 35.],\n","                        [34., 35., 35.],\n","                        [35., 35., 35.]],\n","              \n","                       [[35., 35., 36.],\n","                        [34., 35., 36.],\n","                        [35., 36., 38.]],\n","              \n","                       ...,\n","              \n","                       [[36., 36., 36.],\n","                        [36., 36., 36.],\n","                        [36., 36., 36.]],\n","              \n","                       [[37., 22., 37.],\n","                        [44., 21., 44.],\n","                        [35., 30., 40.]],\n","              \n","                       [[33., 39., 37.],\n","                        [29., 41., 33.],\n","                        [31., 38., 34.]]],\n","              \n","              \n","                      [[[45., 46., 37.],\n","                        [41., 51., 41.],\n","                        [25., 48., 44.]],\n","              \n","                       [[38., 38., 39.],\n","                        [38., 38., 40.],\n","                        [39., 40., 41.]],\n","              \n","                       [[31., 34., 40.],\n","                        [36., 34., 35.],\n","                        [38., 34., 32.]],\n","              \n","                       ...,\n","              \n","                       [[41., 41., 41.],\n","                        [41., 41., 41.],\n","                        [41., 41., 41.]],\n","              \n","                       [[14., 28., 20.],\n","                        [20., 20., 23.],\n","                        [14., 18., 32.]],\n","              \n","                       [[36., 37., 39.],\n","                        [38., 45., 51.],\n","                        [42., 49., 56.]]],\n","              \n","              \n","                      [[[ 8.,  1.,  0.],\n","                        [10.,  8.,  8.],\n","                        [11., 14.,  5.]],\n","              \n","                       [[20., 21., 22.],\n","                        [20., 21., 21.],\n","                        [21., 21., 21.]],\n","              \n","                       [[20., 21., 23.],\n","                        [13., 13., 13.],\n","                        [13., 12., 11.]],\n","              \n","                       ...,\n","              \n","                       [[21., 21., 21.],\n","                        [21., 21., 21.],\n","                        [21., 21., 21.]],\n","              \n","                       [[33., 16., 25.],\n","                        [27.,  7., 29.],\n","                        [ 8., 19., 22.]],\n","              \n","                       [[ 8., 20.,  9.],\n","                        [10., 23., 11.],\n","                        [14., 23., 26.]]],\n","              \n","              \n","                      ...,\n","              \n","              \n","                      [[[35., 39., 53.],\n","                        [39., 28., 32.],\n","                        [16., 12., 24.]],\n","              \n","                       [[30., 31., 31.],\n","                        [30., 31., 31.],\n","                        [31., 33., 33.]],\n","              \n","                       [[32., 33., 31.],\n","                        [24., 27., 28.],\n","                        [22., 28., 29.]],\n","              \n","                       ...,\n","              \n","                       [[30., 30., 30.],\n","                        [30., 30., 30.],\n","                        [30., 30., 30.]],\n","              \n","                       [[37., 35., 35.],\n","                        [41., 37., 35.],\n","                        [43., 43., 40.]],\n","              \n","                       [[29., 38., 36.],\n","                        [36., 42., 39.],\n","                        [24., 22., 18.]]],\n","              \n","              \n","                      [[[18., 25., 24.],\n","                        [18., 22., 21.],\n","                        [17., 22., 21.]],\n","              \n","                       [[21., 21., 21.],\n","                        [21., 21., 21.],\n","                        [22., 22., 21.]],\n","              \n","                       [[19., 22., 24.],\n","                        [19., 20., 20.],\n","                        [19., 20., 18.]],\n","              \n","                       ...,\n","              \n","                       [[22., 22., 22.],\n","                        [22., 22., 22.],\n","                        [22., 22., 22.]],\n","              \n","                       [[19., 25., 26.],\n","                        [30., 23., 22.],\n","                        [19., 15., 24.]],\n","              \n","                       [[17., 26., 23.],\n","                        [20., 27., 26.],\n","                        [24., 26., 27.]]],\n","              \n","              \n","                      [[[34., 39., 35.],\n","                        [40., 31., 25.],\n","                        [33., 23., 25.]],\n","              \n","                       [[32., 33., 33.],\n","                        [33., 33., 34.],\n","                        [33., 33., 32.]],\n","              \n","                       [[31., 34., 35.],\n","                        [32., 35., 37.],\n","                        [33., 35., 37.]],\n","              \n","                       ...,\n","              \n","                       [[32., 32., 32.],\n","                        [32., 32., 32.],\n","                        [32., 32., 32.]],\n","              \n","                       [[33., 36., 27.],\n","                        [39., 17., 18.],\n","                        [28.,  9., 35.]],\n","              \n","                       [[31., 36., 38.],\n","                        [27., 34., 32.],\n","                        [29., 37., 33.]]]], device='cuda:0')),\n","             ('module.layer1.2.conv1.wrapped_module.bias',\n","              tensor([   290.,   3784.,   -364., -22697.,   1187.,  -2977.,   1215.,  -2535.,\n","                         751.,    302.,   -561.,    538.,  -1190.,   -755.,   -215.,    183.],\n","                     device='cuda:0')),\n","             ('module.layer1.2.conv2.num_forwards',\n","              tensor([40], device='cuda:0')),\n","             ('module.layer1.2.conv2.force_readjust',\n","              tensor(False, device='cuda:0')),\n","             ('module.layer1.2.conv2.output_scale',\n","              tensor([12.3374], device='cuda:0')),\n","             ('module.layer1.2.conv2.output_zero_point',\n","              tensor([-36.], device='cuda:0')),\n","             ('module.layer1.2.conv2.w_scale', tensor([[[[1.0564e+02]]],\n","              \n","              \n","                      [[[1.5389e+02]]],\n","              \n","              \n","                      [[[7.8287e+01]]],\n","              \n","              \n","                      [[[2.0190e+02]]],\n","              \n","              \n","                      [[[2.0053e+02]]],\n","              \n","              \n","                      [[[2.3090e+02]]],\n","              \n","              \n","                      [[[1.8355e+02]]],\n","              \n","              \n","                      [[[1.1279e+02]]],\n","              \n","              \n","                      [[[1.2151e+02]]],\n","              \n","              \n","                      [[[8.3326e+02]]],\n","              \n","              \n","                      [[[5.3741e+01]]],\n","              \n","              \n","                      [[[1.0971e+02]]],\n","              \n","              \n","                      [[[2.6374e+02]]],\n","              \n","              \n","                      [[[4.2645e+05]]],\n","              \n","              \n","                      [[[8.2917e+01]]],\n","              \n","              \n","                      [[[2.2834e+02]]]], device='cuda:0')),\n","             ('module.layer1.2.conv2.w_zero_point', tensor([[[[-29.]]],\n","              \n","              \n","                      [[[-25.]]],\n","              \n","              \n","                      [[[-31.]]],\n","              \n","              \n","                      [[[-36.]]],\n","              \n","              \n","                      [[[-21.]]],\n","              \n","              \n","                      [[[-34.]]],\n","              \n","              \n","                      [[[-26.]]],\n","              \n","              \n","                      [[[-37.]]],\n","              \n","              \n","                      [[[-36.]]],\n","              \n","              \n","                      [[[-29.]]],\n","              \n","              \n","                      [[[-42.]]],\n","              \n","              \n","                      [[[-37.]]],\n","              \n","              \n","                      [[[-28.]]],\n","              \n","              \n","                      [[[-23.]]],\n","              \n","              \n","                      [[[-30.]]],\n","              \n","              \n","                      [[[-34.]]]], device='cuda:0')),\n","             ('module.layer1.2.conv2.fp_bias',\n","              tensor([-0.4849, -0.4158, -0.5719,  0.1680, -0.2105,  0.0181, -0.1813,  0.4380,\n","                       0.7847,  0.0946,  1.4698,  0.3243,  0.0639, -0.0031, -0.2415,  0.3647],\n","                     device='cuda:0')),\n","             ('module.layer1.2.conv2.accum_scale', tensor([[[2.9737e+03]],\n","              \n","                      [[4.3317e+03]],\n","              \n","                      [[2.2036e+03]],\n","              \n","                      [[5.6829e+03]],\n","              \n","                      [[5.6443e+03]],\n","              \n","                      [[6.4994e+03]],\n","              \n","                      [[5.1666e+03]],\n","              \n","                      [[3.1749e+03]],\n","              \n","                      [[3.4201e+03]],\n","              \n","                      [[2.3454e+04]],\n","              \n","                      [[1.5127e+03]],\n","              \n","                      [[3.0882e+03]],\n","              \n","                      [[7.4237e+03]],\n","              \n","                      [[1.2004e+07]],\n","              \n","                      [[2.3339e+03]],\n","              \n","                      [[6.4272e+03]]], device='cuda:0')),\n","             ('module.layer1.2.conv2.is_simulated_quant_weight_shifted',\n","              tensor(False, device='cuda:0')),\n","             ('module.layer1.2.conv2.wrapped_module.weight',\n","              tensor([[[[16., 37., 16.],\n","                        [33., 29., 31.],\n","                        [32., 21., 40.]],\n","              \n","                       [[36., 29., 25.],\n","                        [36., 25., 23.],\n","                        [26., 19., 18.]],\n","              \n","                       [[30., 25., 22.],\n","                        [32., 20., 24.],\n","                        [30., 25., 38.]],\n","              \n","                       ...,\n","              \n","                       [[15., 35., 62.],\n","                        [ 5., 23., 63.],\n","                        [ 0., 21., 47.]],\n","              \n","                       [[41., 30., 21.],\n","                        [38., 28., 45.],\n","                        [23., 16., 34.]],\n","              \n","                       [[15., 50., 41.],\n","                        [16., 46., 47.],\n","                        [ 8., 40., 50.]]],\n","              \n","              \n","                      [[[35., 48.,  7.],\n","                        [31., 51.,  8.],\n","                        [24., 60.,  1.]],\n","              \n","                       [[21., 26., 23.],\n","                        [41., 38., 33.],\n","                        [21., 27., 23.]],\n","              \n","                       [[19., 45., 26.],\n","                        [22., 40., 15.],\n","                        [33., 37., 18.]],\n","              \n","                       ...,\n","              \n","                       [[31., 28., 30.],\n","                        [27., 31., 22.],\n","                        [33., 32., 24.]],\n","              \n","                       [[27., 40., 16.],\n","                        [40., 63., 45.],\n","                        [27., 53., 26.]],\n","              \n","                       [[42., 36., 10.],\n","                        [33., 34., 25.],\n","                        [ 0., 32., 21.]]],\n","              \n","              \n","                      [[[23., 41., 22.],\n","                        [26., 26., 33.],\n","                        [27., 22., 32.]],\n","              \n","                       [[38., 40., 30.],\n","                        [37., 34., 31.],\n","                        [40., 35., 30.]],\n","              \n","                       [[24., 34., 27.],\n","                        [32., 36., 38.],\n","                        [35., 35., 33.]],\n","              \n","                       ...,\n","              \n","                       [[36., 39., 41.],\n","                        [36., 35., 36.],\n","                        [29., 31., 30.]],\n","              \n","                       [[37., 49., 26.],\n","                        [43., 56., 60.],\n","                        [49., 55., 63.]],\n","              \n","                       [[24., 29., 17.],\n","                        [20., 26., 25.],\n","                        [ 0., 25., 34.]]],\n","              \n","              \n","                      ...,\n","              \n","              \n","                      [[[20., 22., 25.],\n","                        [14., 15., 23.],\n","                        [18., 23., 29.]],\n","              \n","                       [[19., 13., 29.],\n","                        [ 8., 14., 19.],\n","                        [14., 13., 25.]],\n","              \n","                       [[ 6.,  7., 12.],\n","                        [28., 22., 18.],\n","                        [26., 25., 24.]],\n","              \n","                       ...,\n","              \n","                       [[63., 60., 54.],\n","                        [63., 63., 51.],\n","                        [55., 59., 57.]],\n","              \n","                       [[14., 24., 25.],\n","                        [20., 19., 17.],\n","                        [15., 17., 31.]],\n","              \n","                       [[28., 27., 46.],\n","                        [34., 33., 60.],\n","                        [47., 54., 61.]]],\n","              \n","              \n","                      [[[23., 33., 24.],\n","                        [44., 47., 60.],\n","                        [45., 37., 34.]],\n","              \n","                       [[38., 40., 40.],\n","                        [35., 32., 39.],\n","                        [41., 37., 30.]],\n","              \n","                       [[29., 40., 34.],\n","                        [36., 27., 42.],\n","                        [40., 36., 40.]],\n","              \n","                       ...,\n","              \n","                       [[13., 18., 31.],\n","                        [25., 16., 38.],\n","                        [18., 29., 28.]],\n","              \n","                       [[22., 26., 25.],\n","                        [ 0., 14., 43.],\n","                        [21., 25., 39.]],\n","              \n","                       [[34., 35., 40.],\n","                        [22., 48., 62.],\n","                        [17., 63., 46.]]],\n","              \n","              \n","                      [[[27., 25., 34.],\n","                        [ 4., 33., 35.],\n","                        [31., 36., 43.]],\n","              \n","                       [[47., 33., 21.],\n","                        [50., 47., 26.],\n","                        [44., 48., 33.]],\n","              \n","                       [[38., 24., 13.],\n","                        [44., 42., 31.],\n","                        [38., 46., 32.]],\n","              \n","                       ...,\n","              \n","                       [[45., 37., 24.],\n","                        [36., 37., 30.],\n","                        [63., 44., 37.]],\n","              \n","                       [[39.,  0., 15.],\n","                        [53., 31.,  6.],\n","                        [59., 38., 24.]],\n","              \n","                       [[25., 32.,  5.],\n","                        [11.,  4.,  2.],\n","                        [44., 16.,  1.]]]], device='cuda:0')),\n","             ('module.layer1.2.conv2.wrapped_module.bias',\n","              tensor([ -1442.,  -1801.,  -1260.,    955.,  -1188.,    118.,   -937.,   1391.,\n","                        2684.,   2219.,   2223.,   1001.,    474., -36715.,   -564.,   2344.],\n","                     device='cuda:0')),\n","             ('module.layer1.2.relu2.num_forwards',\n","              tensor([40], device='cuda:0')),\n","             ('module.layer1.2.relu2.force_readjust',\n","              tensor(False, device='cuda:0')),\n","             ('module.layer1.2.relu2.output_scale',\n","              tensor([7.1279], device='cuda:0')),\n","             ('module.layer1.2.relu2.output_zero_point',\n","              tensor([0.], device='cuda:0')),\n","             ('module.layer1.2.residual_eltwiseadd.num_forwards',\n","              tensor([40], device='cuda:0')),\n","             ('module.layer1.2.residual_eltwiseadd.force_readjust',\n","              tensor(False, device='cuda:0')),\n","             ('module.layer1.2.residual_eltwiseadd.output_scale',\n","              tensor([7.1279], device='cuda:0')),\n","             ('module.layer1.2.residual_eltwiseadd.output_zero_point',\n","              tensor([0.], device='cuda:0')),\n","             ('module.layer1.3.conv1.num_forwards',\n","              tensor([40], device='cuda:0')),\n","             ('module.layer1.3.conv1.force_readjust',\n","              tensor(False, device='cuda:0')),\n","             ('module.layer1.3.conv1.output_scale',\n","              tensor([44.0769], device='cuda:0')),\n","             ('module.layer1.3.conv1.output_zero_point',\n","              tensor([0.], device='cuda:0')),\n","             ('module.layer1.3.conv1.w_scale', tensor([[[[4.7708e+06]]],\n","              \n","              \n","                      [[[7.9436e+05]]],\n","              \n","              \n","                      [[[5.3535e+02]]],\n","              \n","              \n","                      [[[1.2667e+03]]],\n","              \n","              \n","                      [[[1.0312e+06]]],\n","              \n","              \n","                      [[[4.6027e+02]]],\n","              \n","              \n","                      [[[1.8604e+03]]],\n","              \n","              \n","                      [[[1.0067e+03]]],\n","              \n","              \n","                      [[[4.7853e+02]]],\n","              \n","              \n","                      [[[4.7242e+02]]],\n","              \n","              \n","                      [[[5.6972e+05]]],\n","              \n","              \n","                      [[[7.9633e+03]]],\n","              \n","              \n","                      [[[5.5435e+05]]],\n","              \n","              \n","                      [[[4.0348e+02]]],\n","              \n","              \n","                      [[[4.4850e+02]]],\n","              \n","              \n","                      [[[8.6386e+05]]]], device='cuda:0')),\n","             ('module.layer1.3.conv1.w_zero_point', tensor([[[[-41.]]],\n","              \n","              \n","                      [[[-40.]]],\n","              \n","              \n","                      [[[-26.]]],\n","              \n","              \n","                      [[[-23.]]],\n","              \n","              \n","                      [[[-22.]]],\n","              \n","              \n","                      [[[-22.]]],\n","              \n","              \n","                      [[[-40.]]],\n","              \n","              \n","                      [[[-27.]]],\n","              \n","              \n","                      [[[-32.]]],\n","              \n","              \n","                      [[[-32.]]],\n","              \n","              \n","                      [[[-36.]]],\n","              \n","              \n","                      [[[-33.]]],\n","              \n","              \n","                      [[[-41.]]],\n","              \n","              \n","                      [[[-23.]]],\n","              \n","              \n","                      [[[-35.]]],\n","              \n","              \n","                      [[[-23.]]]], device='cuda:0')),\n","             ('module.layer1.3.conv1.fp_bias',\n","              tensor([-4.5256e-04, -3.4339e-04,  1.0159e-01, -2.6967e-01, -2.1598e-03,\n","                      -1.2630e+00,  1.7931e-01, -2.1908e-01,  3.6326e-01,  6.8814e-01,\n","                      -9.6575e-04,  1.1105e-02, -4.2278e-04, -1.3538e+00,  3.8317e-01,\n","                      -3.3907e-03], device='cuda:0')),\n","             ('module.layer1.3.conv1.accum_scale', tensor([[[3.4006e+07]],\n","              \n","                      [[5.6621e+06]],\n","              \n","                      [[3.8159e+03]],\n","              \n","                      [[9.0292e+03]],\n","              \n","                      [[7.3502e+06]],\n","              \n","                      [[3.2808e+03]],\n","              \n","                      [[1.3261e+04]],\n","              \n","                      [[7.1753e+03]],\n","              \n","                      [[3.4109e+03]],\n","              \n","                      [[3.3674e+03]],\n","              \n","                      [[4.0609e+06]],\n","              \n","                      [[5.6762e+04]],\n","              \n","                      [[3.9513e+06]],\n","              \n","                      [[2.8760e+03]],\n","              \n","                      [[3.1969e+03]],\n","              \n","                      [[6.1575e+06]]], device='cuda:0')),\n","             ('module.layer1.3.conv1.is_simulated_quant_weight_shifted',\n","              tensor(False, device='cuda:0')),\n","             ('module.layer1.3.conv1.wrapped_module.weight',\n","              tensor([[[[44., 54., 45.],\n","                        [45., 43., 50.],\n","                        [43., 43., 49.]],\n","              \n","                       [[34., 30., 33.],\n","                        [28., 43., 45.],\n","                        [27., 35., 34.]],\n","              \n","                       [[50., 50., 52.],\n","                        [48., 53., 52.],\n","                        [63., 53., 49.]],\n","              \n","                       ...,\n","              \n","                       [[18., 18., 39.],\n","                        [26., 18., 43.],\n","                        [25., 29., 39.]],\n","              \n","                       [[44., 55., 43.],\n","                        [54., 48., 47.],\n","                        [42., 38., 42.]],\n","              \n","                       [[19., 27., 20.],\n","                        [12., 15., 14.],\n","                        [12., 20., 19.]]],\n","              \n","              \n","                      [[[39., 31., 39.],\n","                        [38., 33., 44.],\n","                        [34., 41., 41.]],\n","              \n","                       [[31., 26., 24.],\n","                        [38., 33., 45.],\n","                        [57., 38., 43.]],\n","              \n","                       [[30., 34., 39.],\n","                        [31., 19., 34.],\n","                        [47., 36., 46.]],\n","              \n","                       ...,\n","              \n","                       [[44., 39., 40.],\n","                        [22., 26., 23.],\n","                        [22., 28., 15.]],\n","              \n","                       [[47., 61., 59.],\n","                        [37., 58., 50.],\n","                        [22., 42., 38.]],\n","              \n","                       [[16., 24., 21.],\n","                        [15., 27.,  8.],\n","                        [ 0., 29.,  5.]]],\n","              \n","              \n","                      [[[27., 35., 35.],\n","                        [24., 30., 24.],\n","                        [14., 19., 19.]],\n","              \n","                       [[26., 27., 27.],\n","                        [25., 27., 26.],\n","                        [26., 28., 28.]],\n","              \n","                       [[22., 21., 24.],\n","                        [23., 23., 27.],\n","                        [23., 25., 29.]],\n","              \n","                       ...,\n","              \n","                       [[26., 26., 26.],\n","                        [26., 26., 26.],\n","                        [26., 26., 26.]],\n","              \n","                       [[29., 16., 20.],\n","                        [ 8., 17., 24.],\n","                        [14., 20., 21.]],\n","              \n","                       [[24., 23., 21.],\n","                        [38., 31., 26.],\n","                        [27., 18., 13.]]],\n","              \n","              \n","                      ...,\n","              \n","              \n","                      [[[24., 29., 31.],\n","                        [21., 25., 28.],\n","                        [26., 31., 35.]],\n","              \n","                       [[24., 27., 28.],\n","                        [25., 28., 28.],\n","                        [29., 31., 31.]],\n","              \n","                       [[30., 34., 35.],\n","                        [30., 32., 33.],\n","                        [36., 38., 40.]],\n","              \n","                       ...,\n","              \n","                       [[23., 23., 23.],\n","                        [23., 23., 23.],\n","                        [23., 23., 23.]],\n","              \n","                       [[13.,  4.,  8.],\n","                        [ 9.,  3., 12.],\n","                        [18., 21., 27.]],\n","              \n","                       [[23., 23., 28.],\n","                        [20., 22., 24.],\n","                        [23., 24., 24.]]],\n","              \n","              \n","                      [[[34., 31., 35.],\n","                        [34., 31., 32.],\n","                        [32., 29., 39.]],\n","              \n","                       [[35., 36., 33.],\n","                        [36., 37., 33.],\n","                        [36., 37., 35.]],\n","              \n","                       [[38., 35., 37.],\n","                        [37., 32., 33.],\n","                        [35., 32., 32.]],\n","              \n","                       ...,\n","              \n","                       [[35., 35., 35.],\n","                        [35., 35., 35.],\n","                        [35., 35., 35.]],\n","              \n","                       [[31., 35., 41.],\n","                        [12., 31., 39.],\n","                        [19., 31., 30.]],\n","              \n","                       [[33., 27., 32.],\n","                        [35., 28., 37.],\n","                        [31., 28., 40.]]],\n","              \n","              \n","                      [[[28., 31., 30.],\n","                        [21., 27., 30.],\n","                        [11., 20., 18.]],\n","              \n","                       [[29., 39., 53.],\n","                        [32., 43., 48.],\n","                        [41., 43., 51.]],\n","              \n","                       [[27., 24., 20.],\n","                        [22., 28., 16.],\n","                        [28., 25., 16.]],\n","              \n","                       ...,\n","              \n","                       [[36., 38., 34.],\n","                        [41., 29., 33.],\n","                        [37., 41., 28.]],\n","              \n","                       [[20., 24., 20.],\n","                        [13., 20., 24.],\n","                        [13., 23., 23.]],\n","              \n","                       [[55., 55., 48.],\n","                        [50., 50., 35.],\n","                        [60., 51., 35.]]]], device='cuda:0')),\n","             ('module.layer1.3.conv1.wrapped_module.bias',\n","              tensor([-15390.,  -1944.,    388.,  -2435., -15875.,  -4144.,   2378.,  -1572.,\n","                        1239.,   2317.,  -3922.,    630.,  -1671.,  -3893.,   1225., -20879.],\n","                     device='cuda:0')),\n","             ('module.layer1.3.conv2.num_forwards',\n","              tensor([40], device='cuda:0')),\n","             ('module.layer1.3.conv2.force_readjust',\n","              tensor(False, device='cuda:0')),\n","             ('module.layer1.3.conv2.output_scale',\n","              tensor([17.3173], device='cuda:0')),\n","             ('module.layer1.3.conv2.output_zero_point',\n","              tensor([-35.], device='cuda:0')),\n","             ('module.layer1.3.conv2.w_scale', tensor([[[[ 103.7770]]],\n","              \n","              \n","                      [[[ 374.4550]]],\n","              \n","              \n","                      [[[ 413.1720]]],\n","              \n","              \n","                      [[[ 232.5848]]],\n","              \n","              \n","                      [[[ 456.0291]]],\n","              \n","              \n","                      [[[ 482.4908]]],\n","              \n","              \n","                      [[[ 837.8493]]],\n","              \n","              \n","                      [[[ 152.1751]]],\n","              \n","              \n","                      [[[1401.8989]]],\n","              \n","              \n","                      [[[  95.2389]]],\n","              \n","              \n","                      [[[ 223.1034]]],\n","              \n","              \n","                      [[[ 621.6130]]],\n","              \n","              \n","                      [[[ 335.1241]]],\n","              \n","              \n","                      [[[  56.1434]]],\n","              \n","              \n","                      [[[ 339.0035]]],\n","              \n","              \n","                      [[[ 151.0315]]]], device='cuda:0')),\n","             ('module.layer1.3.conv2.w_zero_point', tensor([[[[-27.]]],\n","              \n","              \n","                      [[[-30.]]],\n","              \n","              \n","                      [[[-22.]]],\n","              \n","              \n","                      [[[-41.]]],\n","              \n","              \n","                      [[[-23.]]],\n","              \n","              \n","                      [[[-30.]]],\n","              \n","              \n","                      [[[-43.]]],\n","              \n","              \n","                      [[[-38.]]],\n","              \n","              \n","                      [[[-41.]]],\n","              \n","              \n","                      [[[-24.]]],\n","              \n","              \n","                      [[[-36.]]],\n","              \n","              \n","                      [[[-34.]]],\n","              \n","              \n","                      [[[-32.]]],\n","              \n","              \n","                      [[[-26.]]],\n","              \n","              \n","                      [[[-41.]]],\n","              \n","              \n","                      [[[-36.]]]], device='cuda:0')),\n","             ('module.layer1.3.conv2.fp_bias',\n","              tensor([-0.1534, -0.1410, -0.3128,  0.1994, -0.2188,  0.1751,  0.1624,  0.3793,\n","                       0.0586,  0.2881,  0.0968,  0.1546,  0.0568,  0.7840,  0.1181,  0.2540],\n","                     device='cuda:0')),\n","             ('module.layer1.3.conv2.accum_scale', tensor([[[ 4574.1704]],\n","              \n","                      [[16504.8164]],\n","              \n","                      [[18211.3438]],\n","              \n","                      [[10251.6191]],\n","              \n","                      [[20100.3496]],\n","              \n","                      [[21266.6992]],\n","              \n","                      [[36929.8047]],\n","              \n","                      [[ 6707.4077]],\n","              \n","                      [[61791.3633]],\n","              \n","                      [[ 4197.8340]],\n","              \n","                      [[ 9833.7090]],\n","              \n","                      [[27398.7754]],\n","              \n","                      [[14771.2354]],\n","              \n","                      [[ 2474.6282]],\n","              \n","                      [[14942.2256]],\n","              \n","                      [[ 6657.0029]]], device='cuda:0')),\n","             ('module.layer1.3.conv2.is_simulated_quant_weight_shifted',\n","              tensor(False, device='cuda:0')),\n","             ('module.layer1.3.conv2.wrapped_module.weight',\n","              tensor([[[[27., 27., 27.],\n","                        [27., 27., 27.],\n","                        [27., 27., 27.]],\n","              \n","                       [[27., 27., 27.],\n","                        [27., 27., 27.],\n","                        [27., 27., 27.]],\n","              \n","                       [[24.,  9.,  9.],\n","                        [33.,  4.,  8.],\n","                        [46., 12., 12.]],\n","              \n","                       ...,\n","              \n","                       [[ 9., 16., 27.],\n","                        [25., 21., 26.],\n","                        [29., 26., 33.]],\n","              \n","                       [[31., 33., 10.],\n","                        [16., 20.,  0.],\n","                        [18., 26.,  2.]],\n","              \n","                       [[27., 27., 27.],\n","                        [27., 27., 27.],\n","                        [27., 27., 27.]]],\n","              \n","              \n","                      [[[30., 30., 30.],\n","                        [30., 30., 30.],\n","                        [30., 30., 29.]],\n","              \n","                       [[30., 30., 30.],\n","                        [30., 29., 30.],\n","                        [30., 30., 29.]],\n","              \n","                       [[27., 22., 20.],\n","                        [29., 24., 22.],\n","                        [33., 32., 31.]],\n","              \n","                       ...,\n","              \n","                       [[32., 37., 38.],\n","                        [13., 17., 25.],\n","                        [33., 37., 47.]],\n","              \n","                       [[ 0., 26., 29.],\n","                        [19., 37., 33.],\n","                        [13., 40., 58.]],\n","              \n","                       [[30., 30., 30.],\n","                        [30., 30., 30.],\n","                        [30., 29., 29.]]],\n","              \n","              \n","                      [[[21., 22., 22.],\n","                        [22., 22., 22.],\n","                        [22., 22., 22.]],\n","              \n","                       [[22., 21., 21.],\n","                        [22., 22., 22.],\n","                        [22., 22., 22.]],\n","              \n","                       [[18., 19.,  2.],\n","                        [24., 27.,  5.],\n","                        [22., 29., 15.]],\n","              \n","                       ...,\n","              \n","                       [[38., 42., 43.],\n","                        [10., 15., 21.],\n","                        [10., 10., 22.]],\n","              \n","                       [[ 4.,  1., 43.],\n","                        [34., 18.,  3.],\n","                        [38., 33.,  6.]],\n","              \n","                       [[21., 22., 22.],\n","                        [22., 21., 22.],\n","                        [22., 22., 22.]]],\n","              \n","              \n","                      ...,\n","              \n","              \n","                      [[[26., 26., 26.],\n","                        [26., 26., 26.],\n","                        [26., 26., 26.]],\n","              \n","                       [[26., 26., 26.],\n","                        [26., 26., 26.],\n","                        [26., 26., 26.]],\n","              \n","                       [[26., 31., 35.],\n","                        [15., 23., 26.],\n","                        [12., 17., 18.]],\n","              \n","                       ...,\n","              \n","                       [[21., 20., 23.],\n","                        [18., 17., 19.],\n","                        [26., 20., 15.]],\n","              \n","                       [[ 0., 14., 10.],\n","                        [13., 18., 20.],\n","                        [30., 32., 23.]],\n","              \n","                       [[26., 26., 26.],\n","                        [26., 26., 26.],\n","                        [26., 26., 26.]]],\n","              \n","              \n","                      [[[41., 41., 41.],\n","                        [41., 41., 41.],\n","                        [41., 41., 41.]],\n","              \n","                       [[41., 41., 41.],\n","                        [41., 41., 41.],\n","                        [41., 41., 41.]],\n","              \n","                       [[47., 42., 45.],\n","                        [53., 36., 39.],\n","                        [40., 35., 37.]],\n","              \n","                       ...,\n","              \n","                       [[42., 31., 25.],\n","                        [48., 36., 29.],\n","                        [50., 38., 35.]],\n","              \n","                       [[46., 48., 31.],\n","                        [54., 51.,  0.],\n","                        [51., 58., 23.]],\n","              \n","                       [[41., 41., 41.],\n","                        [41., 41., 41.],\n","                        [41., 41., 41.]]],\n","              \n","              \n","                      [[[37., 36., 36.],\n","                        [37., 36., 36.],\n","                        [36., 36., 36.]],\n","              \n","                       [[37., 37., 37.],\n","                        [37., 37., 37.],\n","                        [37., 37., 37.]],\n","              \n","                       [[41., 41., 43.],\n","                        [35., 49., 49.],\n","                        [37., 45., 50.]],\n","              \n","                       ...,\n","              \n","                       [[30., 44., 38.],\n","                        [41., 43., 45.],\n","                        [37., 38., 45.]],\n","              \n","                       [[54., 57., 25.],\n","                        [43., 47., 58.],\n","                        [35., 36., 56.]],\n","              \n","                       [[36., 36., 36.],\n","                        [36., 36., 36.],\n","                        [36., 36., 36.]]]], device='cuda:0')),\n","             ('module.layer1.3.conv2.wrapped_module.bias',\n","              tensor([ -702., -2327., -5697.,  2044., -4398.,  3724.,  5997.,  2544.,  3622.,\n","                       1209.,   952.,  4235.,   839.,  1940.,  1765.,  1691.],\n","                     device='cuda:0')),\n","             ('module.layer1.3.relu2.num_forwards',\n","              tensor([40], device='cuda:0')),\n","             ('module.layer1.3.relu2.force_readjust',\n","              tensor(False, device='cuda:0')),\n","             ('module.layer1.3.relu2.output_scale',\n","              tensor([7.0363], device='cuda:0')),\n","             ('module.layer1.3.relu2.output_zero_point',\n","              tensor([0.], device='cuda:0')),\n","             ('module.layer1.3.residual_eltwiseadd.num_forwards',\n","              tensor([40], device='cuda:0')),\n","             ('module.layer1.3.residual_eltwiseadd.force_readjust',\n","              tensor(False, device='cuda:0')),\n","             ('module.layer1.3.residual_eltwiseadd.output_scale',\n","              tensor([7.0363], device='cuda:0')),\n","             ('module.layer1.3.residual_eltwiseadd.output_zero_point',\n","              tensor([0.], device='cuda:0')),\n","             ('module.layer1.4.conv1.num_forwards',\n","              tensor([40], device='cuda:0')),\n","             ('module.layer1.4.conv1.force_readjust',\n","              tensor(False, device='cuda:0')),\n","             ('module.layer1.4.conv1.output_scale',\n","              tensor([62.6261], device='cuda:0')),\n","             ('module.layer1.4.conv1.output_zero_point',\n","              tensor([0.], device='cuda:0')),\n","             ('module.layer1.4.conv1.w_scale', tensor([[[[   749.3959]]],\n","              \n","              \n","                      [[[   782.0984]]],\n","              \n","              \n","                      [[[  3358.0564]]],\n","              \n","              \n","                      [[[127966.2969]]],\n","              \n","              \n","                      [[[   624.3129]]],\n","              \n","              \n","                      [[[  5906.7358]]],\n","              \n","              \n","                      [[[   461.7435]]],\n","              \n","              \n","                      [[[   937.2846]]],\n","              \n","              \n","                      [[[   531.5295]]],\n","              \n","              \n","                      [[[   613.9966]]],\n","              \n","              \n","                      [[[  1130.6847]]],\n","              \n","              \n","                      [[[   334.8650]]],\n","              \n","              \n","                      [[[  8540.7588]]],\n","              \n","              \n","                      [[[   472.0684]]],\n","              \n","              \n","                      [[[   792.8665]]],\n","              \n","              \n","                      [[[ 16249.7148]]]], device='cuda:0')),\n","             ('module.layer1.4.conv1.w_zero_point', tensor([[[[-25.]]],\n","              \n","              \n","                      [[[-26.]]],\n","              \n","              \n","                      [[[-32.]]],\n","              \n","              \n","                      [[[-19.]]],\n","              \n","              \n","                      [[[-30.]]],\n","              \n","              \n","                      [[[-26.]]],\n","              \n","              \n","                      [[[-33.]]],\n","              \n","              \n","                      [[[-31.]]],\n","              \n","              \n","                      [[[-30.]]],\n","              \n","              \n","                      [[[-38.]]],\n","              \n","              \n","                      [[[-33.]]],\n","              \n","              \n","                      [[[-22.]]],\n","              \n","              \n","                      [[[-39.]]],\n","              \n","              \n","                      [[[-46.]]],\n","              \n","              \n","                      [[[-33.]]],\n","              \n","              \n","                      [[[-34.]]]], device='cuda:0')),\n","             ('module.layer1.4.conv1.fp_bias',\n","              tensor([-0.7734, -0.2687, -0.1228, -0.0209, -0.7211,  0.0539, -0.6993, -0.6185,\n","                      -0.3982,  0.2551,  0.1397, -1.2107, -0.1246,  0.2174,  0.2743, -0.0374],\n","                     device='cuda:0')),\n","             ('module.layer1.4.conv1.accum_scale', tensor([[[  5272.9834]],\n","              \n","                      [[  5503.0894]],\n","              \n","                      [[ 23628.3340]],\n","              \n","                      [[900410.8750]],\n","              \n","                      [[  4392.8604]],\n","              \n","                      [[ 41561.6406]],\n","              \n","                      [[  3248.9714]],\n","              \n","                      [[  6595.0273]],\n","              \n","                      [[  3740.0081]],\n","              \n","                      [[  4320.2720]],\n","              \n","                      [[  7955.8511]],\n","              \n","                      [[  2356.2146]],\n","              \n","                      [[ 60095.4492]],\n","              \n","                      [[  3321.6208]],\n","              \n","                      [[  5578.8564]],\n","              \n","                      [[114338.0703]]], device='cuda:0')),\n","             ('module.layer1.4.conv1.is_simulated_quant_weight_shifted',\n","              tensor(False, device='cuda:0')),\n","             ('module.layer1.4.conv1.wrapped_module.weight',\n","              tensor([[[[ 9., 33., 33.],\n","                        [24., 41., 33.],\n","                        [27., 35., 21.]],\n","              \n","                       [[23., 23., 27.],\n","                        [27., 26., 31.],\n","                        [25., 24., 31.]],\n","              \n","                       [[22., 27., 37.],\n","                        [22., 24., 33.],\n","                        [26., 26., 36.]],\n","              \n","                       ...,\n","              \n","                       [[20., 21., 22.],\n","                        [22., 19., 21.],\n","                        [17., 13., 15.]],\n","              \n","                       [[17., 47., 42.],\n","                        [13., 30., 18.],\n","                        [ 5., 28., 15.]],\n","              \n","                       [[26., 28., 16.],\n","                        [23., 31., 18.],\n","                        [24., 30., 20.]]],\n","              \n","              \n","                      [[[15., 15., 15.],\n","                        [26., 21., 16.],\n","                        [33., 32., 30.]],\n","              \n","                       [[25., 23., 25.],\n","                        [26., 24., 24.],\n","                        [26., 27., 24.]],\n","              \n","                       [[24., 19., 24.],\n","                        [19., 20., 21.],\n","                        [19., 21., 21.]],\n","              \n","                       ...,\n","              \n","                       [[31., 32., 25.],\n","                        [26., 28., 26.],\n","                        [21., 21., 23.]],\n","              \n","                       [[ 5.,  6.,  7.],\n","                        [22.,  5.,  6.],\n","                        [26.,  0.,  0.]],\n","              \n","                       [[25., 19., 10.],\n","                        [18., 30., 21.],\n","                        [21., 34., 33.]]],\n","              \n","              \n","                      [[[15., 23., 35.],\n","                        [23., 29., 39.],\n","                        [35., 39., 45.]],\n","              \n","                       [[33., 30., 32.],\n","                        [37., 34., 37.],\n","                        [36., 30., 34.]],\n","              \n","                       [[36., 31., 37.],\n","                        [37., 34., 37.],\n","                        [34., 29., 34.]],\n","              \n","                       ...,\n","              \n","                       [[34., 35., 35.],\n","                        [34., 38., 34.],\n","                        [31., 38., 36.]],\n","              \n","                       [[36., 24., 28.],\n","                        [20., 17., 30.],\n","                        [21., 16., 41.]],\n","              \n","                       [[44., 44., 43.],\n","                        [48., 50., 51.],\n","                        [63., 61., 53.]]],\n","              \n","              \n","                      ...,\n","              \n","              \n","                      [[[49., 49., 49.],\n","                        [44., 46., 46.],\n","                        [43., 50., 48.]],\n","              \n","                       [[43., 46., 45.],\n","                        [45., 47., 46.],\n","                        [46., 45., 45.]],\n","              \n","                       [[47., 48., 45.],\n","                        [46., 46., 45.],\n","                        [47., 48., 46.]],\n","              \n","                       ...,\n","              \n","                       [[47., 48., 48.],\n","                        [47., 46., 47.],\n","                        [46., 47., 47.]],\n","              \n","                       [[52., 47., 51.],\n","                        [52., 52., 48.],\n","                        [48., 51., 45.]],\n","              \n","                       [[53., 56., 46.],\n","                        [47., 45., 46.],\n","                        [53., 49., 48.]]],\n","              \n","              \n","                      [[[32., 41., 36.],\n","                        [34., 43., 38.],\n","                        [30., 39., 30.]],\n","              \n","                       [[30., 30., 25.],\n","                        [31., 32., 31.],\n","                        [28., 30., 30.]],\n","              \n","                       [[28., 30., 20.],\n","                        [25., 31., 23.],\n","                        [29., 32., 30.]],\n","              \n","                       ...,\n","              \n","                       [[34., 36., 35.],\n","                        [39., 33., 35.],\n","                        [38., 34., 30.]],\n","              \n","                       [[26., 36., 45.],\n","                        [28., 18., 26.],\n","                        [13., 13., 14.]],\n","              \n","                       [[25., 30., 34.],\n","                        [31., 35., 32.],\n","                        [31., 36., 38.]]],\n","              \n","              \n","                      [[[35., 39., 31.],\n","                        [34., 33., 29.],\n","                        [38., 34., 33.]],\n","              \n","                       [[35., 35., 34.],\n","                        [35., 35., 36.],\n","                        [32., 34., 34.]],\n","              \n","                       [[35., 34., 32.],\n","                        [39., 39., 38.],\n","                        [35., 36., 34.]],\n","              \n","                       ...,\n","              \n","                       [[30., 31., 29.],\n","                        [29., 30., 31.],\n","                        [30., 30., 32.]],\n","              \n","                       [[22., 46., 31.],\n","                        [35., 48., 43.],\n","                        [42., 40., 36.]],\n","              \n","                       [[30., 30., 29.],\n","                        [31., 34., 23.],\n","                        [29., 31., 22.]]]], device='cuda:0')),\n","             ('module.layer1.4.conv1.wrapped_module.bias',\n","              tensor([ -4078.,  -1479.,  -2901., -18780.,  -3168.,   2238.,  -2272.,  -4079.,\n","                       -1489.,   1102.,   1112.,  -2853.,  -7488.,    722.,   1530.,  -4281.],\n","                     device='cuda:0')),\n","             ('module.layer1.4.conv2.num_forwards',\n","              tensor([40], device='cuda:0')),\n","             ('module.layer1.4.conv2.force_readjust',\n","              tensor(False, device='cuda:0')),\n","             ('module.layer1.4.conv2.output_scale',\n","              tensor([40.3739], device='cuda:0')),\n","             ('module.layer1.4.conv2.output_zero_point',\n","              tensor([-29.], device='cuda:0')),\n","             ('module.layer1.4.conv2.w_scale', tensor([[[[170.5480]]],\n","              \n","              \n","                      [[[201.9672]]],\n","              \n","              \n","                      [[[213.3193]]],\n","              \n","              \n","                      [[[129.5031]]],\n","              \n","              \n","                      [[[385.8332]]],\n","              \n","              \n","                      [[[743.1646]]],\n","              \n","              \n","                      [[[ 70.8027]]],\n","              \n","              \n","                      [[[162.0965]]],\n","              \n","              \n","                      [[[173.6987]]],\n","              \n","              \n","                      [[[145.5280]]],\n","              \n","              \n","                      [[[104.8246]]],\n","              \n","              \n","                      [[[133.5421]]],\n","              \n","              \n","                      [[[ 88.8458]]],\n","              \n","              \n","                      [[[109.2873]]],\n","              \n","              \n","                      [[[119.0321]]],\n","              \n","              \n","                      [[[159.2432]]]], device='cuda:0')),\n","             ('module.layer1.4.conv2.w_zero_point', tensor([[[[-36.]]],\n","              \n","              \n","                      [[[-18.]]],\n","              \n","              \n","                      [[[-27.]]],\n","              \n","              \n","                      [[[-43.]]],\n","              \n","              \n","                      [[[-42.]]],\n","              \n","              \n","                      [[[-23.]]],\n","              \n","              \n","                      [[[-27.]]],\n","              \n","              \n","                      [[[-35.]]],\n","              \n","              \n","                      [[[-33.]]],\n","              \n","              \n","                      [[[-30.]]],\n","              \n","              \n","                      [[[-37.]]],\n","              \n","              \n","                      [[[-28.]]],\n","              \n","              \n","                      [[[-38.]]],\n","              \n","              \n","                      [[[-30.]]],\n","              \n","              \n","                      [[[-40.]]],\n","              \n","              \n","                      [[[-39.]]]], device='cuda:0')),\n","             ('module.layer1.4.conv2.fp_bias',\n","              tensor([-0.0326, -0.2163, -0.1812,  0.4234, -0.0543,  0.2223, -0.0781,  0.3413,\n","                       0.2444, -0.0318,  0.2379, -0.0833,  0.2922,  0.1616,  0.0247,  0.4540],\n","                     device='cuda:0')),\n","             ('module.layer1.4.conv2.accum_scale', tensor([[[10680.7549]],\n","              \n","                      [[12648.4121]],\n","              \n","                      [[13359.3525]],\n","              \n","                      [[ 8110.2734]],\n","              \n","                      [[24163.2227]],\n","              \n","                      [[46541.4844]],\n","              \n","                      [[ 4434.0952]],\n","              \n","                      [[10151.4658]],\n","              \n","                      [[10878.0674]],\n","              \n","                      [[ 9113.8506]],\n","              \n","                      [[ 6564.7544]],\n","              \n","                      [[ 8363.2197]],\n","              \n","                      [[ 5564.0669]],\n","              \n","                      [[ 6844.2373]],\n","              \n","                      [[ 7454.5142]],\n","              \n","                      [[ 9972.7764]]], device='cuda:0')),\n","             ('module.layer1.4.conv2.is_simulated_quant_weight_shifted',\n","              tensor(False, device='cuda:0')),\n","             ('module.layer1.4.conv2.wrapped_module.weight',\n","              tensor([[[[55., 48., 40.],\n","                        [48., 24.,  7.],\n","                        [20.,  0., 32.]],\n","              \n","                       [[ 5., 25., 57.],\n","                        [ 7., 15., 59.],\n","                        [15., 13., 36.]],\n","              \n","                       [[39., 39., 38.],\n","                        [40., 38., 35.],\n","                        [37., 35., 35.]],\n","              \n","                       ...,\n","              \n","                       [[ 9.,  7., 26.],\n","                        [46., 43., 52.],\n","                        [29., 48., 57.]],\n","              \n","                       [[18., 16., 29.],\n","                        [23., 12., 30.],\n","                        [ 8.,  2., 22.]],\n","              \n","                       [[35., 29., 26.],\n","                        [38., 32., 31.],\n","                        [35., 34., 33.]]],\n","              \n","              \n","                      [[[27., 24., 15.],\n","                        [21., 23., 21.],\n","                        [ 8., 14., 13.]],\n","              \n","                       [[14., 14., 16.],\n","                        [14., 15., 21.],\n","                        [13., 16., 20.]],\n","              \n","                       [[18., 17., 16.],\n","                        [18., 18., 16.],\n","                        [19., 18., 16.]],\n","              \n","                       ...,\n","              \n","                       [[26., 24., 11.],\n","                        [27., 21.,  0.],\n","                        [34., 16., 14.]],\n","              \n","                       [[15., 28., 18.],\n","                        [28., 42., 31.],\n","                        [17., 23., 19.]],\n","              \n","                       [[17., 18., 17.],\n","                        [19., 20., 19.],\n","                        [21., 20., 20.]]],\n","              \n","              \n","                      [[[39., 27., 25.],\n","                        [36., 28., 25.],\n","                        [22., 12., 14.]],\n","              \n","                       [[28., 27., 26.],\n","                        [26., 25., 27.],\n","                        [24., 23., 25.]],\n","              \n","                       [[26., 27., 27.],\n","                        [27., 27., 27.],\n","                        [27., 27., 26.]],\n","              \n","                       ...,\n","              \n","                       [[39., 28., 16.],\n","                        [36., 42., 16.],\n","                        [ 0., 13., 17.]],\n","              \n","                       [[18., 22., 18.],\n","                        [24., 25., 34.],\n","                        [18., 18., 27.]],\n","              \n","                       [[27., 26., 26.],\n","                        [31., 29., 29.],\n","                        [31., 28., 28.]]],\n","              \n","              \n","                      ...,\n","              \n","              \n","                      [[[30., 29., 36.],\n","                        [22., 25., 32.],\n","                        [21., 25., 36.]],\n","              \n","                       [[33., 19., 17.],\n","                        [39., 29., 29.],\n","                        [39., 33., 37.]],\n","              \n","                       [[28., 28., 28.],\n","                        [29., 29., 29.],\n","                        [31., 31., 30.]],\n","              \n","                       ...,\n","              \n","                       [[26., 20., 37.],\n","                        [23., 37., 63.],\n","                        [24., 17., 21.]],\n","              \n","                       [[ 8., 22., 42.],\n","                        [18., 23., 36.],\n","                        [20., 23., 23.]],\n","              \n","                       [[34., 32., 31.],\n","                        [32., 32., 31.],\n","                        [27., 29., 29.]]],\n","              \n","              \n","                      [[[40., 33., 35.],\n","                        [45., 25., 26.],\n","                        [32., 15., 41.]],\n","              \n","                       [[52., 34., 47.],\n","                        [45., 32., 38.],\n","                        [41., 35., 34.]],\n","              \n","                       [[41., 38., 39.],\n","                        [42., 37., 41.],\n","                        [41., 37., 40.]],\n","              \n","                       ...,\n","              \n","                       [[46., 41., 20.],\n","                        [44., 29., 39.],\n","                        [34., 41., 63.]],\n","              \n","                       [[40., 39., 44.],\n","                        [32., 33., 57.],\n","                        [43., 40., 38.]],\n","              \n","                       [[41., 38., 42.],\n","                        [40., 36., 39.],\n","                        [37., 34., 38.]]],\n","              \n","              \n","                      [[[54., 44., 55.],\n","                        [48., 44., 48.],\n","                        [37., 43., 51.]],\n","              \n","                       [[54., 45., 34.],\n","                        [50., 47., 35.],\n","                        [37., 39., 45.]],\n","              \n","                       [[37., 40., 37.],\n","                        [36., 39., 35.],\n","                        [33., 38., 36.]],\n","              \n","                       ...,\n","              \n","                       [[29., 18., 40.],\n","                        [34.,  0., 10.],\n","                        [44., 33., 20.]],\n","              \n","                       [[27., 14.,  4.],\n","                        [38., 45., 27.],\n","                        [48., 63., 48.]],\n","              \n","                       [[37., 40., 37.],\n","                        [39., 41., 39.],\n","                        [42., 42., 40.]]]], device='cuda:0')),\n","             ('module.layer1.4.conv2.wrapped_module.bias',\n","              tensor([ -348., -2736., -2420.,  3434., -1312., 10346.,  -346.,  3465.,  2659.,\n","                       -290.,  1562.,  -696.,  1626.,  1106.,   184.,  4527.],\n","                     device='cuda:0')),\n","             ('module.layer1.4.relu2.num_forwards',\n","              tensor([40], device='cuda:0')),\n","             ('module.layer1.4.relu2.force_readjust',\n","              tensor(False, device='cuda:0')),\n","             ('module.layer1.4.relu2.output_scale',\n","              tensor([6.8248], device='cuda:0')),\n","             ('module.layer1.4.relu2.output_zero_point',\n","              tensor([0.], device='cuda:0')),\n","             ('module.layer1.4.residual_eltwiseadd.num_forwards',\n","              tensor([40], device='cuda:0')),\n","             ('module.layer1.4.residual_eltwiseadd.force_readjust',\n","              tensor(False, device='cuda:0')),\n","             ('module.layer1.4.residual_eltwiseadd.output_scale',\n","              tensor([6.8248], device='cuda:0')),\n","             ('module.layer1.4.residual_eltwiseadd.output_zero_point',\n","              tensor([0.], device='cuda:0')),\n","             ('module.layer1.5.conv1.num_forwards',\n","              tensor([40], device='cuda:0')),\n","             ('module.layer1.5.conv1.force_readjust',\n","              tensor(False, device='cuda:0')),\n","             ('module.layer1.5.conv1.output_scale',\n","              tensor([33.1277], device='cuda:0')),\n","             ('module.layer1.5.conv1.output_zero_point',\n","              tensor([0.], device='cuda:0')),\n","             ('module.layer1.5.conv1.w_scale', tensor([[[[5.8544e+02]]],\n","              \n","              \n","                      [[[3.3896e+02]]],\n","              \n","              \n","                      [[[6.7080e+05]]],\n","              \n","              \n","                      [[[2.5081e+02]]],\n","              \n","              \n","                      [[[3.7188e+02]]],\n","              \n","              \n","                      [[[6.9399e+02]]],\n","              \n","              \n","                      [[[1.0310e+03]]],\n","              \n","              \n","                      [[[5.4502e+02]]],\n","              \n","              \n","                      [[[5.8617e+05]]],\n","              \n","              \n","                      [[[3.7710e+02]]],\n","              \n","              \n","                      [[[3.7993e+02]]],\n","              \n","              \n","                      [[[8.0956e+05]]],\n","              \n","              \n","                      [[[1.2529e+03]]],\n","              \n","              \n","                      [[[2.9718e+02]]],\n","              \n","              \n","                      [[[6.7233e+02]]],\n","              \n","              \n","                      [[[7.2248e+02]]]], device='cuda:0')),\n","             ('module.layer1.5.conv1.w_zero_point', tensor([[[[-28.]]],\n","              \n","              \n","                      [[[-41.]]],\n","              \n","              \n","                      [[[-44.]]],\n","              \n","              \n","                      [[[-21.]]],\n","              \n","              \n","                      [[[-26.]]],\n","              \n","              \n","                      [[[-22.]]],\n","              \n","              \n","                      [[[-26.]]],\n","              \n","              \n","                      [[[-30.]]],\n","              \n","              \n","                      [[[-49.]]],\n","              \n","              \n","                      [[[-34.]]],\n","              \n","              \n","                      [[[-27.]]],\n","              \n","              \n","                      [[[-23.]]],\n","              \n","              \n","                      [[[-40.]]],\n","              \n","              \n","                      [[[-33.]]],\n","              \n","              \n","                      [[[-32.]]],\n","              \n","              \n","                      [[[-33.]]]], device='cuda:0')),\n","             ('module.layer1.5.conv1.fp_bias',\n","              tensor([-9.7457e-01,  3.7921e-01, -5.0638e-05, -1.1780e-01,  5.5562e-01,\n","                      -5.4378e-01,  1.3785e-01, -3.6645e-01, -5.6000e-06, -9.3494e-02,\n","                      -5.0181e-01, -3.4027e-03,  3.0561e-01, -5.2634e-01,  3.7857e-02,\n","                       1.0125e+00], device='cuda:0')),\n","             ('module.layer1.5.conv1.accum_scale', tensor([[[3.9955e+03]],\n","              \n","                      [[2.3133e+03]],\n","              \n","                      [[4.5781e+06]],\n","              \n","                      [[1.7117e+03]],\n","              \n","                      [[2.5380e+03]],\n","              \n","                      [[4.7363e+03]],\n","              \n","                      [[7.0367e+03]],\n","              \n","                      [[3.7196e+03]],\n","              \n","                      [[4.0005e+06]],\n","              \n","                      [[2.5737e+03]],\n","              \n","                      [[2.5929e+03]],\n","              \n","                      [[5.5251e+06]],\n","              \n","                      [[8.5510e+03]],\n","              \n","                      [[2.0282e+03]],\n","              \n","                      [[4.5885e+03]],\n","              \n","                      [[4.9308e+03]]], device='cuda:0')),\n","             ('module.layer1.5.conv1.is_simulated_quant_weight_shifted',\n","              tensor(False, device='cuda:0')),\n","             ('module.layer1.5.conv1.wrapped_module.weight',\n","              tensor([[[[21., 24., 24.],\n","                        [23., 23., 26.],\n","                        [17., 20., 23.]],\n","              \n","                       [[29., 33., 32.],\n","                        [27., 32., 31.],\n","                        [25., 30., 27.]],\n","              \n","                       [[37., 39., 32.],\n","                        [37., 38., 30.],\n","                        [32., 33., 26.]],\n","              \n","                       ...,\n","              \n","                       [[23., 32., 36.],\n","                        [22., 28., 39.],\n","                        [28., 31., 40.]],\n","              \n","                       [[13., 29., 28.],\n","                        [25., 27., 36.],\n","                        [14., 21., 22.]],\n","              \n","                       [[47., 39., 23.],\n","                        [59., 47., 17.],\n","                        [59., 49., 28.]]],\n","              \n","              \n","                      [[[35., 37., 42.],\n","                        [31., 33., 38.],\n","                        [28., 31., 37.]],\n","              \n","                       [[38., 37., 34.],\n","                        [39., 39., 36.],\n","                        [41., 40., 39.]],\n","              \n","                       [[38., 39., 41.],\n","                        [36., 37., 39.],\n","                        [39., 39., 39.]],\n","              \n","                       ...,\n","              \n","                       [[43., 40., 43.],\n","                        [48., 47., 46.],\n","                        [43., 44., 48.]],\n","              \n","                       [[46., 36., 47.],\n","                        [39., 37., 34.],\n","                        [32., 30., 45.]],\n","              \n","                       [[40., 46., 38.],\n","                        [41., 40., 41.],\n","                        [52., 44., 37.]]],\n","              \n","              \n","                      [[[48., 37., 44.],\n","                        [47., 53., 50.],\n","                        [46., 45., 40.]],\n","              \n","                       [[44., 52., 59.],\n","                        [46., 55., 55.],\n","                        [46., 54., 56.]],\n","              \n","                       [[45., 51., 55.],\n","                        [35., 51., 49.],\n","                        [49., 56., 48.]],\n","              \n","                       ...,\n","              \n","                       [[39., 44., 63.],\n","                        [41., 46., 54.],\n","                        [45., 50., 57.]],\n","              \n","                       [[38., 19., 19.],\n","                        [37., 27., 31.],\n","                        [44., 46., 27.]],\n","              \n","                       [[17.,  8.,  0.],\n","                        [36., 16.,  6.],\n","                        [42., 24., 16.]]],\n","              \n","              \n","                      ...,\n","              \n","              \n","                      [[[36., 34., 31.],\n","                        [31., 29., 34.],\n","                        [30., 34., 39.]],\n","              \n","                       [[29., 29., 29.],\n","                        [34., 33., 32.],\n","                        [32., 28., 28.]],\n","              \n","                       [[31., 32., 34.],\n","                        [31., 33., 32.],\n","                        [29., 31., 32.]],\n","              \n","                       ...,\n","              \n","                       [[37., 36., 38.],\n","                        [37., 34., 32.],\n","                        [34., 32., 32.]],\n","              \n","                       [[39., 35., 13.],\n","                        [29., 34., 29.],\n","                        [26., 30., 33.]],\n","              \n","                       [[35., 32., 37.],\n","                        [32., 26., 29.],\n","                        [37., 36., 38.]]],\n","              \n","              \n","                      [[[34., 30., 23.],\n","                        [35., 32., 25.],\n","                        [30., 27., 33.]],\n","              \n","                       [[31., 31., 31.],\n","                        [32., 33., 32.],\n","                        [30., 34., 35.]],\n","              \n","                       [[31., 31., 25.],\n","                        [33., 34., 29.],\n","                        [30., 34., 32.]],\n","              \n","                       ...,\n","              \n","                       [[31., 29., 33.],\n","                        [33., 34., 36.],\n","                        [37., 39., 36.]],\n","              \n","                       [[28., 28., 18.],\n","                        [42., 42., 23.],\n","                        [34., 46., 47.]],\n","              \n","                       [[37., 43., 52.],\n","                        [40., 35., 48.],\n","                        [63., 40., 36.]]],\n","              \n","              \n","                      [[[53., 39., 25.],\n","                        [46., 38., 29.],\n","                        [50., 43., 37.]],\n","              \n","                       [[38., 41., 37.],\n","                        [39., 37., 33.],\n","                        [41., 38., 34.]],\n","              \n","                       [[32., 32., 32.],\n","                        [33., 34., 38.],\n","                        [39., 36., 38.]],\n","              \n","                       ...,\n","              \n","                       [[36., 35., 32.],\n","                        [33., 34., 36.],\n","                        [24., 26., 34.]],\n","              \n","                       [[33., 35., 18.],\n","                        [19., 47., 43.],\n","                        [19., 40., 49.]],\n","              \n","                       [[21., 19., 24.],\n","                        [35., 25., 25.],\n","                        [37., 36., 21.]]]], device='cuda:0')),\n","             ('module.layer1.5.conv1.wrapped_module.bias',\n","              tensor([ -3894.,    877.,   -232.,   -202.,   1410.,  -2575.,    970.,  -1363.,\n","                         -22.,   -241.,  -1301., -18800.,   2613.,  -1068.,    174.,   4993.],\n","                     device='cuda:0')),\n","             ('module.layer1.5.conv2.num_forwards',\n","              tensor([40], device='cuda:0')),\n","             ('module.layer1.5.conv2.force_readjust',\n","              tensor(False, device='cuda:0')),\n","             ('module.layer1.5.conv2.output_scale',\n","              tensor([14.2662], device='cuda:0')),\n","             ('module.layer1.5.conv2.output_zero_point',\n","              tensor([-36.], device='cuda:0')),\n","             ('module.layer1.5.conv2.w_scale', tensor([[[[  89.7136]]],\n","              \n","              \n","                      [[[1278.3951]]],\n","              \n","              \n","                      [[[  91.5602]]],\n","              \n","              \n","                      [[[  82.0488]]],\n","              \n","              \n","                      [[[ 658.5463]]],\n","              \n","              \n","                      [[[ 153.0542]]],\n","              \n","              \n","                      [[[  82.8196]]],\n","              \n","              \n","                      [[[ 133.9174]]],\n","              \n","              \n","                      [[[ 536.1757]]],\n","              \n","              \n","                      [[[ 841.1111]]],\n","              \n","              \n","                      [[[ 131.5685]]],\n","              \n","              \n","                      [[[1461.7157]]],\n","              \n","              \n","                      [[[ 291.4763]]],\n","              \n","              \n","                      [[[ 149.5683]]],\n","              \n","              \n","                      [[[  78.1353]]],\n","              \n","              \n","                      [[[ 116.2364]]]], device='cuda:0')),\n","             ('module.layer1.5.conv2.w_zero_point', tensor([[[[-28.]]],\n","              \n","              \n","                      [[[-23.]]],\n","              \n","              \n","                      [[[-28.]]],\n","              \n","              \n","                      [[[-42.]]],\n","              \n","              \n","                      [[[-33.]]],\n","              \n","              \n","                      [[[-26.]]],\n","              \n","              \n","                      [[[-27.]]],\n","              \n","              \n","                      [[[-29.]]],\n","              \n","              \n","                      [[[-40.]]],\n","              \n","              \n","                      [[[-31.]]],\n","              \n","              \n","                      [[[-35.]]],\n","              \n","              \n","                      [[[-31.]]],\n","              \n","              \n","                      [[[-39.]]],\n","              \n","              \n","                      [[[-28.]]],\n","              \n","              \n","                      [[[-31.]]],\n","              \n","              \n","                      [[[-36.]]]], device='cuda:0')),\n","             ('module.layer1.5.conv2.fp_bias',\n","              tensor([ 0.4020, -0.0762,  0.0583,  1.2242, -0.0382,  0.3693,  0.2824,  0.1326,\n","                       0.0866, -0.0213,  0.3084,  0.0153,  0.1010,  0.2958, -0.1804,  0.4928],\n","                     device='cuda:0')),\n","             ('module.layer1.5.conv2.accum_scale', tensor([[[ 2972.0022]],\n","              \n","                      [[42350.2383]],\n","              \n","                      [[ 3033.1741]],\n","              \n","                      [[ 2718.0857]],\n","              \n","                      [[21816.0977]],\n","              \n","                      [[ 5070.3257]],\n","              \n","                      [[ 2743.6204]],\n","              \n","                      [[ 4436.3706]],\n","              \n","                      [[17762.2441]],\n","              \n","                      [[27864.0430]],\n","              \n","                      [[ 4358.5566]],\n","              \n","                      [[48423.2188]],\n","              \n","                      [[ 9655.9277]],\n","              \n","                      [[ 4954.8477]],\n","              \n","                      [[ 2588.4397]],\n","              \n","                      [[ 3850.6399]]], device='cuda:0')),\n","             ('module.layer1.5.conv2.is_simulated_quant_weight_shifted',\n","              tensor(False, device='cuda:0')),\n","             ('module.layer1.5.conv2.wrapped_module.weight',\n","              tensor([[[[22., 14., 19.],\n","                        [20., 20., 35.],\n","                        [26., 31., 51.]],\n","              \n","                       [[16., 30., 44.],\n","                        [ 3., 35., 63.],\n","                        [25., 50., 59.]],\n","              \n","                       [[28., 28., 28.],\n","                        [28., 28., 28.],\n","                        [28., 28., 28.]],\n","              \n","                       ...,\n","              \n","                       [[12., 14., 47.],\n","                        [12., 20., 41.],\n","                        [ 2., 39., 56.]],\n","              \n","                       [[26., 28., 27.],\n","                        [25., 32., 36.],\n","                        [28., 36., 33.]],\n","              \n","                       [[18., 20., 35.],\n","                        [27., 30., 35.],\n","                        [30., 28., 25.]]],\n","              \n","              \n","                      [[[12., 18., 19.],\n","                        [ 9., 20., 21.],\n","                        [10., 20., 25.]],\n","              \n","                       [[16., 27., 23.],\n","                        [28., 34., 26.],\n","                        [63., 61., 37.]],\n","              \n","                       [[23., 23., 23.],\n","                        [23., 23., 23.],\n","                        [23., 23., 23.]],\n","              \n","                       ...,\n","              \n","                       [[12., 19., 12.],\n","                        [24., 29., 34.],\n","                        [23., 27., 21.]],\n","              \n","                       [[25., 25., 26.],\n","                        [22., 24., 25.],\n","                        [25., 25., 29.]],\n","              \n","                       [[20., 20., 24.],\n","                        [22., 24., 26.],\n","                        [24., 26., 26.]]],\n","              \n","              \n","                      [[[29., 24., 35.],\n","                        [36., 26., 31.],\n","                        [42., 41., 33.]],\n","              \n","                       [[32., 16., 11.],\n","                        [29., 44., 28.],\n","                        [19., 27., 40.]],\n","              \n","                       [[28., 28., 28.],\n","                        [28., 28., 28.],\n","                        [28., 28., 28.]],\n","              \n","                       ...,\n","              \n","                       [[49., 25., 25.],\n","                        [63., 29.,  9.],\n","                        [12., 43., 31.]],\n","              \n","                       [[37., 25., 24.],\n","                        [30., 35., 29.],\n","                        [31., 27., 26.]],\n","              \n","                       [[29., 26., 26.],\n","                        [30., 28., 24.],\n","                        [27., 31., 25.]]],\n","              \n","              \n","                      ...,\n","              \n","              \n","                      [[[17., 21., 20.],\n","                        [34., 34., 26.],\n","                        [28., 31., 29.]],\n","              \n","                       [[30., 21., 38.],\n","                        [ 7., 14., 40.],\n","                        [18.,  6., 20.]],\n","              \n","                       [[28., 28., 28.],\n","                        [28., 28., 28.],\n","                        [28., 28., 28.]],\n","              \n","                       ...,\n","              \n","                       [[40., 27., 13.],\n","                        [23., 51., 55.],\n","                        [30., 11., 27.]],\n","              \n","                       [[32., 33., 29.],\n","                        [27., 23., 24.],\n","                        [27., 23., 21.]],\n","              \n","                       [[37., 29., 18.],\n","                        [33., 32., 28.],\n","                        [26., 25., 27.]]],\n","              \n","              \n","                      [[[39., 31., 23.],\n","                        [34., 33., 16.],\n","                        [43., 35., 13.]],\n","              \n","                       [[44., 23., 27.],\n","                        [23., 28., 32.],\n","                        [35., 24., 39.]],\n","              \n","                       [[31., 31., 31.],\n","                        [31., 31., 31.],\n","                        [31., 31., 31.]],\n","              \n","                       ...,\n","              \n","                       [[40., 35., 32.],\n","                        [31., 36., 29.],\n","                        [16., 41., 35.]],\n","              \n","                       [[32., 31., 24.],\n","                        [33., 35., 22.],\n","                        [35., 32., 22.]],\n","              \n","                       [[27., 30., 28.],\n","                        [29., 30., 32.],\n","                        [29., 30., 32.]]],\n","              \n","              \n","                      [[[16., 35., 31.],\n","                        [ 7., 26., 37.],\n","                        [14., 17., 19.]],\n","              \n","                       [[10.,  4., 11.],\n","                        [21., 13., 14.],\n","                        [40., 31., 26.]],\n","              \n","                       [[36., 36., 36.],\n","                        [36., 36., 36.],\n","                        [36., 36., 36.]],\n","              \n","                       ...,\n","              \n","                       [[15., 44., 51.],\n","                        [19.,  0., 35.],\n","                        [31., 20., 35.]],\n","              \n","                       [[32., 22., 27.],\n","                        [43., 32., 26.],\n","                        [30., 26., 22.]],\n","              \n","                       [[32., 37., 36.],\n","                        [36., 31., 34.],\n","                        [40., 22., 27.]]]], device='cuda:0')),\n","             ('module.layer1.5.conv2.wrapped_module.bias',\n","              tensor([ 1195., -3227.,   177.,  3328.,  -833.,  1872.,   775.,   588.,  1537.,\n","                       -593.,  1344.,   740.,   975.,  1466.,  -467.,  1898.],\n","                     device='cuda:0')),\n","             ('module.layer1.5.relu2.num_forwards',\n","              tensor([40], device='cuda:0')),\n","             ('module.layer1.5.relu2.force_readjust',\n","              tensor(False, device='cuda:0')),\n","             ('module.layer1.5.relu2.output_scale',\n","              tensor([6.3841], device='cuda:0')),\n","             ('module.layer1.5.relu2.output_zero_point',\n","              tensor([0.], device='cuda:0')),\n","             ('module.layer1.5.residual_eltwiseadd.num_forwards',\n","              tensor([40], device='cuda:0')),\n","             ('module.layer1.5.residual_eltwiseadd.force_readjust',\n","              tensor(False, device='cuda:0')),\n","             ('module.layer1.5.residual_eltwiseadd.output_scale',\n","              tensor([6.3841], device='cuda:0')),\n","             ('module.layer1.5.residual_eltwiseadd.output_zero_point',\n","              tensor([0.], device='cuda:0')),\n","             ('module.layer1.6.conv1.num_forwards',\n","              tensor([40], device='cuda:0')),\n","             ('module.layer1.6.conv1.force_readjust',\n","              tensor(False, device='cuda:0')),\n","             ('module.layer1.6.conv1.output_scale',\n","              tensor([28.1586], device='cuda:0')),\n","             ('module.layer1.6.conv1.output_zero_point',\n","              tensor([0.], device='cuda:0')),\n","             ('module.layer1.6.conv1.w_scale', tensor([[[[3.3811e+02]]],\n","              \n","              \n","                      [[[2.9156e+02]]],\n","              \n","              \n","                      [[[3.0478e+02]]],\n","              \n","              \n","                      [[[5.2291e+02]]],\n","              \n","              \n","                      [[[2.3900e+02]]],\n","              \n","              \n","                      [[[3.8294e+02]]],\n","              \n","              \n","                      [[[2.5297e+02]]],\n","              \n","              \n","                      [[[5.3711e+02]]],\n","              \n","              \n","                      [[[4.0485e+02]]],\n","              \n","              \n","                      [[[6.6243e+05]]],\n","              \n","              \n","                      [[[2.4880e+02]]],\n","              \n","              \n","                      [[[2.7971e+02]]],\n","              \n","              \n","                      [[[4.1306e+02]]],\n","              \n","              \n","                      [[[4.2930e+05]]],\n","              \n","              \n","                      [[[2.2664e+02]]],\n","              \n","              \n","                      [[[3.5306e+02]]]], device='cuda:0')),\n","             ('module.layer1.6.conv1.w_zero_point', tensor([[[[-34.]]],\n","              \n","              \n","                      [[[-34.]]],\n","              \n","              \n","                      [[[-35.]]],\n","              \n","              \n","                      [[[-32.]]],\n","              \n","              \n","                      [[[-28.]]],\n","              \n","              \n","                      [[[-37.]]],\n","              \n","              \n","                      [[[-23.]]],\n","              \n","              \n","                      [[[-24.]]],\n","              \n","              \n","                      [[[-40.]]],\n","              \n","              \n","                      [[[-40.]]],\n","              \n","              \n","                      [[[-30.]]],\n","              \n","              \n","                      [[[-39.]]],\n","              \n","              \n","                      [[[-38.]]],\n","              \n","              \n","                      [[[-37.]]],\n","              \n","              \n","                      [[[-30.]]],\n","              \n","              \n","                      [[[-30.]]]], device='cuda:0')),\n","             ('module.layer1.6.conv1.fp_bias',\n","              tensor([ 3.0149e-01, -4.8343e-01, -4.0765e-01,  1.2714e-01, -1.7941e-01,\n","                      -9.8203e-02, -1.5358e+00, -6.5454e-01,  8.6668e-02,  3.5398e-04,\n","                      -8.0544e-01,  2.6903e-01,  5.2843e-01,  6.5613e-04, -4.3428e-01,\n","                      -2.1402e-01], device='cuda:0')),\n","             ('module.layer1.6.conv1.accum_scale', tensor([[[2.1585e+03]],\n","              \n","                      [[1.8614e+03]],\n","              \n","                      [[1.9458e+03]],\n","              \n","                      [[3.3383e+03]],\n","              \n","                      [[1.5258e+03]],\n","              \n","                      [[2.4447e+03]],\n","              \n","                      [[1.6150e+03]],\n","              \n","                      [[3.4290e+03]],\n","              \n","                      [[2.5846e+03]],\n","              \n","                      [[4.2290e+06]],\n","              \n","                      [[1.5883e+03]],\n","              \n","                      [[1.7857e+03]],\n","              \n","                      [[2.6370e+03]],\n","              \n","                      [[2.7407e+06]],\n","              \n","                      [[1.4469e+03]],\n","              \n","                      [[2.2540e+03]]], device='cuda:0')),\n","             ('module.layer1.6.conv1.is_simulated_quant_weight_shifted',\n","              tensor(False, device='cuda:0')),\n","             ('module.layer1.6.conv1.wrapped_module.weight',\n","              tensor([[[[27., 27., 35.],\n","                        [30., 29., 46.],\n","                        [23., 29., 44.]],\n","              \n","                       [[36., 32., 34.],\n","                        [35., 31., 31.],\n","                        [37., 34., 36.]],\n","              \n","                       [[36., 32., 34.],\n","                        [27., 29., 26.],\n","                        [29., 35., 30.]],\n","              \n","                       ...,\n","              \n","                       [[32., 33., 37.],\n","                        [30., 33., 39.],\n","                        [31., 27., 30.]],\n","              \n","                       [[21., 21., 30.],\n","                        [26.,  6., 33.],\n","                        [26., 17., 29.]],\n","              \n","                       [[28., 39., 22.],\n","                        [33., 47., 32.],\n","                        [23., 36., 45.]]],\n","              \n","              \n","                      [[[28., 28., 28.],\n","                        [25., 31., 26.],\n","                        [33., 36., 33.]],\n","              \n","                       [[35., 34., 33.],\n","                        [33., 31., 29.],\n","                        [32., 30., 28.]],\n","              \n","                       [[30., 35., 41.],\n","                        [30., 32., 36.],\n","                        [30., 26., 31.]],\n","              \n","                       ...,\n","              \n","                       [[39., 39., 30.],\n","                        [32., 32., 30.],\n","                        [28., 33., 29.]],\n","              \n","                       [[44., 30., 27.],\n","                        [33., 34., 32.],\n","                        [36., 29., 36.]],\n","              \n","                       [[46., 39., 47.],\n","                        [30., 35., 36.],\n","                        [31., 34., 36.]]],\n","              \n","              \n","                      [[[31., 40., 34.],\n","                        [38., 40., 37.],\n","                        [25., 34., 36.]],\n","              \n","                       [[38., 36., 35.],\n","                        [31., 31., 30.],\n","                        [35., 35., 35.]],\n","              \n","                       [[36., 32., 35.],\n","                        [26., 29., 30.],\n","                        [27., 26., 32.]],\n","              \n","                       ...,\n","              \n","                       [[36., 36., 28.],\n","                        [26., 30., 33.],\n","                        [33., 31., 28.]],\n","              \n","                       [[26., 41., 42.],\n","                        [36., 37., 30.],\n","                        [35., 42., 28.]],\n","              \n","                       [[25., 40., 39.],\n","                        [34., 50., 38.],\n","                        [24., 32., 38.]]],\n","              \n","              \n","                      ...,\n","              \n","              \n","                      [[[33., 33., 36.],\n","                        [46., 36., 38.],\n","                        [34., 42., 41.]],\n","              \n","                       [[44., 30., 33.],\n","                        [51., 34., 27.],\n","                        [53., 51., 36.]],\n","              \n","                       [[47., 44., 54.],\n","                        [42., 50., 35.],\n","                        [45., 37., 24.]],\n","              \n","                       ...,\n","              \n","                       [[63., 37., 40.],\n","                        [50., 43., 35.],\n","                        [47., 43., 39.]],\n","              \n","                       [[24., 11., 19.],\n","                        [30., 25., 35.],\n","                        [34., 34., 28.]],\n","              \n","                       [[ 4.,  2., 16.],\n","                        [ 4.,  3., 12.],\n","                        [ 0., 12., 19.]]],\n","              \n","              \n","                      [[[26., 29., 25.],\n","                        [25., 28., 24.],\n","                        [21., 24., 27.]],\n","              \n","                       [[30., 29., 26.],\n","                        [30., 29., 26.],\n","                        [31., 29., 26.]],\n","              \n","                       [[29., 31., 29.],\n","                        [36., 32., 29.],\n","                        [38., 34., 29.]],\n","              \n","                       ...,\n","              \n","                       [[37., 34., 35.],\n","                        [33., 33., 34.],\n","                        [35., 33., 29.]],\n","              \n","                       [[22., 29., 24.],\n","                        [31., 32., 27.],\n","                        [34., 32., 25.]],\n","              \n","                       [[40., 33., 32.],\n","                        [37., 24., 25.],\n","                        [27., 19., 25.]]],\n","              \n","              \n","                      [[[31., 28., 21.],\n","                        [32., 24., 22.],\n","                        [31., 25., 22.]],\n","              \n","                       [[29., 27., 29.],\n","                        [31., 27., 29.],\n","                        [30., 28., 29.]],\n","              \n","                       [[29., 25., 30.],\n","                        [35., 39., 35.],\n","                        [30., 39., 39.]],\n","              \n","                       ...,\n","              \n","                       [[27., 29., 33.],\n","                        [38., 36., 33.],\n","                        [31., 33., 26.]],\n","              \n","                       [[37., 36., 33.],\n","                        [42., 23., 28.],\n","                        [13., 29., 14.]],\n","              \n","                       [[38., 42., 23.],\n","                        [27., 36., 43.],\n","                        [32., 24., 22.]]]], device='cuda:0')),\n","             ('module.layer1.6.conv1.wrapped_module.bias',\n","              tensor([  651.,  -900.,  -793.,   424.,  -274.,  -240., -2480., -2244.,   224.,\n","                       1497., -1279.,   480.,  1393.,  1798.,  -628.,  -482.],\n","                     device='cuda:0')),\n","             ('module.layer1.6.conv2.num_forwards',\n","              tensor([40], device='cuda:0')),\n","             ('module.layer1.6.conv2.force_readjust',\n","              tensor(False, device='cuda:0')),\n","             ('module.layer1.6.conv2.output_scale',\n","              tensor([11.5991], device='cuda:0')),\n","             ('module.layer1.6.conv2.output_zero_point',\n","              tensor([-30.], device='cuda:0')),\n","             ('module.layer1.6.conv2.w_scale', tensor([[[[  92.2893]]],\n","              \n","              \n","                      [[[ 116.7852]]],\n","              \n","              \n","                      [[[ 110.1976]]],\n","              \n","              \n","                      [[[ 129.5321]]],\n","              \n","              \n","                      [[[ 113.0760]]],\n","              \n","              \n","                      [[[ 133.2074]]],\n","              \n","              \n","                      [[[  43.2088]]],\n","              \n","              \n","                      [[[ 162.6521]]],\n","              \n","              \n","                      [[[ 246.2419]]],\n","              \n","              \n","                      [[[ 540.2479]]],\n","              \n","              \n","                      [[[ 408.6800]]],\n","              \n","              \n","                      [[[1131.3734]]],\n","              \n","              \n","                      [[[  84.5516]]],\n","              \n","              \n","                      [[[ 231.2324]]],\n","              \n","              \n","                      [[[  71.9306]]],\n","              \n","              \n","                      [[[ 243.5807]]]], device='cuda:0')),\n","             ('module.layer1.6.conv2.w_zero_point', tensor([[[[-35.]]],\n","              \n","              \n","                      [[[-36.]]],\n","              \n","              \n","                      [[[-31.]]],\n","              \n","              \n","                      [[[-42.]]],\n","              \n","              \n","                      [[[-18.]]],\n","              \n","              \n","                      [[[-38.]]],\n","              \n","              \n","                      [[[-26.]]],\n","              \n","              \n","                      [[[-30.]]],\n","              \n","              \n","                      [[[-35.]]],\n","              \n","              \n","                      [[[-31.]]],\n","              \n","              \n","                      [[[-38.]]],\n","              \n","              \n","                      [[[-29.]]],\n","              \n","              \n","                      [[[-28.]]],\n","              \n","              \n","                      [[[-38.]]],\n","              \n","              \n","                      [[[-34.]]],\n","              \n","              \n","                      [[[-24.]]]], device='cuda:0')),\n","             ('module.layer1.6.conv2.fp_bias',\n","              tensor([-0.3155,  0.3414,  0.2406,  0.8222, -0.1610,  0.5049, -0.2586,  0.0120,\n","                       0.1783, -0.0393,  0.1329,  0.0085,  0.1854,  0.3821, -0.4849,  0.1005],\n","                     device='cuda:0')),\n","             ('module.layer1.6.conv2.accum_scale', tensor([[[ 2598.7402]],\n","              \n","                      [[ 3288.5127]],\n","              \n","                      [[ 3103.0151]],\n","              \n","                      [[ 3647.4475]],\n","              \n","                      [[ 3184.0645]],\n","              \n","                      [[ 3750.9377]],\n","              \n","                      [[ 1216.7010]],\n","              \n","                      [[ 4580.0610]],\n","              \n","                      [[ 6933.8354]],\n","              \n","                      [[15212.6426]],\n","              \n","                      [[11507.8721]],\n","              \n","                      [[31857.9316]],\n","              \n","                      [[ 2380.8574]],\n","              \n","                      [[ 6511.1899]],\n","              \n","                      [[ 2025.4673]],\n","              \n","                      [[ 6858.9019]]], device='cuda:0')),\n","             ('module.layer1.6.conv2.is_simulated_quant_weight_shifted',\n","              tensor(False, device='cuda:0')),\n","             ('module.layer1.6.conv2.wrapped_module.weight',\n","              tensor([[[[43., 43., 26.],\n","                        [52., 32., 20.],\n","                        [45., 38., 37.]],\n","              \n","                       [[18., 33., 51.],\n","                        [ 7., 35., 55.],\n","                        [12., 35., 54.]],\n","              \n","                       [[29., 31., 41.],\n","                        [14., 24., 44.],\n","                        [31., 36., 35.]],\n","              \n","                       ...,\n","              \n","                       [[35., 35., 35.],\n","                        [35., 35., 35.],\n","                        [35., 35., 35.]],\n","              \n","                       [[53., 59., 39.],\n","                        [45., 58., 58.],\n","                        [32., 47., 50.]],\n","              \n","                       [[36., 41., 43.],\n","                        [ 9., 24., 39.],\n","                        [24., 52., 54.]]],\n","              \n","              \n","                      [[[24., 51., 46.],\n","                        [15., 38., 41.],\n","                        [20., 39., 40.]],\n","              \n","                       [[18., 18., 30.],\n","                        [25., 19., 29.],\n","                        [19., 18., 25.]],\n","              \n","                       [[35., 40., 32.],\n","                        [49., 63., 50.],\n","                        [35., 55., 40.]],\n","              \n","                       ...,\n","              \n","                       [[36., 36., 36.],\n","                        [36., 36., 36.],\n","                        [36., 36., 36.]],\n","              \n","                       [[36., 29., 22.],\n","                        [44., 24., 28.],\n","                        [35., 30., 40.]],\n","              \n","                       [[28., 26., 35.],\n","                        [31., 31., 42.],\n","                        [33., 32., 32.]]],\n","              \n","              \n","                      [[[31., 55., 44.],\n","                        [23., 10., 48.],\n","                        [41., 15., 28.]],\n","              \n","                       [[32., 39., 32.],\n","                        [35., 42., 34.],\n","                        [31., 22., 39.]],\n","              \n","                       [[45., 41.,  5.],\n","                        [13., 41., 54.],\n","                        [33., 18., 45.]],\n","              \n","                       ...,\n","              \n","                       [[31., 31., 31.],\n","                        [31., 31., 31.],\n","                        [31., 31., 31.]],\n","              \n","                       [[28.,  8.,  7.],\n","                        [17., 18., 16.],\n","                        [20., 29., 22.]],\n","              \n","                       [[22., 20., 20.],\n","                        [31., 39., 35.],\n","                        [27., 33., 28.]]],\n","              \n","              \n","                      ...,\n","              \n","              \n","                      [[[29., 15., 40.],\n","                        [29., 48., 33.],\n","                        [39., 43., 50.]],\n","              \n","                       [[41., 43., 39.],\n","                        [39., 28., 33.],\n","                        [24., 21., 42.]],\n","              \n","                       [[23., 32., 54.],\n","                        [52., 39., 31.],\n","                        [36., 43., 54.]],\n","              \n","                       ...,\n","              \n","                       [[38., 38., 38.],\n","                        [38., 38., 38.],\n","                        [38., 38., 38.]],\n","              \n","                       [[ 7.,  7., 29.],\n","                        [ 0., 12., 19.],\n","                        [21., 15., 16.]],\n","              \n","                       [[40., 46., 53.],\n","                        [33., 42., 49.],\n","                        [27., 30., 44.]]],\n","              \n","              \n","                      [[[40., 33., 16.],\n","                        [62.,  4., 32.],\n","                        [48., 21., 15.]],\n","              \n","                       [[30., 27., 43.],\n","                        [31., 25., 34.],\n","                        [27., 33., 42.]],\n","              \n","                       [[38., 26., 39.],\n","                        [36., 19., 56.],\n","                        [44., 29., 43.]],\n","              \n","                       ...,\n","              \n","                       [[34., 34., 34.],\n","                        [34., 34., 34.],\n","                        [34., 34., 34.]],\n","              \n","                       [[33., 49., 35.],\n","                        [34., 40., 41.],\n","                        [33., 38., 41.]],\n","              \n","                       [[41., 34., 39.],\n","                        [29., 27., 33.],\n","                        [41., 37., 35.]]],\n","              \n","              \n","                      [[[20., 44., 17.],\n","                        [22., 63., 36.],\n","                        [14., 39., 30.]],\n","              \n","                       [[16., 27., 10.],\n","                        [21., 18., 18.],\n","                        [15., 18.,  9.]],\n","              \n","                       [[30.,  5.,  1.],\n","                        [30., 41., 25.],\n","                        [40., 38., 24.]],\n","              \n","                       ...,\n","              \n","                       [[24., 24., 24.],\n","                        [24., 24., 24.],\n","                        [24., 24., 24.]],\n","              \n","                       [[22.,  7.,  1.],\n","                        [26., 18., 20.],\n","                        [25., 27., 33.]],\n","              \n","                       [[30., 24., 22.],\n","                        [15., 12.,  8.],\n","                        [15., 11., 17.]]]], device='cuda:0')),\n","             ('module.layer1.6.conv2.wrapped_module.bias',\n","              tensor([-820., 1123.,  747., 2999., -513., 1894., -315.,   55., 1237., -597.,\n","                      1529.,  270.,  441., 2488., -982.,  689.], device='cuda:0')),\n","             ('module.layer1.6.relu2.num_forwards',\n","              tensor([40], device='cuda:0')),\n","             ('module.layer1.6.relu2.force_readjust',\n","              tensor(False, device='cuda:0')),\n","             ('module.layer1.6.relu2.output_scale',\n","              tensor([5.6114], device='cuda:0')),\n","             ('module.layer1.6.relu2.output_zero_point',\n","              tensor([0.], device='cuda:0')),\n","             ('module.layer1.6.residual_eltwiseadd.num_forwards',\n","              tensor([40], device='cuda:0')),\n","             ('module.layer1.6.residual_eltwiseadd.force_readjust',\n","              tensor(False, device='cuda:0')),\n","             ('module.layer1.6.residual_eltwiseadd.output_scale',\n","              tensor([5.6114], device='cuda:0')),\n","             ('module.layer1.6.residual_eltwiseadd.output_zero_point',\n","              tensor([0.], device='cuda:0')),\n","             ('module.layer1.7.conv1.num_forwards',\n","              tensor([40], device='cuda:0')),\n","             ('module.layer1.7.conv1.force_readjust',\n","              tensor(False, device='cuda:0')),\n","             ('module.layer1.7.conv1.output_scale',\n","              tensor([25.5958], device='cuda:0')),\n","             ('module.layer1.7.conv1.output_zero_point',\n","              tensor([0.], device='cuda:0')),\n","             ('module.layer1.7.conv1.w_scale', tensor([[[[5.6126e+02]]],\n","              \n","              \n","                      [[[4.0824e+02]]],\n","              \n","              \n","                      [[[2.8042e+02]]],\n","              \n","              \n","                      [[[5.3769e+02]]],\n","              \n","              \n","                      [[[3.2131e+02]]],\n","              \n","              \n","                      [[[3.3504e+02]]],\n","              \n","              \n","                      [[[2.1809e+02]]],\n","              \n","              \n","                      [[[7.3286e+05]]],\n","              \n","              \n","                      [[[3.7039e+02]]],\n","              \n","              \n","                      [[[4.6756e+02]]],\n","              \n","              \n","                      [[[4.1708e+02]]],\n","              \n","              \n","                      [[[4.7263e+02]]],\n","              \n","              \n","                      [[[4.3886e+02]]],\n","              \n","              \n","                      [[[5.7091e+02]]],\n","              \n","              \n","                      [[[3.2649e+02]]],\n","              \n","              \n","                      [[[1.7845e+02]]]], device='cuda:0')),\n","             ('module.layer1.7.conv1.w_zero_point', tensor([[[[-28.]]],\n","              \n","              \n","                      [[[-31.]]],\n","              \n","              \n","                      [[[-30.]]],\n","              \n","              \n","                      [[[-27.]]],\n","              \n","              \n","                      [[[-31.]]],\n","              \n","              \n","                      [[[-36.]]],\n","              \n","              \n","                      [[[-30.]]],\n","              \n","              \n","                      [[[-19.]]],\n","              \n","              \n","                      [[[-31.]]],\n","              \n","              \n","                      [[[-28.]]],\n","              \n","              \n","                      [[[-27.]]],\n","              \n","              \n","                      [[[-33.]]],\n","              \n","              \n","                      [[[-39.]]],\n","              \n","              \n","                      [[[-30.]]],\n","              \n","              \n","                      [[[-31.]]],\n","              \n","              \n","                      [[[-30.]]]], device='cuda:0')),\n","             ('module.layer1.7.conv1.fp_bias',\n","              tensor([-0.2850, -0.1314, -0.6494, -0.0181,  0.1499,  0.0593, -0.4293, -0.0031,\n","                      -0.4750,  0.2260,  0.0419, -0.0828,  0.6380,  0.0742, -0.4524,  0.0504],\n","                     device='cuda:0')),\n","             ('module.layer1.7.conv1.accum_scale', tensor([[[3.1494e+03]],\n","              \n","                      [[2.2908e+03]],\n","              \n","                      [[1.5735e+03]],\n","              \n","                      [[3.0172e+03]],\n","              \n","                      [[1.8030e+03]],\n","              \n","                      [[1.8800e+03]],\n","              \n","                      [[1.2238e+03]],\n","              \n","                      [[4.1124e+06]],\n","              \n","                      [[2.0784e+03]],\n","              \n","                      [[2.6237e+03]],\n","              \n","                      [[2.3404e+03]],\n","              \n","                      [[2.6521e+03]],\n","              \n","                      [[2.4626e+03]],\n","              \n","                      [[3.2036e+03]],\n","              \n","                      [[1.8321e+03]],\n","              \n","                      [[1.0014e+03]]], device='cuda:0')),\n","             ('module.layer1.7.conv1.is_simulated_quant_weight_shifted',\n","              tensor(False, device='cuda:0')),\n","             ('module.layer1.7.conv1.wrapped_module.weight',\n","              tensor([[[[27., 29., 39.],\n","                        [24., 25., 35.],\n","                        [25., 20., 31.]],\n","              \n","                       [[27., 33., 37.],\n","                        [24., 36., 29.],\n","                        [27., 44., 28.]],\n","              \n","                       [[32., 39., 27.],\n","                        [31., 35., 20.],\n","                        [42., 37., 17.]],\n","              \n","                       ...,\n","              \n","                       [[26., 29., 33.],\n","                        [20., 29., 28.],\n","                        [23., 26., 26.]],\n","              \n","                       [[26., 56., 22.],\n","                        [51., 39., 10.],\n","                        [63., 12., 19.]],\n","              \n","                       [[34., 28., 30.],\n","                        [18., 42., 44.],\n","                        [ 3., 40., 37.]]],\n","              \n","              \n","                      [[[23., 28., 31.],\n","                        [25., 26., 33.],\n","                        [24., 26., 36.]],\n","              \n","                       [[30., 32., 35.],\n","                        [30., 33., 34.],\n","                        [32., 33., 32.]],\n","              \n","                       [[27., 32., 38.],\n","                        [40., 28., 31.],\n","                        [37., 40., 33.]],\n","              \n","                       ...,\n","              \n","                       [[39., 36., 24.],\n","                        [23., 29., 26.],\n","                        [29., 25., 22.]],\n","              \n","                       [[38., 43., 30.],\n","                        [26., 34., 32.],\n","                        [35., 24., 29.]],\n","              \n","                       [[29., 20., 31.],\n","                        [48., 39., 34.],\n","                        [32., 47., 42.]]],\n","              \n","              \n","                      [[[25., 26., 30.],\n","                        [24., 31., 31.],\n","                        [30., 27., 29.]],\n","              \n","                       [[31., 32., 31.],\n","                        [36., 36., 33.],\n","                        [32., 31., 33.]],\n","              \n","                       [[36., 33., 28.],\n","                        [35., 38., 38.],\n","                        [38., 36., 30.]],\n","              \n","                       ...,\n","              \n","                       [[29., 27., 27.],\n","                        [36., 32., 29.],\n","                        [25., 28., 30.]],\n","              \n","                       [[37., 23., 27.],\n","                        [23., 30., 32.],\n","                        [29., 31., 24.]],\n","              \n","                       [[23., 33., 25.],\n","                        [25., 26., 26.],\n","                        [42., 44., 42.]]],\n","              \n","              \n","                      ...,\n","              \n","              \n","                      [[[25., 27., 32.],\n","                        [24., 30., 29.],\n","                        [28., 18., 23.]],\n","              \n","                       [[30., 27., 28.],\n","                        [35., 24., 30.],\n","                        [40., 25., 30.]],\n","              \n","                       [[28., 31., 29.],\n","                        [29., 17., 23.],\n","                        [24., 31., 31.]],\n","              \n","                       ...,\n","              \n","                       [[20., 21., 31.],\n","                        [32., 42., 38.],\n","                        [33., 30., 31.]],\n","              \n","                       [[24., 14., 40.],\n","                        [16., 18., 28.],\n","                        [21., 25., 16.]],\n","              \n","                       [[37., 23., 40.],\n","                        [29., 14., 17.],\n","                        [34., 28., 31.]]],\n","              \n","              \n","                      [[[20., 31., 36.],\n","                        [20., 21., 26.],\n","                        [26., 21., 16.]],\n","              \n","                       [[31., 36., 35.],\n","                        [31., 33., 31.],\n","                        [31., 30., 30.]],\n","              \n","                       [[28., 31., 34.],\n","                        [30., 27., 27.],\n","                        [25., 29., 25.]],\n","              \n","                       ...,\n","              \n","                       [[32., 29., 22.],\n","                        [35., 38., 29.],\n","                        [25., 31., 28.]],\n","              \n","                       [[29., 30., 36.],\n","                        [29., 37., 29.],\n","                        [22., 24., 19.]],\n","              \n","                       [[19., 19., 24.],\n","                        [29., 20., 10.],\n","                        [40., 31., 32.]]],\n","              \n","              \n","                      [[[22., 31., 36.],\n","                        [27., 36., 36.],\n","                        [28., 30., 28.]],\n","              \n","                       [[29., 31., 32.],\n","                        [28., 28., 30.],\n","                        [28., 28., 30.]],\n","              \n","                       [[31., 34., 34.],\n","                        [32., 32., 34.],\n","                        [34., 32., 32.]],\n","              \n","                       ...,\n","              \n","                       [[29., 30., 33.],\n","                        [30., 31., 32.],\n","                        [30., 31., 32.]],\n","              \n","                       [[35., 34., 25.],\n","                        [34., 28., 26.],\n","                        [31., 28., 26.]],\n","              \n","                       [[25., 26., 33.],\n","                        [28., 34., 39.],\n","                        [34., 36., 34.]]]], device='cuda:0')),\n","             ('module.layer1.7.conv1.wrapped_module.bias',\n","              tensor([  -898.,   -301.,  -1022.,    -55.,    270.,    111.,   -525., -12778.,\n","                        -987.,    593.,     98.,   -220.,   1571.,    238.,   -829.,     50.],\n","                     device='cuda:0')),\n","             ('module.layer1.7.conv2.num_forwards',\n","              tensor([40], device='cuda:0')),\n","             ('module.layer1.7.conv2.force_readjust',\n","              tensor(False, device='cuda:0')),\n","             ('module.layer1.7.conv2.output_scale',\n","              tensor([9.1349], device='cuda:0')),\n","             ('module.layer1.7.conv2.output_zero_point',\n","              tensor([-29.], device='cuda:0')),\n","             ('module.layer1.7.conv2.w_scale', tensor([[[[121.9840]]],\n","              \n","              \n","                      [[[ 91.3713]]],\n","              \n","              \n","                      [[[ 65.1951]]],\n","              \n","              \n","                      [[[176.2960]]],\n","              \n","              \n","                      [[[453.0634]]],\n","              \n","              \n","                      [[[176.9006]]],\n","              \n","              \n","                      [[[ 50.5107]]],\n","              \n","              \n","                      [[[ 71.7626]]],\n","              \n","              \n","                      [[[315.4856]]],\n","              \n","              \n","                      [[[999.3789]]],\n","              \n","              \n","                      [[[ 88.1482]]],\n","              \n","              \n","                      [[[593.6392]]],\n","              \n","              \n","                      [[[140.2897]]],\n","              \n","              \n","                      [[[ 99.3800]]],\n","              \n","              \n","                      [[[ 58.6156]]],\n","              \n","              \n","                      [[[149.2157]]]], device='cuda:0')),\n","             ('module.layer1.7.conv2.w_zero_point', tensor([[[[-29.]]],\n","              \n","              \n","                      [[[-41.]]],\n","              \n","              \n","                      [[[-28.]]],\n","              \n","              \n","                      [[[-36.]]],\n","              \n","              \n","                      [[[-31.]]],\n","              \n","              \n","                      [[[-38.]]],\n","              \n","              \n","                      [[[-29.]]],\n","              \n","              \n","                      [[[-34.]]],\n","              \n","              \n","                      [[[-38.]]],\n","              \n","              \n","                      [[[-30.]]],\n","              \n","              \n","                      [[[-42.]]],\n","              \n","              \n","                      [[[-45.]]],\n","              \n","              \n","                      [[[-31.]]],\n","              \n","              \n","                      [[[-38.]]],\n","              \n","              \n","                      [[[-28.]]],\n","              \n","              \n","                      [[[-32.]]]], device='cuda:0')),\n","             ('module.layer1.7.conv2.fp_bias',\n","              tensor([-0.2527,  0.9502,  0.1846,  0.4076, -0.0119,  0.2312, -0.4490,  0.8684,\n","                       0.0698,  0.0182,  0.4140,  0.1132, -0.0422,  0.4636,  0.3376,  0.1273],\n","                     device='cuda:0')),\n","             ('module.layer1.7.conv2.accum_scale', tensor([[[ 3122.2737]],\n","              \n","                      [[ 2338.7163]],\n","              \n","                      [[ 1668.7169]],\n","              \n","                      [[ 4512.4297]],\n","              \n","                      [[11596.5010]],\n","              \n","                      [[ 4527.9038]],\n","              \n","                      [[ 1292.8607]],\n","              \n","                      [[ 1836.8177]],\n","              \n","                      [[ 8075.0923]],\n","              \n","                      [[25579.8594]],\n","              \n","                      [[ 2256.2197]],\n","              \n","                      [[15194.6436]],\n","              \n","                      [[ 3590.8223]],\n","              \n","                      [[ 2543.7056]],\n","              \n","                      [[ 1500.3108]],\n","              \n","                      [[ 3819.2886]]], device='cuda:0')),\n","             ('module.layer1.7.conv2.is_simulated_quant_weight_shifted',\n","              tensor(False, device='cuda:0')),\n","             ('module.layer1.7.conv2.wrapped_module.weight',\n","              tensor([[[[24., 46., 28.],\n","                        [40., 44., 28.],\n","                        [41., 32., 23.]],\n","              \n","                       [[30., 24., 22.],\n","                        [27., 25., 40.],\n","                        [29., 23., 47.]],\n","              \n","                       [[17., 22., 48.],\n","                        [ 0., 17., 51.],\n","                        [ 5., 29., 35.]],\n","              \n","                       ...,\n","              \n","                       [[30., 29., 33.],\n","                        [26., 28., 31.],\n","                        [37., 28., 23.]],\n","              \n","                       [[ 8., 13., 45.],\n","                        [15., 13., 57.],\n","                        [28., 44., 41.]],\n","              \n","                       [[11., 39., 39.],\n","                        [10., 55., 58.],\n","                        [18., 44., 32.]]],\n","              \n","              \n","                      [[[40., 31., 33.],\n","                        [42., 33., 36.],\n","                        [36., 48., 49.]],\n","              \n","                       [[42., 32., 21.],\n","                        [37., 24., 31.],\n","                        [44., 21., 21.]],\n","              \n","                       [[47., 41., 44.],\n","                        [43., 40., 33.],\n","                        [34., 31., 33.]],\n","              \n","                       ...,\n","              \n","                       [[38., 36., 48.],\n","                        [43., 38., 45.],\n","                        [47., 42., 41.]],\n","              \n","                       [[34., 30., 48.],\n","                        [39., 10., 18.],\n","                        [34., 30., 35.]],\n","              \n","                       [[38., 40., 41.],\n","                        [49., 42., 37.],\n","                        [59., 53., 45.]]],\n","              \n","              \n","                      [[[24., 19., 25.],\n","                        [29.,  8., 15.],\n","                        [31., 10., 14.]],\n","              \n","                       [[33., 30., 25.],\n","                        [27., 31., 38.],\n","                        [12., 39., 46.]],\n","              \n","                       [[23., 30., 38.],\n","                        [36., 32., 30.],\n","                        [29., 19., 11.]],\n","              \n","                       ...,\n","              \n","                       [[35., 33., 35.],\n","                        [26., 20., 34.],\n","                        [20., 39., 30.]],\n","              \n","                       [[28., 36., 42.],\n","                        [24., 40., 38.],\n","                        [23., 30., 40.]],\n","              \n","                       [[13.,  8., 19.],\n","                        [24.,  8.,  9.],\n","                        [34., 20.,  9.]]],\n","              \n","              \n","                      ...,\n","              \n","              \n","                      [[[25., 26., 39.],\n","                        [22., 11., 34.],\n","                        [22., 20., 29.]],\n","              \n","                       [[34., 42., 41.],\n","                        [37., 44., 50.],\n","                        [38., 34., 33.]],\n","              \n","                       [[47., 36., 23.],\n","                        [39., 25., 40.],\n","                        [37., 26., 18.]],\n","              \n","                       ...,\n","              \n","                       [[34., 34., 34.],\n","                        [53., 44., 33.],\n","                        [43., 26., 32.]],\n","              \n","                       [[54., 55., 51.],\n","                        [45., 46., 46.],\n","                        [34., 35., 47.]],\n","              \n","                       [[13., 24., 29.],\n","                        [31., 34., 31.],\n","                        [41., 34., 38.]]],\n","              \n","              \n","                      [[[29., 24., 24.],\n","                        [32., 32., 24.],\n","                        [32., 26., 28.]],\n","              \n","                       [[21., 25., 30.],\n","                        [27., 22., 35.],\n","                        [29., 27., 31.]],\n","              \n","                       [[33., 29., 26.],\n","                        [34., 28., 16.],\n","                        [25., 18., 21.]],\n","              \n","                       ...,\n","              \n","                       [[26., 29., 22.],\n","                        [34., 28., 15.],\n","                        [31., 36., 10.]],\n","              \n","                       [[31., 29., 28.],\n","                        [35., 31., 22.],\n","                        [38., 29., 26.]],\n","              \n","                       [[35., 26., 24.],\n","                        [28., 31., 32.],\n","                        [21., 22., 30.]]],\n","              \n","              \n","                      [[[27., 37., 48.],\n","                        [27., 37., 42.],\n","                        [21., 38., 45.]],\n","              \n","                       [[32., 18., 29.],\n","                        [33., 29., 20.],\n","                        [28., 25., 24.]],\n","              \n","                       [[ 0., 20., 33.],\n","                        [ 5.,  4., 36.],\n","                        [19., 15., 19.]],\n","              \n","                       ...,\n","              \n","                       [[40., 30., 24.],\n","                        [26., 35., 43.],\n","                        [26., 25., 31.]],\n","              \n","                       [[19., 25., 21.],\n","                        [21., 26., 29.],\n","                        [23., 22., 13.]],\n","              \n","                       [[24., 34., 36.],\n","                        [38., 25., 21.],\n","                        [30., 34., 24.]]]], device='cuda:0')),\n","             ('module.layer1.7.conv2.wrapped_module.bias',\n","              tensor([-789., 2222.,  308., 1839., -138., 1047., -581., 1595.,  563.,  466.,\n","                       934., 1721., -151., 1179.,  506.,  486.], device='cuda:0')),\n","             ('module.layer1.7.relu2.num_forwards',\n","              tensor([40], device='cuda:0')),\n","             ('module.layer1.7.relu2.force_readjust',\n","              tensor(False, device='cuda:0')),\n","             ('module.layer1.7.relu2.output_scale',\n","              tensor([5.4430], device='cuda:0')),\n","             ('module.layer1.7.relu2.output_zero_point',\n","              tensor([0.], device='cuda:0')),\n","             ('module.layer1.7.residual_eltwiseadd.num_forwards',\n","              tensor([40], device='cuda:0')),\n","             ('module.layer1.7.residual_eltwiseadd.force_readjust',\n","              tensor(False, device='cuda:0')),\n","             ('module.layer1.7.residual_eltwiseadd.output_scale',\n","              tensor([5.4430], device='cuda:0')),\n","             ('module.layer1.7.residual_eltwiseadd.output_zero_point',\n","              tensor([0.], device='cuda:0')),\n","             ('module.layer1.8.conv1.num_forwards',\n","              tensor([40], device='cuda:0')),\n","             ('module.layer1.8.conv1.force_readjust',\n","              tensor(False, device='cuda:0')),\n","             ('module.layer1.8.conv1.output_scale',\n","              tensor([20.1206], device='cuda:0')),\n","             ('module.layer1.8.conv1.output_zero_point',\n","              tensor([0.], device='cuda:0')),\n","             ('module.layer1.8.conv1.w_scale', tensor([[[[1.1764e+03]]],\n","              \n","              \n","                      [[[9.0456e+02]]],\n","              \n","              \n","                      [[[1.7164e+02]]],\n","              \n","              \n","                      [[[3.9779e+02]]],\n","              \n","              \n","                      [[[3.4045e+02]]],\n","              \n","              \n","                      [[[2.8881e+06]]],\n","              \n","              \n","                      [[[2.1520e+02]]],\n","              \n","              \n","                      [[[2.2636e+02]]],\n","              \n","              \n","                      [[[3.4235e+02]]],\n","              \n","              \n","                      [[[2.9016e+02]]],\n","              \n","              \n","                      [[[3.2985e+02]]],\n","              \n","              \n","                      [[[4.6076e+02]]],\n","              \n","              \n","                      [[[2.7219e+02]]],\n","              \n","              \n","                      [[[3.5298e+02]]],\n","              \n","              \n","                      [[[6.0893e+05]]],\n","              \n","              \n","                      [[[3.3342e+05]]]], device='cuda:0')),\n","             ('module.layer1.8.conv1.w_zero_point', tensor([[[[-34.]]],\n","              \n","              \n","                      [[[-39.]]],\n","              \n","              \n","                      [[[-32.]]],\n","              \n","              \n","                      [[[-31.]]],\n","              \n","              \n","                      [[[-28.]]],\n","              \n","              \n","                      [[[ -8.]]],\n","              \n","              \n","                      [[[-31.]]],\n","              \n","              \n","                      [[[-38.]]],\n","              \n","              \n","                      [[[-32.]]],\n","              \n","              \n","                      [[[-36.]]],\n","              \n","              \n","                      [[[-31.]]],\n","              \n","              \n","                      [[[-22.]]],\n","              \n","              \n","                      [[[-44.]]],\n","              \n","              \n","                      [[[-30.]]],\n","              \n","              \n","                      [[[-38.]]],\n","              \n","              \n","                      [[[-32.]]]], device='cuda:0')),\n","             ('module.layer1.8.conv1.fp_bias',\n","              tensor([ 4.3502e-01,  9.0834e-01,  1.8020e-01, -2.3086e-01, -7.9125e-02,\n","                      -2.7617e-03, -4.0597e-01,  1.1646e-01, -6.8226e-01,  1.6747e-01,\n","                      -5.9856e-01, -6.8906e-01,  3.1833e-01, -1.1924e+00,  2.8335e-05,\n","                      -1.3006e-03], device='cuda:0')),\n","             ('module.layer1.8.conv1.accum_scale', tensor([[[6.4034e+03]],\n","              \n","                      [[4.9235e+03]],\n","              \n","                      [[9.3425e+02]],\n","              \n","                      [[2.1652e+03]],\n","              \n","                      [[1.8531e+03]],\n","              \n","                      [[1.5720e+07]],\n","              \n","                      [[1.1714e+03]],\n","              \n","                      [[1.2321e+03]],\n","              \n","                      [[1.8634e+03]],\n","              \n","                      [[1.5793e+03]],\n","              \n","                      [[1.7954e+03]],\n","              \n","                      [[2.5079e+03]],\n","              \n","                      [[1.4815e+03]],\n","              \n","                      [[1.9213e+03]],\n","              \n","                      [[3.3144e+06]],\n","              \n","                      [[1.8148e+06]]], device='cuda:0')),\n","             ('module.layer1.8.conv1.is_simulated_quant_weight_shifted',\n","              tensor(False, device='cuda:0')),\n","             ('module.layer1.8.conv1.wrapped_module.weight',\n","              tensor([[[[24., 28., 27.],\n","                        [25., 23., 20.],\n","                        [24., 18., 20.]],\n","              \n","                       [[51., 57., 54.],\n","                        [50., 56., 57.],\n","                        [45., 56., 57.]],\n","              \n","                       [[29., 33., 34.],\n","                        [17., 19., 26.],\n","                        [22., 28., 27.]],\n","              \n","                       ...,\n","              \n","                       [[24., 31., 31.],\n","                        [24., 33., 30.],\n","                        [19., 30., 39.]],\n","              \n","                       [[31., 40., 30.],\n","                        [19., 18., 13.],\n","                        [ 6.,  3.,  7.]],\n","              \n","                       [[36., 28., 36.],\n","                        [41., 26., 22.],\n","                        [47., 33., 27.]]],\n","              \n","              \n","                      [[[25., 38., 30.],\n","                        [26., 33., 26.],\n","                        [35., 36., 31.]],\n","              \n","                       [[50., 59., 58.],\n","                        [51., 61., 63.],\n","                        [46., 62., 62.]],\n","              \n","                       [[40., 39., 40.],\n","                        [40., 41., 39.],\n","                        [37., 35., 28.]],\n","              \n","                       ...,\n","              \n","                       [[29., 27., 27.],\n","                        [17., 23., 27.],\n","                        [23., 36., 42.]],\n","              \n","                       [[32., 36., 38.],\n","                        [17., 11., 16.],\n","                        [13.,  9., 21.]],\n","              \n","                       [[37., 21., 23.],\n","                        [28., 10.,  0.],\n","                        [38., 29., 21.]]],\n","              \n","              \n","                      [[[35., 32., 26.],\n","                        [25., 33., 31.],\n","                        [20., 30., 32.]],\n","              \n","                       [[23., 32., 35.],\n","                        [23., 32., 36.],\n","                        [25., 28., 35.]],\n","              \n","                       [[24., 26., 35.],\n","                        [32., 35., 36.],\n","                        [27., 31., 36.]],\n","              \n","                       ...,\n","              \n","                       [[29., 29., 35.],\n","                        [36., 29., 34.],\n","                        [36., 29., 27.]],\n","              \n","                       [[26., 32., 29.],\n","                        [34., 35., 27.],\n","                        [28., 32., 25.]],\n","              \n","                       [[27., 34., 39.],\n","                        [27., 32., 35.],\n","                        [25., 27., 30.]]],\n","              \n","              \n","                      ...,\n","              \n","              \n","                      [[[25., 33., 24.],\n","                        [26., 44., 28.],\n","                        [21., 32., 31.]],\n","              \n","                       [[26., 26., 45.],\n","                        [26., 24., 40.],\n","                        [24., 26., 41.]],\n","              \n","                       [[32., 36., 34.],\n","                        [33., 35., 31.],\n","                        [40., 30., 45.]],\n","              \n","                       ...,\n","              \n","                       [[33., 28., 39.],\n","                        [35., 30., 40.],\n","                        [37., 37., 34.]],\n","              \n","                       [[11., 54.,  6.],\n","                        [14., 63.,  3.],\n","                        [ 2., 38., 10.]],\n","              \n","                       [[45., 20., 29.],\n","                        [39., 22., 44.],\n","                        [27., 22., 41.]]],\n","              \n","              \n","                      [[[25.,  1., 29.],\n","                        [19., 12., 29.],\n","                        [43., 20., 25.]],\n","              \n","                       [[52., 34., 24.],\n","                        [44., 37., 33.],\n","                        [26., 32., 52.]],\n","              \n","                       [[53., 33., 29.],\n","                        [42., 41., 50.],\n","                        [35., 47., 32.]],\n","              \n","                       ...,\n","              \n","                       [[30., 50., 35.],\n","                        [42., 15., 34.],\n","                        [51., 46., 41.]],\n","              \n","                       [[35., 30., 20.],\n","                        [42., 51., 32.],\n","                        [27., 38., 32.]],\n","              \n","                       [[18., 13.,  0.],\n","                        [24., 23., 20.],\n","                        [26., 25., 14.]]],\n","              \n","              \n","                      [[[26., 34., 32.],\n","                        [33., 37., 43.],\n","                        [42., 33., 38.]],\n","              \n","                       [[44., 31., 48.],\n","                        [39., 38., 29.],\n","                        [22., 32., 29.]],\n","              \n","                       [[20., 17., 18.],\n","                        [ 8.,  8., 20.],\n","                        [ 7., 12., 13.]],\n","              \n","                       ...,\n","              \n","                       [[23., 41., 39.],\n","                        [26., 38., 34.],\n","                        [28., 39., 45.]],\n","              \n","                       [[50., 37., 34.],\n","                        [38., 39., 48.],\n","                        [39., 26., 38.]],\n","              \n","                       [[ 7.,  7., 13.],\n","                        [ 6.,  8., 17.],\n","                        [17., 35., 31.]]]], device='cuda:0')),\n","             ('module.layer1.8.conv1.wrapped_module.bias',\n","              tensor([  2786.,   4472.,    168.,   -500.,   -147., -43413.,   -476.,    143.,\n","                       -1271.,    264.,  -1075.,  -1728.,    472.,  -2291.,     94.,  -2360.],\n","                     device='cuda:0')),\n","             ('module.layer1.8.conv2.num_forwards',\n","              tensor([40], device='cuda:0')),\n","             ('module.layer1.8.conv2.force_readjust',\n","              tensor(False, device='cuda:0')),\n","             ('module.layer1.8.conv2.output_scale',\n","              tensor([5.9507], device='cuda:0')),\n","             ('module.layer1.8.conv2.output_zero_point',\n","              tensor([-27.], device='cuda:0')),\n","             ('module.layer1.8.conv2.w_scale', tensor([[[[ 126.1161]]],\n","              \n","              \n","                      [[[  98.7186]]],\n","              \n","              \n","                      [[[  71.1053]]],\n","              \n","              \n","                      [[[ 131.3045]]],\n","              \n","              \n","                      [[[1868.1150]]],\n","              \n","              \n","                      [[[ 212.2259]]],\n","              \n","              \n","                      [[[  53.9235]]],\n","              \n","              \n","                      [[[  61.7490]]],\n","              \n","              \n","                      [[[ 132.4540]]],\n","              \n","              \n","                      [[[ 432.1204]]],\n","              \n","              \n","                      [[[ 104.3843]]],\n","              \n","              \n","                      [[[ 263.3186]]],\n","              \n","              \n","                      [[[ 193.5260]]],\n","              \n","              \n","                      [[[  92.3248]]],\n","              \n","              \n","                      [[[  85.2024]]],\n","              \n","              \n","                      [[[ 169.4523]]]], device='cuda:0')),\n","             ('module.layer1.8.conv2.w_zero_point', tensor([[[[-24.]]],\n","              \n","              \n","                      [[[-47.]]],\n","              \n","              \n","                      [[[-29.]]],\n","              \n","              \n","                      [[[-42.]]],\n","              \n","              \n","                      [[[-29.]]],\n","              \n","              \n","                      [[[-28.]]],\n","              \n","              \n","                      [[[-22.]]],\n","              \n","              \n","                      [[[-29.]]],\n","              \n","              \n","                      [[[-37.]]],\n","              \n","              \n","                      [[[-25.]]],\n","              \n","              \n","                      [[[-43.]]],\n","              \n","              \n","                      [[[-39.]]],\n","              \n","              \n","                      [[[-43.]]],\n","              \n","              \n","                      [[[-32.]]],\n","              \n","              \n","                      [[[-25.]]],\n","              \n","              \n","                      [[[-38.]]]], device='cuda:0')),\n","             ('module.layer1.8.conv2.fp_bias',\n","              tensor([-0.3813,  1.3179,  0.1555,  0.6950,  0.0586, -0.1358, -0.9327,  1.2728,\n","                       0.0248,  0.0032,  1.1431,  0.2391,  0.0766,  0.6512, -0.0077,  0.0747],\n","                     device='cuda:0')),\n","             ('module.layer1.8.conv2.accum_scale', tensor([[[ 2537.5334]],\n","              \n","                      [[ 1986.2788]],\n","              \n","                      [[ 1430.6826]],\n","              \n","                      [[ 2641.9280]],\n","              \n","                      [[37587.6289]],\n","              \n","                      [[ 4270.1157]],\n","              \n","                      [[ 1084.9744]],\n","              \n","                      [[ 1242.4281]],\n","              \n","                      [[ 2665.0574]],\n","              \n","                      [[ 8694.5293]],\n","              \n","                      [[ 2100.2773]],\n","              \n","                      [[ 5298.1333]],\n","              \n","                      [[ 3893.8628]],\n","              \n","                      [[ 1857.6324]],\n","              \n","                      [[ 1714.3253]],\n","              \n","                      [[ 3409.4851]]], device='cuda:0')),\n","             ('module.layer1.8.conv2.is_simulated_quant_weight_shifted',\n","              tensor(False, device='cuda:0')),\n","             ('module.layer1.8.conv2.wrapped_module.weight',\n","              tensor([[[[21., 21., 21.],\n","                        [22., 22., 22.],\n","                        [22., 21., 22.]],\n","              \n","                       [[17., 19., 20.],\n","                        [19., 19., 19.],\n","                        [18., 17., 19.]],\n","              \n","                       [[35., 46., 39.],\n","                        [48., 63., 50.],\n","                        [39., 35., 35.]],\n","              \n","                       ...,\n","              \n","                       [[10.,  5.,  3.],\n","                        [32., 28., 25.],\n","                        [30., 15., 34.]],\n","              \n","                       [[24., 24., 24.],\n","                        [24., 24., 24.],\n","                        [24., 24., 24.]],\n","              \n","                       [[24., 24., 24.],\n","                        [24., 24., 24.],\n","                        [24., 24., 24.]]],\n","              \n","              \n","                      [[[44., 48., 46.],\n","                        [42., 46., 44.],\n","                        [46., 49., 45.]],\n","              \n","                       [[47., 52., 50.],\n","                        [45., 51., 50.],\n","                        [43., 49., 48.]],\n","              \n","                       [[43., 39., 49.],\n","                        [53., 44., 50.],\n","                        [58., 57., 52.]],\n","              \n","                       ...,\n","              \n","                       [[49., 49., 40.],\n","                        [53., 60., 42.],\n","                        [40., 47., 38.]],\n","              \n","                       [[47., 47., 47.],\n","                        [47., 47., 47.],\n","                        [47., 47., 47.]],\n","              \n","                       [[47., 47., 47.],\n","                        [47., 47., 47.],\n","                        [47., 47., 47.]]],\n","              \n","              \n","                      [[[30., 29., 30.],\n","                        [32., 32., 32.],\n","                        [32., 31., 31.]],\n","              \n","                       [[29., 28., 28.],\n","                        [31., 30., 30.],\n","                        [30., 28., 28.]],\n","              \n","                       [[26., 29., 31.],\n","                        [25., 31., 39.],\n","                        [21., 31., 36.]],\n","              \n","                       ...,\n","              \n","                       [[33., 29., 17.],\n","                        [25., 23., 18.],\n","                        [31., 20., 25.]],\n","              \n","                       [[29., 29., 29.],\n","                        [29., 29., 29.],\n","                        [29., 29., 29.]],\n","              \n","                       [[29., 29., 29.],\n","                        [29., 29., 29.],\n","                        [29., 29., 29.]]],\n","              \n","              \n","                      ...,\n","              \n","              \n","                      [[[27., 25., 26.],\n","                        [30., 29., 29.],\n","                        [33., 31., 31.]],\n","              \n","                       [[29., 25., 25.],\n","                        [27., 23., 24.],\n","                        [30., 24., 24.]],\n","              \n","                       [[47., 55., 50.],\n","                        [43., 53., 40.],\n","                        [27., 46., 39.]],\n","              \n","                       ...,\n","              \n","                       [[29., 27., 29.],\n","                        [ 8.,  5., 16.],\n","                        [ 9.,  0., 14.]],\n","              \n","                       [[32., 32., 32.],\n","                        [32., 32., 32.],\n","                        [32., 32., 32.]],\n","              \n","                       [[32., 32., 32.],\n","                        [32., 32., 32.],\n","                        [32., 32., 32.]]],\n","              \n","              \n","                      [[[27., 27., 26.],\n","                        [26., 27., 26.],\n","                        [27., 27., 25.]],\n","              \n","                       [[25., 24., 23.],\n","                        [24., 23., 21.],\n","                        [25., 24., 22.]],\n","              \n","                       [[14., 21., 28.],\n","                        [24., 26., 28.],\n","                        [22., 18., 19.]],\n","              \n","                       ...,\n","              \n","                       [[22.,  0., 12.],\n","                        [40.,  4., 27.],\n","                        [33.,  5., 26.]],\n","              \n","                       [[25., 25., 25.],\n","                        [25., 25., 25.],\n","                        [25., 25., 25.]],\n","              \n","                       [[25., 25., 25.],\n","                        [25., 25., 25.],\n","                        [25., 25., 25.]]],\n","              \n","              \n","                      [[[36., 34., 35.],\n","                        [35., 32., 31.],\n","                        [35., 33., 32.]],\n","              \n","                       [[36., 34., 37.],\n","                        [32., 29., 30.],\n","                        [30., 28., 28.]],\n","              \n","                       [[45., 54., 47.],\n","                        [43., 52., 51.],\n","                        [34., 49., 48.]],\n","              \n","                       ...,\n","              \n","                       [[36., 63., 35.],\n","                        [22., 58., 34.],\n","                        [14., 44., 28.]],\n","              \n","                       [[38., 38., 38.],\n","                        [38., 38., 38.],\n","                        [38., 38., 38.]],\n","              \n","                       [[38., 38., 38.],\n","                        [38., 38., 38.],\n","                        [38., 38., 38.]]]], device='cuda:0')),\n","             ('module.layer1.8.conv2.wrapped_module.bias',\n","              tensor([ -968.,  2618.,   222.,  1836.,  2204.,  -580., -1012.,  1581.,    66.,\n","                         28.,  2401.,  1267.,   298.,  1210.,   -13.,   255.],\n","                     device='cuda:0')),\n","             ('module.layer1.8.relu2.num_forwards',\n","              tensor([40], device='cuda:0')),\n","             ('module.layer1.8.relu2.force_readjust',\n","              tensor(False, device='cuda:0')),\n","             ('module.layer1.8.relu2.output_scale',\n","              tensor([7.2012], device='cuda:0')),\n","             ('module.layer1.8.relu2.output_zero_point',\n","              tensor([0.], device='cuda:0')),\n","             ('module.layer1.8.residual_eltwiseadd.num_forwards',\n","              tensor([40], device='cuda:0')),\n","             ('module.layer1.8.residual_eltwiseadd.force_readjust',\n","              tensor(False, device='cuda:0')),\n","             ('module.layer1.8.residual_eltwiseadd.output_scale',\n","              tensor([7.2012], device='cuda:0')),\n","             ('module.layer1.8.residual_eltwiseadd.output_zero_point',\n","              tensor([0.], device='cuda:0')),\n","             ('module.layer2.0.conv1.num_forwards',\n","              tensor([40], device='cuda:0')),\n","             ('module.layer2.0.conv1.force_readjust',\n","              tensor(False, device='cuda:0')),\n","             ('module.layer2.0.conv1.output_scale',\n","              tensor([22.4956], device='cuda:0')),\n","             ('module.layer2.0.conv1.output_zero_point',\n","              tensor([0.], device='cuda:0')),\n","             ('module.layer2.0.conv1.w_scale', tensor([[[[511.6422]]],\n","              \n","              \n","                      [[[574.3472]]],\n","              \n","              \n","                      [[[499.4911]]],\n","              \n","              \n","                      [[[410.6469]]],\n","              \n","              \n","                      [[[396.6120]]],\n","              \n","              \n","                      [[[326.8914]]],\n","              \n","              \n","                      [[[435.7282]]],\n","              \n","              \n","                      [[[383.8489]]],\n","              \n","              \n","                      [[[420.6682]]],\n","              \n","              \n","                      [[[375.0262]]],\n","              \n","              \n","                      [[[474.1515]]],\n","              \n","              \n","                      [[[418.7980]]],\n","              \n","              \n","                      [[[356.7230]]],\n","              \n","              \n","                      [[[480.2847]]],\n","              \n","              \n","                      [[[434.4331]]],\n","              \n","              \n","                      [[[587.6644]]],\n","              \n","              \n","                      [[[349.8592]]],\n","              \n","              \n","                      [[[378.5166]]],\n","              \n","              \n","                      [[[574.6216]]],\n","              \n","              \n","                      [[[520.2092]]],\n","              \n","              \n","                      [[[407.8553]]],\n","              \n","              \n","                      [[[272.6594]]],\n","              \n","              \n","                      [[[515.8693]]],\n","              \n","              \n","                      [[[390.7837]]],\n","              \n","              \n","                      [[[461.7543]]],\n","              \n","              \n","                      [[[609.0986]]],\n","              \n","              \n","                      [[[233.4442]]],\n","              \n","              \n","                      [[[389.1316]]],\n","              \n","              \n","                      [[[437.7423]]],\n","              \n","              \n","                      [[[682.0997]]],\n","              \n","              \n","                      [[[418.2844]]],\n","              \n","              \n","                      [[[504.2938]]]], device='cuda:0')),\n","             ('module.layer2.0.conv1.w_zero_point', tensor([[[[-31.]]],\n","              \n","              \n","                      [[[-36.]]],\n","              \n","              \n","                      [[[-29.]]],\n","              \n","              \n","                      [[[-29.]]],\n","              \n","              \n","                      [[[-31.]]],\n","              \n","              \n","                      [[[-35.]]],\n","              \n","              \n","                      [[[-27.]]],\n","              \n","              \n","                      [[[-26.]]],\n","              \n","              \n","                      [[[-32.]]],\n","              \n","              \n","                      [[[-32.]]],\n","              \n","              \n","                      [[[-23.]]],\n","              \n","              \n","                      [[[-31.]]],\n","              \n","              \n","                      [[[-33.]]],\n","              \n","              \n","                      [[[-26.]]],\n","              \n","              \n","                      [[[-28.]]],\n","              \n","              \n","                      [[[-26.]]],\n","              \n","              \n","                      [[[-40.]]],\n","              \n","              \n","                      [[[-37.]]],\n","              \n","              \n","                      [[[-29.]]],\n","              \n","              \n","                      [[[-29.]]],\n","              \n","              \n","                      [[[-24.]]],\n","              \n","              \n","                      [[[-41.]]],\n","              \n","              \n","                      [[[-31.]]],\n","              \n","              \n","                      [[[-30.]]],\n","              \n","              \n","                      [[[-27.]]],\n","              \n","              \n","                      [[[-27.]]],\n","              \n","              \n","                      [[[-28.]]],\n","              \n","              \n","                      [[[-35.]]],\n","              \n","              \n","                      [[[-20.]]],\n","              \n","              \n","                      [[[-28.]]],\n","              \n","              \n","                      [[[-31.]]],\n","              \n","              \n","                      [[[-29.]]]], device='cuda:0')),\n","             ('module.layer2.0.conv1.fp_bias',\n","              tensor([-0.3136,  0.1518, -1.2373, -1.2207, -0.0150, -0.7198,  0.1807, -0.2573,\n","                      -1.5213,  0.7615, -0.6818,  0.5184, -0.0434, -0.3644, -0.5792,  0.6989,\n","                       1.5584, -0.9078,  0.6930,  1.9755, -0.2126,  0.1413, -0.5672,  0.0220,\n","                       0.0268, -1.0482, -0.6446,  0.1230, -1.8327,  0.1207, -2.1183,  1.8732],\n","                     device='cuda:0')),\n","             ('module.layer2.0.conv1.accum_scale', tensor([[[3684.4189]],\n","              \n","                      [[4135.9678]],\n","              \n","                      [[3596.9165]],\n","              \n","                      [[2957.1353]],\n","              \n","                      [[2856.0671]],\n","              \n","                      [[2353.9983]],\n","              \n","                      [[3137.7498]],\n","              \n","                      [[2764.1584]],\n","              \n","                      [[3029.2998]],\n","              \n","                      [[2700.6248]],\n","              \n","                      [[3414.4419]],\n","              \n","                      [[3015.8323]],\n","              \n","                      [[2568.8201]],\n","              \n","                      [[3458.6082]],\n","              \n","                      [[3128.4233]],\n","              \n","                      [[4231.8667]],\n","              \n","                      [[2519.3926]],\n","              \n","                      [[2725.7595]],\n","              \n","                      [[4137.9438]],\n","              \n","                      [[3746.1111]],\n","              \n","                      [[2937.0322]],\n","              \n","                      [[1963.4646]],\n","              \n","                      [[3714.8586]],\n","              \n","                      [[2814.0969]],\n","              \n","                      [[3325.1677]],\n","              \n","                      [[4386.2183]],\n","              \n","                      [[1681.0695]],\n","              \n","                      [[2802.2000]],\n","              \n","                      [[3152.2534]],\n","              \n","                      [[4911.9106]],\n","              \n","                      [[3012.1338]],\n","              \n","                      [[3631.5015]]], device='cuda:0')),\n","             ('module.layer2.0.conv1.is_simulated_quant_weight_shifted',\n","              tensor(False, device='cuda:0')),\n","             ('module.layer2.0.conv1.wrapped_module.weight',\n","              tensor([[[[48., 30., 18.],\n","                        [31.,  8., 30.],\n","                        [24., 24., 35.]],\n","              \n","                       [[27., 20., 16.],\n","                        [20., 19., 28.],\n","                        [13., 26., 36.]],\n","              \n","                       [[24., 19., 39.],\n","                        [20., 37., 49.],\n","                        [38., 44., 45.]],\n","              \n","                       ...,\n","              \n","                       [[35., 37., 29.],\n","                        [39., 26.,  7.],\n","                        [22., 13., 21.]],\n","              \n","                       [[63., 43., 39.],\n","                        [35.,  2., 32.],\n","                        [23., 37., 46.]],\n","              \n","                       [[25., 27., 25.],\n","                        [37., 35., 44.],\n","                        [37., 27., 40.]]],\n","              \n","              \n","                      [[[20., 14., 22.],\n","                        [15., 22., 29.],\n","                        [21., 18., 35.]],\n","              \n","                       [[24., 22., 18.],\n","                        [27., 31., 19.],\n","                        [29., 26., 18.]],\n","              \n","                       [[37., 38., 41.],\n","                        [42., 35., 36.],\n","                        [47., 40., 48.]],\n","              \n","                       ...,\n","              \n","                       [[30., 30., 33.],\n","                        [29., 35., 39.],\n","                        [37., 42., 45.]],\n","              \n","                       [[21., 15., 30.],\n","                        [ 0., 28., 21.],\n","                        [15.,  9., 31.]],\n","              \n","                       [[45., 34., 39.],\n","                        [43., 35., 43.],\n","                        [33., 32., 37.]]],\n","              \n","              \n","                      [[[34., 41., 30.],\n","                        [37., 38., 32.],\n","                        [39., 37., 32.]],\n","              \n","                       [[46., 45., 49.],\n","                        [53., 42., 49.],\n","                        [42., 43., 44.]],\n","              \n","                       [[11., 26., 33.],\n","                        [15., 26., 30.],\n","                        [ 8., 21., 25.]],\n","              \n","                       ...,\n","              \n","                       [[18., 26., 33.],\n","                        [16., 23., 25.],\n","                        [25., 26., 25.]],\n","              \n","                       [[23., 26., 23.],\n","                        [22., 19., 16.],\n","                        [11.,  1., 19.]],\n","              \n","                       [[39., 40., 42.],\n","                        [34., 37., 37.],\n","                        [25., 20., 20.]]],\n","              \n","              \n","                      ...,\n","              \n","              \n","                      [[[26., 19., 12.],\n","                        [27., 28.,  9.],\n","                        [30., 19., 16.]],\n","              \n","                       [[ 0.,  7.,  4.],\n","                        [13., 16., 14.],\n","                        [28., 27., 18.]],\n","              \n","                       [[54., 49., 36.],\n","                        [45., 43., 47.],\n","                        [47., 56., 52.]],\n","              \n","                       ...,\n","              \n","                       [[41., 44., 33.],\n","                        [31., 22., 36.],\n","                        [17., 25., 39.]],\n","              \n","                       [[15., 10., 18.],\n","                        [10., 23., 13.],\n","                        [30., 13., 16.]],\n","              \n","                       [[41., 40., 38.],\n","                        [52., 40., 42.],\n","                        [49., 57., 48.]]],\n","              \n","              \n","                      [[[33., 34., 17.],\n","                        [32., 26., 23.],\n","                        [17., 22., 29.]],\n","              \n","                       [[22., 23., 23.],\n","                        [19., 31., 46.],\n","                        [27., 43., 58.]],\n","              \n","                       [[28., 25., 40.],\n","                        [31., 45., 45.],\n","                        [34., 35., 41.]],\n","              \n","                       ...,\n","              \n","                       [[16., 13.,  9.],\n","                        [14., 23., 15.],\n","                        [25., 25., 36.]],\n","              \n","                       [[26., 23., 12.],\n","                        [29., 31., 40.],\n","                        [52., 50., 37.]],\n","              \n","                       [[34., 40., 43.],\n","                        [34., 33., 25.],\n","                        [17., 28., 29.]]],\n","              \n","              \n","                      [[[ 7.,  5.,  6.],\n","                        [22., 23., 13.],\n","                        [38., 29., 25.]],\n","              \n","                       [[25., 16., 23.],\n","                        [26., 21., 31.],\n","                        [22., 21., 27.]],\n","              \n","                       [[26., 17., 20.],\n","                        [29., 22., 22.],\n","                        [44., 19., 22.]],\n","              \n","                       ...,\n","              \n","                       [[28., 27., 27.],\n","                        [36., 32., 23.],\n","                        [35., 34., 35.]],\n","              \n","                       [[12.,  1., 11.],\n","                        [ 5., 10.,  5.],\n","                        [23.,  5., 13.]],\n","              \n","                       [[18., 23., 25.],\n","                        [25., 27., 17.],\n","                        [39., 32., 14.]]]], device='cuda:0')),\n","             ('module.layer2.0.conv1.wrapped_module.bias',\n","              tensor([-1155.,   628., -4450., -3610.,   -43., -1694.,   567.,  -711., -4608.,\n","                       2056., -2328.,  1564.,  -111., -1260., -1812.,  2958.,  3926., -2474.,\n","                       2867.,  7400.,  -624.,   277., -2107.,    62.,    89., -4598., -1084.,\n","                        345., -5777.,   593., -6381.,  6802.], device='cuda:0')),\n","             ('module.layer2.0.conv2.num_forwards',\n","              tensor([40], device='cuda:0')),\n","             ('module.layer2.0.conv2.force_readjust',\n","              tensor(False, device='cuda:0')),\n","             ('module.layer2.0.conv2.output_scale',\n","              tensor([7.3352], device='cuda:0')),\n","             ('module.layer2.0.conv2.output_zero_point',\n","              tensor([-27.], device='cuda:0')),\n","             ('module.layer2.0.conv2.w_scale', tensor([[[[2.9083e+02]]],\n","              \n","              \n","                      [[[1.4203e+02]]],\n","              \n","              \n","                      [[[1.1540e+02]]],\n","              \n","              \n","                      [[[1.0102e+02]]],\n","              \n","              \n","                      [[[1.0414e+02]]],\n","              \n","              \n","                      [[[1.0525e+02]]],\n","              \n","              \n","                      [[[9.6921e+01]]],\n","              \n","              \n","                      [[[1.1724e+02]]],\n","              \n","              \n","                      [[[1.2453e+02]]],\n","              \n","              \n","                      [[[1.4828e+02]]],\n","              \n","              \n","                      [[[6.7202e+01]]],\n","              \n","              \n","                      [[[1.4518e+02]]],\n","              \n","              \n","                      [[[8.8903e+01]]],\n","              \n","              \n","                      [[[1.8122e+02]]],\n","              \n","              \n","                      [[[1.3770e+02]]],\n","              \n","              \n","                      [[[1.6860e+02]]],\n","              \n","              \n","                      [[[1.2418e+02]]],\n","              \n","              \n","                      [[[1.7927e+02]]],\n","              \n","              \n","                      [[[1.6706e+02]]],\n","              \n","              \n","                      [[[1.6428e+02]]],\n","              \n","              \n","                      [[[1.8153e+02]]],\n","              \n","              \n","                      [[[1.3150e+02]]],\n","              \n","              \n","                      [[[2.2060e+02]]],\n","              \n","              \n","                      [[[2.1443e+02]]],\n","              \n","              \n","                      [[[1.5003e+02]]],\n","              \n","              \n","                      [[[1.9085e+02]]],\n","              \n","              \n","                      [[[3.7184e+05]]],\n","              \n","              \n","                      [[[1.4253e+02]]],\n","              \n","              \n","                      [[[1.2738e+02]]],\n","              \n","              \n","                      [[[1.1475e+02]]],\n","              \n","              \n","                      [[[1.9862e+02]]],\n","              \n","              \n","                      [[[1.4239e+02]]]], device='cuda:0')),\n","             ('module.layer2.0.conv2.w_zero_point', tensor([[[[-36.]]],\n","              \n","              \n","                      [[[-30.]]],\n","              \n","              \n","                      [[[-23.]]],\n","              \n","              \n","                      [[[-34.]]],\n","              \n","              \n","                      [[[-28.]]],\n","              \n","              \n","                      [[[-33.]]],\n","              \n","              \n","                      [[[-29.]]],\n","              \n","              \n","                      [[[-26.]]],\n","              \n","              \n","                      [[[-26.]]],\n","              \n","              \n","                      [[[-35.]]],\n","              \n","              \n","                      [[[-32.]]],\n","              \n","              \n","                      [[[-28.]]],\n","              \n","              \n","                      [[[-30.]]],\n","              \n","              \n","                      [[[-27.]]],\n","              \n","              \n","                      [[[-27.]]],\n","              \n","              \n","                      [[[-34.]]],\n","              \n","              \n","                      [[[-34.]]],\n","              \n","              \n","                      [[[-35.]]],\n","              \n","              \n","                      [[[-26.]]],\n","              \n","              \n","                      [[[-32.]]],\n","              \n","              \n","                      [[[-23.]]],\n","              \n","              \n","                      [[[-29.]]],\n","              \n","              \n","                      [[[-31.]]],\n","              \n","              \n","                      [[[-35.]]],\n","              \n","              \n","                      [[[-24.]]],\n","              \n","              \n","                      [[[-32.]]],\n","              \n","              \n","                      [[[-26.]]],\n","              \n","              \n","                      [[[-34.]]],\n","              \n","              \n","                      [[[-27.]]],\n","              \n","              \n","                      [[[-26.]]],\n","              \n","              \n","                      [[[-30.]]],\n","              \n","              \n","                      [[[-30.]]]], device='cuda:0')),\n","             ('module.layer2.0.conv2.fp_bias',\n","              tensor([ 0.7113,  1.4785,  0.0834,  0.8207,  0.2750,  1.6346,  0.4279,  0.0854,\n","                       0.3189,  1.0900,  0.0754, -0.5480,  0.3695,  0.1296,  0.6606,  0.9535,\n","                       0.6076,  1.8258,  0.0177,  0.4116,  0.1102, -0.1408,  0.2118,  0.8184,\n","                       0.5609,  0.2279, -0.0023,  0.1846,  0.2595, -0.0197,  1.1834,  0.9338],\n","                     device='cuda:0')),\n","             ('module.layer2.0.conv2.accum_scale', tensor([[[6.5423e+03]],\n","              \n","                      [[3.1950e+03]],\n","              \n","                      [[2.5960e+03]],\n","              \n","                      [[2.2726e+03]],\n","              \n","                      [[2.3427e+03]],\n","              \n","                      [[2.3676e+03]],\n","              \n","                      [[2.1803e+03]],\n","              \n","                      [[2.6375e+03]],\n","              \n","                      [[2.8014e+03]],\n","              \n","                      [[3.3356e+03]],\n","              \n","                      [[1.5118e+03]],\n","              \n","                      [[3.2659e+03]],\n","              \n","                      [[1.9999e+03]],\n","              \n","                      [[4.0766e+03]],\n","              \n","                      [[3.0975e+03]],\n","              \n","                      [[3.7927e+03]],\n","              \n","                      [[2.7935e+03]],\n","              \n","                      [[4.0328e+03]],\n","              \n","                      [[3.7580e+03]],\n","              \n","                      [[3.6956e+03]],\n","              \n","                      [[4.0836e+03]],\n","              \n","                      [[2.9581e+03]],\n","              \n","                      [[4.9626e+03]],\n","              \n","                      [[4.8237e+03]],\n","              \n","                      [[3.3751e+03]],\n","              \n","                      [[4.2933e+03]],\n","              \n","                      [[8.3647e+06]],\n","              \n","                      [[3.2062e+03]],\n","              \n","                      [[2.8656e+03]],\n","              \n","                      [[2.5814e+03]],\n","              \n","                      [[4.4681e+03]],\n","              \n","                      [[3.2032e+03]]], device='cuda:0')),\n","             ('module.layer2.0.conv2.is_simulated_quant_weight_shifted',\n","              tensor(False, device='cuda:0')),\n","             ('module.layer2.0.conv2.wrapped_module.weight',\n","              tensor([[[[39., 35., 41.],\n","                        [38., 40., 35.],\n","                        [44., 44., 40.]],\n","              \n","                       [[30., 33., 27.],\n","                        [31., 42., 36.],\n","                        [34., 47., 40.]],\n","              \n","                       [[30., 35., 34.],\n","                        [18.,  7., 19.],\n","                        [ 9.,  0., 18.]],\n","              \n","                       ...,\n","              \n","                       [[39., 34., 31.],\n","                        [34., 29., 31.],\n","                        [41., 43., 38.]],\n","              \n","                       [[31., 26., 36.],\n","                        [27., 32., 30.],\n","                        [13., 31., 35.]],\n","              \n","                       [[42., 56., 50.],\n","                        [44., 63., 50.],\n","                        [19., 23., 29.]]],\n","              \n","              \n","                      [[[34., 29., 22.],\n","                        [31., 14., 12.],\n","                        [22.,  4., 17.]],\n","              \n","                       [[31., 30., 30.],\n","                        [18., 10., 21.],\n","                        [22., 16., 28.]],\n","              \n","                       [[26., 20., 22.],\n","                        [22., 30., 20.],\n","                        [25., 32., 17.]],\n","              \n","                       ...,\n","              \n","                       [[22., 24., 29.],\n","                        [23., 11., 10.],\n","                        [38., 19.,  4.]],\n","              \n","                       [[44., 26., 19.],\n","                        [15., 13.,  5.],\n","                        [17., 21., 24.]],\n","              \n","                       [[29., 38., 31.],\n","                        [35., 47., 26.],\n","                        [22., 37., 27.]]],\n","              \n","              \n","                      [[[34., 25., 28.],\n","                        [25., 28., 33.],\n","                        [28., 15., 14.]],\n","              \n","                       [[31., 24., 17.],\n","                        [11.,  9., 13.],\n","                        [11., 13., 20.]],\n","              \n","                       [[12.,  9.,  0.],\n","                        [21., 21., 19.],\n","                        [34., 50., 35.]],\n","              \n","                       ...,\n","              \n","                       [[36., 36., 39.],\n","                        [22., 24., 28.],\n","                        [ 7., 12., 16.]],\n","              \n","                       [[34., 20., 30.],\n","                        [27., 38., 29.],\n","                        [21., 20., 26.]],\n","              \n","                       [[17., 14., 16.],\n","                        [11.,  6.,  7.],\n","                        [25., 20., 21.]]],\n","              \n","              \n","                      ...,\n","              \n","              \n","                      [[[25., 21., 20.],\n","                        [20., 41., 53.],\n","                        [29., 60., 42.]],\n","              \n","                       [[19., 17., 18.],\n","                        [30., 49., 50.],\n","                        [33., 32., 19.]],\n","              \n","                       [[27., 29., 32.],\n","                        [19., 18., 32.],\n","                        [10., 18., 32.]],\n","              \n","                       ...,\n","              \n","                       [[24., 30., 14.],\n","                        [26., 12., 10.],\n","                        [29., 28., 16.]],\n","              \n","                       [[23.,  8., 23.],\n","                        [16., 50., 53.],\n","                        [17., 41., 21.]],\n","              \n","                       [[24., 19., 12.],\n","                        [34., 19., 30.],\n","                        [19., 27., 28.]]],\n","              \n","              \n","                      [[[33., 26., 34.],\n","                        [37., 24., 23.],\n","                        [29., 35., 34.]],\n","              \n","                       [[35., 23., 37.],\n","                        [21.,  1., 39.],\n","                        [13.,  3., 27.]],\n","              \n","                       [[20.,  6., 27.],\n","                        [29., 16., 23.],\n","                        [37., 26., 25.]],\n","              \n","                       ...,\n","              \n","                       [[31., 17., 35.],\n","                        [14.,  0., 30.],\n","                        [19., 11., 39.]],\n","              \n","                       [[26., 24., 32.],\n","                        [20., 19., 27.],\n","                        [35., 21., 28.]],\n","              \n","                       [[27., 39., 42.],\n","                        [13., 12., 45.],\n","                        [14., 13., 31.]]],\n","              \n","              \n","                      [[[17., 30., 40.],\n","                        [ 8., 20., 27.],\n","                        [19., 24., 31.]],\n","              \n","                       [[34., 23., 23.],\n","                        [39., 16., 20.],\n","                        [44., 26., 22.]],\n","              \n","                       [[36., 32., 37.],\n","                        [44., 29., 25.],\n","                        [42., 37., 21.]],\n","              \n","                       ...,\n","              \n","                       [[32., 27., 47.],\n","                        [36., 19., 29.],\n","                        [36., 10.,  3.]],\n","              \n","                       [[26., 29., 30.],\n","                        [21., 25., 33.],\n","                        [23., 20., 22.]],\n","              \n","                       [[47., 28., 36.],\n","                        [49., 23., 25.],\n","                        [43., 16.,  6.]]]], device='cuda:0')),\n","             ('module.layer2.0.conv2.wrapped_module.bias',\n","              tensor([  4654.,   4724.,    216.,   1865.,    644.,   3870.,    933.,    225.,\n","                         893.,   3636.,    114.,  -1790.,    739.,    528.,   2046.,   3616.,\n","                        1697.,   7363.,     67.,   1521.,    450.,   -416.,   1051.,   3948.,\n","                        1893.,    978., -19418.,    592.,    744.,    -51.,   5288.,   2991.],\n","                     device='cuda:0')),\n","             ('module.layer2.0.relu2.num_forwards',\n","              tensor([40], device='cuda:0')),\n","             ('module.layer2.0.relu2.force_readjust',\n","              tensor(False, device='cuda:0')),\n","             ('module.layer2.0.relu2.output_scale',\n","              tensor([8.7224], device='cuda:0')),\n","             ('module.layer2.0.relu2.output_zero_point',\n","              tensor([0.], device='cuda:0')),\n","             ('module.layer2.0.downsample.0.num_forwards',\n","              tensor([40], device='cuda:0')),\n","             ('module.layer2.0.downsample.0.force_readjust',\n","              tensor(False, device='cuda:0')),\n","             ('module.layer2.0.downsample.0.output_scale',\n","              tensor([9.1303], device='cuda:0')),\n","             ('module.layer2.0.downsample.0.output_zero_point',\n","              tensor([-21.], device='cuda:0')),\n","             ('module.layer2.0.downsample.0.w_scale', tensor([[[[6.0889e+01]]],\n","              \n","              \n","                      [[[1.3158e+02]]],\n","              \n","              \n","                      [[[3.0882e+02]]],\n","              \n","              \n","                      [[[4.2129e+02]]],\n","              \n","              \n","                      [[[1.7566e+02]]],\n","              \n","              \n","                      [[[1.1895e+02]]],\n","              \n","              \n","                      [[[2.6595e+02]]],\n","              \n","              \n","                      [[[1.6133e+02]]],\n","              \n","              \n","                      [[[1.0894e+02]]],\n","              \n","              \n","                      [[[8.7686e+01]]],\n","              \n","              \n","                      [[[1.2575e+02]]],\n","              \n","              \n","                      [[[1.0060e+02]]],\n","              \n","              \n","                      [[[1.1858e+02]]],\n","              \n","              \n","                      [[[1.0729e+02]]],\n","              \n","              \n","                      [[[1.4043e+02]]],\n","              \n","              \n","                      [[[7.4511e+01]]],\n","              \n","              \n","                      [[[2.5096e+02]]],\n","              \n","              \n","                      [[[1.1328e+02]]],\n","              \n","              \n","                      [[[1.5099e+02]]],\n","              \n","              \n","                      [[[1.1288e+02]]],\n","              \n","              \n","                      [[[5.3983e+01]]],\n","              \n","              \n","                      [[[2.2228e+02]]],\n","              \n","              \n","                      [[[1.6106e+02]]],\n","              \n","              \n","                      [[[4.0678e+02]]],\n","              \n","              \n","                      [[[3.8234e+02]]],\n","              \n","              \n","                      [[[9.0879e+02]]],\n","              \n","              \n","                      [[[3.6317e+05]]],\n","              \n","              \n","                      [[[1.1040e+02]]],\n","              \n","              \n","                      [[[7.4081e+01]]],\n","              \n","              \n","                      [[[9.3132e+01]]],\n","              \n","              \n","                      [[[9.0302e+01]]],\n","              \n","              \n","                      [[[3.2386e+02]]]], device='cuda:0')),\n","             ('module.layer2.0.downsample.0.w_zero_point', tensor([[[[-38.]]],\n","              \n","              \n","                      [[[-31.]]],\n","              \n","              \n","                      [[[-31.]]],\n","              \n","              \n","                      [[[-42.]]],\n","              \n","              \n","                      [[[-24.]]],\n","              \n","              \n","                      [[[-35.]]],\n","              \n","              \n","                      [[[-33.]]],\n","              \n","              \n","                      [[[-25.]]],\n","              \n","              \n","                      [[[-37.]]],\n","              \n","              \n","                      [[[-31.]]],\n","              \n","              \n","                      [[[-39.]]],\n","              \n","              \n","                      [[[-25.]]],\n","              \n","              \n","                      [[[-37.]]],\n","              \n","              \n","                      [[[-16.]]],\n","              \n","              \n","                      [[[-46.]]],\n","              \n","              \n","                      [[[-38.]]],\n","              \n","              \n","                      [[[-39.]]],\n","              \n","              \n","                      [[[-30.]]],\n","              \n","              \n","                      [[[-25.]]],\n","              \n","              \n","                      [[[-30.]]],\n","              \n","              \n","                      [[[-26.]]],\n","              \n","              \n","                      [[[-20.]]],\n","              \n","              \n","                      [[[-26.]]],\n","              \n","              \n","                      [[[-39.]]],\n","              \n","              \n","                      [[[-35.]]],\n","              \n","              \n","                      [[[-37.]]],\n","              \n","              \n","                      [[[-33.]]],\n","              \n","              \n","                      [[[-28.]]],\n","              \n","              \n","                      [[[-26.]]],\n","              \n","              \n","                      [[[-24.]]],\n","              \n","              \n","                      [[[-42.]]],\n","              \n","              \n","                      [[[-28.]]]], device='cuda:0')),\n","             ('module.layer2.0.downsample.0.fp_bias',\n","              tensor([ 1.5534e+00,  1.2326e+00, -7.8006e-02,  7.3776e-01,  3.4696e-01,\n","                      -7.6662e-02,  2.1585e-01, -2.5956e-01,  7.2422e-02, -7.0096e-01,\n","                      -3.0226e-02, -5.1034e-01,  6.5890e-01, -1.0542e+00,  1.7236e+00,\n","                       2.0761e+00,  5.6629e-01,  6.8770e-01, -8.4013e-01, -9.8360e-01,\n","                      -1.9155e+00, -2.5783e-01,  3.5782e-01,  5.4529e-01,  6.3588e-01,\n","                      -9.5813e-02, -1.8854e-03,  8.2768e-01, -3.2773e-01, -1.9618e-01,\n","                       1.1457e+00,  2.4443e-01], device='cuda:0')),\n","             ('module.layer2.0.downsample.0.accum_scale',\n","              tensor([[[4.3847e+02]],\n","              \n","                      [[9.4756e+02]],\n","              \n","                      [[2.2238e+03]],\n","              \n","                      [[3.0338e+03]],\n","              \n","                      [[1.2650e+03]],\n","              \n","                      [[8.5659e+02]],\n","              \n","                      [[1.9152e+03]],\n","              \n","                      [[1.1618e+03]],\n","              \n","                      [[7.8448e+02]],\n","              \n","                      [[6.3144e+02]],\n","              \n","                      [[9.0555e+02]],\n","              \n","                      [[7.2442e+02]],\n","              \n","                      [[8.5391e+02]],\n","              \n","                      [[7.7263e+02]],\n","              \n","                      [[1.0113e+03]],\n","              \n","                      [[5.3656e+02]],\n","              \n","                      [[1.8072e+03]],\n","              \n","                      [[8.1577e+02]],\n","              \n","                      [[1.0873e+03]],\n","              \n","                      [[8.1288e+02]],\n","              \n","                      [[3.8874e+02]],\n","              \n","                      [[1.6007e+03]],\n","              \n","                      [[1.1598e+03]],\n","              \n","                      [[2.9293e+03]],\n","              \n","                      [[2.7533e+03]],\n","              \n","                      [[6.5444e+03]],\n","              \n","                      [[2.6152e+06]],\n","              \n","                      [[7.9501e+02]],\n","              \n","                      [[5.3347e+02]],\n","              \n","                      [[6.7066e+02]],\n","              \n","                      [[6.5028e+02]],\n","              \n","                      [[2.3322e+03]]], device='cuda:0')),\n","             ('module.layer2.0.downsample.0.is_simulated_quant_weight_shifted',\n","              tensor(False, device='cuda:0')),\n","             ('module.layer2.0.downsample.0.wrapped_module.weight',\n","              tensor([[[[45.]],\n","              \n","                       [[30.]],\n","              \n","                       [[40.]],\n","              \n","                       [[50.]],\n","              \n","                       [[63.]],\n","              \n","                       [[28.]],\n","              \n","                       [[40.]],\n","              \n","                       [[41.]],\n","              \n","                       [[57.]],\n","              \n","                       [[ 7.]],\n","              \n","                       [[28.]],\n","              \n","                       [[ 0.]],\n","              \n","                       [[34.]],\n","              \n","                       [[35.]],\n","              \n","                       [[45.]],\n","              \n","                       [[42.]]],\n","              \n","              \n","                      [[[28.]],\n","              \n","                       [[63.]],\n","              \n","                       [[ 0.]],\n","              \n","                       [[39.]],\n","              \n","                       [[17.]],\n","              \n","                       [[16.]],\n","              \n","                       [[18.]],\n","              \n","                       [[17.]],\n","              \n","                       [[33.]],\n","              \n","                       [[16.]],\n","              \n","                       [[56.]],\n","              \n","                       [[22.]],\n","              \n","                       [[26.]],\n","              \n","                       [[32.]],\n","              \n","                       [[28.]],\n","              \n","                       [[39.]]],\n","              \n","              \n","                      [[[51.]],\n","              \n","                       [[34.]],\n","              \n","                       [[ 0.]],\n","              \n","                       [[35.]],\n","              \n","                       [[63.]],\n","              \n","                       [[29.]],\n","              \n","                       [[29.]],\n","              \n","                       [[26.]],\n","              \n","                       [[ 8.]],\n","              \n","                       [[61.]],\n","              \n","                       [[41.]],\n","              \n","                       [[48.]],\n","              \n","                       [[34.]],\n","              \n","                       [[44.]],\n","              \n","                       [[40.]],\n","              \n","                       [[32.]]],\n","              \n","              \n","                      [[[32.]],\n","              \n","                       [[63.]],\n","              \n","                       [[ 9.]],\n","              \n","                       [[12.]],\n","              \n","                       [[41.]],\n","              \n","                       [[ 0.]],\n","              \n","                       [[42.]],\n","              \n","                       [[46.]],\n","              \n","                       [[55.]],\n","              \n","                       [[45.]],\n","              \n","                       [[45.]],\n","              \n","                       [[36.]],\n","              \n","                       [[43.]],\n","              \n","                       [[44.]],\n","              \n","                       [[17.]],\n","              \n","                       [[26.]]],\n","              \n","              \n","                      [[[46.]],\n","              \n","                       [[22.]],\n","              \n","                       [[13.]],\n","              \n","                       [[ 0.]],\n","              \n","                       [[43.]],\n","              \n","                       [[63.]],\n","              \n","                       [[20.]],\n","              \n","                       [[41.]],\n","              \n","                       [[22.]],\n","              \n","                       [[ 8.]],\n","              \n","                       [[12.]],\n","              \n","                       [[ 0.]],\n","              \n","                       [[29.]],\n","              \n","                       [[ 1.]],\n","              \n","                       [[45.]],\n","              \n","                       [[ 5.]]],\n","              \n","              \n","                      [[[36.]],\n","              \n","                       [[27.]],\n","              \n","                       [[26.]],\n","              \n","                       [[42.]],\n","              \n","                       [[ 0.]],\n","              \n","                       [[51.]],\n","              \n","                       [[26.]],\n","              \n","                       [[35.]],\n","              \n","                       [[41.]],\n","              \n","                       [[63.]],\n","              \n","                       [[30.]],\n","              \n","                       [[40.]],\n","              \n","                       [[21.]],\n","              \n","                       [[48.]],\n","              \n","                       [[40.]],\n","              \n","                       [[18.]]],\n","              \n","              \n","                      [[[12.]],\n","              \n","                       [[27.]],\n","              \n","                       [[ 9.]],\n","              \n","                       [[21.]],\n","              \n","                       [[33.]],\n","              \n","                       [[62.]],\n","              \n","                       [[13.]],\n","              \n","                       [[47.]],\n","              \n","                       [[47.]],\n","              \n","                       [[19.]],\n","              \n","                       [[61.]],\n","              \n","                       [[ 0.]],\n","              \n","                       [[63.]],\n","              \n","                       [[39.]],\n","              \n","                       [[34.]],\n","              \n","                       [[25.]]],\n","              \n","              \n","                      [[[23.]],\n","              \n","                       [[29.]],\n","              \n","                       [[10.]],\n","              \n","                       [[35.]],\n","              \n","                       [[ 9.]],\n","              \n","                       [[ 0.]],\n","              \n","                       [[22.]],\n","              \n","                       [[63.]],\n","              \n","                       [[17.]],\n","              \n","                       [[43.]],\n","              \n","                       [[16.]],\n","              \n","                       [[34.]],\n","              \n","                       [[27.]],\n","              \n","                       [[42.]],\n","              \n","                       [[51.]],\n","              \n","                       [[20.]]],\n","              \n","              \n","                      [[[36.]],\n","              \n","                       [[29.]],\n","              \n","                       [[39.]],\n","              \n","                       [[52.]],\n","              \n","                       [[34.]],\n","              \n","                       [[39.]],\n","              \n","                       [[28.]],\n","              \n","                       [[20.]],\n","              \n","                       [[62.]],\n","              \n","                       [[28.]],\n","              \n","                       [[24.]],\n","              \n","                       [[63.]],\n","              \n","                       [[41.]],\n","              \n","                       [[52.]],\n","              \n","                       [[59.]],\n","              \n","                       [[ 0.]]],\n","              \n","              \n","                      [[[21.]],\n","              \n","                       [[27.]],\n","              \n","                       [[28.]],\n","              \n","                       [[37.]],\n","              \n","                       [[ 0.]],\n","              \n","                       [[41.]],\n","              \n","                       [[26.]],\n","              \n","                       [[28.]],\n","              \n","                       [[28.]],\n","              \n","                       [[63.]],\n","              \n","                       [[35.]],\n","              \n","                       [[51.]],\n","              \n","                       [[26.]],\n","              \n","                       [[17.]],\n","              \n","                       [[34.]],\n","              \n","                       [[44.]]],\n","              \n","              \n","                      [[[56.]],\n","              \n","                       [[40.]],\n","              \n","                       [[44.]],\n","              \n","                       [[32.]],\n","              \n","                       [[35.]],\n","              \n","                       [[43.]],\n","              \n","                       [[33.]],\n","              \n","                       [[37.]],\n","              \n","                       [[28.]],\n","              \n","                       [[41.]],\n","              \n","                       [[63.]],\n","              \n","                       [[ 0.]],\n","              \n","                       [[46.]],\n","              \n","                       [[46.]],\n","              \n","                       [[37.]],\n","              \n","                       [[60.]]],\n","              \n","              \n","                      [[[27.]],\n","              \n","                       [[20.]],\n","              \n","                       [[32.]],\n","              \n","                       [[17.]],\n","              \n","                       [[63.]],\n","              \n","                       [[40.]],\n","              \n","                       [[35.]],\n","              \n","                       [[19.]],\n","              \n","                       [[ 7.]],\n","              \n","                       [[ 0.]],\n","              \n","                       [[26.]],\n","              \n","                       [[52.]],\n","              \n","                       [[26.]],\n","              \n","                       [[32.]],\n","              \n","                       [[27.]],\n","              \n","                       [[37.]]],\n","              \n","              \n","                      [[[63.]],\n","              \n","                       [[33.]],\n","              \n","                       [[41.]],\n","              \n","                       [[32.]],\n","              \n","                       [[17.]],\n","              \n","                       [[ 0.]],\n","              \n","                       [[37.]],\n","              \n","                       [[46.]],\n","              \n","                       [[28.]],\n","              \n","                       [[41.]],\n","              \n","                       [[25.]],\n","              \n","                       [[55.]],\n","              \n","                       [[37.]],\n","              \n","                       [[33.]],\n","              \n","                       [[41.]],\n","              \n","                       [[43.]]],\n","              \n","              \n","                      [[[ 0.]],\n","              \n","                       [[52.]],\n","              \n","                       [[14.]],\n","              \n","                       [[63.]],\n","              \n","                       [[ 2.]],\n","              \n","                       [[30.]],\n","              \n","                       [[16.]],\n","              \n","                       [[19.]],\n","              \n","                       [[17.]],\n","              \n","                       [[10.]],\n","              \n","                       [[23.]],\n","              \n","                       [[ 6.]],\n","              \n","                       [[ 5.]],\n","              \n","                       [[16.]],\n","              \n","                       [[22.]],\n","              \n","                       [[23.]]],\n","              \n","              \n","                      [[[46.]],\n","              \n","                       [[28.]],\n","              \n","                       [[40.]],\n","              \n","                       [[ 0.]],\n","              \n","                       [[37.]],\n","              \n","                       [[16.]],\n","              \n","                       [[56.]],\n","              \n","                       [[44.]],\n","              \n","                       [[38.]],\n","              \n","                       [[41.]],\n","              \n","                       [[54.]],\n","              \n","                       [[33.]],\n","              \n","                       [[63.]],\n","              \n","                       [[45.]],\n","              \n","                       [[39.]],\n","              \n","                       [[45.]]],\n","              \n","              \n","                      [[[44.]],\n","              \n","                       [[43.]],\n","              \n","                       [[30.]],\n","              \n","                       [[ 0.]],\n","              \n","                       [[63.]],\n","              \n","                       [[30.]],\n","              \n","                       [[33.]],\n","              \n","                       [[26.]],\n","              \n","                       [[43.]],\n","              \n","                       [[45.]],\n","              \n","                       [[40.]],\n","              \n","                       [[47.]],\n","              \n","                       [[38.]],\n","              \n","                       [[33.]],\n","              \n","                       [[24.]],\n","              \n","                       [[22.]]],\n","              \n","              \n","                      [[[52.]],\n","              \n","                       [[ 0.]],\n","              \n","                       [[49.]],\n","              \n","                       [[34.]],\n","              \n","                       [[15.]],\n","              \n","                       [[53.]],\n","              \n","                       [[50.]],\n","              \n","                       [[20.]],\n","              \n","                       [[30.]],\n","              \n","                       [[31.]],\n","              \n","                       [[15.]],\n","              \n","                       [[10.]],\n","              \n","                       [[57.]],\n","              \n","                       [[20.]],\n","              \n","                       [[63.]],\n","              \n","                       [[41.]]],\n","              \n","              \n","                      [[[16.]],\n","              \n","                       [[ 5.]],\n","              \n","                       [[33.]],\n","              \n","                       [[35.]],\n","              \n","                       [[ 9.]],\n","              \n","                       [[30.]],\n","              \n","                       [[33.]],\n","              \n","                       [[24.]],\n","              \n","                       [[63.]],\n","              \n","                       [[51.]],\n","              \n","                       [[ 5.]],\n","              \n","                       [[ 0.]],\n","              \n","                       [[ 7.]],\n","              \n","                       [[20.]],\n","              \n","                       [[38.]],\n","              \n","                       [[32.]]],\n","              \n","              \n","                      [[[ 0.]],\n","              \n","                       [[31.]],\n","              \n","                       [[19.]],\n","              \n","                       [[33.]],\n","              \n","                       [[ 0.]],\n","              \n","                       [[41.]],\n","              \n","                       [[27.]],\n","              \n","                       [[25.]],\n","              \n","                       [[63.]],\n","              \n","                       [[43.]],\n","              \n","                       [[40.]],\n","              \n","                       [[39.]],\n","              \n","                       [[10.]],\n","              \n","                       [[22.]],\n","              \n","                       [[ 0.]],\n","              \n","                       [[24.]]],\n","              \n","              \n","                      [[[49.]],\n","              \n","                       [[17.]],\n","              \n","                       [[28.]],\n","              \n","                       [[ 0.]],\n","              \n","                       [[20.]],\n","              \n","                       [[59.]],\n","              \n","                       [[47.]],\n","              \n","                       [[29.]],\n","              \n","                       [[63.]],\n","              \n","                       [[39.]],\n","              \n","                       [[29.]],\n","              \n","                       [[24.]],\n","              \n","                       [[34.]],\n","              \n","                       [[30.]],\n","              \n","                       [[45.]],\n","              \n","                       [[28.]]],\n","              \n","              \n","                      [[[37.]],\n","              \n","                       [[31.]],\n","              \n","                       [[25.]],\n","              \n","                       [[39.]],\n","              \n","                       [[56.]],\n","              \n","                       [[10.]],\n","              \n","                       [[21.]],\n","              \n","                       [[31.]],\n","              \n","                       [[45.]],\n","              \n","                       [[63.]],\n","              \n","                       [[31.]],\n","              \n","                       [[ 0.]],\n","              \n","                       [[30.]],\n","              \n","                       [[34.]],\n","              \n","                       [[26.]],\n","              \n","                       [[22.]]],\n","              \n","              \n","                      [[[17.]],\n","              \n","                       [[18.]],\n","              \n","                       [[18.]],\n","              \n","                       [[23.]],\n","              \n","                       [[16.]],\n","              \n","                       [[ 1.]],\n","              \n","                       [[30.]],\n","              \n","                       [[28.]],\n","              \n","                       [[63.]],\n","              \n","                       [[31.]],\n","              \n","                       [[31.]],\n","              \n","                       [[ 5.]],\n","              \n","                       [[18.]],\n","              \n","                       [[20.]],\n","              \n","                       [[ 0.]],\n","              \n","                       [[11.]]],\n","              \n","              \n","                      [[[34.]],\n","              \n","                       [[29.]],\n","              \n","                       [[22.]],\n","              \n","                       [[31.]],\n","              \n","                       [[48.]],\n","              \n","                       [[26.]],\n","              \n","                       [[22.]],\n","              \n","                       [[15.]],\n","              \n","                       [[25.]],\n","              \n","                       [[ 9.]],\n","              \n","                       [[10.]],\n","              \n","                       [[53.]],\n","              \n","                       [[ 0.]],\n","              \n","                       [[29.]],\n","              \n","                       [[34.]],\n","              \n","                       [[63.]]],\n","              \n","              \n","                      [[[ 0.]],\n","              \n","                       [[32.]],\n","              \n","                       [[44.]],\n","              \n","                       [[40.]],\n","              \n","                       [[20.]],\n","              \n","                       [[63.]],\n","              \n","                       [[22.]],\n","              \n","                       [[27.]],\n","              \n","                       [[12.]],\n","              \n","                       [[47.]],\n","              \n","                       [[26.]],\n","              \n","                       [[24.]],\n","              \n","                       [[47.]],\n","              \n","                       [[ 1.]],\n","              \n","                       [[35.]],\n","              \n","                       [[24.]]],\n","              \n","              \n","                      [[[63.]],\n","              \n","                       [[10.]],\n","              \n","                       [[39.]],\n","              \n","                       [[ 3.]],\n","              \n","                       [[41.]],\n","              \n","                       [[11.]],\n","              \n","                       [[35.]],\n","              \n","                       [[ 0.]],\n","              \n","                       [[21.]],\n","              \n","                       [[39.]],\n","              \n","                       [[49.]],\n","              \n","                       [[13.]],\n","              \n","                       [[29.]],\n","              \n","                       [[54.]],\n","              \n","                       [[35.]],\n","              \n","                       [[50.]]],\n","              \n","              \n","                      [[[14.]],\n","              \n","                       [[40.]],\n","              \n","                       [[61.]],\n","              \n","                       [[45.]],\n","              \n","                       [[37.]],\n","              \n","                       [[20.]],\n","              \n","                       [[41.]],\n","              \n","                       [[24.]],\n","              \n","                       [[22.]],\n","              \n","                       [[28.]],\n","              \n","                       [[48.]],\n","              \n","                       [[43.]],\n","              \n","                       [[49.]],\n","              \n","                       [[63.]],\n","              \n","                       [[ 0.]],\n","              \n","                       [[34.]]],\n","              \n","              \n","                      [[[16.]],\n","              \n","                       [[55.]],\n","              \n","                       [[49.]],\n","              \n","                       [[ 5.]],\n","              \n","                       [[46.]],\n","              \n","                       [[43.]],\n","              \n","                       [[63.]],\n","              \n","                       [[49.]],\n","              \n","                       [[25.]],\n","              \n","                       [[13.]],\n","              \n","                       [[18.]],\n","              \n","                       [[45.]],\n","              \n","                       [[45.]],\n","              \n","                       [[18.]],\n","              \n","                       [[23.]],\n","              \n","                       [[ 0.]]],\n","              \n","              \n","                      [[[ 0.]],\n","              \n","                       [[47.]],\n","              \n","                       [[34.]],\n","              \n","                       [[32.]],\n","              \n","                       [[ 9.]],\n","              \n","                       [[ 5.]],\n","              \n","                       [[18.]],\n","              \n","                       [[46.]],\n","              \n","                       [[29.]],\n","              \n","                       [[22.]],\n","              \n","                       [[63.]],\n","              \n","                       [[34.]],\n","              \n","                       [[33.]],\n","              \n","                       [[37.]],\n","              \n","                       [[ 0.]],\n","              \n","                       [[30.]]],\n","              \n","              \n","                      [[[27.]],\n","              \n","                       [[12.]],\n","              \n","                       [[63.]],\n","              \n","                       [[22.]],\n","              \n","                       [[18.]],\n","              \n","                       [[24.]],\n","              \n","                       [[25.]],\n","              \n","                       [[ 0.]],\n","              \n","                       [[21.]],\n","              \n","                       [[35.]],\n","              \n","                       [[29.]],\n","              \n","                       [[23.]],\n","              \n","                       [[26.]],\n","              \n","                       [[62.]],\n","              \n","                       [[28.]],\n","              \n","                       [[39.]]],\n","              \n","              \n","                      [[[20.]],\n","              \n","                       [[ 0.]],\n","              \n","                       [[11.]],\n","              \n","                       [[29.]],\n","              \n","                       [[27.]],\n","              \n","                       [[34.]],\n","              \n","                       [[30.]],\n","              \n","                       [[63.]],\n","              \n","                       [[27.]],\n","              \n","                       [[26.]],\n","              \n","                       [[12.]],\n","              \n","                       [[35.]],\n","              \n","                       [[24.]],\n","              \n","                       [[ 2.]],\n","              \n","                       [[20.]],\n","              \n","                       [[25.]]],\n","              \n","              \n","                      [[[53.]],\n","              \n","                       [[48.]],\n","              \n","                       [[49.]],\n","              \n","                       [[52.]],\n","              \n","                       [[25.]],\n","              \n","                       [[63.]],\n","              \n","                       [[44.]],\n","              \n","                       [[27.]],\n","              \n","                       [[ 0.]],\n","              \n","                       [[51.]],\n","              \n","                       [[23.]],\n","              \n","                       [[31.]],\n","              \n","                       [[38.]],\n","              \n","                       [[34.]],\n","              \n","                       [[55.]],\n","              \n","                       [[43.]]],\n","              \n","              \n","                      [[[28.]],\n","              \n","                       [[22.]],\n","              \n","                       [[25.]],\n","              \n","                       [[58.]],\n","              \n","                       [[10.]],\n","              \n","                       [[13.]],\n","              \n","                       [[18.]],\n","              \n","                       [[ 5.]],\n","              \n","                       [[ 0.]],\n","              \n","                       [[42.]],\n","              \n","                       [[ 9.]],\n","              \n","                       [[13.]],\n","              \n","                       [[30.]],\n","              \n","                       [[17.]],\n","              \n","                       [[55.]],\n","              \n","                       [[63.]]]], device='cuda:0')),\n","             ('module.layer2.0.downsample.0.wrapped_module.bias',\n","              tensor([  681.,  1168.,  -173.,  2238.,   439.,   -66.,   413.,  -302.,    57.,\n","                       -443.,   -27.,  -370.,   563.,  -815.,  1743.,  1114.,  1023.,   561.,\n","                       -913.,  -800.,  -745.,  -413.,   415.,  1597.,  1751.,  -627., -4931.,\n","                        658.,  -175.,  -132.,   745.,   570.], device='cuda:0')),\n","             ('module.layer2.0.residual_eltwiseadd.num_forwards',\n","              tensor([40], device='cuda:0')),\n","             ('module.layer2.0.residual_eltwiseadd.force_readjust',\n","              tensor(False, device='cuda:0')),\n","             ('module.layer2.0.residual_eltwiseadd.output_scale',\n","              tensor([8.7224], device='cuda:0')),\n","             ('module.layer2.0.residual_eltwiseadd.output_zero_point',\n","              tensor([0.], device='cuda:0')),\n","             ('module.layer2.1.conv1.num_forwards',\n","              tensor([40], device='cuda:0')),\n","             ('module.layer2.1.conv1.force_readjust',\n","              tensor(False, device='cuda:0')),\n","             ('module.layer2.1.conv1.output_scale',\n","              tensor([36.3573], device='cuda:0')),\n","             ('module.layer2.1.conv1.output_zero_point',\n","              tensor([0.], device='cuda:0')),\n","             ('module.layer2.1.conv1.w_scale', tensor([[[[3.6807e+02]]],\n","              \n","              \n","                      [[[5.8751e+02]]],\n","              \n","              \n","                      [[[4.6114e+02]]],\n","              \n","              \n","                      [[[6.5779e+02]]],\n","              \n","              \n","                      [[[7.8639e+02]]],\n","              \n","              \n","                      [[[5.5923e+02]]],\n","              \n","              \n","                      [[[4.9426e+02]]],\n","              \n","              \n","                      [[[5.8912e+02]]],\n","              \n","              \n","                      [[[5.0565e+02]]],\n","              \n","              \n","                      [[[4.7794e+02]]],\n","              \n","              \n","                      [[[4.9970e+02]]],\n","              \n","              \n","                      [[[9.5270e+02]]],\n","              \n","              \n","                      [[[4.5240e+02]]],\n","              \n","              \n","                      [[[4.3298e+02]]],\n","              \n","              \n","                      [[[6.0840e+02]]],\n","              \n","              \n","                      [[[6.1717e+02]]],\n","              \n","              \n","                      [[[7.9892e+05]]],\n","              \n","              \n","                      [[[4.6842e+02]]],\n","              \n","              \n","                      [[[3.2977e+02]]],\n","              \n","              \n","                      [[[4.7005e+02]]],\n","              \n","              \n","                      [[[6.6969e+02]]],\n","              \n","              \n","                      [[[6.8912e+02]]],\n","              \n","              \n","                      [[[4.0477e+02]]],\n","              \n","              \n","                      [[[5.3837e+02]]],\n","              \n","              \n","                      [[[6.2887e+02]]],\n","              \n","              \n","                      [[[2.5033e+05]]],\n","              \n","              \n","                      [[[4.3613e+02]]],\n","              \n","              \n","                      [[[5.4466e+02]]],\n","              \n","              \n","                      [[[4.8131e+02]]],\n","              \n","              \n","                      [[[6.8476e+02]]],\n","              \n","              \n","                      [[[6.1769e+02]]],\n","              \n","              \n","                      [[[5.0461e+02]]]], device='cuda:0')),\n","             ('module.layer2.1.conv1.w_zero_point', tensor([[[[-32.]]],\n","              \n","              \n","                      [[[-28.]]],\n","              \n","              \n","                      [[[-33.]]],\n","              \n","              \n","                      [[[-35.]]],\n","              \n","              \n","                      [[[-32.]]],\n","              \n","              \n","                      [[[-27.]]],\n","              \n","              \n","                      [[[-25.]]],\n","              \n","              \n","                      [[[-27.]]],\n","              \n","              \n","                      [[[-29.]]],\n","              \n","              \n","                      [[[-34.]]],\n","              \n","              \n","                      [[[-25.]]],\n","              \n","              \n","                      [[[-34.]]],\n","              \n","              \n","                      [[[-26.]]],\n","              \n","              \n","                      [[[-25.]]],\n","              \n","              \n","                      [[[-34.]]],\n","              \n","              \n","                      [[[-33.]]],\n","              \n","              \n","                      [[[-43.]]],\n","              \n","              \n","                      [[[-35.]]],\n","              \n","              \n","                      [[[-35.]]],\n","              \n","              \n","                      [[[-32.]]],\n","              \n","              \n","                      [[[-31.]]],\n","              \n","              \n","                      [[[-30.]]],\n","              \n","              \n","                      [[[-18.]]],\n","              \n","              \n","                      [[[-26.]]],\n","              \n","              \n","                      [[[-33.]]],\n","              \n","              \n","                      [[[-31.]]],\n","              \n","              \n","                      [[[-34.]]],\n","              \n","              \n","                      [[[-25.]]],\n","              \n","              \n","                      [[[-29.]]],\n","              \n","              \n","                      [[[-31.]]],\n","              \n","              \n","                      [[[-34.]]],\n","              \n","              \n","                      [[[-30.]]]], device='cuda:0')),\n","             ('module.layer2.1.conv1.fp_bias',\n","              tensor([-2.1931e-01, -2.0550e-01, -2.2256e-02,  1.7712e-01,  4.7397e-01,\n","                      -3.8010e-01, -1.0607e-01, -5.8006e-01,  1.8404e-01,  9.7214e-02,\n","                      -4.3790e-01,  3.8751e-01, -4.2128e-01,  4.4122e-02, -2.4897e-01,\n","                       1.4562e-01, -1.8723e-04,  4.4838e-01,  1.0151e-01, -5.3239e-02,\n","                      -6.3444e-03,  3.4689e-01, -5.9315e-01, -1.0803e-01, -2.2685e-03,\n","                       4.8800e-02,  8.5850e-02, -4.0829e-01, -1.1963e-01, -1.3571e-03,\n","                       1.4721e-01,  2.9835e-01], device='cuda:0')),\n","             ('module.layer2.1.conv1.accum_scale', tensor([[[3.2104e+03]],\n","              \n","                      [[5.1245e+03]],\n","              \n","                      [[4.0223e+03]],\n","              \n","                      [[5.7375e+03]],\n","              \n","                      [[6.8592e+03]],\n","              \n","                      [[4.8778e+03]],\n","              \n","                      [[4.3111e+03]],\n","              \n","                      [[5.1385e+03]],\n","              \n","                      [[4.4105e+03]],\n","              \n","                      [[4.1688e+03]],\n","              \n","                      [[4.3586e+03]],\n","              \n","                      [[8.3098e+03]],\n","              \n","                      [[3.9460e+03]],\n","              \n","                      [[3.7766e+03]],\n","              \n","                      [[5.3067e+03]],\n","              \n","                      [[5.3832e+03]],\n","              \n","                      [[6.9685e+06]],\n","              \n","                      [[4.0857e+03]],\n","              \n","                      [[2.8764e+03]],\n","              \n","                      [[4.0999e+03]],\n","              \n","                      [[5.8413e+03]],\n","              \n","                      [[6.0107e+03]],\n","              \n","                      [[3.5306e+03]],\n","              \n","                      [[4.6959e+03]],\n","              \n","                      [[5.4853e+03]],\n","              \n","                      [[2.1835e+06]],\n","              \n","                      [[3.8041e+03]],\n","              \n","                      [[4.7508e+03]],\n","              \n","                      [[4.1982e+03]],\n","              \n","                      [[5.9728e+03]],\n","              \n","                      [[5.3877e+03]],\n","              \n","                      [[4.4014e+03]]], device='cuda:0')),\n","             ('module.layer2.1.conv1.is_simulated_quant_weight_shifted',\n","              tensor(False, device='cuda:0')),\n","             ('module.layer2.1.conv1.wrapped_module.weight',\n","              tensor([[[[24., 15., 22.],\n","                        [31., 23., 23.],\n","                        [34., 40., 30.]],\n","              \n","                       [[41., 42., 39.],\n","                        [34., 28., 44.],\n","                        [31., 36., 36.]],\n","              \n","                       [[20., 27., 32.],\n","                        [30., 33., 37.],\n","                        [34., 46., 41.]],\n","              \n","                       ...,\n","              \n","                       [[39., 27., 34.],\n","                        [52., 10., 31.],\n","                        [48., 24., 48.]],\n","              \n","                       [[12., 31., 21.],\n","                        [25., 18., 32.],\n","                        [46., 22., 45.]],\n","              \n","                       [[24., 36., 36.],\n","                        [28., 31., 32.],\n","                        [38., 32., 32.]]],\n","              \n","              \n","                      [[[29., 30., 20.],\n","                        [29., 44., 20.],\n","                        [28., 36.,  3.]],\n","              \n","                       [[34., 21., 29.],\n","                        [41., 29., 11.],\n","                        [39., 48., 14.]],\n","              \n","                       [[27., 35., 44.],\n","                        [35., 30., 32.],\n","                        [26., 31., 42.]],\n","              \n","                       ...,\n","              \n","                       [[26., 23., 19.],\n","                        [23., 29., 33.],\n","                        [34., 42., 16.]],\n","              \n","                       [[25., 18., 23.],\n","                        [17., 13., 62.],\n","                        [ 4., 14., 46.]],\n","              \n","                       [[29., 37., 35.],\n","                        [34., 41., 45.],\n","                        [31., 35., 39.]]],\n","              \n","              \n","                      [[[34., 42., 44.],\n","                        [37., 40., 46.],\n","                        [38., 28., 48.]],\n","              \n","                       [[29., 25., 28.],\n","                        [38., 34., 43.],\n","                        [37., 37., 33.]],\n","              \n","                       [[42., 31., 27.],\n","                        [39., 33., 30.],\n","                        [29., 30., 26.]],\n","              \n","                       ...,\n","              \n","                       [[21., 27., 15.],\n","                        [30., 25., 15.],\n","                        [39., 33., 32.]],\n","              \n","                       [[25., 22., 21.],\n","                        [39., 28., 24.],\n","                        [51., 35., 36.]],\n","              \n","                       [[25., 30., 39.],\n","                        [27., 32., 35.],\n","                        [26., 32., 35.]]],\n","              \n","              \n","                      ...,\n","              \n","              \n","                      [[[61., 23.,  8.],\n","                        [53., 20., 13.],\n","                        [30., 43., 19.]],\n","              \n","                       [[31., 45., 34.],\n","                        [30., 43., 32.],\n","                        [27., 32., 17.]],\n","              \n","                       [[40., 47., 37.],\n","                        [48., 39., 32.],\n","                        [24., 28., 28.]],\n","              \n","                       ...,\n","              \n","                       [[35., 37., 23.],\n","                        [19., 24., 19.],\n","                        [31., 46., 50.]],\n","              \n","                       [[27., 45., 32.],\n","                        [24., 40., 29.],\n","                        [ 0., 16., 29.]],\n","              \n","                       [[36., 27., 18.],\n","                        [35., 28., 28.],\n","                        [39., 37., 37.]]],\n","              \n","              \n","                      [[[48., 32., 34.],\n","                        [47., 12., 34.],\n","                        [38., 11., 25.]],\n","              \n","                       [[21., 21., 29.],\n","                        [27., 31., 33.],\n","                        [35., 40., 31.]],\n","              \n","                       [[36., 33., 35.],\n","                        [29., 26., 21.],\n","                        [34., 30., 27.]],\n","              \n","                       ...,\n","              \n","                       [[54., 60., 13.],\n","                        [54., 42.,  0.],\n","                        [49., 36.,  1.]],\n","              \n","                       [[10., 46., 49.],\n","                        [ 4., 42., 51.],\n","                        [15., 41., 29.]],\n","              \n","                       [[19., 24., 34.],\n","                        [20., 31., 42.],\n","                        [23., 30., 43.]]],\n","              \n","              \n","                      [[[30., 35., 22.],\n","                        [18., 26., 25.],\n","                        [30., 27., 36.]],\n","              \n","                       [[30., 41., 26.],\n","                        [32., 44., 28.],\n","                        [38., 30., 20.]],\n","              \n","                       [[39., 32., 26.],\n","                        [38., 38., 38.],\n","                        [42., 42., 36.]],\n","              \n","                       ...,\n","              \n","                       [[ 4., 28., 29.],\n","                        [55., 53., 28.],\n","                        [28., 21., 12.]],\n","              \n","                       [[63., 37., 16.],\n","                        [39.,  8., 30.],\n","                        [11., 26., 43.]],\n","              \n","                       [[31., 27., 35.],\n","                        [32., 26., 25.],\n","                        [32., 27., 26.]]]], device='cuda:0')),\n","             ('module.layer2.1.conv1.wrapped_module.bias',\n","              tensor([-7.0400e+02, -1.0530e+03, -9.0000e+01,  1.0160e+03,  3.2510e+03,\n","                      -1.8540e+03, -4.5700e+02, -2.9810e+03,  8.1200e+02,  4.0500e+02,\n","                      -1.9090e+03,  3.2200e+03, -1.6620e+03,  1.6700e+02, -1.3210e+03,\n","                       7.8400e+02, -1.3050e+03,  1.8320e+03,  2.9200e+02, -2.1800e+02,\n","                      -3.7000e+01,  2.0850e+03, -2.0940e+03, -5.0700e+02, -1.2000e+01,\n","                       1.0655e+05,  3.2700e+02, -1.9400e+03, -5.0200e+02, -8.0000e+00,\n","                       7.9300e+02,  1.3130e+03], device='cuda:0')),\n","             ('module.layer2.1.conv2.num_forwards',\n","              tensor([40], device='cuda:0')),\n","             ('module.layer2.1.conv2.force_readjust',\n","              tensor(False, device='cuda:0')),\n","             ('module.layer2.1.conv2.output_scale',\n","              tensor([11.8291], device='cuda:0')),\n","             ('module.layer2.1.conv2.output_zero_point',\n","              tensor([-26.], device='cuda:0')),\n","             ('module.layer2.1.conv2.w_scale', tensor([[[[303.1599]]],\n","              \n","              \n","                      [[[187.4948]]],\n","              \n","              \n","                      [[[121.6342]]],\n","              \n","              \n","                      [[[101.7449]]],\n","              \n","              \n","                      [[[ 67.1254]]],\n","              \n","              \n","                      [[[111.5424]]],\n","              \n","              \n","                      [[[122.2812]]],\n","              \n","              \n","                      [[[ 93.7772]]],\n","              \n","              \n","                      [[[160.9586]]],\n","              \n","              \n","                      [[[116.4511]]],\n","              \n","              \n","                      [[[140.2536]]],\n","              \n","              \n","                      [[[134.5925]]],\n","              \n","              \n","                      [[[140.0949]]],\n","              \n","              \n","                      [[[156.7495]]],\n","              \n","              \n","                      [[[689.4172]]],\n","              \n","              \n","                      [[[127.4073]]],\n","              \n","              \n","                      [[[ 69.7292]]],\n","              \n","              \n","                      [[[145.3845]]],\n","              \n","              \n","                      [[[127.5033]]],\n","              \n","              \n","                      [[[137.9427]]],\n","              \n","              \n","                      [[[223.6752]]],\n","              \n","              \n","                      [[[ 87.6904]]],\n","              \n","              \n","                      [[[300.3641]]],\n","              \n","              \n","                      [[[ 93.6355]]],\n","              \n","              \n","                      [[[ 80.5200]]],\n","              \n","              \n","                      [[[ 49.4936]]],\n","              \n","              \n","                      [[[ 44.2691]]],\n","              \n","              \n","                      [[[182.0278]]],\n","              \n","              \n","                      [[[154.8503]]],\n","              \n","              \n","                      [[[226.3780]]],\n","              \n","              \n","                      [[[264.5471]]],\n","              \n","              \n","                      [[[ 71.2218]]]], device='cuda:0')),\n","             ('module.layer2.1.conv2.w_zero_point', tensor([[[[-33.]]],\n","              \n","              \n","                      [[[-33.]]],\n","              \n","              \n","                      [[[-34.]]],\n","              \n","              \n","                      [[[-26.]]],\n","              \n","              \n","                      [[[-28.]]],\n","              \n","              \n","                      [[[-31.]]],\n","              \n","              \n","                      [[[-32.]]],\n","              \n","              \n","                      [[[-27.]]],\n","              \n","              \n","                      [[[-25.]]],\n","              \n","              \n","                      [[[-25.]]],\n","              \n","              \n","                      [[[-24.]]],\n","              \n","              \n","                      [[[-32.]]],\n","              \n","              \n","                      [[[-27.]]],\n","              \n","              \n","                      [[[-24.]]],\n","              \n","              \n","                      [[[-34.]]],\n","              \n","              \n","                      [[[-31.]]],\n","              \n","              \n","                      [[[-29.]]],\n","              \n","              \n","                      [[[-36.]]],\n","              \n","              \n","                      [[[-28.]]],\n","              \n","              \n","                      [[[-27.]]],\n","              \n","              \n","                      [[[-37.]]],\n","              \n","              \n","                      [[[-33.]]],\n","              \n","              \n","                      [[[-32.]]],\n","              \n","              \n","                      [[[-35.]]],\n","              \n","              \n","                      [[[-29.]]],\n","              \n","              \n","                      [[[-26.]]],\n","              \n","              \n","                      [[[-17.]]],\n","              \n","              \n","                      [[[-30.]]],\n","              \n","              \n","                      [[[-30.]]],\n","              \n","              \n","                      [[[-27.]]],\n","              \n","              \n","                      [[[-25.]]],\n","              \n","              \n","                      [[[-42.]]]], device='cuda:0')),\n","             ('module.layer2.1.conv2.fp_bias',\n","              tensor([ 0.1025,  0.1116,  0.0929,  0.1198,  0.0331,  0.0311,  0.3401,  0.1181,\n","                       0.0257,  0.3083, -0.1069,  0.2421,  0.1245, -0.1597, -0.0274, -0.1385,\n","                       0.5887,  0.5765, -0.2252, -0.1257,  0.0885, -0.1065, -0.0372,  0.7598,\n","                       0.3979, -0.8329, -0.5819, -0.1349,  0.0667, -0.0505, -0.0893,  0.3531],\n","                     device='cuda:0')),\n","             ('module.layer2.1.conv2.accum_scale', tensor([[[11022.0762]],\n","              \n","                      [[ 6816.8027]],\n","              \n","                      [[ 4422.2896]],\n","              \n","                      [[ 3699.1702]],\n","              \n","                      [[ 2440.4993]],\n","              \n","                      [[ 4055.3818]],\n","              \n","                      [[ 4445.8140]],\n","              \n","                      [[ 3409.4851]],\n","              \n","                      [[ 5852.0220]],\n","              \n","                      [[ 4233.8481]],\n","              \n","                      [[ 5099.2407]],\n","              \n","                      [[ 4893.4214]],\n","              \n","                      [[ 5093.4727]],\n","              \n","                      [[ 5698.9888]],\n","              \n","                      [[25065.3477]],\n","              \n","                      [[ 4632.1855]],\n","              \n","                      [[ 2535.1641]],\n","              \n","                      [[ 5285.7881]],\n","              \n","                      [[ 4635.6748]],\n","              \n","                      [[ 5015.2251]],\n","              \n","                      [[ 8132.2266]],\n","              \n","                      [[ 3188.1853]],\n","              \n","                      [[10920.4287]],\n","              \n","                      [[ 3404.3352]],\n","              \n","                      [[ 2927.4900]],\n","              \n","                      [[ 1799.4554]],\n","              \n","                      [[ 1609.5037]],\n","              \n","                      [[ 6618.0405]],\n","              \n","                      [[ 5629.9390]],\n","              \n","                      [[ 8230.4912]],\n","              \n","                      [[ 9618.2178]],\n","              \n","                      [[ 2589.4309]]], device='cuda:0')),\n","             ('module.layer2.1.conv2.is_simulated_quant_weight_shifted',\n","              tensor(False, device='cuda:0')),\n","             ('module.layer2.1.conv2.wrapped_module.weight',\n","              tensor([[[[57., 48., 32.],\n","                        [33., 40., 33.],\n","                        [18., 19., 23.]],\n","              \n","                       [[22., 39., 53.],\n","                        [29., 27., 51.],\n","                        [42., 27., 47.]],\n","              \n","                       [[30., 42., 33.],\n","                        [22., 43., 36.],\n","                        [25., 31., 27.]],\n","              \n","                       ...,\n","              \n","                       [[ 0., 38., 47.],\n","                        [15., 41., 43.],\n","                        [22., 42., 44.]],\n","              \n","                       [[27., 24.,  5.],\n","                        [42., 30., 19.],\n","                        [50., 35., 30.]],\n","              \n","                       [[24., 30., 37.],\n","                        [34., 30., 28.],\n","                        [35., 40., 40.]]],\n","              \n","              \n","                      [[[33., 30., 38.],\n","                        [25., 28., 29.],\n","                        [23., 27., 21.]],\n","              \n","                       [[37., 35., 45.],\n","                        [34., 26., 41.],\n","                        [39., 28., 25.]],\n","              \n","                       [[40., 36., 30.],\n","                        [37., 37., 31.],\n","                        [28., 28., 27.]],\n","              \n","                       ...,\n","              \n","                       [[41., 27., 25.],\n","                        [34., 28., 29.],\n","                        [32., 30., 32.]],\n","              \n","                       [[34., 31., 23.],\n","                        [38., 36., 30.],\n","                        [39., 40., 37.]],\n","              \n","                       [[12., 26., 31.],\n","                        [25., 29., 28.],\n","                        [27., 26., 32.]]],\n","              \n","              \n","                      [[[37., 25., 25.],\n","                        [27., 20., 29.],\n","                        [39., 28., 36.]],\n","              \n","                       [[47., 36., 24.],\n","                        [25., 37., 40.],\n","                        [ 9., 23., 31.]],\n","              \n","                       [[29., 31., 30.],\n","                        [30., 42., 17.],\n","                        [32., 22., 15.]],\n","              \n","                       ...,\n","              \n","                       [[18., 37., 30.],\n","                        [31., 41., 52.],\n","                        [38., 40., 37.]],\n","              \n","                       [[25., 19., 18.],\n","                        [31., 33., 43.],\n","                        [54., 54., 50.]],\n","              \n","                       [[40., 28., 23.],\n","                        [35., 26., 26.],\n","                        [35., 43., 50.]]],\n","              \n","              \n","                      ...,\n","              \n","              \n","                      [[[33., 27., 25.],\n","                        [21., 13., 10.],\n","                        [31., 25., 27.]],\n","              \n","                       [[33., 25., 15.],\n","                        [22., 19., 21.],\n","                        [16., 25., 30.]],\n","              \n","                       [[18., 19., 29.],\n","                        [26., 25., 32.],\n","                        [25., 21., 19.]],\n","              \n","                       ...,\n","              \n","                       [[23., 27., 37.],\n","                        [25., 30., 36.],\n","                        [28., 28., 25.]],\n","              \n","                       [[24., 36., 40.],\n","                        [35., 60., 53.],\n","                        [24., 55., 36.]],\n","              \n","                       [[31., 32., 38.],\n","                        [26., 50., 63.],\n","                        [25., 44., 31.]]],\n","              \n","              \n","                      [[[ 6., 51., 13.],\n","                        [16., 40., 26.],\n","                        [34., 42., 38.]],\n","              \n","                       [[63., 36., 23.],\n","                        [59., 43., 17.],\n","                        [33., 38., 14.]],\n","              \n","                       [[32., 25., 30.],\n","                        [25., 17., 17.],\n","                        [17.,  8., 19.]],\n","              \n","                       ...,\n","              \n","                       [[ 3.,  3., 16.],\n","                        [31., 43., 32.],\n","                        [46., 58., 34.]],\n","              \n","                       [[12., 20., 28.],\n","                        [34., 34., 24.],\n","                        [36., 27., 10.]],\n","              \n","                       [[32., 14., 21.],\n","                        [31., 31., 42.],\n","                        [31., 34., 42.]]],\n","              \n","              \n","                      [[[48., 43., 60.],\n","                        [53., 44., 50.],\n","                        [44., 42., 35.]],\n","              \n","                       [[44., 42., 55.],\n","                        [40., 49., 47.],\n","                        [50., 44., 42.]],\n","              \n","                       [[47., 35., 45.],\n","                        [49., 33., 46.],\n","                        [53., 42., 41.]],\n","              \n","                       ...,\n","              \n","                       [[35., 24., 19.],\n","                        [41., 35., 30.],\n","                        [42., 47., 57.]],\n","              \n","                       [[33., 43., 44.],\n","                        [29., 27., 35.],\n","                        [39., 30., 34.]],\n","              \n","                       [[53., 51., 38.],\n","                        [61., 40., 35.],\n","                        [54., 53., 60.]]]], device='cuda:0')),\n","             ('module.layer2.1.conv2.wrapped_module.bias',\n","              tensor([ 1130.,   761.,   411.,   443.,    81.,   126.,  1512.,   403.,   150.,\n","                       1305.,  -545.,  1185.,   634.,  -910.,  -687.,  -641.,  1493.,  3047.,\n","                      -1044.,  -631.,   720.,  -340.,  -407.,  2587.,  1165., -1499.,  -937.,\n","                       -893.,   375.,  -416.,  -859.,   914.], device='cuda:0')),\n","             ('module.layer2.1.relu2.num_forwards',\n","              tensor([40], device='cuda:0')),\n","             ('module.layer2.1.relu2.force_readjust',\n","              tensor(False, device='cuda:0')),\n","             ('module.layer2.1.relu2.output_scale',\n","              tensor([8.3671], device='cuda:0')),\n","             ('module.layer2.1.relu2.output_zero_point',\n","              tensor([0.], device='cuda:0')),\n","             ('module.layer2.1.residual_eltwiseadd.num_forwards',\n","              tensor([40], device='cuda:0')),\n","             ('module.layer2.1.residual_eltwiseadd.force_readjust',\n","              tensor(False, device='cuda:0')),\n","             ('module.layer2.1.residual_eltwiseadd.output_scale',\n","              tensor([8.3671], device='cuda:0')),\n","             ('module.layer2.1.residual_eltwiseadd.output_zero_point',\n","              tensor([0.], device='cuda:0')),\n","             ('module.layer2.2.conv1.num_forwards',\n","              tensor([40], device='cuda:0')),\n","             ('module.layer2.2.conv1.force_readjust',\n","              tensor(False, device='cuda:0')),\n","             ('module.layer2.2.conv1.output_scale',\n","              tensor([36.8667], device='cuda:0')),\n","             ('module.layer2.2.conv1.output_zero_point',\n","              tensor([0.], device='cuda:0')),\n","             ('module.layer2.2.conv1.w_scale', tensor([[[[7.9905e+02]]],\n","              \n","              \n","                      [[[3.9621e+02]]],\n","              \n","              \n","                      [[[4.5600e+02]]],\n","              \n","              \n","                      [[[4.7993e+02]]],\n","              \n","              \n","                      [[[5.2614e+02]]],\n","              \n","              \n","                      [[[5.5957e+02]]],\n","              \n","              \n","                      [[[6.9115e+02]]],\n","              \n","              \n","                      [[[5.2136e+02]]],\n","              \n","              \n","                      [[[6.4165e+02]]],\n","              \n","              \n","                      [[[4.9417e+02]]],\n","              \n","              \n","                      [[[7.0933e+02]]],\n","              \n","              \n","                      [[[8.0609e+02]]],\n","              \n","              \n","                      [[[8.0708e+02]]],\n","              \n","              \n","                      [[[7.3144e+02]]],\n","              \n","              \n","                      [[[7.6133e+02]]],\n","              \n","              \n","                      [[[7.7919e+02]]],\n","              \n","              \n","                      [[[6.4724e+02]]],\n","              \n","              \n","                      [[[5.7680e+02]]],\n","              \n","              \n","                      [[[5.3118e+02]]],\n","              \n","              \n","                      [[[7.2022e+02]]],\n","              \n","              \n","                      [[[5.1779e+02]]],\n","              \n","              \n","                      [[[7.9037e+02]]],\n","              \n","              \n","                      [[[4.0565e+06]]],\n","              \n","              \n","                      [[[3.5685e+02]]],\n","              \n","              \n","                      [[[4.8722e+02]]],\n","              \n","              \n","                      [[[4.7652e+02]]],\n","              \n","              \n","                      [[[5.9633e+02]]],\n","              \n","              \n","                      [[[5.4418e+02]]],\n","              \n","              \n","                      [[[5.5068e+02]]],\n","              \n","              \n","                      [[[5.0110e+02]]],\n","              \n","              \n","                      [[[3.4855e+02]]],\n","              \n","              \n","                      [[[7.1721e+02]]]], device='cuda:0')),\n","             ('module.layer2.2.conv1.w_zero_point', tensor([[[[-30.]]],\n","              \n","              \n","                      [[[-31.]]],\n","              \n","              \n","                      [[[-35.]]],\n","              \n","              \n","                      [[[-26.]]],\n","              \n","              \n","                      [[[-27.]]],\n","              \n","              \n","                      [[[-31.]]],\n","              \n","              \n","                      [[[-26.]]],\n","              \n","              \n","                      [[[-29.]]],\n","              \n","              \n","                      [[[-27.]]],\n","              \n","              \n","                      [[[-34.]]],\n","              \n","              \n","                      [[[-33.]]],\n","              \n","              \n","                      [[[-28.]]],\n","              \n","              \n","                      [[[-29.]]],\n","              \n","              \n","                      [[[-33.]]],\n","              \n","              \n","                      [[[-25.]]],\n","              \n","              \n","                      [[[-34.]]],\n","              \n","              \n","                      [[[-32.]]],\n","              \n","              \n","                      [[[-25.]]],\n","              \n","              \n","                      [[[-30.]]],\n","              \n","              \n","                      [[[-36.]]],\n","              \n","              \n","                      [[[-36.]]],\n","              \n","              \n","                      [[[-35.]]],\n","              \n","              \n","                      [[[-40.]]],\n","              \n","              \n","                      [[[-24.]]],\n","              \n","              \n","                      [[[-30.]]],\n","              \n","              \n","                      [[[-37.]]],\n","              \n","              \n","                      [[[-24.]]],\n","              \n","              \n","                      [[[-35.]]],\n","              \n","              \n","                      [[[-30.]]],\n","              \n","              \n","                      [[[-32.]]],\n","              \n","              \n","                      [[[-31.]]],\n","              \n","              \n","                      [[[-26.]]]], device='cuda:0')),\n","             ('module.layer2.2.conv1.fp_bias',\n","              tensor([-2.7832e-01,  3.8585e-01, -1.0921e-01, -1.9813e-01, -4.2277e-01,\n","                      -8.0176e-03,  9.0581e-03,  4.3854e-01, -6.7399e-01, -4.3058e-01,\n","                       4.0510e-02,  3.9719e-02,  3.6750e-01,  3.4565e-01, -7.3133e-01,\n","                       4.6225e-01,  2.2204e-01, -3.3405e-01, -1.2159e-01,  3.4466e-01,\n","                       4.1493e-01,  2.2558e-01,  3.9455e-05,  2.2025e-01, -3.0964e-01,\n","                       1.5385e-01,  1.8425e-01, -1.9759e-01, -2.5155e-01, -3.0609e-01,\n","                      -1.4558e-01, -1.9583e-01], device='cuda:0')),\n","             ('module.layer2.2.conv1.accum_scale', tensor([[[6.6857e+03]],\n","              \n","                      [[3.3151e+03]],\n","              \n","                      [[3.8154e+03]],\n","              \n","                      [[4.0156e+03]],\n","              \n","                      [[4.4023e+03]],\n","              \n","                      [[4.6819e+03]],\n","              \n","                      [[5.7829e+03]],\n","              \n","                      [[4.3622e+03]],\n","              \n","                      [[5.3688e+03]],\n","              \n","                      [[4.1348e+03]],\n","              \n","                      [[5.9350e+03]],\n","              \n","                      [[6.7446e+03]],\n","              \n","                      [[6.7529e+03]],\n","              \n","                      [[6.1200e+03]],\n","              \n","                      [[6.3701e+03]],\n","              \n","                      [[6.5196e+03]],\n","              \n","                      [[5.4155e+03]],\n","              \n","                      [[4.8261e+03]],\n","              \n","                      [[4.4445e+03]],\n","              \n","                      [[6.0261e+03]],\n","              \n","                      [[4.3324e+03]],\n","              \n","                      [[6.6131e+03]],\n","              \n","                      [[3.3941e+07]],\n","              \n","                      [[2.9858e+03]],\n","              \n","                      [[4.0766e+03]],\n","              \n","                      [[3.9870e+03]],\n","              \n","                      [[4.9895e+03]],\n","              \n","                      [[4.5532e+03]],\n","              \n","                      [[4.6076e+03]],\n","              \n","                      [[4.1927e+03]],\n","              \n","                      [[2.9164e+03]],\n","              \n","                      [[6.0010e+03]]], device='cuda:0')),\n","             ('module.layer2.2.conv1.is_simulated_quant_weight_shifted',\n","              tensor(False, device='cuda:0')),\n","             ('module.layer2.2.conv1.wrapped_module.weight',\n","              tensor([[[[33., 16., 15.],\n","                        [44., 33., 33.],\n","                        [48., 33., 38.]],\n","              \n","                       [[51., 45., 17.],\n","                        [41., 38., 27.],\n","                        [32., 31., 30.]],\n","              \n","                       [[19., 21., 37.],\n","                        [35., 34., 44.],\n","                        [36., 47., 49.]],\n","              \n","                       ...,\n","              \n","                       [[22., 20., 16.],\n","                        [60., 63., 36.],\n","                        [50., 57., 42.]],\n","              \n","                       [[ 7.,  7., 26.],\n","                        [22., 19., 18.],\n","                        [40., 55., 44.]],\n","              \n","                       [[38., 36., 39.],\n","                        [34., 26., 22.],\n","                        [36., 32., 29.]]],\n","              \n","              \n","                      [[[33., 16., 41.],\n","                        [28., 24., 29.],\n","                        [38., 30., 25.]],\n","              \n","                       [[33., 21., 33.],\n","                        [28., 24., 30.],\n","                        [31., 27., 17.]],\n","              \n","                       [[32., 32., 34.],\n","                        [35., 35., 29.],\n","                        [19., 23., 16.]],\n","              \n","                       ...,\n","              \n","                       [[43., 23., 21.],\n","                        [37., 14., 30.],\n","                        [27., 43., 55.]],\n","              \n","                       [[14., 15., 14.],\n","                        [36., 55., 48.],\n","                        [35., 32., 33.]],\n","              \n","                       [[32., 26., 29.],\n","                        [37., 37., 25.],\n","                        [25., 24., 15.]]],\n","              \n","              \n","                      [[[33., 33., 45.],\n","                        [35., 29., 26.],\n","                        [22., 17., 21.]],\n","              \n","                       [[41., 47., 43.],\n","                        [26., 40., 36.],\n","                        [28., 41., 33.]],\n","              \n","                       [[25., 23., 28.],\n","                        [45., 42., 46.],\n","                        [39., 37., 38.]],\n","              \n","                       ...,\n","              \n","                       [[25., 18., 13.],\n","                        [62., 23.,  7.],\n","                        [50., 33., 32.]],\n","              \n","                       [[31., 15., 18.],\n","                        [23., 19., 21.],\n","                        [50., 47., 40.]],\n","              \n","                       [[36., 45., 52.],\n","                        [41., 40., 46.],\n","                        [34., 33., 38.]]],\n","              \n","              \n","                      ...,\n","              \n","              \n","                      [[[36., 38., 31.],\n","                        [29., 28., 41.],\n","                        [11., 16., 21.]],\n","              \n","                       [[31., 37., 23.],\n","                        [18., 20., 21.],\n","                        [30., 39., 23.]],\n","              \n","                       [[37., 31., 38.],\n","                        [26., 18., 22.],\n","                        [33., 31., 30.]],\n","              \n","                       ...,\n","              \n","                       [[12., 19., 43.],\n","                        [34., 21., 30.],\n","                        [41., 15., 32.]],\n","              \n","                       [[54., 30., 45.],\n","                        [29., 45., 36.],\n","                        [49., 46., 44.]],\n","              \n","                       [[36., 46., 47.],\n","                        [26., 26., 21.],\n","                        [29., 31., 32.]]],\n","              \n","              \n","                      [[[30., 39., 26.],\n","                        [21., 33., 32.],\n","                        [13., 33., 44.]],\n","              \n","                       [[35., 25., 25.],\n","                        [36., 33., 20.],\n","                        [31., 38., 25.]],\n","              \n","                       [[31., 35., 37.],\n","                        [35., 33., 35.],\n","                        [39., 21., 24.]],\n","              \n","                       ...,\n","              \n","                       [[27., 35., 30.],\n","                        [24., 28., 18.],\n","                        [30., 18., 33.]],\n","              \n","                       [[25., 28., 31.],\n","                        [28., 35., 31.],\n","                        [25., 46., 40.]],\n","              \n","                       [[41., 37., 35.],\n","                        [40., 34., 18.],\n","                        [37., 39., 18.]]],\n","              \n","              \n","                      [[[24., 19., 29.],\n","                        [22., 18., 29.],\n","                        [22., 20., 33.]],\n","              \n","                       [[15., 13.,  1.],\n","                        [45., 38., 14.],\n","                        [36., 37., 22.]],\n","              \n","                       [[34., 29., 34.],\n","                        [41., 42., 50.],\n","                        [24., 33., 34.]],\n","              \n","                       ...,\n","              \n","                       [[42., 30., 15.],\n","                        [10.,  2., 24.],\n","                        [25., 33., 46.]],\n","              \n","                       [[14.,  7., 14.],\n","                        [10.,  3., 20.],\n","                        [30., 32., 38.]],\n","              \n","                       [[25., 35., 30.],\n","                        [19., 22., 20.],\n","                        [24., 20., 18.]]]], device='cuda:0')),\n","             ('module.layer2.2.conv1.wrapped_module.bias',\n","              tensor([-1861.,  1279.,  -417.,  -796., -1861.,   -38.,    52.,  1913., -3618.,\n","                      -1780.,   240.,   268.,  2482.,  2115., -4659.,  3014.,  1202., -1612.,\n","                       -540.,  2077.,  1798.,  1492.,  1339.,   658., -1262.,   613.,   919.,\n","                       -900., -1159., -1283.,  -425., -1175.], device='cuda:0')),\n","             ('module.layer2.2.conv2.num_forwards',\n","              tensor([40], device='cuda:0')),\n","             ('module.layer2.2.conv2.force_readjust',\n","              tensor(False, device='cuda:0')),\n","             ('module.layer2.2.conv2.output_scale',\n","              tensor([11.7166], device='cuda:0')),\n","             ('module.layer2.2.conv2.output_zero_point',\n","              tensor([-26.], device='cuda:0')),\n","             ('module.layer2.2.conv2.w_scale', tensor([[[[  183.2885]]],\n","              \n","              \n","                      [[[  138.3399]]],\n","              \n","              \n","                      [[[  145.6036]]],\n","              \n","              \n","                      [[[  168.4560]]],\n","              \n","              \n","                      [[[   66.1926]]],\n","              \n","              \n","                      [[[   64.2285]]],\n","              \n","              \n","                      [[[  247.5015]]],\n","              \n","              \n","                      [[[  119.6321]]],\n","              \n","              \n","                      [[[  118.5747]]],\n","              \n","              \n","                      [[[   68.9565]]],\n","              \n","              \n","                      [[[  131.4570]]],\n","              \n","              \n","                      [[[  152.6141]]],\n","              \n","              \n","                      [[[  121.7381]]],\n","              \n","              \n","                      [[[  103.8022]]],\n","              \n","              \n","                      [[[  186.6215]]],\n","              \n","              \n","                      [[[   93.4912]]],\n","              \n","              \n","                      [[[   94.7155]]],\n","              \n","              \n","                      [[[  168.4099]]],\n","              \n","              \n","                      [[[   80.8276]]],\n","              \n","              \n","                      [[[   65.5988]]],\n","              \n","              \n","                      [[[  242.9458]]],\n","              \n","              \n","                      [[[  112.1031]]],\n","              \n","              \n","                      [[[  212.7038]]],\n","              \n","              \n","                      [[[  136.0895]]],\n","              \n","              \n","                      [[[  134.1011]]],\n","              \n","              \n","                      [[[   50.4519]]],\n","              \n","              \n","                      [[[   47.5565]]],\n","              \n","              \n","                      [[[  280.3653]]],\n","              \n","              \n","                      [[[  234.9301]]],\n","              \n","              \n","                      [[[  109.6547]]],\n","              \n","              \n","                      [[[10574.1094]]],\n","              \n","              \n","                      [[[   98.2748]]]], device='cuda:0')),\n","             ('module.layer2.2.conv2.w_zero_point', tensor([[[[-30.]]],\n","              \n","              \n","                      [[[-32.]]],\n","              \n","              \n","                      [[[-38.]]],\n","              \n","              \n","                      [[[-34.]]],\n","              \n","              \n","                      [[[-31.]]],\n","              \n","              \n","                      [[[-32.]]],\n","              \n","              \n","                      [[[-29.]]],\n","              \n","              \n","                      [[[-36.]]],\n","              \n","              \n","                      [[[-27.]]],\n","              \n","              \n","                      [[[-31.]]],\n","              \n","              \n","                      [[[-33.]]],\n","              \n","              \n","                      [[[-32.]]],\n","              \n","              \n","                      [[[-40.]]],\n","              \n","              \n","                      [[[-32.]]],\n","              \n","              \n","                      [[[-37.]]],\n","              \n","              \n","                      [[[-22.]]],\n","              \n","              \n","                      [[[-25.]]],\n","              \n","              \n","                      [[[-34.]]],\n","              \n","              \n","                      [[[-29.]]],\n","              \n","              \n","                      [[[-27.]]],\n","              \n","              \n","                      [[[-30.]]],\n","              \n","              \n","                      [[[-28.]]],\n","              \n","              \n","                      [[[-29.]]],\n","              \n","              \n","                      [[[-25.]]],\n","              \n","              \n","                      [[[-27.]]],\n","              \n","              \n","                      [[[-16.]]],\n","              \n","              \n","                      [[[-23.]]],\n","              \n","              \n","                      [[[-33.]]],\n","              \n","              \n","                      [[[-32.]]],\n","              \n","              \n","                      [[[-38.]]],\n","              \n","              \n","                      [[[-32.]]],\n","              \n","              \n","                      [[[-27.]]]], device='cuda:0')),\n","             ('module.layer2.2.conv2.fp_bias',\n","              tensor([-0.0481,  0.1880,  0.4748,  0.2426, -0.1824, -0.2315,  0.0884,  0.4187,\n","                      -0.0691, -0.0372,  0.4500,  0.1372,  0.2553, -0.1885,  0.0914, -0.6076,\n","                      -0.0255,  0.3631, -0.2162,  0.4215, -0.0232, -0.1516,  0.1137, -0.4513,\n","                       0.1195, -0.1995, -0.2382, -0.0196,  0.0757,  0.0806,  0.0060, -0.0870],\n","                     device='cuda:0')),\n","             ('module.layer2.2.conv2.accum_scale', tensor([[[  6757.2451]],\n","              \n","                      [[  5100.1377]],\n","              \n","                      [[  5367.9263]],\n","              \n","                      [[  6210.4180]],\n","              \n","                      [[  2440.3025]],\n","              \n","                      [[  2367.8921]],\n","              \n","                      [[  9124.5654]],\n","              \n","                      [[  4410.4438]],\n","              \n","                      [[  4371.4614]],\n","              \n","                      [[  2542.1995]],\n","              \n","                      [[  4846.3872]],\n","              \n","                      [[  5626.3789]],\n","              \n","                      [[  4488.0850]],\n","              \n","                      [[  3826.8445]],\n","              \n","                      [[  6880.1211]],\n","              \n","                      [[  3446.7141]],\n","              \n","                      [[  3491.8499]],\n","              \n","                      [[  6208.7197]],\n","              \n","                      [[  2979.8494]],\n","              \n","                      [[  2418.4141]],\n","              \n","                      [[  8956.6143]],\n","              \n","                      [[  4132.8716]],\n","              \n","                      [[  7841.6899]],\n","              \n","                      [[  5017.1724]],\n","              \n","                      [[  4943.8677]],\n","              \n","                      [[  1859.9974]],\n","              \n","                      [[  1753.2505]],\n","              \n","                      [[ 10336.1475]],\n","              \n","                      [[  8661.1025]],\n","              \n","                      [[  4042.6077]],\n","              \n","                      [[389832.6562]],\n","              \n","                      [[  3623.0674]]], device='cuda:0')),\n","             ('module.layer2.2.conv2.is_simulated_quant_weight_shifted',\n","              tensor(False, device='cuda:0')),\n","             ('module.layer2.2.conv2.wrapped_module.weight',\n","              tensor([[[[39., 32., 29.],\n","                        [36., 29., 30.],\n","                        [40., 34., 33.]],\n","              \n","                       [[42., 27., 26.],\n","                        [24., 27., 37.],\n","                        [49., 61., 43.]],\n","              \n","                       [[34., 33., 31.],\n","                        [18., 33., 30.],\n","                        [40., 50., 31.]],\n","              \n","                       ...,\n","              \n","                       [[32., 21., 16.],\n","                        [42., 27., 17.],\n","                        [45., 48., 41.]],\n","              \n","                       [[46., 21., 26.],\n","                        [46., 28., 30.],\n","                        [34., 30., 21.]],\n","              \n","                       [[13., 29., 23.],\n","                        [19., 25., 20.],\n","                        [23., 24., 26.]]],\n","              \n","              \n","                      [[[31., 27., 24.],\n","                        [32., 33., 32.],\n","                        [29., 23., 28.]],\n","              \n","                       [[51., 31., 45.],\n","                        [43., 29., 28.],\n","                        [50., 37., 31.]],\n","              \n","                       [[39., 36., 35.],\n","                        [26., 28., 31.],\n","                        [34., 43., 45.]],\n","              \n","                       ...,\n","              \n","                       [[40., 43., 47.],\n","                        [28., 32., 34.],\n","                        [25., 32., 22.]],\n","              \n","                       [[21., 33., 40.],\n","                        [35., 36., 28.],\n","                        [27., 27., 13.]],\n","              \n","                       [[22., 33., 49.],\n","                        [33., 36., 42.],\n","                        [36., 33., 40.]]],\n","              \n","              \n","                      [[[42., 27., 22.],\n","                        [52., 33., 28.],\n","                        [42., 37., 32.]],\n","              \n","                       [[43., 41., 39.],\n","                        [38., 56., 56.],\n","                        [22., 24., 34.]],\n","              \n","                       [[34., 35., 35.],\n","                        [32., 33., 36.],\n","                        [23., 22., 26.]],\n","              \n","                       ...,\n","              \n","                       [[24., 28., 41.],\n","                        [33., 39., 53.],\n","                        [24., 22., 26.]],\n","              \n","                       [[26., 25., 20.],\n","                        [44., 57., 39.],\n","                        [33., 56., 58.]],\n","              \n","                       [[47., 43., 36.],\n","                        [16., 22., 10.],\n","                        [20., 21.,  0.]]],\n","              \n","              \n","                      ...,\n","              \n","              \n","                      [[[36., 40., 36.],\n","                        [31., 36., 36.],\n","                        [31., 37., 33.]],\n","              \n","                       [[33., 50., 31.],\n","                        [40., 42., 44.],\n","                        [27., 23., 25.]],\n","              \n","                       [[41., 38., 50.],\n","                        [27., 30., 38.],\n","                        [29., 37., 42.]],\n","              \n","                       ...,\n","              \n","                       [[34., 35., 27.],\n","                        [35., 28., 22.],\n","                        [39., 44., 35.]],\n","              \n","                       [[35., 31., 25.],\n","                        [36., 34., 37.],\n","                        [37., 33., 31.]],\n","              \n","                       [[38., 32., 21.],\n","                        [38., 38., 31.],\n","                        [32., 36., 25.]]],\n","              \n","              \n","                      [[[32., 33., 32.],\n","                        [28., 29., 29.],\n","                        [27., 29., 30.]],\n","              \n","                       [[37., 47., 41.],\n","                        [23., 44., 30.],\n","                        [33., 35., 21.]],\n","              \n","                       [[30., 46., 45.],\n","                        [20., 33., 32.],\n","                        [31., 33., 34.]],\n","              \n","                       ...,\n","              \n","                       [[43., 42., 54.],\n","                        [28., 20., 30.],\n","                        [36., 26., 32.]],\n","              \n","                       [[29., 38., 27.],\n","                        [35., 45., 20.],\n","                        [40., 36., 28.]],\n","              \n","                       [[50., 36., 34.],\n","                        [36., 25., 30.],\n","                        [24., 22., 30.]]],\n","              \n","              \n","                      [[[29., 22.,  9.],\n","                        [33., 27., 19.],\n","                        [33., 31., 26.]],\n","              \n","                       [[15., 11., 41.],\n","                        [28., 32., 48.],\n","                        [41., 31., 49.]],\n","              \n","                       [[17., 18., 18.],\n","                        [30., 33., 20.],\n","                        [26., 21.,  9.]],\n","              \n","                       ...,\n","              \n","                       [[ 9., 17., 25.],\n","                        [ 9., 10., 18.],\n","                        [33., 35., 30.]],\n","              \n","                       [[ 5., 40., 27.],\n","                        [16., 50., 44.],\n","                        [28., 42., 52.]],\n","              \n","                       [[49., 33., 22.],\n","                        [43., 41., 30.],\n","                        [39., 29., 28.]]]], device='cuda:0')),\n","             ('module.layer2.2.conv2.wrapped_module.bias',\n","              tensor([ -325.,   959.,  2549.,  1506.,  -445.,  -548.,   807.,  1847.,  -302.,\n","                        -95.,  2181.,   772.,  1146.,  -721.,   629., -2094.,   -89.,  2255.,\n","                       -644.,  1019.,  -208.,  -627.,   892., -2264.,   591.,  -371.,  -418.,\n","                       -202.,   656.,   326.,  2336.,  -315.], device='cuda:0')),\n","             ('module.layer2.2.relu2.num_forwards',\n","              tensor([40], device='cuda:0')),\n","             ('module.layer2.2.relu2.force_readjust',\n","              tensor(False, device='cuda:0')),\n","             ('module.layer2.2.relu2.output_scale',\n","              tensor([7.9452], device='cuda:0')),\n","             ('module.layer2.2.relu2.output_zero_point',\n","              tensor([0.], device='cuda:0')),\n","             ('module.layer2.2.residual_eltwiseadd.num_forwards',\n","              tensor([40], device='cuda:0')),\n","             ('module.layer2.2.residual_eltwiseadd.force_readjust',\n","              tensor(False, device='cuda:0')),\n","             ('module.layer2.2.residual_eltwiseadd.output_scale',\n","              tensor([7.9452], device='cuda:0')),\n","             ('module.layer2.2.residual_eltwiseadd.output_zero_point',\n","              tensor([0.], device='cuda:0')),\n","             ('module.layer2.3.conv1.num_forwards',\n","              tensor([40], device='cuda:0')),\n","             ('module.layer2.3.conv1.force_readjust',\n","              tensor(False, device='cuda:0')),\n","             ('module.layer2.3.conv1.output_scale',\n","              tensor([38.0191], device='cuda:0')),\n","             ('module.layer2.3.conv1.output_zero_point',\n","              tensor([0.], device='cuda:0')),\n","             ('module.layer2.3.conv1.w_scale', tensor([[[[570.2943]]],\n","              \n","              \n","                      [[[572.2844]]],\n","              \n","              \n","                      [[[952.7141]]],\n","              \n","              \n","                      [[[769.4903]]],\n","              \n","              \n","                      [[[677.2106]]],\n","              \n","              \n","                      [[[927.7922]]],\n","              \n","              \n","                      [[[560.0508]]],\n","              \n","              \n","                      [[[965.1926]]],\n","              \n","              \n","                      [[[441.9619]]],\n","              \n","              \n","                      [[[510.5712]]],\n","              \n","              \n","                      [[[664.8567]]],\n","              \n","              \n","                      [[[593.0104]]],\n","              \n","              \n","                      [[[452.3085]]],\n","              \n","              \n","                      [[[642.5535]]],\n","              \n","              \n","                      [[[467.1097]]],\n","              \n","              \n","                      [[[746.1713]]],\n","              \n","              \n","                      [[[657.7921]]],\n","              \n","              \n","                      [[[555.3337]]],\n","              \n","              \n","                      [[[685.2126]]],\n","              \n","              \n","                      [[[979.6417]]],\n","              \n","              \n","                      [[[625.1968]]],\n","              \n","              \n","                      [[[491.1125]]],\n","              \n","              \n","                      [[[463.4532]]],\n","              \n","              \n","                      [[[436.6272]]],\n","              \n","              \n","                      [[[589.3232]]],\n","              \n","              \n","                      [[[489.7736]]],\n","              \n","              \n","                      [[[375.2543]]],\n","              \n","              \n","                      [[[855.5883]]],\n","              \n","              \n","                      [[[457.4440]]],\n","              \n","              \n","                      [[[512.3211]]],\n","              \n","              \n","                      [[[534.9551]]],\n","              \n","              \n","                      [[[828.1794]]]], device='cuda:0')),\n","             ('module.layer2.3.conv1.w_zero_point', tensor([[[[-36.]]],\n","              \n","              \n","                      [[[-32.]]],\n","              \n","              \n","                      [[[-23.]]],\n","              \n","              \n","                      [[[-32.]]],\n","              \n","              \n","                      [[[-30.]]],\n","              \n","              \n","                      [[[-30.]]],\n","              \n","              \n","                      [[[-30.]]],\n","              \n","              \n","                      [[[-29.]]],\n","              \n","              \n","                      [[[-30.]]],\n","              \n","              \n","                      [[[-32.]]],\n","              \n","              \n","                      [[[-37.]]],\n","              \n","              \n","                      [[[-25.]]],\n","              \n","              \n","                      [[[-26.]]],\n","              \n","              \n","                      [[[-29.]]],\n","              \n","              \n","                      [[[-36.]]],\n","              \n","              \n","                      [[[-29.]]],\n","              \n","              \n","                      [[[-30.]]],\n","              \n","              \n","                      [[[-32.]]],\n","              \n","              \n","                      [[[-22.]]],\n","              \n","              \n","                      [[[-25.]]],\n","              \n","              \n","                      [[[-26.]]],\n","              \n","              \n","                      [[[-30.]]],\n","              \n","              \n","                      [[[-34.]]],\n","              \n","              \n","                      [[[-26.]]],\n","              \n","              \n","                      [[[-27.]]],\n","              \n","              \n","                      [[[-37.]]],\n","              \n","              \n","                      [[[-24.]]],\n","              \n","              \n","                      [[[-30.]]],\n","              \n","              \n","                      [[[-27.]]],\n","              \n","              \n","                      [[[-33.]]],\n","              \n","              \n","                      [[[-25.]]],\n","              \n","              \n","                      [[[-36.]]]], device='cuda:0')),\n","             ('module.layer2.3.conv1.fp_bias',\n","              tensor([-0.1104,  0.0239, -0.3264, -0.5926, -0.1061, -0.4344, -0.1575, -0.4253,\n","                      -0.2706, -0.2299, -0.0495,  0.1093, -0.6884,  0.6544,  0.4385,  0.0328,\n","                       0.3622,  0.1377, -0.5351, -0.6403, -0.0142,  0.2752,  0.4412, -0.3384,\n","                       0.1691, -0.1707,  0.0537, -0.0102,  0.0526,  0.4465,  0.2093,  0.3574],\n","                     device='cuda:0')),\n","             ('module.layer2.3.conv1.accum_scale', tensor([[[4531.1211]],\n","              \n","                      [[4546.9331]],\n","              \n","                      [[7569.5361]],\n","              \n","                      [[6113.7798]],\n","              \n","                      [[5380.5967]],\n","              \n","                      [[7371.5259]],\n","              \n","                      [[4449.7349]],\n","              \n","                      [[7668.6802]],\n","              \n","                      [[3511.4902]],\n","              \n","                      [[4056.6072]],\n","              \n","                      [[5282.4414]],\n","              \n","                      [[4711.6064]],\n","              \n","                      [[3593.6963]],\n","              \n","                      [[5105.2373]],\n","              \n","                      [[3711.2957]],\n","              \n","                      [[5928.5049]],\n","              \n","                      [[5226.3115]],\n","              \n","                      [[4412.2559]],\n","              \n","                      [[5444.1738]],\n","              \n","                      [[7783.4819]],\n","              \n","                      [[4967.3345]],\n","              \n","                      [[3902.0037]],\n","              \n","                      [[3682.2437]],\n","              \n","                      [[3469.1052]],\n","              \n","                      [[4682.3105]],\n","              \n","                      [[3891.3652]],\n","              \n","                      [[2981.4832]],\n","              \n","                      [[6797.8481]],\n","              \n","                      [[3634.4995]],\n","              \n","                      [[4070.5107]],\n","              \n","                      [[4250.3433]],\n","              \n","                      [[6580.0791]]], device='cuda:0')),\n","             ('module.layer2.3.conv1.is_simulated_quant_weight_shifted',\n","              tensor(False, device='cuda:0')),\n","             ('module.layer2.3.conv1.wrapped_module.weight',\n","              tensor([[[[46., 43., 28.],\n","                        [29., 51., 48.],\n","                        [42., 34., 45.]],\n","              \n","                       [[44., 54., 28.],\n","                        [20., 35., 39.],\n","                        [34., 29., 35.]],\n","              \n","                       [[50., 48., 44.],\n","                        [45., 49., 40.],\n","                        [34., 55., 54.]],\n","              \n","                       ...,\n","              \n","                       [[38., 32., 19.],\n","                        [32., 35., 46.],\n","                        [32., 31., 41.]],\n","              \n","                       [[45., 48., 54.],\n","                        [31., 34., 40.],\n","                        [22.,  0.,  7.]],\n","              \n","                       [[42., 39., 29.],\n","                        [32., 37., 30.],\n","                        [26., 23., 25.]]],\n","              \n","              \n","                      [[[33., 24.,  0.],\n","                        [34., 35., 28.],\n","                        [35., 38., 42.]],\n","              \n","                       [[41., 28., 18.],\n","                        [39., 43., 23.],\n","                        [49., 63., 60.]],\n","              \n","                       [[34., 38., 39.],\n","                        [32., 41., 38.],\n","                        [39., 43., 43.]],\n","              \n","                       ...,\n","              \n","                       [[20., 40., 34.],\n","                        [48., 36., 19.],\n","                        [44., 30., 28.]],\n","              \n","                       [[39., 37., 44.],\n","                        [44., 25., 22.],\n","                        [19.,  4., 20.]],\n","              \n","                       [[24., 26., 34.],\n","                        [30., 25., 30.],\n","                        [34., 29., 25.]]],\n","              \n","              \n","                      [[[10., 27., 24.],\n","                        [ 4., 23., 26.],\n","                        [ 2., 15., 37.]],\n","              \n","                       [[32., 31., 34.],\n","                        [30., 31., 40.],\n","                        [27., 15., 29.]],\n","              \n","                       [[28., 32., 42.],\n","                        [37., 41., 39.],\n","                        [30., 35., 32.]],\n","              \n","                       ...,\n","              \n","                       [[ 8., 20., 24.],\n","                        [10., 23., 31.],\n","                        [11., 27., 50.]],\n","              \n","                       [[26., 24., 17.],\n","                        [47., 56., 48.],\n","                        [ 5., 27., 27.]],\n","              \n","                       [[32., 29., 34.],\n","                        [32., 27., 27.],\n","                        [21., 18., 16.]]],\n","              \n","              \n","                      ...,\n","              \n","              \n","                      [[[43., 27., 30.],\n","                        [41., 32., 24.],\n","                        [36., 39., 20.]],\n","              \n","                       [[34., 25., 24.],\n","                        [42., 33., 21.],\n","                        [40., 32., 33.]],\n","              \n","                       [[32., 31., 37.],\n","                        [26., 32., 47.],\n","                        [23., 25., 41.]],\n","              \n","                       ...,\n","              \n","                       [[35., 40., 33.],\n","                        [45., 39., 24.],\n","                        [41., 40., 30.]],\n","              \n","                       [[39., 22., 18.],\n","                        [42., 31., 13.],\n","                        [23., 37., 17.]],\n","              \n","                       [[21., 26., 22.],\n","                        [29., 32., 23.],\n","                        [30., 34., 26.]]],\n","              \n","              \n","                      [[[28., 28., 22.],\n","                        [28., 20., 22.],\n","                        [23., 10., 21.]],\n","              \n","                       [[15., 21., 37.],\n","                        [11., 18., 24.],\n","                        [23., 20., 19.]],\n","              \n","                       [[16., 15., 16.],\n","                        [16., 26., 32.],\n","                        [24., 25., 23.]],\n","              \n","                       ...,\n","              \n","                       [[43., 18., 16.],\n","                        [28.,  5., 46.],\n","                        [31., 33., 63.]],\n","              \n","                       [[23., 20., 11.],\n","                        [19., 14.,  9.],\n","                        [17., 18.,  9.]],\n","              \n","                       [[26., 23., 21.],\n","                        [21., 19., 15.],\n","                        [18., 23., 19.]]],\n","              \n","              \n","                      [[[35., 38., 27.],\n","                        [48., 56., 46.],\n","                        [29., 39., 36.]],\n","              \n","                       [[34., 42., 50.],\n","                        [33., 53., 61.],\n","                        [36., 43., 55.]],\n","              \n","                       [[32., 32., 36.],\n","                        [27., 28., 36.],\n","                        [29., 28., 40.]],\n","              \n","                       ...,\n","              \n","                       [[53., 35., 30.],\n","                        [52., 30., 22.],\n","                        [22., 20., 29.]],\n","              \n","                       [[37., 27., 24.],\n","                        [48.,  0., 12.],\n","                        [63., 21., 26.]],\n","              \n","                       [[40., 32., 37.],\n","                        [34., 27., 37.],\n","                        [39., 34., 36.]]]], device='cuda:0')),\n","             ('module.layer2.3.conv1.wrapped_module.bias',\n","              tensor([ -500.,   109., -2471., -3623.,  -571., -3202.,  -701., -3261.,  -950.,\n","                       -933.,  -262.,   515., -2474.,  3341.,  1627.,   195.,  1893.,   607.,\n","                      -2913., -4984.,   -71.,  1074.,  1624., -1174.,   792.,  -664.,   160.,\n","                        -69.,   191.,  1817.,   889.,  2352.], device='cuda:0')),\n","             ('module.layer2.3.conv2.num_forwards',\n","              tensor([40], device='cuda:0')),\n","             ('module.layer2.3.conv2.force_readjust',\n","              tensor(False, device='cuda:0')),\n","             ('module.layer2.3.conv2.output_scale',\n","              tensor([12.9729], device='cuda:0')),\n","             ('module.layer2.3.conv2.output_zero_point',\n","              tensor([-30.], device='cuda:0')),\n","             ('module.layer2.3.conv2.w_scale', tensor([[[[123.4426]]],\n","              \n","              \n","                      [[[232.1879]]],\n","              \n","              \n","                      [[[138.7323]]],\n","              \n","              \n","                      [[[ 79.1695]]],\n","              \n","              \n","                      [[[ 74.5163]]],\n","              \n","              \n","                      [[[120.8957]]],\n","              \n","              \n","                      [[[101.6093]]],\n","              \n","              \n","                      [[[103.8416]]],\n","              \n","              \n","                      [[[ 50.9227]]],\n","              \n","              \n","                      [[[ 83.8110]]],\n","              \n","              \n","                      [[[ 82.9618]]],\n","              \n","              \n","                      [[[134.4875]]],\n","              \n","              \n","                      [[[116.8712]]],\n","              \n","              \n","                      [[[170.1813]]],\n","              \n","              \n","                      [[[190.8749]]],\n","              \n","              \n","                      [[[482.4386]]],\n","              \n","              \n","                      [[[122.3972]]],\n","              \n","              \n","                      [[[ 98.7302]]],\n","              \n","              \n","                      [[[ 38.2262]]],\n","              \n","              \n","                      [[[156.0359]]],\n","              \n","              \n","                      [[[362.9949]]],\n","              \n","              \n","                      [[[ 67.3775]]],\n","              \n","              \n","                      [[[122.9369]]],\n","              \n","              \n","                      [[[105.2016]]],\n","              \n","              \n","                      [[[160.6403]]],\n","              \n","              \n","                      [[[157.0128]]],\n","              \n","              \n","                      [[[ 81.8888]]],\n","              \n","              \n","                      [[[317.8610]]],\n","              \n","              \n","                      [[[131.2924]]],\n","              \n","              \n","                      [[[107.0569]]],\n","              \n","              \n","                      [[[117.9912]]],\n","              \n","              \n","                      [[[ 96.1943]]]], device='cuda:0')),\n","             ('module.layer2.3.conv2.w_zero_point', tensor([[[[-25.]]],\n","              \n","              \n","                      [[[-35.]]],\n","              \n","              \n","                      [[[-34.]]],\n","              \n","              \n","                      [[[-20.]]],\n","              \n","              \n","                      [[[-28.]]],\n","              \n","              \n","                      [[[-31.]]],\n","              \n","              \n","                      [[[-26.]]],\n","              \n","              \n","                      [[[-28.]]],\n","              \n","              \n","                      [[[-39.]]],\n","              \n","              \n","                      [[[-32.]]],\n","              \n","              \n","                      [[[-19.]]],\n","              \n","              \n","                      [[[-32.]]],\n","              \n","              \n","                      [[[-33.]]],\n","              \n","              \n","                      [[[-28.]]],\n","              \n","              \n","                      [[[-32.]]],\n","              \n","              \n","                      [[[-26.]]],\n","              \n","              \n","                      [[[-30.]]],\n","              \n","              \n","                      [[[-38.]]],\n","              \n","              \n","                      [[[-28.]]],\n","              \n","              \n","                      [[[-29.]]],\n","              \n","              \n","                      [[[-33.]]],\n","              \n","              \n","                      [[[-26.]]],\n","              \n","              \n","                      [[[-35.]]],\n","              \n","              \n","                      [[[-31.]]],\n","              \n","              \n","                      [[[-30.]]],\n","              \n","              \n","                      [[[-27.]]],\n","              \n","              \n","                      [[[-23.]]],\n","              \n","              \n","                      [[[-38.]]],\n","              \n","              \n","                      [[[-31.]]],\n","              \n","              \n","                      [[[-25.]]],\n","              \n","              \n","                      [[[-26.]]],\n","              \n","              \n","                      [[[-24.]]]], device='cuda:0')),\n","             ('module.layer2.3.conv2.fp_bias',\n","              tensor([ 0.0578,  0.0734,  0.4741, -0.1018, -0.2713,  0.1148, -0.1087,  0.1147,\n","                      -0.3202, -0.2311, -0.1553,  0.0903,  0.2611, -0.0799, -0.0584, -0.0672,\n","                       0.1687,  0.5817,  0.0551, -0.2479, -0.0723, -0.0734, -0.1963,  0.3566,\n","                      -0.0349,  0.2214, -0.1309,  0.1417, -0.1663,  0.0148, -0.2536, -0.1435],\n","                     device='cuda:0')),\n","             ('module.layer2.3.conv2.accum_scale', tensor([[[ 4693.1748]],\n","              \n","                      [[ 8827.5752]],\n","              \n","                      [[ 5274.4766]],\n","              \n","                      [[ 3009.9539]],\n","              \n","                      [[ 2833.0439]],\n","              \n","                      [[ 4596.3442]],\n","              \n","                      [[ 3863.0942]],\n","              \n","                      [[ 3947.9626]],\n","              \n","                      [[ 1936.0366]],\n","              \n","                      [[ 3186.4175]],\n","              \n","                      [[ 3154.1311]],\n","              \n","                      [[ 5113.0938]],\n","              \n","                      [[ 4443.3374]],\n","              \n","                      [[ 6470.1396]],\n","              \n","                      [[ 7256.8911]],\n","              \n","                      [[18341.8809]],\n","              \n","                      [[ 4653.4326]],\n","              \n","                      [[ 3753.6345]],\n","              \n","                      [[ 1453.3237]],\n","              \n","                      [[ 5932.3433]],\n","              \n","                      [[13800.7373]],\n","              \n","                      [[ 2561.6328]],\n","              \n","                      [[ 4673.9487]],\n","              \n","                      [[ 3999.6709]],\n","              \n","                      [[ 6107.4004]],\n","              \n","                      [[ 5969.4839]],\n","              \n","                      [[ 3113.3396]],\n","              \n","                      [[12084.7891]],\n","              \n","                      [[ 4991.6167]],\n","              \n","                      [[ 4070.2080]],\n","              \n","                      [[ 4485.9189]],\n","              \n","                      [[ 3657.2195]]], device='cuda:0')),\n","             ('module.layer2.3.conv2.is_simulated_quant_weight_shifted',\n","              tensor(False, device='cuda:0')),\n","             ('module.layer2.3.conv2.wrapped_module.weight',\n","              tensor([[[[24., 24., 26.],\n","                        [29., 29., 32.],\n","                        [37., 36., 18.]],\n","              \n","                       [[32., 31., 24.],\n","                        [27., 19., 15.],\n","                        [28., 33., 36.]],\n","              \n","                       [[29., 28., 28.],\n","                        [21., 20., 22.],\n","                        [15., 15., 18.]],\n","              \n","                       ...,\n","              \n","                       [[23., 12., 13.],\n","                        [32., 16., 21.],\n","                        [26., 20., 22.]],\n","              \n","                       [[33., 25., 29.],\n","                        [11., 19., 26.],\n","                        [13., 31., 31.]],\n","              \n","                       [[29., 36., 26.],\n","                        [24., 26., 27.],\n","                        [27., 27., 28.]]],\n","              \n","              \n","                      [[[42., 37., 28.],\n","                        [35., 36., 40.],\n","                        [46., 46., 45.]],\n","              \n","                       [[31., 33., 23.],\n","                        [39., 30., 20.],\n","                        [40., 41., 42.]],\n","              \n","                       [[30., 34., 34.],\n","                        [27., 26., 25.],\n","                        [27., 27., 26.]],\n","              \n","                       ...,\n","              \n","                       [[43., 36., 33.],\n","                        [16., 24., 35.],\n","                        [16., 24., 38.]],\n","              \n","                       [[47., 32., 25.],\n","                        [44., 29., 20.],\n","                        [25., 25., 26.]],\n","              \n","                       [[42., 45., 40.],\n","                        [44., 40., 41.],\n","                        [35., 38., 43.]]],\n","              \n","              \n","                      [[[30., 36., 41.],\n","                        [29., 30., 42.],\n","                        [36., 23., 47.]],\n","              \n","                       [[47., 39., 24.],\n","                        [42., 38., 18.],\n","                        [49., 47., 24.]],\n","              \n","                       [[27., 34., 31.],\n","                        [35., 39., 38.],\n","                        [23., 26., 27.]],\n","              \n","                       ...,\n","              \n","                       [[36., 43., 40.],\n","                        [28., 33., 33.],\n","                        [10., 28., 32.]],\n","              \n","                       [[38., 43., 33.],\n","                        [49., 45., 27.],\n","                        [53., 44., 36.]],\n","              \n","                       [[32., 32., 24.],\n","                        [33., 21., 11.],\n","                        [63., 35., 17.]]],\n","              \n","              \n","                      ...,\n","              \n","              \n","                      [[[19., 18., 21.],\n","                        [15., 16., 24.],\n","                        [13., 20., 35.]],\n","              \n","                       [[20., 29., 32.],\n","                        [21., 32., 34.],\n","                        [22., 12., 13.]],\n","              \n","                       [[32., 30., 24.],\n","                        [31., 28., 24.],\n","                        [24., 23., 20.]],\n","              \n","                       ...,\n","              \n","                       [[ 5., 12., 24.],\n","                        [11., 15., 11.],\n","                        [24., 18., 24.]],\n","              \n","                       [[29., 45., 41.],\n","                        [11., 20., 28.],\n","                        [ 4.,  7., 19.]],\n","              \n","                       [[39., 24.,  6.],\n","                        [18., 21., 34.],\n","                        [16., 29., 30.]]],\n","              \n","              \n","                      [[[28., 13., 19.],\n","                        [34., 22., 30.],\n","                        [31., 24., 35.]],\n","              \n","                       [[23., 21., 31.],\n","                        [23., 29., 33.],\n","                        [38., 48., 42.]],\n","              \n","                       [[16., 18., 27.],\n","                        [27., 35., 44.],\n","                        [26., 34., 41.]],\n","              \n","                       ...,\n","              \n","                       [[34., 34., 21.],\n","                        [36., 32., 25.],\n","                        [26., 32., 35.]],\n","              \n","                       [[40., 22., 27.],\n","                        [35., 15., 22.],\n","                        [22.,  6., 15.]],\n","              \n","                       [[18., 42., 45.],\n","                        [10., 46., 46.],\n","                        [ 6., 39., 30.]]],\n","              \n","              \n","                      [[[24., 25., 29.],\n","                        [30., 16., 17.],\n","                        [31., 32., 33.]],\n","              \n","                       [[30., 26., 19.],\n","                        [32., 27., 14.],\n","                        [41., 38., 32.]],\n","              \n","                       [[20., 26., 22.],\n","                        [21., 22., 20.],\n","                        [21., 19., 16.]],\n","              \n","                       ...,\n","              \n","                       [[10., 25., 21.],\n","                        [17., 25.,  3.],\n","                        [22., 18.,  0.]],\n","              \n","                       [[18., 22., 15.],\n","                        [21., 28., 15.],\n","                        [11., 28., 25.]],\n","              \n","                       [[20., 13., 15.],\n","                        [36., 22., 19.],\n","                        [18., 18., 20.]]]], device='cuda:0')),\n","             ('module.layer2.3.conv2.wrapped_module.bias',\n","              tensor([  271.,   648.,  2500.,  -307.,  -769.,   528.,  -420.,   453.,  -620.,\n","                       -736.,  -490.,   462.,  1160.,  -517.,  -424., -1232.,   785.,  2183.,\n","                         80., -1470.,  -998.,  -188.,  -918.,  1426.,  -213.,  1322.,  -407.,\n","                       1713.,  -830.,    60., -1138.,  -525.], device='cuda:0')),\n","             ('module.layer2.3.relu2.num_forwards',\n","              tensor([40], device='cuda:0')),\n","             ('module.layer2.3.relu2.force_readjust',\n","              tensor(False, device='cuda:0')),\n","             ('module.layer2.3.relu2.output_scale',\n","              tensor([7.6618], device='cuda:0')),\n","             ('module.layer2.3.relu2.output_zero_point',\n","              tensor([0.], device='cuda:0')),\n","             ('module.layer2.3.residual_eltwiseadd.num_forwards',\n","              tensor([40], device='cuda:0')),\n","             ('module.layer2.3.residual_eltwiseadd.force_readjust',\n","              tensor(False, device='cuda:0')),\n","             ('module.layer2.3.residual_eltwiseadd.output_scale',\n","              tensor([7.6618], device='cuda:0')),\n","             ('module.layer2.3.residual_eltwiseadd.output_zero_point',\n","              tensor([0.], device='cuda:0')),\n","             ('module.layer2.4.conv1.num_forwards',\n","              tensor([40], device='cuda:0')),\n","             ('module.layer2.4.conv1.force_readjust',\n","              tensor(False, device='cuda:0')),\n","             ('module.layer2.4.conv1.output_scale',\n","              tensor([41.1958], device='cuda:0')),\n","             ('module.layer2.4.conv1.output_zero_point',\n","              tensor([0.], device='cuda:0')),\n","             ('module.layer2.4.conv1.w_scale', tensor([[[[ 978.5945]]],\n","              \n","              \n","                      [[[ 944.1397]]],\n","              \n","              \n","                      [[[ 570.2558]]],\n","              \n","              \n","                      [[[1703.3218]]],\n","              \n","              \n","                      [[[ 776.2528]]],\n","              \n","              \n","                      [[[ 626.5858]]],\n","              \n","              \n","                      [[[ 785.0042]]],\n","              \n","              \n","                      [[[ 582.1342]]],\n","              \n","              \n","                      [[[ 869.6219]]],\n","              \n","              \n","                      [[[ 829.3231]]],\n","              \n","              \n","                      [[[ 705.7006]]],\n","              \n","              \n","                      [[[ 509.8283]]],\n","              \n","              \n","                      [[[ 508.4665]]],\n","              \n","              \n","                      [[[ 785.9044]]],\n","              \n","              \n","                      [[[ 413.8281]]],\n","              \n","              \n","                      [[[ 459.2779]]],\n","              \n","              \n","                      [[[ 754.5883]]],\n","              \n","              \n","                      [[[ 870.8300]]],\n","              \n","              \n","                      [[[1725.1854]]],\n","              \n","              \n","                      [[[ 535.7258]]],\n","              \n","              \n","                      [[[ 961.6764]]],\n","              \n","              \n","                      [[[ 914.8514]]],\n","              \n","              \n","                      [[[ 828.0274]]],\n","              \n","              \n","                      [[[ 842.9272]]],\n","              \n","              \n","                      [[[1014.6591]]],\n","              \n","              \n","                      [[[ 952.9836]]],\n","              \n","              \n","                      [[[1096.2198]]],\n","              \n","              \n","                      [[[ 546.4764]]],\n","              \n","              \n","                      [[[ 690.9125]]],\n","              \n","              \n","                      [[[ 826.6961]]],\n","              \n","              \n","                      [[[1256.0494]]],\n","              \n","              \n","                      [[[1343.1779]]]], device='cuda:0')),\n","             ('module.layer2.4.conv1.w_zero_point', tensor([[[[-30.]]],\n","              \n","              \n","                      [[[-29.]]],\n","              \n","              \n","                      [[[-29.]]],\n","              \n","              \n","                      [[[-26.]]],\n","              \n","              \n","                      [[[-31.]]],\n","              \n","              \n","                      [[[-27.]]],\n","              \n","              \n","                      [[[-31.]]],\n","              \n","              \n","                      [[[-33.]]],\n","              \n","              \n","                      [[[-27.]]],\n","              \n","              \n","                      [[[-32.]]],\n","              \n","              \n","                      [[[-30.]]],\n","              \n","              \n","                      [[[-24.]]],\n","              \n","              \n","                      [[[-30.]]],\n","              \n","              \n","                      [[[-29.]]],\n","              \n","              \n","                      [[[-32.]]],\n","              \n","              \n","                      [[[-31.]]],\n","              \n","              \n","                      [[[-35.]]],\n","              \n","              \n","                      [[[-33.]]],\n","              \n","              \n","                      [[[-29.]]],\n","              \n","              \n","                      [[[-29.]]],\n","              \n","              \n","                      [[[-31.]]],\n","              \n","              \n","                      [[[-33.]]],\n","              \n","              \n","                      [[[-29.]]],\n","              \n","              \n","                      [[[-29.]]],\n","              \n","              \n","                      [[[-31.]]],\n","              \n","              \n","                      [[[-28.]]],\n","              \n","              \n","                      [[[-23.]]],\n","              \n","              \n","                      [[[-26.]]],\n","              \n","              \n","                      [[[-32.]]],\n","              \n","              \n","                      [[[-31.]]],\n","              \n","              \n","                      [[[-30.]]],\n","              \n","              \n","                      [[[-30.]]]], device='cuda:0')),\n","             ('module.layer2.4.conv1.fp_bias',\n","              tensor([-0.4213, -0.7618, -0.1156, -0.6688,  0.1177, -1.0026,  0.1638, -0.2890,\n","                      -0.1492, -0.1551,  0.0526,  0.5726,  0.3280,  0.1732,  0.1979, -0.3404,\n","                       0.7181, -0.1292,  0.0876,  0.1857,  0.4831,  0.5537, -0.2150,  0.2877,\n","                       0.0298, -0.5933, -0.5855,  0.2303, -0.2268, -0.1556, -0.7149, -0.1749],\n","                     device='cuda:0')),\n","             ('module.layer2.4.conv1.accum_scale', tensor([[[ 7497.7725]],\n","              \n","                      [[ 7233.7876]],\n","              \n","                      [[ 4369.1724]],\n","              \n","                      [[13050.4707]],\n","              \n","                      [[ 5947.4756]],\n","              \n","                      [[ 4800.7607]],\n","              \n","                      [[ 6014.5269]],\n","              \n","                      [[ 4460.1816]],\n","              \n","                      [[ 6662.8491]],\n","              \n","                      [[ 6354.0879]],\n","              \n","                      [[ 5406.9199]],\n","              \n","                      [[ 3906.1904]],\n","              \n","                      [[ 3895.7568]],\n","              \n","                      [[ 6021.4233]],\n","              \n","                      [[ 3170.6587]],\n","              \n","                      [[ 3518.8843]],\n","              \n","                      [[ 5781.4868]],\n","              \n","                      [[ 6672.1045]],\n","              \n","                      [[13217.9854]],\n","              \n","                      [[ 4104.6113]],\n","              \n","                      [[ 7368.1494]],\n","              \n","                      [[ 7009.3867]],\n","              \n","                      [[ 6344.1611]],\n","              \n","                      [[ 6458.3203]],\n","              \n","                      [[ 7774.0908]],\n","              \n","                      [[ 7301.5479]],\n","              \n","                      [[ 8398.9912]],\n","              \n","                      [[ 4186.9805]],\n","              \n","                      [[ 5293.6172]],\n","              \n","                      [[ 6333.9609]],\n","              \n","                      [[ 9623.5703]],\n","              \n","                      [[10291.1289]]], device='cuda:0')),\n","             ('module.layer2.4.conv1.is_simulated_quant_weight_shifted',\n","              tensor(False, device='cuda:0')),\n","             ('module.layer2.4.conv1.wrapped_module.weight',\n","              tensor([[[[34., 25., 24.],\n","                        [27., 41., 35.],\n","                        [17., 16., 16.]],\n","              \n","                       [[44., 38., 41.],\n","                        [39., 44., 45.],\n","                        [33., 30., 42.]],\n","              \n","                       [[43., 43., 43.],\n","                        [25., 29., 23.],\n","                        [24., 37., 39.]],\n","              \n","                       ...,\n","              \n","                       [[16., 42., 38.],\n","                        [35., 38., 29.],\n","                        [46., 25., 12.]],\n","              \n","                       [[24., 37., 32.],\n","                        [17., 26., 31.],\n","                        [19., 37., 39.]],\n","              \n","                       [[42., 42., 33.],\n","                        [38., 34., 28.],\n","                        [20., 22., 22.]]],\n","              \n","              \n","                      [[[33., 27., 24.],\n","                        [41., 21., 35.],\n","                        [36., 23., 38.]],\n","              \n","                       [[42., 36., 28.],\n","                        [46., 42., 31.],\n","                        [40., 34., 37.]],\n","              \n","                       [[26., 34., 30.],\n","                        [25., 21., 24.],\n","                        [28., 17., 18.]],\n","              \n","                       ...,\n","              \n","                       [[19., 23., 20.],\n","                        [ 9., 34., 51.],\n","                        [ 8., 31., 49.]],\n","              \n","                       [[25., 30., 22.],\n","                        [29., 20., 16.],\n","                        [62., 42., 32.]],\n","              \n","                       [[32., 30., 29.],\n","                        [32., 37., 38.],\n","                        [55., 39., 35.]]],\n","              \n","              \n","                      [[[10., 18., 28.],\n","                        [24., 30., 31.],\n","                        [45., 38., 34.]],\n","              \n","                       [[31., 35., 41.],\n","                        [37., 22., 32.],\n","                        [21., 21., 36.]],\n","              \n","                       [[28., 34., 36.],\n","                        [22., 30., 23.],\n","                        [26., 35., 26.]],\n","              \n","                       ...,\n","              \n","                       [[20., 31., 33.],\n","                        [27., 39., 24.],\n","                        [42., 34., 12.]],\n","              \n","                       [[19., 42., 42.],\n","                        [20., 36., 20.],\n","                        [32., 22., 17.]],\n","              \n","                       [[33., 32., 13.],\n","                        [41., 25., 13.],\n","                        [30., 16., 24.]]],\n","              \n","              \n","                      ...,\n","              \n","              \n","                      [[[23., 38., 34.],\n","                        [24., 43., 47.],\n","                        [16., 32., 45.]],\n","              \n","                       [[48., 26., 11.],\n","                        [42., 33., 17.],\n","                        [36., 30., 26.]],\n","              \n","                       [[27., 39., 52.],\n","                        [25., 36., 53.],\n","                        [39., 32., 31.]],\n","              \n","                       ...,\n","              \n","                       [[25., 20., 20.],\n","                        [15., 24., 39.],\n","                        [15., 31., 50.]],\n","              \n","                       [[ 4., 32., 63.],\n","                        [ 9., 11., 46.],\n","                        [ 0.,  8., 26.]],\n","              \n","                       [[19., 41., 45.],\n","                        [16., 23., 36.],\n","                        [22., 29., 31.]]],\n","              \n","              \n","                      [[[31., 43., 51.],\n","                        [15., 24., 28.],\n","                        [19., 27., 27.]],\n","              \n","                       [[26., 50., 59.],\n","                        [17., 41., 52.],\n","                        [14., 25., 34.]],\n","              \n","                       [[25., 23., 13.],\n","                        [28., 25., 23.],\n","                        [27., 24., 22.]],\n","              \n","                       ...,\n","              \n","                       [[10., 13., 20.],\n","                        [17., 22., 24.],\n","                        [32., 30., 29.]],\n","              \n","                       [[55., 47., 39.],\n","                        [37., 33., 28.],\n","                        [26., 40., 30.]],\n","              \n","                       [[28., 35., 34.],\n","                        [37., 36., 41.],\n","                        [46., 42., 45.]]],\n","              \n","              \n","                      [[[35., 25., 32.],\n","                        [31., 39., 41.],\n","                        [19., 26., 32.]],\n","              \n","                       [[25., 19., 23.],\n","                        [37., 44., 42.],\n","                        [39., 49., 38.]],\n","              \n","                       [[37., 54., 52.],\n","                        [32., 46., 37.],\n","                        [10., 21., 30.]],\n","              \n","                       ...,\n","              \n","                       [[ 8., 28., 30.],\n","                        [24., 39., 36.],\n","                        [21., 33., 38.]],\n","              \n","                       [[ 6., 34., 29.],\n","                        [41., 59., 35.],\n","                        [55., 55., 28.]],\n","              \n","                       [[15., 17., 14.],\n","                        [ 7., 26., 39.],\n","                        [16., 34., 50.]]]], device='cuda:0')),\n","             ('module.layer2.4.conv1.wrapped_module.bias',\n","              tensor([-3158., -5511.,  -505., -8728.,   700., -4813.,   985., -1289.,  -994.,\n","                       -986.,   285.,  2237.,  1278.,  1043.,   628., -1198.,  4152.,  -862.,\n","                       1158.,   762.,  3559.,  3881., -1364.,  1858.,   232., -4332., -4917.,\n","                        964., -1200.,  -985., -6880., -1800.], device='cuda:0')),\n","             ('module.layer2.4.conv2.num_forwards',\n","              tensor([40], device='cuda:0')),\n","             ('module.layer2.4.conv2.force_readjust',\n","              tensor(False, device='cuda:0')),\n","             ('module.layer2.4.conv2.output_scale',\n","              tensor([13.9882], device='cuda:0')),\n","             ('module.layer2.4.conv2.output_zero_point',\n","              tensor([-29.], device='cuda:0')),\n","             ('module.layer2.4.conv2.w_scale', tensor([[[[ 86.1763]]],\n","              \n","              \n","                      [[[225.8532]]],\n","              \n","              \n","                      [[[ 74.7584]]],\n","              \n","              \n","                      [[[190.5187]]],\n","              \n","              \n","                      [[[ 64.2401]]],\n","              \n","              \n","                      [[[ 46.2911]]],\n","              \n","              \n","                      [[[118.6653]]],\n","              \n","              \n","                      [[[108.6048]]],\n","              \n","              \n","                      [[[109.6651]]],\n","              \n","              \n","                      [[[ 46.5921]]],\n","              \n","              \n","                      [[[149.9291]]],\n","              \n","              \n","                      [[[130.7833]]],\n","              \n","              \n","                      [[[ 86.3382]]],\n","              \n","              \n","                      [[[105.9645]]],\n","              \n","              \n","                      [[[107.6914]]],\n","              \n","              \n","                      [[[126.9774]]],\n","              \n","              \n","                      [[[ 92.3800]]],\n","              \n","              \n","                      [[[153.8642]]],\n","              \n","              \n","                      [[[ 61.3910]]],\n","              \n","              \n","                      [[[142.7939]]],\n","              \n","              \n","                      [[[534.6208]]],\n","              \n","              \n","                      [[[ 90.3558]]],\n","              \n","              \n","                      [[[469.3120]]],\n","              \n","              \n","                      [[[167.6726]]],\n","              \n","              \n","                      [[[113.8041]]],\n","              \n","              \n","                      [[[153.8915]]],\n","              \n","              \n","                      [[[ 59.2004]]],\n","              \n","              \n","                      [[[447.7412]]],\n","              \n","              \n","                      [[[113.3934]]],\n","              \n","              \n","                      [[[140.1488]]],\n","              \n","              \n","                      [[[134.5169]]],\n","              \n","              \n","                      [[[ 72.6244]]]], device='cuda:0')),\n","             ('module.layer2.4.conv2.w_zero_point', tensor([[[[-42.]]],\n","              \n","              \n","                      [[[-38.]]],\n","              \n","              \n","                      [[[-28.]]],\n","              \n","              \n","                      [[[-26.]]],\n","              \n","              \n","                      [[[-34.]]],\n","              \n","              \n","                      [[[-26.]]],\n","              \n","              \n","                      [[[-31.]]],\n","              \n","              \n","                      [[[-24.]]],\n","              \n","              \n","                      [[[-31.]]],\n","              \n","              \n","                      [[[-28.]]],\n","              \n","              \n","                      [[[-28.]]],\n","              \n","              \n","                      [[[-32.]]],\n","              \n","              \n","                      [[[-26.]]],\n","              \n","              \n","                      [[[-22.]]],\n","              \n","              \n","                      [[[-28.]]],\n","              \n","              \n","                      [[[-34.]]],\n","              \n","              \n","                      [[[-31.]]],\n","              \n","              \n","                      [[[-30.]]],\n","              \n","              \n","                      [[[-23.]]],\n","              \n","              \n","                      [[[-31.]]],\n","              \n","              \n","                      [[[-29.]]],\n","              \n","              \n","                      [[[-25.]]],\n","              \n","              \n","                      [[[-26.]]],\n","              \n","              \n","                      [[[-32.]]],\n","              \n","              \n","                      [[[-30.]]],\n","              \n","              \n","                      [[[-30.]]],\n","              \n","              \n","                      [[[-31.]]],\n","              \n","              \n","                      [[[-28.]]],\n","              \n","              \n","                      [[[-32.]]],\n","              \n","              \n","                      [[[-24.]]],\n","              \n","              \n","                      [[[-39.]]],\n","              \n","              \n","                      [[[-31.]]]], device='cuda:0')),\n","             ('module.layer2.4.conv2.fp_bias',\n","              tensor([ 0.1699,  0.2111,  0.3886, -0.0138,  0.0418,  0.1615, -0.0459, -0.0528,\n","                      -0.1861,  0.0480, -0.0027, -0.1141, -0.2534, -0.2506,  0.0621,  0.0334,\n","                      -0.0391,  0.0665, -0.1875, -0.2606, -0.0215, -0.5219, -0.0069,  0.2185,\n","                       0.1208,  0.2163,  0.1820,  0.0770, -0.1374, -0.0480, -0.0300,  0.3144],\n","                     device='cuda:0')),\n","             ('module.layer2.4.conv2.accum_scale', tensor([[[ 3550.0996]],\n","              \n","                      [[ 9304.1934]],\n","              \n","                      [[ 3079.7307]],\n","              \n","                      [[ 7848.5635]],\n","              \n","                      [[ 2646.4199]],\n","              \n","                      [[ 1906.9974]],\n","              \n","                      [[ 4888.5073]],\n","              \n","                      [[ 4474.0571]],\n","              \n","                      [[ 4517.7349]],\n","              \n","                      [[ 1919.3949]],\n","              \n","                      [[ 6176.4414]],\n","              \n","                      [[ 5387.7183]],\n","              \n","                      [[ 3556.7666]],\n","              \n","                      [[ 4365.2861]],\n","              \n","                      [[ 4436.4268]],\n","              \n","                      [[ 5230.9307]],\n","              \n","                      [[ 3805.6633]],\n","              \n","                      [[ 6338.5532]],\n","              \n","                      [[ 2529.0483]],\n","              \n","                      [[ 5882.5015]],\n","              \n","                      [[22024.1074]],\n","              \n","                      [[ 3722.2739]],\n","              \n","                      [[19333.6621]],\n","              \n","                      [[ 6907.3994]],\n","              \n","                      [[ 4688.2446]],\n","              \n","                      [[ 6339.6753]],\n","              \n","                      [[ 2438.8032]],\n","              \n","                      [[18445.0391]],\n","              \n","                      [[ 4671.3286]],\n","              \n","                      [[ 5773.5376]],\n","              \n","                      [[ 5541.5254]],\n","              \n","                      [[ 2991.8157]]], device='cuda:0')),\n","             ('module.layer2.4.conv2.is_simulated_quant_weight_shifted',\n","              tensor(False, device='cuda:0')),\n","             ('module.layer2.4.conv2.wrapped_module.weight',\n","              tensor([[[[36., 32., 37.],\n","                        [33., 30., 37.],\n","                        [32., 31., 40.]],\n","              \n","                       [[56., 59., 55.],\n","                        [41., 48., 48.],\n","                        [32., 34., 32.]],\n","              \n","                       [[52., 41., 41.],\n","                        [58., 33., 34.],\n","                        [42., 31., 31.]],\n","              \n","                       ...,\n","              \n","                       [[43., 54., 45.],\n","                        [32., 41., 31.],\n","                        [20., 38., 35.]],\n","              \n","                       [[46., 44., 43.],\n","                        [41., 37., 38.],\n","                        [45., 43., 43.]],\n","              \n","                       [[32., 40., 37.],\n","                        [45., 46., 41.],\n","                        [44., 42., 41.]]],\n","              \n","              \n","                      [[[35., 30., 23.],\n","                        [35., 36., 27.],\n","                        [32., 29., 22.]],\n","              \n","                       [[36., 45., 44.],\n","                        [29., 39., 46.],\n","                        [36., 49., 52.]],\n","              \n","                       [[43., 25., 23.],\n","                        [45., 32., 26.],\n","                        [54., 46., 37.]],\n","              \n","                       ...,\n","              \n","                       [[26., 48., 60.],\n","                        [29., 33., 46.],\n","                        [38., 21., 35.]],\n","              \n","                       [[45., 41., 36.],\n","                        [42., 39., 35.],\n","                        [35., 36., 36.]],\n","              \n","                       [[34., 38., 38.],\n","                        [34., 34., 35.],\n","                        [41., 34., 36.]]],\n","              \n","              \n","                      [[[14., 26., 17.],\n","                        [23., 28., 19.],\n","                        [27., 34., 23.]],\n","              \n","                       [[20., 18.,  8.],\n","                        [17., 14., 11.],\n","                        [20., 12.,  9.]],\n","              \n","                       [[32., 21., 22.],\n","                        [43., 22., 33.],\n","                        [44., 35., 22.]],\n","              \n","                       ...,\n","              \n","                       [[38., 34.,  9.],\n","                        [26., 31., 15.],\n","                        [16., 30., 45.]],\n","              \n","                       [[29., 19., 19.],\n","                        [28., 26., 24.],\n","                        [30., 27., 26.]],\n","              \n","                       [[30., 27., 24.],\n","                        [22., 25., 25.],\n","                        [16., 22., 25.]]],\n","              \n","              \n","                      ...,\n","              \n","              \n","                      [[[34., 27., 29.],\n","                        [24., 19., 16.],\n","                        [30., 29., 23.]],\n","              \n","                       [[32., 35., 29.],\n","                        [40., 32., 26.],\n","                        [32., 24., 29.]],\n","              \n","                       [[ 4.,  0., 26.],\n","                        [27., 21., 29.],\n","                        [20.,  4., 12.]],\n","              \n","                       ...,\n","              \n","                       [[28., 31., 33.],\n","                        [18., 19., 36.],\n","                        [12.,  8., 22.]],\n","              \n","                       [[17., 16., 20.],\n","                        [15., 15., 18.],\n","                        [17., 17., 17.]],\n","              \n","                       [[21., 18., 24.],\n","                        [24., 21., 24.],\n","                        [15., 22., 27.]]],\n","              \n","              \n","                      [[[33., 37., 40.],\n","                        [33., 33., 36.],\n","                        [25., 29., 24.]],\n","              \n","                       [[38., 41., 38.],\n","                        [43., 36., 38.],\n","                        [39., 32., 35.]],\n","              \n","                       [[32., 26., 24.],\n","                        [47., 31., 31.],\n","                        [51., 27., 39.]],\n","              \n","                       ...,\n","              \n","                       [[38., 44., 43.],\n","                        [47., 39., 35.],\n","                        [37., 33., 20.]],\n","              \n","                       [[37., 41., 43.],\n","                        [38., 36., 33.],\n","                        [37., 34., 29.]],\n","              \n","                       [[26., 36., 41.],\n","                        [26., 35., 43.],\n","                        [32., 37., 42.]]],\n","              \n","              \n","                      [[[31., 27., 23.],\n","                        [23., 17., 15.],\n","                        [37., 26., 15.]],\n","              \n","                       [[25., 20., 18.],\n","                        [40., 37., 25.],\n","                        [37., 42., 35.]],\n","              \n","                       [[26., 29., 38.],\n","                        [36., 35., 36.],\n","                        [31., 34., 29.]],\n","              \n","                       ...,\n","              \n","                       [[ 6.,  7., 13.],\n","                        [24., 36., 47.],\n","                        [24., 34., 52.]],\n","              \n","                       [[24., 27., 33.],\n","                        [20., 19., 26.],\n","                        [22., 23., 22.]],\n","              \n","                       [[21., 28., 23.],\n","                        [30., 30., 29.],\n","                        [42., 44., 39.]]]], device='cuda:0')),\n","             ('module.layer2.4.conv2.wrapped_module.bias',\n","              tensor([  603.,  1964.,  1197.,  -108.,   111.,   308.,  -224.,  -236.,  -841.,\n","                         92.,   -17.,  -615.,  -901., -1094.,   275.,   175.,  -149.,   422.,\n","                       -474., -1533.,  -473., -1943.,  -133.,  1509.,   566.,  1371.,   444.,\n","                       1421.,  -642.,  -277.,  -166.,   941.], device='cuda:0')),\n","             ('module.layer2.4.relu2.num_forwards',\n","              tensor([40], device='cuda:0')),\n","             ('module.layer2.4.relu2.force_readjust',\n","              tensor(False, device='cuda:0')),\n","             ('module.layer2.4.relu2.output_scale',\n","              tensor([7.3921], device='cuda:0')),\n","             ('module.layer2.4.relu2.output_zero_point',\n","              tensor([0.], device='cuda:0')),\n","             ('module.layer2.4.residual_eltwiseadd.num_forwards',\n","              tensor([40], device='cuda:0')),\n","             ('module.layer2.4.residual_eltwiseadd.force_readjust',\n","              tensor(False, device='cuda:0')),\n","             ('module.layer2.4.residual_eltwiseadd.output_scale',\n","              tensor([7.3921], device='cuda:0')),\n","             ('module.layer2.4.residual_eltwiseadd.output_zero_point',\n","              tensor([0.], device='cuda:0')),\n","             ('module.layer2.5.conv1.num_forwards',\n","              tensor([40], device='cuda:0')),\n","             ('module.layer2.5.conv1.force_readjust',\n","              tensor(False, device='cuda:0')),\n","             ('module.layer2.5.conv1.output_scale',\n","              tensor([41.1563], device='cuda:0')),\n","             ('module.layer2.5.conv1.output_zero_point',\n","              tensor([0.], device='cuda:0')),\n","             ('module.layer2.5.conv1.w_scale', tensor([[[[ 927.3324]]],\n","              \n","              \n","                      [[[ 966.1693]]],\n","              \n","              \n","                      [[[ 348.0957]]],\n","              \n","              \n","                      [[[ 674.5836]]],\n","              \n","              \n","                      [[[ 891.8338]]],\n","              \n","              \n","                      [[[1318.3035]]],\n","              \n","              \n","                      [[[ 752.0477]]],\n","              \n","              \n","                      [[[1036.7469]]],\n","              \n","              \n","                      [[[1058.4453]]],\n","              \n","              \n","                      [[[ 790.2072]]],\n","              \n","              \n","                      [[[ 816.6612]]],\n","              \n","              \n","                      [[[ 731.5690]]],\n","              \n","              \n","                      [[[ 722.0124]]],\n","              \n","              \n","                      [[[ 377.3869]]],\n","              \n","              \n","                      [[[ 521.1864]]],\n","              \n","              \n","                      [[[1098.8875]]],\n","              \n","              \n","                      [[[ 799.3673]]],\n","              \n","              \n","                      [[[ 521.2645]]],\n","              \n","              \n","                      [[[ 692.8644]]],\n","              \n","              \n","                      [[[ 949.7746]]],\n","              \n","              \n","                      [[[1028.5793]]],\n","              \n","              \n","                      [[[1057.8112]]],\n","              \n","              \n","                      [[[ 843.7750]]],\n","              \n","              \n","                      [[[ 818.1635]]],\n","              \n","              \n","                      [[[ 668.9278]]],\n","              \n","              \n","                      [[[ 793.9818]]],\n","              \n","              \n","                      [[[ 571.1022]]],\n","              \n","              \n","                      [[[ 767.3098]]],\n","              \n","              \n","                      [[[1534.8517]]],\n","              \n","              \n","                      [[[1138.5948]]],\n","              \n","              \n","                      [[[1034.0886]]],\n","              \n","              \n","                      [[[ 806.3762]]]], device='cuda:0')),\n","             ('module.layer2.5.conv1.w_zero_point', tensor([[[[-27.]]],\n","              \n","              \n","                      [[[-29.]]],\n","              \n","              \n","                      [[[-24.]]],\n","              \n","              \n","                      [[[-27.]]],\n","              \n","              \n","                      [[[-33.]]],\n","              \n","              \n","                      [[[-27.]]],\n","              \n","              \n","                      [[[-36.]]],\n","              \n","              \n","                      [[[-30.]]],\n","              \n","              \n","                      [[[-33.]]],\n","              \n","              \n","                      [[[-24.]]],\n","              \n","              \n","                      [[[-34.]]],\n","              \n","              \n","                      [[[-28.]]],\n","              \n","              \n","                      [[[-30.]]],\n","              \n","              \n","                      [[[-28.]]],\n","              \n","              \n","                      [[[-31.]]],\n","              \n","              \n","                      [[[-34.]]],\n","              \n","              \n","                      [[[-29.]]],\n","              \n","              \n","                      [[[-26.]]],\n","              \n","              \n","                      [[[-31.]]],\n","              \n","              \n","                      [[[-28.]]],\n","              \n","              \n","                      [[[-32.]]],\n","              \n","              \n","                      [[[-37.]]],\n","              \n","              \n","                      [[[-32.]]],\n","              \n","              \n","                      [[[-28.]]],\n","              \n","              \n","                      [[[-34.]]],\n","              \n","              \n","                      [[[-29.]]],\n","              \n","              \n","                      [[[-29.]]],\n","              \n","              \n","                      [[[-31.]]],\n","              \n","              \n","                      [[[-31.]]],\n","              \n","              \n","                      [[[-26.]]],\n","              \n","              \n","                      [[[-36.]]],\n","              \n","              \n","                      [[[-31.]]]], device='cuda:0')),\n","             ('module.layer2.5.conv1.fp_bias',\n","              tensor([ 0.2092,  0.1384,  0.1523,  0.0230,  0.3162,  0.0454,  0.1086, -0.5491,\n","                       0.3112, -1.3281,  0.6631, -0.4109,  0.1092,  0.0812,  0.3159,  0.8091,\n","                       0.3608,  0.6603, -0.0179, -0.8236,  0.0969,  0.1535,  0.3886, -0.2876,\n","                       0.4871, -0.0156, -0.0573, -0.4070,  0.2682, -0.7860,  0.7386,  0.0571],\n","                     device='cuda:0')),\n","             ('module.layer2.5.conv1.accum_scale', tensor([[[ 6854.9653]],\n","              \n","                      [[ 7142.0527]],\n","              \n","                      [[ 2573.1702]],\n","              \n","                      [[ 4986.6123]],\n","              \n","                      [[ 6592.5552]],\n","              \n","                      [[ 9745.0762]],\n","              \n","                      [[ 5559.2373]],\n","              \n","                      [[ 7663.7725]],\n","              \n","                      [[ 7824.1699]],\n","              \n","                      [[ 5841.3174]],\n","              \n","                      [[ 6036.8691]],\n","              \n","                      [[ 5407.8560]],\n","              \n","                      [[ 5337.2124]],\n","              \n","                      [[ 2789.6943]],\n","              \n","                      [[ 3852.6799]],\n","              \n","                      [[ 8123.1235]],\n","              \n","                      [[ 5909.0303]],\n","              \n","                      [[ 3853.2568]],\n","              \n","                      [[ 5121.7466]],\n","              \n","                      [[ 7020.8613]],\n","              \n","                      [[ 7603.3965]],\n","              \n","                      [[ 7819.4819]],\n","              \n","                      [[ 6237.2979]],\n","              \n","                      [[ 6047.9746]],\n","              \n","                      [[ 4944.8042]],\n","              \n","                      [[ 5869.2197]],\n","              \n","                      [[ 4221.6641]],\n","              \n","                      [[ 5672.0571]],\n","              \n","                      [[11345.8301]],\n","              \n","                      [[ 8416.6455]],\n","              \n","                      [[ 7644.1221]],\n","              \n","                      [[ 5960.8408]]], device='cuda:0')),\n","             ('module.layer2.5.conv1.is_simulated_quant_weight_shifted',\n","              tensor(False, device='cuda:0')),\n","             ('module.layer2.5.conv1.wrapped_module.weight',\n","              tensor([[[[25., 35., 41.],\n","                        [31., 54., 63.],\n","                        [39., 55., 53.]],\n","              \n","                       [[38., 39., 52.],\n","                        [44., 46., 53.],\n","                        [32., 27., 26.]],\n","              \n","                       [[14., 13., 13.],\n","                        [16., 12., 16.],\n","                        [10.,  6., 11.]],\n","              \n","                       ...,\n","              \n","                       [[44., 36., 24.],\n","                        [28., 14.,  9.],\n","                        [31., 14.,  1.]],\n","              \n","                       [[13., 34., 26.],\n","                        [10., 20., 19.],\n","                        [ 7., 15., 21.]],\n","              \n","                       [[33., 36., 36.],\n","                        [22., 21., 21.],\n","                        [27., 22., 23.]]],\n","              \n","              \n","                      [[[31., 28., 12.],\n","                        [37., 29., 15.],\n","                        [39., 37.,  9.]],\n","              \n","                       [[37., 48., 24.],\n","                        [30., 46., 25.],\n","                        [24., 42., 33.]],\n","              \n","                       [[22., 25., 28.],\n","                        [26., 30., 35.],\n","                        [27., 22., 33.]],\n","              \n","                       ...,\n","              \n","                       [[29., 31.,  2.],\n","                        [37., 28.,  5.],\n","                        [13., 25., 39.]],\n","              \n","                       [[39.,  6., 23.],\n","                        [56., 23., 21.],\n","                        [63., 27., 25.]],\n","              \n","                       [[24., 36., 42.],\n","                        [23., 40., 51.],\n","                        [28., 32., 39.]]],\n","              \n","              \n","                      [[[25., 25., 24.],\n","                        [23., 27., 28.],\n","                        [20., 22., 15.]],\n","              \n","                       [[33., 21., 21.],\n","                        [32., 24., 30.],\n","                        [27., 31., 28.]],\n","              \n","                       [[22., 14., 17.],\n","                        [23., 14., 14.],\n","                        [28., 36., 22.]],\n","              \n","                       ...,\n","              \n","                       [[15., 27., 21.],\n","                        [16., 10., 20.],\n","                        [26., 10., 27.]],\n","              \n","                       [[19., 33., 22.],\n","                        [ 9., 26., 16.],\n","                        [27., 40., 31.]],\n","              \n","                       [[10., 17., 24.],\n","                        [23., 22., 24.],\n","                        [34., 33., 26.]]],\n","              \n","              \n","                      ...,\n","              \n","              \n","                      [[[12., 12., 27.],\n","                        [20., 26., 29.],\n","                        [26., 24., 26.]],\n","              \n","                       [[34., 54., 33.],\n","                        [29., 45., 37.],\n","                        [25., 35., 19.]],\n","              \n","                       [[21., 17.,  6.],\n","                        [36., 25., 16.],\n","                        [37., 28., 25.]],\n","              \n","                       ...,\n","              \n","                       [[28., 31., 28.],\n","                        [18., 21., 16.],\n","                        [12., 23., 16.]],\n","              \n","                       [[57., 38., 34.],\n","                        [33., 39., 30.],\n","                        [20., 25., 13.]],\n","              \n","                       [[19., 27., 26.],\n","                        [23., 29., 20.],\n","                        [18., 19., 10.]]],\n","              \n","              \n","                      [[[38., 21., 27.],\n","                        [42., 25., 42.],\n","                        [42., 42., 55.]],\n","              \n","                       [[39., 30., 36.],\n","                        [43., 39., 38.],\n","                        [32., 28., 21.]],\n","              \n","                       [[32., 38., 46.],\n","                        [45., 49., 52.],\n","                        [36., 32., 27.]],\n","              \n","                       ...,\n","              \n","                       [[32., 36., 37.],\n","                        [25., 21., 35.],\n","                        [36., 26., 48.]],\n","              \n","                       [[ 9.,  0.,  8.],\n","                        [18.,  9.,  6.],\n","                        [32., 18., 20.]],\n","              \n","                       [[31., 25., 30.],\n","                        [34., 26., 27.],\n","                        [53., 43., 45.]]],\n","              \n","              \n","                      [[[20., 10., 17.],\n","                        [39., 27., 23.],\n","                        [44., 25., 28.]],\n","              \n","                       [[39., 36., 43.],\n","                        [51., 35., 42.],\n","                        [16.,  9., 18.]],\n","              \n","                       [[63., 53., 41.],\n","                        [36., 27., 20.],\n","                        [19., 14., 13.]],\n","              \n","                       ...,\n","              \n","                       [[16., 14., 25.],\n","                        [21., 26., 43.],\n","                        [41., 51., 36.]],\n","              \n","                       [[19.,  2., 17.],\n","                        [31., 15., 25.],\n","                        [33., 26., 32.]],\n","              \n","                       [[34., 43., 38.],\n","                        [33., 38., 31.],\n","                        [28., 25., 24.]]]], device='cuda:0')),\n","             ('module.layer2.5.conv1.wrapped_module.bias',\n","              tensor([ 1434.,   988.,   392.,   115.,  2085.,   443.,   604., -4208.,  2435.,\n","                      -7758.,  4003., -2222.,   583.,   226.,  1217.,  6573.,  2132.,  2544.,\n","                        -92., -5782.,   737.,  1200.,  2424., -1739.,  2409.,   -92.,  -242.,\n","                      -2308.,  3043., -6615.,  5646.,   340.], device='cuda:0')),\n","             ('module.layer2.5.conv2.num_forwards',\n","              tensor([40], device='cuda:0')),\n","             ('module.layer2.5.conv2.force_readjust',\n","              tensor(False, device='cuda:0')),\n","             ('module.layer2.5.conv2.output_scale',\n","              tensor([16.8392], device='cuda:0')),\n","             ('module.layer2.5.conv2.output_zero_point',\n","              tensor([-30.], device='cuda:0')),\n","             ('module.layer2.5.conv2.w_scale', tensor([[[[224.9650]]],\n","              \n","              \n","                      [[[ 95.2522]]],\n","              \n","              \n","                      [[[ 99.3108]]],\n","              \n","              \n","                      [[[211.6591]]],\n","              \n","              \n","                      [[[ 83.0511]]],\n","              \n","              \n","                      [[[ 74.3590]]],\n","              \n","              \n","                      [[[122.0763]]],\n","              \n","              \n","                      [[[ 65.6855]]],\n","              \n","              \n","                      [[[ 94.4505]]],\n","              \n","              \n","                      [[[170.0413]]],\n","              \n","              \n","                      [[[122.4772]]],\n","              \n","              \n","                      [[[ 99.1351]]],\n","              \n","              \n","                      [[[ 88.8732]]],\n","              \n","              \n","                      [[[269.8861]]],\n","              \n","              \n","                      [[[154.4456]]],\n","              \n","              \n","                      [[[113.2995]]],\n","              \n","              \n","                      [[[ 60.5435]]],\n","              \n","              \n","                      [[[162.2410]]],\n","              \n","              \n","                      [[[101.0445]]],\n","              \n","              \n","                      [[[134.3038]]],\n","              \n","              \n","                      [[[145.5103]]],\n","              \n","              \n","                      [[[118.6325]]],\n","              \n","              \n","                      [[[341.7117]]],\n","              \n","              \n","                      [[[114.9247]]],\n","              \n","              \n","                      [[[155.6183]]],\n","              \n","              \n","                      [[[ 92.6720]]],\n","              \n","              \n","                      [[[110.5167]]],\n","              \n","              \n","                      [[[139.5482]]],\n","              \n","              \n","                      [[[175.8356]]],\n","              \n","              \n","                      [[[109.6672]]],\n","              \n","              \n","                      [[[134.2350]]],\n","              \n","              \n","                      [[[ 67.2555]]]], device='cuda:0')),\n","             ('module.layer2.5.conv2.w_zero_point', tensor([[[[-35.]]],\n","              \n","              \n","                      [[[-26.]]],\n","              \n","              \n","                      [[[-31.]]],\n","              \n","              \n","                      [[[-33.]]],\n","              \n","              \n","                      [[[-30.]]],\n","              \n","              \n","                      [[[-27.]]],\n","              \n","              \n","                      [[[-35.]]],\n","              \n","              \n","                      [[[-27.]]],\n","              \n","              \n","                      [[[-23.]]],\n","              \n","              \n","                      [[[-29.]]],\n","              \n","              \n","                      [[[-27.]]],\n","              \n","              \n","                      [[[-28.]]],\n","              \n","              \n","                      [[[-33.]]],\n","              \n","              \n","                      [[[-34.]]],\n","              \n","              \n","                      [[[-35.]]],\n","              \n","              \n","                      [[[-25.]]],\n","              \n","              \n","                      [[[-23.]]],\n","              \n","              \n","                      [[[-36.]]],\n","              \n","              \n","                      [[[-28.]]],\n","              \n","              \n","                      [[[-35.]]],\n","              \n","              \n","                      [[[-35.]]],\n","              \n","              \n","                      [[[-35.]]],\n","              \n","              \n","                      [[[-32.]]],\n","              \n","              \n","                      [[[-32.]]],\n","              \n","              \n","                      [[[-27.]]],\n","              \n","              \n","                      [[[-24.]]],\n","              \n","              \n","                      [[[-32.]]],\n","              \n","              \n","                      [[[-31.]]],\n","              \n","              \n","                      [[[-37.]]],\n","              \n","              \n","                      [[[-32.]]],\n","              \n","              \n","                      [[[-37.]]],\n","              \n","              \n","                      [[[-25.]]]], device='cuda:0')),\n","             ('module.layer2.5.conv2.fp_bias',\n","              tensor([ 0.0735, -0.0730,  0.1514, -0.0315,  0.0877,  0.1191,  0.1793,  0.1641,\n","                      -0.1921, -0.1782,  0.1482,  0.2608,  0.2009, -0.0217,  0.2327,  0.0951,\n","                       0.1332,  0.0996, -0.1860,  0.1566, -0.0861,  0.2062,  0.0094,  0.0814,\n","                       0.1158,  0.1114,  0.1489, -0.0020, -0.0876,  0.0035,  0.0613,  0.0110],\n","                     device='cuda:0')),\n","             ('module.layer2.5.conv2.accum_scale', tensor([[[ 9258.7383]],\n","              \n","                      [[ 3920.2336]],\n","              \n","                      [[ 4087.2700]],\n","              \n","                      [[ 8711.1143]],\n","              \n","                      [[ 3418.0813]],\n","              \n","                      [[ 3060.3445]],\n","              \n","                      [[ 5024.2139]],\n","              \n","                      [[ 2703.3748]],\n","              \n","                      [[ 3887.2388]],\n","              \n","                      [[ 6998.2798]],\n","              \n","                      [[ 5040.7153]],\n","              \n","                      [[ 4080.0398]],\n","              \n","                      [[ 3657.6968]],\n","              \n","                      [[11107.5254]],\n","              \n","                      [[ 6356.4185]],\n","              \n","                      [[ 4662.9937]],\n","              \n","                      [[ 2491.7480]],\n","              \n","                      [[ 6677.2485]],\n","              \n","                      [[ 4158.6216]],\n","              \n","                      [[ 5527.4531]],\n","              \n","                      [[ 5988.6719]],\n","              \n","                      [[ 4882.4819]],\n","              \n","                      [[14063.6064]],\n","              \n","                      [[ 4729.8823]],\n","              \n","                      [[ 6404.6826]],\n","              \n","                      [[ 3814.0415]],\n","              \n","                      [[ 4548.4644]],\n","              \n","                      [[ 5743.2959]],\n","              \n","                      [[ 7236.7500]],\n","              \n","                      [[ 4513.5015]],\n","              \n","                      [[ 5524.6221]],\n","              \n","                      [[ 2767.9922]]], device='cuda:0')),\n","             ('module.layer2.5.conv2.is_simulated_quant_weight_shifted',\n","              tensor(False, device='cuda:0')),\n","             ('module.layer2.5.conv2.wrapped_module.weight',\n","              tensor([[[[19., 36., 36.],\n","                        [28., 51., 46.],\n","                        [24., 35., 37.]],\n","              \n","                       [[20., 28., 29.],\n","                        [27., 41., 39.],\n","                        [48., 55., 50.]],\n","              \n","                       [[30., 24., 60.],\n","                        [27., 36., 51.],\n","                        [41., 41., 41.]],\n","              \n","                       ...,\n","              \n","                       [[30., 26., 21.],\n","                        [23., 24., 21.],\n","                        [25., 34., 34.]],\n","              \n","                       [[29., 34., 28.],\n","                        [36., 40., 31.],\n","                        [33., 39., 36.]],\n","              \n","                       [[15.,  9.,  5.],\n","                        [10.,  5., 11.],\n","                        [13., 11., 12.]]],\n","              \n","              \n","                      [[[14., 24., 29.],\n","                        [22., 30., 32.],\n","                        [31., 34., 34.]],\n","              \n","                       [[31., 50., 52.],\n","                        [23., 44., 45.],\n","                        [25., 37., 38.]],\n","              \n","                       [[30., 22., 19.],\n","                        [33., 34., 30.],\n","                        [44., 46., 39.]],\n","              \n","                       ...,\n","              \n","                       [[31., 30., 30.],\n","                        [31., 30., 34.],\n","                        [29., 29., 36.]],\n","              \n","                       [[26., 30., 27.],\n","                        [23., 34., 39.],\n","                        [33., 48., 59.]],\n","              \n","                       [[35., 44., 43.],\n","                        [26., 41., 30.],\n","                        [39., 47., 40.]]],\n","              \n","              \n","                      [[[27., 28., 26.],\n","                        [25., 34., 31.],\n","                        [33., 39., 35.]],\n","              \n","                       [[31., 28., 19.],\n","                        [19., 19., 15.],\n","                        [26., 40., 38.]],\n","              \n","                       [[32., 34., 41.],\n","                        [21., 18., 43.],\n","                        [20., 19., 28.]],\n","              \n","                       ...,\n","              \n","                       [[23., 24., 23.],\n","                        [29., 32., 28.],\n","                        [38., 38., 30.]],\n","              \n","                       [[22., 20., 28.],\n","                        [24., 28., 35.],\n","                        [34., 41., 44.]],\n","              \n","                       [[16., 27., 34.],\n","                        [25., 28., 25.],\n","                        [29., 26., 27.]]],\n","              \n","              \n","                      ...,\n","              \n","              \n","                      [[[31., 35., 33.],\n","                        [31., 25., 32.],\n","                        [30., 31., 35.]],\n","              \n","                       [[49., 46., 34.],\n","                        [43., 34., 31.],\n","                        [31., 21., 19.]],\n","              \n","                       [[57., 33., 26.],\n","                        [59., 45., 25.],\n","                        [63., 47., 26.]],\n","              \n","                       ...,\n","              \n","                       [[29., 22., 19.],\n","                        [36., 28., 23.],\n","                        [40., 28., 24.]],\n","              \n","                       [[26., 33., 31.],\n","                        [30., 35., 30.],\n","                        [28., 30., 27.]],\n","              \n","                       [[32., 52., 33.],\n","                        [35., 38., 36.],\n","                        [28., 21., 26.]]],\n","              \n","              \n","                      [[[26., 24., 34.],\n","                        [26., 27., 37.],\n","                        [28., 32., 41.]],\n","              \n","                       [[48., 39., 28.],\n","                        [39., 31., 38.],\n","                        [32., 35., 32.]],\n","              \n","                       [[23., 21., 15.],\n","                        [32., 38., 35.],\n","                        [33., 34., 49.]],\n","              \n","                       ...,\n","              \n","                       [[29., 25., 24.],\n","                        [29., 24., 19.],\n","                        [34., 31., 27.]],\n","              \n","                       [[28., 33., 41.],\n","                        [33., 34., 40.],\n","                        [32., 24., 24.]],\n","              \n","                       [[49., 48., 35.],\n","                        [38., 38., 36.],\n","                        [27., 36., 36.]]],\n","              \n","              \n","                      [[[24., 24., 26.],\n","                        [28., 28., 29.],\n","                        [28., 31., 32.]],\n","              \n","                       [[21., 28., 16.],\n","                        [22., 21., 21.],\n","                        [30., 22., 24.]],\n","              \n","                       [[43., 36., 48.],\n","                        [26., 28., 45.],\n","                        [ 3.,  0.,  0.]],\n","              \n","                       ...,\n","              \n","                       [[23., 22., 22.],\n","                        [18., 16., 17.],\n","                        [21., 24., 21.]],\n","              \n","                       [[23., 22., 25.],\n","                        [27., 24., 24.],\n","                        [22., 22., 16.]],\n","              \n","                       [[31., 35., 42.],\n","                        [21., 37., 43.],\n","                        [24., 31., 40.]]]], device='cuda:0')),\n","             ('module.layer2.5.conv2.wrapped_module.bias',\n","              tensor([  681.,  -286.,   619.,  -275.,   300.,   364.,   901.,   444.,  -747.,\n","                      -1247.,   747.,  1064.,   735.,  -241.,  1479.,   443.,   332.,   665.,\n","                       -774.,   866.,  -516.,  1007.,   132.,   385.,   741.,   425.,   677.,\n","                        -11.,  -634.,    16.,   339.,    30.], device='cuda:0')),\n","             ('module.layer2.5.relu2.num_forwards',\n","              tensor([40], device='cuda:0')),\n","             ('module.layer2.5.relu2.force_readjust',\n","              tensor(False, device='cuda:0')),\n","             ('module.layer2.5.relu2.output_scale',\n","              tensor([7.2819], device='cuda:0')),\n","             ('module.layer2.5.relu2.output_zero_point',\n","              tensor([0.], device='cuda:0')),\n","             ('module.layer2.5.residual_eltwiseadd.num_forwards',\n","              tensor([40], device='cuda:0')),\n","             ('module.layer2.5.residual_eltwiseadd.force_readjust',\n","              tensor(False, device='cuda:0')),\n","             ('module.layer2.5.residual_eltwiseadd.output_scale',\n","              tensor([7.2819], device='cuda:0')),\n","             ('module.layer2.5.residual_eltwiseadd.output_zero_point',\n","              tensor([0.], device='cuda:0')),\n","             ('module.layer2.6.conv1.num_forwards',\n","              tensor([40], device='cuda:0')),\n","             ('module.layer2.6.conv1.force_readjust',\n","              tensor(False, device='cuda:0')),\n","             ('module.layer2.6.conv1.output_scale',\n","              tensor([47.1487], device='cuda:0')),\n","             ('module.layer2.6.conv1.output_zero_point',\n","              tensor([0.], device='cuda:0')),\n","             ('module.layer2.6.conv1.w_scale', tensor([[[[ 921.1416]]],\n","              \n","              \n","                      [[[ 475.5510]]],\n","              \n","              \n","                      [[[ 728.1865]]],\n","              \n","              \n","                      [[[ 737.1661]]],\n","              \n","              \n","                      [[[ 774.2001]]],\n","              \n","              \n","                      [[[ 886.3846]]],\n","              \n","              \n","                      [[[ 781.4603]]],\n","              \n","              \n","                      [[[ 774.1653]]],\n","              \n","              \n","                      [[[ 696.8798]]],\n","              \n","              \n","                      [[[ 634.2567]]],\n","              \n","              \n","                      [[[ 756.4658]]],\n","              \n","              \n","                      [[[ 679.1245]]],\n","              \n","              \n","                      [[[1186.7983]]],\n","              \n","              \n","                      [[[ 956.8385]]],\n","              \n","              \n","                      [[[1345.0931]]],\n","              \n","              \n","                      [[[ 900.9373]]],\n","              \n","              \n","                      [[[ 802.4783]]],\n","              \n","              \n","                      [[[ 694.8948]]],\n","              \n","              \n","                      [[[ 683.5662]]],\n","              \n","              \n","                      [[[ 600.3216]]],\n","              \n","              \n","                      [[[1386.4369]]],\n","              \n","              \n","                      [[[ 879.3786]]],\n","              \n","              \n","                      [[[ 888.7184]]],\n","              \n","              \n","                      [[[ 633.0313]]],\n","              \n","              \n","                      [[[ 568.6485]]],\n","              \n","              \n","                      [[[ 889.9122]]],\n","              \n","              \n","                      [[[ 959.6845]]],\n","              \n","              \n","                      [[[ 573.8163]]],\n","              \n","              \n","                      [[[1297.4761]]],\n","              \n","              \n","                      [[[ 443.9484]]],\n","              \n","              \n","                      [[[ 565.6987]]],\n","              \n","              \n","                      [[[1297.4635]]]], device='cuda:0')),\n","             ('module.layer2.6.conv1.w_zero_point', tensor([[[[-28.]]],\n","              \n","              \n","                      [[[-25.]]],\n","              \n","              \n","                      [[[-31.]]],\n","              \n","              \n","                      [[[-26.]]],\n","              \n","              \n","                      [[[-33.]]],\n","              \n","              \n","                      [[[-31.]]],\n","              \n","              \n","                      [[[-24.]]],\n","              \n","              \n","                      [[[-28.]]],\n","              \n","              \n","                      [[[-26.]]],\n","              \n","              \n","                      [[[-26.]]],\n","              \n","              \n","                      [[[-31.]]],\n","              \n","              \n","                      [[[-31.]]],\n","              \n","              \n","                      [[[-33.]]],\n","              \n","              \n","                      [[[-34.]]],\n","              \n","              \n","                      [[[-27.]]],\n","              \n","              \n","                      [[[-34.]]],\n","              \n","              \n","                      [[[-27.]]],\n","              \n","              \n","                      [[[-28.]]],\n","              \n","              \n","                      [[[-21.]]],\n","              \n","              \n","                      [[[-31.]]],\n","              \n","              \n","                      [[[-26.]]],\n","              \n","              \n","                      [[[-26.]]],\n","              \n","              \n","                      [[[-28.]]],\n","              \n","              \n","                      [[[-26.]]],\n","              \n","              \n","                      [[[-26.]]],\n","              \n","              \n","                      [[[-31.]]],\n","              \n","              \n","                      [[[-25.]]],\n","              \n","              \n","                      [[[-32.]]],\n","              \n","              \n","                      [[[-30.]]],\n","              \n","              \n","                      [[[-27.]]],\n","              \n","              \n","                      [[[-31.]]],\n","              \n","              \n","                      [[[-29.]]]], device='cuda:0')),\n","             ('module.layer2.6.conv1.fp_bias',\n","              tensor([-0.1172, -0.4433, -0.2534, -0.5116,  0.2642,  0.1202, -0.6605,  0.2568,\n","                      -0.3979,  0.5049, -0.6309,  0.2085, -0.0523, -0.0595, -0.0711,  0.2638,\n","                       0.2084, -0.0076, -0.0304, -0.2647, -0.2975, -0.1163,  0.0436,  0.1713,\n","                       0.2284,  0.2147,  0.1033, -0.0682, -0.0064,  0.1437, -0.1300, -0.3293],\n","                     device='cuda:0')),\n","             ('module.layer2.6.conv1.accum_scale', tensor([[[ 6707.6279]],\n","              \n","                      [[ 3462.8977]],\n","              \n","                      [[ 5302.5552]],\n","              \n","                      [[ 5367.9434]],\n","              \n","                      [[ 5637.6196]],\n","              \n","                      [[ 6454.5327]],\n","              \n","                      [[ 5690.4873]],\n","              \n","                      [[ 5637.3667]],\n","              \n","                      [[ 5074.5840]],\n","              \n","                      [[ 4618.5713]],\n","              \n","                      [[ 5508.4810]],\n","              \n","                      [[ 4945.2925]],\n","              \n","                      [[ 8642.1045]],\n","              \n","                      [[ 6967.5679]],\n","              \n","                      [[ 9794.7852]],\n","              \n","                      [[ 6560.5029]],\n","              \n","                      [[ 5843.5376]],\n","              \n","                      [[ 5060.1299]],\n","              \n","                      [[ 4977.6362]],\n","              \n","                      [[ 4371.4604]],\n","              \n","                      [[10095.8447]],\n","              \n","                      [[ 6403.5156]],\n","              \n","                      [[ 6471.5269]],\n","              \n","                      [[ 4609.6479]],\n","              \n","                      [[ 4140.8213]],\n","              \n","                      [[ 6480.2197]],\n","              \n","                      [[ 6988.2925]],\n","              \n","                      [[ 4178.4526]],\n","              \n","                      [[ 9448.0449]],\n","              \n","                      [[ 3232.7720]],\n","              \n","                      [[ 4119.3413]],\n","              \n","                      [[ 9447.9531]]], device='cuda:0')),\n","             ('module.layer2.6.conv1.is_simulated_quant_weight_shifted',\n","              tensor(False, device='cuda:0')),\n","             ('module.layer2.6.conv1.wrapped_module.weight',\n","              tensor([[[[14., 19., 22.],\n","                        [14., 15., 19.],\n","                        [10.,  1., 12.]],\n","              \n","                       [[23., 30., 29.],\n","                        [34., 32., 20.],\n","                        [39., 34., 23.]],\n","              \n","                       [[49., 47., 29.],\n","                        [46., 35., 10.],\n","                        [26., 13.,  0.]],\n","              \n","                       ...,\n","              \n","                       [[38., 31., 32.],\n","                        [49., 44., 43.],\n","                        [49., 49., 33.]],\n","              \n","                       [[17.,  9., 13.],\n","                        [21., 22., 23.],\n","                        [22., 15., 36.]],\n","              \n","                       [[33., 36., 34.],\n","                        [28., 33., 32.],\n","                        [33., 35., 29.]]],\n","              \n","              \n","                      [[[24., 27., 32.],\n","                        [32., 35., 30.],\n","                        [15., 23., 11.]],\n","              \n","                       [[29., 24., 21.],\n","                        [38., 46., 38.],\n","                        [30., 39., 33.]],\n","              \n","                       [[21., 14., 15.],\n","                        [23., 12., 22.],\n","                        [25., 24., 38.]],\n","              \n","                       ...,\n","              \n","                       [[63., 55., 12.],\n","                        [26., 18., 15.],\n","                        [13., 27., 27.]],\n","              \n","                       [[32., 34., 37.],\n","                        [46., 21., 31.],\n","                        [11., 10., 10.]],\n","              \n","                       [[ 6.,  0., 22.],\n","                        [24., 14., 26.],\n","                        [37., 30., 31.]]],\n","              \n","              \n","                      [[[18., 18., 24.],\n","                        [27., 23., 20.],\n","                        [27., 39., 22.]],\n","              \n","                       [[28., 40., 27.],\n","                        [40., 43., 20.],\n","                        [32., 35., 23.]],\n","              \n","                       [[23., 19.,  9.],\n","                        [28., 26., 31.],\n","                        [19., 24., 29.]],\n","              \n","                       ...,\n","              \n","                       [[46., 16., 20.],\n","                        [34., 37., 41.],\n","                        [24., 56., 55.]],\n","              \n","                       [[46., 32., 38.],\n","                        [34., 23., 50.],\n","                        [26., 22., 33.]],\n","              \n","                       [[27., 47., 44.],\n","                        [37., 43., 33.],\n","                        [43., 29., 15.]]],\n","              \n","              \n","                      ...,\n","              \n","              \n","                      [[[22., 18., 23.],\n","                        [27., 27., 26.],\n","                        [29., 34., 27.]],\n","              \n","                       [[21., 18., 11.],\n","                        [27., 20., 21.],\n","                        [36., 26., 36.]],\n","              \n","                       [[11., 11., 13.],\n","                        [29., 32., 15.],\n","                        [25., 54., 43.]],\n","              \n","                       ...,\n","              \n","                       [[28., 24., 25.],\n","                        [11., 20., 29.],\n","                        [19., 16., 20.]],\n","              \n","                       [[27., 31., 36.],\n","                        [35., 28., 22.],\n","                        [38., 10., 15.]],\n","              \n","                       [[21., 25., 24.],\n","                        [22., 24., 20.],\n","                        [31., 33., 29.]]],\n","              \n","              \n","                      [[[11., 41., 50.],\n","                        [22., 37., 31.],\n","                        [32., 46., 32.]],\n","              \n","                       [[19., 34., 40.],\n","                        [32., 32., 30.],\n","                        [31., 32., 36.]],\n","              \n","                       [[34., 29., 38.],\n","                        [32., 27., 34.],\n","                        [27., 25., 30.]],\n","              \n","                       ...,\n","              \n","                       [[32., 35., 33.],\n","                        [20., 38., 28.],\n","                        [21., 35., 23.]],\n","              \n","                       [[38., 31., 12.],\n","                        [24., 28., 23.],\n","                        [26., 46., 47.]],\n","              \n","                       [[30., 29., 30.],\n","                        [32., 36., 27.],\n","                        [25., 41., 28.]]],\n","              \n","              \n","                      [[[28., 23., 34.],\n","                        [28., 19., 40.],\n","                        [33., 24., 34.]],\n","              \n","                       [[23., 33., 35.],\n","                        [36., 29., 33.],\n","                        [42., 37., 38.]],\n","              \n","                       [[41., 43., 41.],\n","                        [20., 29., 40.],\n","                        [13., 21., 37.]],\n","              \n","                       ...,\n","              \n","                       [[21., 18., 14.],\n","                        [35., 35., 26.],\n","                        [28., 29., 13.]],\n","              \n","                       [[25., 40., 44.],\n","                        [25., 35., 45.],\n","                        [24., 35., 38.]],\n","              \n","                       [[32., 45., 33.],\n","                        [30., 33., 39.],\n","                        [23., 21., 33.]]]], device='cuda:0')),\n","             ('module.layer2.6.conv1.wrapped_module.bias',\n","              tensor([ -786., -1535., -1343., -2746.,  1490.,   776., -3758.,  1448., -2019.,\n","                       2332., -3476.,  1031.,  -452.,  -414.,  -697.,  1730.,  1218.,   -39.,\n","                       -152., -1157., -3004.,  -744.,   282.,   789.,   946.,  1391.,   722.,\n","                       -285.,   -61.,   464.,  -536., -3111.], device='cuda:0')),\n","             ('module.layer2.6.conv2.num_forwards',\n","              tensor([40], device='cuda:0')),\n","             ('module.layer2.6.conv2.force_readjust',\n","              tensor(False, device='cuda:0')),\n","             ('module.layer2.6.conv2.output_scale',\n","              tensor([14.6962], device='cuda:0')),\n","             ('module.layer2.6.conv2.output_zero_point',\n","              tensor([-28.], device='cuda:0')),\n","             ('module.layer2.6.conv2.w_scale', tensor([[[[147.7396]]],\n","              \n","              \n","                      [[[117.1068]]],\n","              \n","              \n","                      [[[ 97.9679]]],\n","              \n","              \n","                      [[[103.0312]]],\n","              \n","              \n","                      [[[ 96.2082]]],\n","              \n","              \n","                      [[[ 57.6676]]],\n","              \n","              \n","                      [[[124.2581]]],\n","              \n","              \n","                      [[[127.7949]]],\n","              \n","              \n","                      [[[ 49.6301]]],\n","              \n","              \n","                      [[[ 62.4499]]],\n","              \n","              \n","                      [[[113.7258]]],\n","              \n","              \n","                      [[[ 93.4766]]],\n","              \n","              \n","                      [[[ 36.8873]]],\n","              \n","              \n","                      [[[148.7661]]],\n","              \n","              \n","                      [[[ 50.1429]]],\n","              \n","              \n","                      [[[198.4262]]],\n","              \n","              \n","                      [[[ 75.9441]]],\n","              \n","              \n","                      [[[ 75.5052]]],\n","              \n","              \n","                      [[[ 47.6242]]],\n","              \n","              \n","                      [[[ 80.4568]]],\n","              \n","              \n","                      [[[ 91.3672]]],\n","              \n","              \n","                      [[[182.1799]]],\n","              \n","              \n","                      [[[194.2444]]],\n","              \n","              \n","                      [[[ 94.9851]]],\n","              \n","              \n","                      [[[137.8337]]],\n","              \n","              \n","                      [[[112.4982]]],\n","              \n","              \n","                      [[[ 46.1004]]],\n","              \n","              \n","                      [[[511.3126]]],\n","              \n","              \n","                      [[[ 97.1553]]],\n","              \n","              \n","                      [[[ 52.5896]]],\n","              \n","              \n","                      [[[142.4043]]],\n","              \n","              \n","                      [[[ 91.0067]]]], device='cuda:0')),\n","             ('module.layer2.6.conv2.w_zero_point', tensor([[[[-27.]]],\n","              \n","              \n","                      [[[-30.]]],\n","              \n","              \n","                      [[[-26.]]],\n","              \n","              \n","                      [[[-31.]]],\n","              \n","              \n","                      [[[-28.]]],\n","              \n","              \n","                      [[[-32.]]],\n","              \n","              \n","                      [[[-29.]]],\n","              \n","              \n","                      [[[-39.]]],\n","              \n","              \n","                      [[[-26.]]],\n","              \n","              \n","                      [[[-25.]]],\n","              \n","              \n","                      [[[-34.]]],\n","              \n","              \n","                      [[[-32.]]],\n","              \n","              \n","                      [[[-20.]]],\n","              \n","              \n","                      [[[-24.]]],\n","              \n","              \n","                      [[[-29.]]],\n","              \n","              \n","                      [[[-31.]]],\n","              \n","              \n","                      [[[-27.]]],\n","              \n","              \n","                      [[[-35.]]],\n","              \n","              \n","                      [[[-26.]]],\n","              \n","              \n","                      [[[-30.]]],\n","              \n","              \n","                      [[[-25.]]],\n","              \n","              \n","                      [[[-35.]]],\n","              \n","              \n","                      [[[-30.]]],\n","              \n","              \n","                      [[[-27.]]],\n","              \n","              \n","                      [[[-23.]]],\n","              \n","              \n","                      [[[-30.]]],\n","              \n","              \n","                      [[[-30.]]],\n","              \n","              \n","                      [[[-37.]]],\n","              \n","              \n","                      [[[-32.]]],\n","              \n","              \n","                      [[[-37.]]],\n","              \n","              \n","                      [[[-27.]]],\n","              \n","              \n","                      [[[-29.]]]], device='cuda:0')),\n","             ('module.layer2.6.conv2.fp_bias',\n","              tensor([ 0.0272,  0.0510,  0.1065, -0.1330,  0.1541,  0.2052, -0.1057,  0.0391,\n","                      -0.2168,  0.4455,  0.1220, -0.1260, -0.1394, -0.1448, -0.0823, -0.1370,\n","                      -0.2301,  0.0821, -0.4506,  0.1826, -0.2618,  0.1910, -0.0013,  0.0620,\n","                       0.1333,  0.0565, -0.3582,  0.0229, -0.1151,  0.1341, -0.0724,  0.0639],\n","                     device='cuda:0')),\n","             ('module.layer2.6.conv2.accum_scale', tensor([[[ 6965.7324]],\n","              \n","                      [[ 5521.4355]],\n","              \n","                      [[ 4619.0625]],\n","              \n","                      [[ 4857.7910]],\n","              \n","                      [[ 4536.0957]],\n","              \n","                      [[ 2718.9548]],\n","              \n","                      [[ 5858.6118]],\n","              \n","                      [[ 6025.3687]],\n","              \n","                      [[ 2339.9944]],\n","              \n","                      [[ 2944.4341]],\n","              \n","                      [[ 5362.0269]],\n","              \n","                      [[ 4407.3037]],\n","              \n","                      [[ 1739.1888]],\n","              \n","                      [[ 7014.1338]],\n","              \n","                      [[ 2364.1731]],\n","              \n","                      [[ 9355.5420]],\n","              \n","                      [[ 3580.6677]],\n","              \n","                      [[ 3559.9739]],\n","              \n","                      [[ 2245.4219]],\n","              \n","                      [[ 3793.4365]],\n","              \n","                      [[ 4307.8462]],\n","              \n","                      [[ 8589.5498]],\n","              \n","                      [[ 9158.3750]],\n","              \n","                      [[ 4478.4272]],\n","              \n","                      [[ 6498.6831]],\n","              \n","                      [[ 5304.1475]],\n","              \n","                      [[ 2173.5747]],\n","              \n","                      [[24107.7402]],\n","              \n","                      [[ 4580.7476]],\n","              \n","                      [[ 2479.5322]],\n","              \n","                      [[ 6714.1807]],\n","              \n","                      [[ 4290.8511]]], device='cuda:0')),\n","             ('module.layer2.6.conv2.is_simulated_quant_weight_shifted',\n","              tensor(False, device='cuda:0')),\n","             ('module.layer2.6.conv2.wrapped_module.weight',\n","              tensor([[[[37., 36., 36.],\n","                        [43., 30., 18.],\n","                        [35., 23.,  7.]],\n","              \n","                       [[33., 28., 33.],\n","                        [23., 29., 28.],\n","                        [33., 38., 33.]],\n","              \n","                       [[18., 12., 26.],\n","                        [29., 33., 31.],\n","                        [36., 39., 45.]],\n","              \n","                       ...,\n","              \n","                       [[28., 19., 35.],\n","                        [22., 21., 39.],\n","                        [29., 30., 45.]],\n","              \n","                       [[32., 32., 54.],\n","                        [41., 54., 62.],\n","                        [34., 51., 58.]],\n","              \n","                       [[17., 27., 23.],\n","                        [20., 27., 25.],\n","                        [19., 24., 24.]]],\n","              \n","              \n","                      [[[35., 30., 28.],\n","                        [42., 29., 26.],\n","                        [47., 37., 29.]],\n","              \n","                       [[52., 55., 40.],\n","                        [56., 55., 39.],\n","                        [62., 57., 53.]],\n","              \n","                       [[42., 37., 44.],\n","                        [31., 26., 34.],\n","                        [27., 38., 51.]],\n","              \n","                       ...,\n","              \n","                       [[35., 18., 15.],\n","                        [38., 10.,  0.],\n","                        [37., 17., 10.]],\n","              \n","                       [[17.,  9.,  7.],\n","                        [46., 26.,  4.],\n","                        [53., 34., 20.]],\n","              \n","                       [[26., 38., 31.],\n","                        [29., 36., 34.],\n","                        [38., 33., 29.]]],\n","              \n","              \n","                      [[[15., 23., 28.],\n","                        [22., 30., 34.],\n","                        [26., 32., 41.]],\n","              \n","                       [[19., 29., 31.],\n","                        [23., 25., 42.],\n","                        [22., 30., 42.]],\n","              \n","                       [[36., 35., 26.],\n","                        [34., 25., 24.],\n","                        [25., 19., 26.]],\n","              \n","                       ...,\n","              \n","                       [[38., 61., 46.],\n","                        [41., 63., 54.],\n","                        [29., 53., 43.]],\n","              \n","                       [[ 9., 10., 26.],\n","                        [ 0., 18., 25.],\n","                        [21., 38., 38.]],\n","              \n","                       [[30., 30., 37.],\n","                        [31., 32., 37.],\n","                        [26., 31., 35.]]],\n","              \n","              \n","                      ...,\n","              \n","              \n","                      [[[31., 29., 31.],\n","                        [29., 40., 40.],\n","                        [29., 41., 44.]],\n","              \n","                       [[55., 47., 34.],\n","                        [52., 51., 44.],\n","                        [51., 46., 41.]],\n","              \n","                       [[37., 41., 40.],\n","                        [49., 54., 54.],\n","                        [49., 54., 45.]],\n","              \n","                       ...,\n","              \n","                       [[27., 32., 32.],\n","                        [33., 30., 37.],\n","                        [41., 21., 21.]],\n","              \n","                       [[40., 36., 24.],\n","                        [45., 20., 15.],\n","                        [26.,  0.,  7.]],\n","              \n","                       [[39., 36., 32.],\n","                        [38., 37., 33.],\n","                        [33., 35., 37.]]],\n","              \n","              \n","                      [[[23., 15., 17.],\n","                        [21., 10., 18.],\n","                        [26., 15., 22.]],\n","              \n","                       [[24., 14., 14.],\n","                        [29., 17.,  8.],\n","                        [36., 34., 30.]],\n","              \n","                       [[34., 34., 21.],\n","                        [47., 44., 33.],\n","                        [50., 45., 27.]],\n","              \n","                       ...,\n","              \n","                       [[54., 36., 22.],\n","                        [30., 29., 24.],\n","                        [21., 46., 49.]],\n","              \n","                       [[17., 11., 18.],\n","                        [16.,  7., 26.],\n","                        [24., 23., 43.]],\n","              \n","                       [[15., 25., 32.],\n","                        [17., 22., 27.],\n","                        [22., 26., 23.]]],\n","              \n","              \n","                      [[[30., 27., 29.],\n","                        [38., 47., 54.],\n","                        [32., 50., 53.]],\n","              \n","                       [[33., 27., 16.],\n","                        [13., 11.,  6.],\n","                        [12., 15., 14.]],\n","              \n","                       [[13., 11.,  0.],\n","                        [ 8., 14., 10.],\n","                        [20., 25., 22.]],\n","              \n","                       ...,\n","              \n","                       [[49., 48., 63.],\n","                        [15., 21., 33.],\n","                        [17., 15., 13.]],\n","              \n","                       [[46., 43., 30.],\n","                        [38., 51., 41.],\n","                        [27., 40., 37.]],\n","              \n","                       [[22., 28., 31.],\n","                        [23., 28., 29.],\n","                        [18., 23., 28.]]]], device='cuda:0')),\n","             ('module.layer2.6.conv2.wrapped_module.bias',\n","              tensor([  190.,   281.,   492.,  -646.,   699.,   558.,  -619.,   236.,  -507.,\n","                       1312.,   654.,  -556.,  -242., -1016.,  -195., -1282.,  -824.,   292.,\n","                      -1012.,   693., -1128.,  1640.,   -12.,   278.,   866.,   300.,  -778.,\n","                        553.,  -527.,   333.,  -486.,   274.], device='cuda:0')),\n","             ('module.layer2.6.relu2.num_forwards',\n","              tensor([40], device='cuda:0')),\n","             ('module.layer2.6.relu2.force_readjust',\n","              tensor(False, device='cuda:0')),\n","             ('module.layer2.6.relu2.output_scale',\n","              tensor([6.9661], device='cuda:0')),\n","             ('module.layer2.6.relu2.output_zero_point',\n","              tensor([0.], device='cuda:0')),\n","             ('module.layer2.6.residual_eltwiseadd.num_forwards',\n","              tensor([40], device='cuda:0')),\n","             ('module.layer2.6.residual_eltwiseadd.force_readjust',\n","              tensor(False, device='cuda:0')),\n","             ('module.layer2.6.residual_eltwiseadd.output_scale',\n","              tensor([6.9661], device='cuda:0')),\n","             ('module.layer2.6.residual_eltwiseadd.output_zero_point',\n","              tensor([0.], device='cuda:0')),\n","             ('module.layer2.7.conv1.num_forwards',\n","              tensor([40], device='cuda:0')),\n","             ('module.layer2.7.conv1.force_readjust',\n","              tensor(False, device='cuda:0')),\n","             ('module.layer2.7.conv1.output_scale',\n","              tensor([52.0360], device='cuda:0')),\n","             ('module.layer2.7.conv1.output_zero_point',\n","              tensor([0.], device='cuda:0')),\n","             ('module.layer2.7.conv1.w_scale', tensor([[[[1498.2118]]],\n","              \n","              \n","                      [[[ 680.6479]]],\n","              \n","              \n","                      [[[ 611.6741]]],\n","              \n","              \n","                      [[[1444.3597]]],\n","              \n","              \n","                      [[[1384.5470]]],\n","              \n","              \n","                      [[[2316.1948]]],\n","              \n","              \n","                      [[[ 748.3950]]],\n","              \n","              \n","                      [[[ 673.7024]]],\n","              \n","              \n","                      [[[ 812.9830]]],\n","              \n","              \n","                      [[[1090.2922]]],\n","              \n","              \n","                      [[[ 865.3160]]],\n","              \n","              \n","                      [[[1596.1112]]],\n","              \n","              \n","                      [[[1229.8353]]],\n","              \n","              \n","                      [[[1291.5085]]],\n","              \n","              \n","                      [[[ 766.4984]]],\n","              \n","              \n","                      [[[1522.9528]]],\n","              \n","              \n","                      [[[1173.0245]]],\n","              \n","              \n","                      [[[ 903.9319]]],\n","              \n","              \n","                      [[[ 932.1581]]],\n","              \n","              \n","                      [[[ 711.6422]]],\n","              \n","              \n","                      [[[ 718.2921]]],\n","              \n","              \n","                      [[[ 561.6059]]],\n","              \n","              \n","                      [[[ 552.4266]]],\n","              \n","              \n","                      [[[1202.5027]]],\n","              \n","              \n","                      [[[ 908.6119]]],\n","              \n","              \n","                      [[[1215.3376]]],\n","              \n","              \n","                      [[[ 742.2844]]],\n","              \n","              \n","                      [[[ 821.7085]]],\n","              \n","              \n","                      [[[ 970.9481]]],\n","              \n","              \n","                      [[[ 622.2578]]],\n","              \n","              \n","                      [[[1223.3252]]],\n","              \n","              \n","                      [[[ 956.5042]]]], device='cuda:0')),\n","             ('module.layer2.7.conv1.w_zero_point', tensor([[[[-27.]]],\n","              \n","              \n","                      [[[-28.]]],\n","              \n","              \n","                      [[[-32.]]],\n","              \n","              \n","                      [[[-31.]]],\n","              \n","              \n","                      [[[-30.]]],\n","              \n","              \n","                      [[[-34.]]],\n","              \n","              \n","                      [[[-29.]]],\n","              \n","              \n","                      [[[-30.]]],\n","              \n","              \n","                      [[[-33.]]],\n","              \n","              \n","                      [[[-23.]]],\n","              \n","              \n","                      [[[-28.]]],\n","              \n","              \n","                      [[[-31.]]],\n","              \n","              \n","                      [[[-28.]]],\n","              \n","              \n","                      [[[-31.]]],\n","              \n","              \n","                      [[[-29.]]],\n","              \n","              \n","                      [[[-29.]]],\n","              \n","              \n","                      [[[-29.]]],\n","              \n","              \n","                      [[[-31.]]],\n","              \n","              \n","                      [[[-31.]]],\n","              \n","              \n","                      [[[-32.]]],\n","              \n","              \n","                      [[[-29.]]],\n","              \n","              \n","                      [[[-25.]]],\n","              \n","              \n","                      [[[-24.]]],\n","              \n","              \n","                      [[[-31.]]],\n","              \n","              \n","                      [[[-27.]]],\n","              \n","              \n","                      [[[-23.]]],\n","              \n","              \n","                      [[[-36.]]],\n","              \n","              \n","                      [[[-30.]]],\n","              \n","              \n","                      [[[-32.]]],\n","              \n","              \n","                      [[[-28.]]],\n","              \n","              \n","                      [[[-30.]]],\n","              \n","              \n","                      [[[-31.]]]], device='cuda:0')),\n","             ('module.layer2.7.conv1.fp_bias',\n","              tensor([-0.3439,  0.3228,  0.5181,  0.0259, -0.4062, -0.1100, -0.1551,  0.2000,\n","                       0.0182,  0.0598, -0.7050, -0.1906, -0.2341,  0.2808, -0.0362, -0.3267,\n","                      -0.2483,  0.0514,  0.1346,  0.2173,  0.2908, -0.3498, -0.3427,  0.0438,\n","                       0.0867, -0.2656,  0.0744,  0.1707,  0.3964,  0.2025,  0.0871, -0.1121],\n","                     device='cuda:0')),\n","             ('module.layer2.7.conv1.accum_scale', tensor([[[10436.6396]],\n","              \n","                      [[ 4741.4375]],\n","              \n","                      [[ 4260.9609]],\n","              \n","                      [[10061.5029]],\n","              \n","                      [[ 9644.8438]],\n","              \n","                      [[16134.7627]],\n","              \n","                      [[ 5213.3682]],\n","              \n","                      [[ 4693.0542]],\n","              \n","                      [[ 5663.2920]],\n","              \n","                      [[ 7595.0459]],\n","              \n","                      [[ 6027.8467]],\n","              \n","                      [[11118.6133]],\n","              \n","                      [[ 8567.1123]],\n","              \n","                      [[ 8996.7314]],\n","              \n","                      [[ 5339.4775]],\n","              \n","                      [[10608.9873]],\n","              \n","                      [[ 8171.3647]],\n","              \n","                      [[ 6296.8481]],\n","              \n","                      [[ 6493.4731]],\n","              \n","                      [[ 4957.3457]],\n","              \n","                      [[ 5003.6689]],\n","              \n","                      [[ 3912.1829]],\n","              \n","                      [[ 3848.2390]],\n","              \n","                      [[ 8376.7109]],\n","              \n","                      [[ 6329.4487]],\n","              \n","                      [[ 8466.1201]],\n","              \n","                      [[ 5170.8013]],\n","              \n","                      [[ 5724.0742]],\n","              \n","                      [[ 6763.6865]],\n","              \n","                      [[ 4334.6875]],\n","              \n","                      [[ 8521.7617]],\n","              \n","                      [[ 6663.0693]]], device='cuda:0')),\n","             ('module.layer2.7.conv1.is_simulated_quant_weight_shifted',\n","              tensor(False, device='cuda:0')),\n","             ('module.layer2.7.conv1.wrapped_module.weight',\n","              tensor([[[[32., 24., 25.],\n","                        [24., 23., 23.],\n","                        [17., 31., 38.]],\n","              \n","                       [[32., 30., 38.],\n","                        [40., 54., 53.],\n","                        [23., 31., 31.]],\n","              \n","                       [[24., 27., 32.],\n","                        [36., 34., 34.],\n","                        [32., 25., 28.]],\n","              \n","                       ...,\n","              \n","                       [[44., 15.,  0.],\n","                        [24., 15., 11.],\n","                        [23., 29., 35.]],\n","              \n","                       [[ 2., 18., 28.],\n","                        [22., 16., 26.],\n","                        [41., 30., 26.]],\n","              \n","                       [[27., 25., 19.],\n","                        [21., 22., 24.],\n","                        [25., 25., 24.]]],\n","              \n","              \n","                      [[[16., 17., 26.],\n","                        [14., 22., 28.],\n","                        [22., 40., 30.]],\n","              \n","                       [[20., 30., 26.],\n","                        [29., 36., 26.],\n","                        [28., 39., 27.]],\n","              \n","                       [[13., 26., 25.],\n","                        [30., 33., 25.],\n","                        [47., 29., 18.]],\n","              \n","                       ...,\n","              \n","                       [[19., 33., 45.],\n","                        [10., 14., 35.],\n","                        [12., 14., 19.]],\n","              \n","                       [[27., 23., 25.],\n","                        [38., 32., 49.],\n","                        [30., 22., 43.]],\n","              \n","                       [[19., 16., 13.],\n","                        [40., 26., 14.],\n","                        [39., 25., 15.]]],\n","              \n","              \n","                      [[[34., 46., 35.],\n","                        [44., 33., 22.],\n","                        [21., 24., 37.]],\n","              \n","                       [[41., 19., 14.],\n","                        [26., 18., 19.],\n","                        [34., 36., 32.]],\n","              \n","                       [[17., 20., 23.],\n","                        [27., 26., 29.],\n","                        [37., 34., 47.]],\n","              \n","                       ...,\n","              \n","                       [[20., 46., 17.],\n","                        [48., 49., 31.],\n","                        [25., 15., 37.]],\n","              \n","                       [[24., 28., 27.],\n","                        [28., 15.,  4.],\n","                        [37., 17., 27.]],\n","              \n","                       [[25., 17., 27.],\n","                        [27., 26., 35.],\n","                        [39., 42., 40.]]],\n","              \n","              \n","                      ...,\n","              \n","              \n","                      [[[24., 27., 48.],\n","                        [13.,  9., 21.],\n","                        [20., 20., 18.]],\n","              \n","                       [[16., 18., 19.],\n","                        [27., 29., 33.],\n","                        [33., 16., 23.]],\n","              \n","                       [[31., 48., 42.],\n","                        [33., 33., 31.],\n","                        [33., 13., 20.]],\n","              \n","                       ...,\n","              \n","                       [[21., 21., 41.],\n","                        [34., 15., 11.],\n","                        [21., 22., 25.]],\n","              \n","                       [[47., 31., 20.],\n","                        [29., 28., 22.],\n","                        [25., 26., 21.]],\n","              \n","                       [[38., 32., 22.],\n","                        [20., 26., 24.],\n","                        [17., 25., 18.]]],\n","              \n","              \n","                      [[[49., 52., 51.],\n","                        [39., 47., 38.],\n","                        [37., 44., 37.]],\n","              \n","                       [[31., 32., 39.],\n","                        [24., 19., 25.],\n","                        [28., 19., 30.]],\n","              \n","                       [[35., 31., 25.],\n","                        [35., 21., 17.],\n","                        [21., 14., 17.]],\n","              \n","                       ...,\n","              \n","                       [[31., 26., 33.],\n","                        [27., 25., 29.],\n","                        [22., 29., 40.]],\n","              \n","                       [[21., 31., 14.],\n","                        [36., 47., 39.],\n","                        [25., 47., 41.]],\n","              \n","                       [[47., 33., 28.],\n","                        [56., 39., 30.],\n","                        [41., 28., 25.]]],\n","              \n","              \n","                      [[[45., 30., 30.],\n","                        [27., 15., 27.],\n","                        [33., 18., 34.]],\n","              \n","                       [[31., 49., 56.],\n","                        [38., 45., 42.],\n","                        [34., 31., 19.]],\n","              \n","                       [[22., 25., 30.],\n","                        [30., 23., 18.],\n","                        [31., 36., 30.]],\n","              \n","                       ...,\n","              \n","                       [[35., 25., 22.],\n","                        [30., 23., 26.],\n","                        [42., 27., 30.]],\n","              \n","                       [[22., 27., 29.],\n","                        [37., 37., 37.],\n","                        [37., 27., 30.]],\n","              \n","                       [[40., 37., 38.],\n","                        [30., 31., 37.],\n","                        [27., 42., 47.]]]], device='cuda:0')),\n","             ('module.layer2.7.conv1.wrapped_module.bias',\n","              tensor([-3589.,  1530.,  2208.,   260., -3918., -1774.,  -809.,   938.,   103.,\n","                        454., -4250., -2120., -2005.,  2526.,  -193., -3466., -2029.,   323.,\n","                        874.,  1077.,  1455., -1368., -1319.,   367.,   549., -2249.,   384.,\n","                        977.,  2681.,   878.,   742.,  -747.], device='cuda:0')),\n","             ('module.layer2.7.conv2.num_forwards',\n","              tensor([40], device='cuda:0')),\n","             ('module.layer2.7.conv2.force_readjust',\n","              tensor(False, device='cuda:0')),\n","             ('module.layer2.7.conv2.output_scale',\n","              tensor([16.8309], device='cuda:0')),\n","             ('module.layer2.7.conv2.output_zero_point',\n","              tensor([-28.], device='cuda:0')),\n","             ('module.layer2.7.conv2.w_scale', tensor([[[[ 118.0312]]],\n","              \n","              \n","                      [[[2383.5486]]],\n","              \n","              \n","                      [[[ 684.7643]]],\n","              \n","              \n","                      [[[  72.0147]]],\n","              \n","              \n","                      [[[  53.2935]]],\n","              \n","              \n","                      [[[  44.9661]]],\n","              \n","              \n","                      [[[ 141.9145]]],\n","              \n","              \n","                      [[[  76.2897]]],\n","              \n","              \n","                      [[[  99.7867]]],\n","              \n","              \n","                      [[[  51.8461]]],\n","              \n","              \n","                      [[[ 125.9580]]],\n","              \n","              \n","                      [[[  47.1840]]],\n","              \n","              \n","                      [[[ 123.8297]]],\n","              \n","              \n","                      [[[ 166.7065]]],\n","              \n","              \n","                      [[[  74.0166]]],\n","              \n","              \n","                      [[[ 118.8594]]],\n","              \n","              \n","                      [[[ 131.5140]]],\n","              \n","              \n","                      [[[  78.0896]]],\n","              \n","              \n","                      [[[  34.6617]]],\n","              \n","              \n","                      [[[  87.3336]]],\n","              \n","              \n","                      [[[  78.8414]]],\n","              \n","              \n","                      [[[  62.5597]]],\n","              \n","              \n","                      [[[ 203.5648]]],\n","              \n","              \n","                      [[[ 105.1373]]],\n","              \n","              \n","                      [[[  58.2219]]],\n","              \n","              \n","                      [[[  80.1295]]],\n","              \n","              \n","                      [[[ 232.4771]]],\n","              \n","              \n","                      [[[ 175.6796]]],\n","              \n","              \n","                      [[[ 148.4507]]],\n","              \n","              \n","                      [[[ 122.6683]]],\n","              \n","              \n","                      [[[  80.3783]]],\n","              \n","              \n","                      [[[ 186.2473]]]], device='cuda:0')),\n","             ('module.layer2.7.conv2.w_zero_point', tensor([[[[-38.]]],\n","              \n","              \n","                      [[[-39.]]],\n","              \n","              \n","                      [[[-22.]]],\n","              \n","              \n","                      [[[-25.]]],\n","              \n","              \n","                      [[[-23.]]],\n","              \n","              \n","                      [[[-27.]]],\n","              \n","              \n","                      [[[-32.]]],\n","              \n","              \n","                      [[[-31.]]],\n","              \n","              \n","                      [[[-33.]]],\n","              \n","              \n","                      [[[-26.]]],\n","              \n","              \n","                      [[[-32.]]],\n","              \n","              \n","                      [[[-18.]]],\n","              \n","              \n","                      [[[-30.]]],\n","              \n","              \n","                      [[[-34.]]],\n","              \n","              \n","                      [[[-36.]]],\n","              \n","              \n","                      [[[-30.]]],\n","              \n","              \n","                      [[[-31.]]],\n","              \n","              \n","                      [[[-26.]]],\n","              \n","              \n","                      [[[-32.]]],\n","              \n","              \n","                      [[[-28.]]],\n","              \n","              \n","                      [[[-24.]]],\n","              \n","              \n","                      [[[-28.]]],\n","              \n","              \n","                      [[[-25.]]],\n","              \n","              \n","                      [[[-38.]]],\n","              \n","              \n","                      [[[-26.]]],\n","              \n","              \n","                      [[[-31.]]],\n","              \n","              \n","                      [[[-29.]]],\n","              \n","              \n","                      [[[-32.]]],\n","              \n","              \n","                      [[[-27.]]],\n","              \n","              \n","                      [[[-29.]]],\n","              \n","              \n","                      [[[-29.]]],\n","              \n","              \n","                      [[[-32.]]]], device='cuda:0')),\n","             ('module.layer2.7.conv2.fp_bias',\n","              tensor([ 0.1420,  0.0111,  0.0667, -0.2914, -0.0443,  0.0918, -0.0551,  0.1196,\n","                      -0.0480,  0.2957,  0.0067, -0.1049, -0.0257,  0.0275,  0.1363,  0.0068,\n","                      -0.1692, -0.0524, -0.1814,  0.1582, -0.0905,  0.1794,  0.0178,  0.2433,\n","                       0.0121,  0.1382,  0.1709, -0.0719,  0.0189, -0.0477,  0.0417, -0.0137],\n","                     device='cuda:0')),\n","             ('module.layer2.7.conv2.accum_scale', tensor([[[  6141.8662]],\n","              \n","                      [[124030.2500]],\n","              \n","                      [[ 35632.3711]],\n","              \n","                      [[  3747.3545]],\n","              \n","                      [[  2773.1802]],\n","              \n","                      [[  2339.8533]],\n","              \n","                      [[  7384.6582]],\n","              \n","                      [[  3969.8076]],\n","              \n","                      [[  5192.4951]],\n","              \n","                      [[  2697.8643]],\n","              \n","                      [[  6554.3452]],\n","              \n","                      [[  2455.2637]],\n","              \n","                      [[  6443.6001]],\n","              \n","                      [[  8674.7334]],\n","              \n","                      [[  3851.5269]],\n","              \n","                      [[  6184.9648]],\n","              \n","                      [[  6843.4565]],\n","              \n","                      [[  4063.4688]],\n","              \n","                      [[  1803.6556]],\n","              \n","                      [[  4544.4893]],\n","              \n","                      [[  4102.5898]],\n","              \n","                      [[  3255.3564]],\n","              \n","                      [[ 10592.6895]],\n","              \n","                      [[  5470.9204]],\n","              \n","                      [[  3029.6309]],\n","              \n","                      [[  4169.6152]],\n","              \n","                      [[ 12097.1689]],\n","              \n","                      [[  9141.6602]],\n","              \n","                      [[  7724.7778]],\n","              \n","                      [[  6383.1616]],\n","              \n","                      [[  4182.5635]],\n","              \n","                      [[  9691.5566]]], device='cuda:0')),\n","             ('module.layer2.7.conv2.is_simulated_quant_weight_shifted',\n","              tensor(False, device='cuda:0')),\n","             ('module.layer2.7.conv2.wrapped_module.weight',\n","              tensor([[[[57., 51., 44.],\n","                        [49., 44., 42.],\n","                        [48., 45., 42.]],\n","              \n","                       [[33., 29., 42.],\n","                        [36., 28., 32.],\n","                        [41., 32., 42.]],\n","              \n","                       [[51., 53., 45.],\n","                        [24., 28., 31.],\n","                        [24., 23., 33.]],\n","              \n","                       ...,\n","              \n","                       [[38., 37., 38.],\n","                        [36., 44., 31.],\n","                        [34., 42., 36.]],\n","              \n","                       [[45., 38., 32.],\n","                        [44., 41., 35.],\n","                        [30., 32., 38.]],\n","              \n","                       [[32., 29., 34.],\n","                        [38., 30., 32.],\n","                        [49., 48., 45.]]],\n","              \n","              \n","                      [[[37., 40., 40.],\n","                        [39., 42., 45.],\n","                        [40., 41., 43.]],\n","              \n","                       [[44., 39., 39.],\n","                        [42., 42., 41.],\n","                        [48., 44., 40.]],\n","              \n","                       [[50., 48., 47.],\n","                        [45., 39., 41.],\n","                        [42., 34., 38.]],\n","              \n","                       ...,\n","              \n","                       [[42., 36., 35.],\n","                        [42., 31., 34.],\n","                        [39., 34., 33.]],\n","              \n","                       [[44., 37., 37.],\n","                        [37., 35., 36.],\n","                        [39., 40., 39.]],\n","              \n","                       [[39., 36., 36.],\n","                        [50., 43., 43.],\n","                        [54., 49., 48.]]],\n","              \n","              \n","                      [[[30., 26., 25.],\n","                        [25., 22., 20.],\n","                        [19., 17., 18.]],\n","              \n","                       [[28., 35., 29.],\n","                        [24., 32., 25.],\n","                        [28., 22., 29.]],\n","              \n","                       [[25., 10.,  3.],\n","                        [36., 21., 12.],\n","                        [30., 19., 15.]],\n","              \n","                       ...,\n","              \n","                       [[34., 36., 35.],\n","                        [35., 38., 41.],\n","                        [14., 24., 28.]],\n","              \n","                       [[14., 15., 15.],\n","                        [27., 28., 27.],\n","                        [24., 30., 26.]],\n","              \n","                       [[14., 21., 17.],\n","                        [22., 23., 18.],\n","                        [23., 25., 19.]]],\n","              \n","              \n","                      ...,\n","              \n","              \n","                      [[[36., 41., 37.],\n","                        [36., 40., 45.],\n","                        [28., 32., 36.]],\n","              \n","                       [[18., 21., 16.],\n","                        [22., 20., 22.],\n","                        [21., 22., 18.]],\n","              \n","                       [[26., 32., 21.],\n","                        [15., 21., 25.],\n","                        [17., 37., 40.]],\n","              \n","                       ...,\n","              \n","                       [[28., 25., 20.],\n","                        [31., 32., 36.],\n","                        [12., 32., 39.]],\n","              \n","                       [[17., 15., 15.],\n","                        [18., 19., 27.],\n","                        [16., 23., 34.]],\n","              \n","                       [[31., 30., 20.],\n","                        [31., 28., 21.],\n","                        [40., 28., 18.]]],\n","              \n","              \n","                      [[[24., 25., 31.],\n","                        [23., 28., 36.],\n","                        [23., 25., 35.]],\n","              \n","                       [[29., 35., 38.],\n","                        [33., 44., 43.],\n","                        [44., 58., 38.]],\n","              \n","                       [[31., 19.,  9.],\n","                        [26., 22.,  8.],\n","                        [32., 23., 16.]],\n","              \n","                       ...,\n","              \n","                       [[32., 27., 30.],\n","                        [26., 15., 33.],\n","                        [27., 25., 25.]],\n","              \n","                       [[23., 24., 19.],\n","                        [26., 26., 27.],\n","                        [48., 43., 40.]],\n","              \n","                       [[31., 37., 44.],\n","                        [34., 36., 43.],\n","                        [17., 14., 23.]]],\n","              \n","              \n","                      [[[34., 38., 34.],\n","                        [29., 26., 25.],\n","                        [29., 28., 26.]],\n","              \n","                       [[34., 54., 53.],\n","                        [39., 46., 36.],\n","                        [47., 35., 29.]],\n","              \n","                       [[33., 40., 51.],\n","                        [47., 47., 36.],\n","                        [42., 34., 24.]],\n","              \n","                       ...,\n","              \n","                       [[31., 34., 29.],\n","                        [40., 49., 39.],\n","                        [16., 25., 28.]],\n","              \n","                       [[39., 46., 44.],\n","                        [44., 46., 52.],\n","                        [41., 39., 49.]],\n","              \n","                       [[32., 36., 32.],\n","                        [17., 33., 30.],\n","                        [16., 33., 33.]]]], device='cuda:0')),\n","             ('module.layer2.7.conv2.wrapped_module.bias',\n","              tensor([  872.,  1383.,  2376., -1092.,  -123.,   215.,  -407.,   475.,  -249.,\n","                        798.,    44.,  -257.,  -165.,   239.,   525.,    42., -1158.,  -213.,\n","                       -327.,   719.,  -371.,   584.,   189.,  1331.,    37.,   576.,  2067.,\n","                       -658.,   146.,  -304.,   174.,  -132.], device='cuda:0')),\n","             ('module.layer2.7.relu2.num_forwards',\n","              tensor([40], device='cuda:0')),\n","             ('module.layer2.7.relu2.force_readjust',\n","              tensor(False, device='cuda:0')),\n","             ('module.layer2.7.relu2.output_scale',\n","              tensor([6.7269], device='cuda:0')),\n","             ('module.layer2.7.relu2.output_zero_point',\n","              tensor([0.], device='cuda:0')),\n","             ('module.layer2.7.residual_eltwiseadd.num_forwards',\n","              tensor([40], device='cuda:0')),\n","             ('module.layer2.7.residual_eltwiseadd.force_readjust',\n","              tensor(False, device='cuda:0')),\n","             ('module.layer2.7.residual_eltwiseadd.output_scale',\n","              tensor([6.7269], device='cuda:0')),\n","             ('module.layer2.7.residual_eltwiseadd.output_zero_point',\n","              tensor([0.], device='cuda:0')),\n","             ('module.layer2.8.conv1.num_forwards',\n","              tensor([40], device='cuda:0')),\n","             ('module.layer2.8.conv1.force_readjust',\n","              tensor(False, device='cuda:0')),\n","             ('module.layer2.8.conv1.output_scale',\n","              tensor([51.3876], device='cuda:0')),\n","             ('module.layer2.8.conv1.output_zero_point',\n","              tensor([0.], device='cuda:0')),\n","             ('module.layer2.8.conv1.w_scale', tensor([[[[6.5111e+02]]],\n","              \n","              \n","                      [[[1.0155e+03]]],\n","              \n","              \n","                      [[[4.4371e+04]]],\n","              \n","              \n","                      [[[6.7116e+02]]],\n","              \n","              \n","                      [[[8.3885e+02]]],\n","              \n","              \n","                      [[[8.0516e+02]]],\n","              \n","              \n","                      [[[9.8818e+02]]],\n","              \n","              \n","                      [[[1.4804e+03]]],\n","              \n","              \n","                      [[[1.1914e+03]]],\n","              \n","              \n","                      [[[8.7015e+02]]],\n","              \n","              \n","                      [[[7.6620e+05]]],\n","              \n","              \n","                      [[[1.0066e+05]]],\n","              \n","              \n","                      [[[8.5609e+02]]],\n","              \n","              \n","                      [[[1.0280e+03]]],\n","              \n","              \n","                      [[[9.5337e+02]]],\n","              \n","              \n","                      [[[7.5458e+02]]],\n","              \n","              \n","                      [[[1.3065e+03]]],\n","              \n","              \n","                      [[[1.0848e+03]]],\n","              \n","              \n","                      [[[6.9715e+02]]],\n","              \n","              \n","                      [[[7.2635e+02]]],\n","              \n","              \n","                      [[[1.2177e+03]]],\n","              \n","              \n","                      [[[1.7489e+03]]],\n","              \n","              \n","                      [[[8.6142e+02]]],\n","              \n","              \n","                      [[[7.4852e+02]]],\n","              \n","              \n","                      [[[8.8233e+02]]],\n","              \n","              \n","                      [[[8.3188e+02]]],\n","              \n","              \n","                      [[[1.8208e+03]]],\n","              \n","              \n","                      [[[1.5030e+03]]],\n","              \n","              \n","                      [[[1.0198e+03]]],\n","              \n","              \n","                      [[[1.2806e+03]]],\n","              \n","              \n","                      [[[9.8150e+02]]],\n","              \n","              \n","                      [[[6.6638e+02]]]], device='cuda:0')),\n","             ('module.layer2.8.conv1.w_zero_point', tensor([[[[-30.]]],\n","              \n","              \n","                      [[[-26.]]],\n","              \n","              \n","                      [[[-32.]]],\n","              \n","              \n","                      [[[-29.]]],\n","              \n","              \n","                      [[[-28.]]],\n","              \n","              \n","                      [[[-25.]]],\n","              \n","              \n","                      [[[-24.]]],\n","              \n","              \n","                      [[[-25.]]],\n","              \n","              \n","                      [[[-32.]]],\n","              \n","              \n","                      [[[-29.]]],\n","              \n","              \n","                      [[[-29.]]],\n","              \n","              \n","                      [[[-30.]]],\n","              \n","              \n","                      [[[-29.]]],\n","              \n","              \n","                      [[[-31.]]],\n","              \n","              \n","                      [[[-32.]]],\n","              \n","              \n","                      [[[-27.]]],\n","              \n","              \n","                      [[[-30.]]],\n","              \n","              \n","                      [[[-32.]]],\n","              \n","              \n","                      [[[-30.]]],\n","              \n","              \n","                      [[[-27.]]],\n","              \n","              \n","                      [[[-30.]]],\n","              \n","              \n","                      [[[-34.]]],\n","              \n","              \n","                      [[[-25.]]],\n","              \n","              \n","                      [[[-31.]]],\n","              \n","              \n","                      [[[-39.]]],\n","              \n","              \n","                      [[[-33.]]],\n","              \n","              \n","                      [[[-32.]]],\n","              \n","              \n","                      [[[-28.]]],\n","              \n","              \n","                      [[[-28.]]],\n","              \n","              \n","                      [[[-30.]]],\n","              \n","              \n","                      [[[-31.]]],\n","              \n","              \n","                      [[[-23.]]]], device='cuda:0')),\n","             ('module.layer2.8.conv1.fp_bias',\n","              tensor([ 0.6030,  0.9180, -0.0638,  0.2510,  0.3309,  0.3731, -0.1374,  0.1190,\n","                      -0.3481,  0.2808, -0.0050, -0.0255,  0.3839, -0.4292, -0.6369,  0.0529,\n","                      -0.2876,  0.2639,  0.2691, -0.0225,  0.1790,  0.1050, -0.0739, -0.0541,\n","                       0.1889,  0.1375,  0.0163, -0.1959, -0.7664, -0.4363,  0.1222,  0.1255],\n","                     device='cuda:0')),\n","             ('module.layer2.8.conv1.accum_scale', tensor([[[4.3800e+03]],\n","              \n","                      [[6.8310e+03]],\n","              \n","                      [[2.9848e+05]],\n","              \n","                      [[4.5148e+03]],\n","              \n","                      [[5.6429e+03]],\n","              \n","                      [[5.4163e+03]],\n","              \n","                      [[6.6474e+03]],\n","              \n","                      [[9.9585e+03]],\n","              \n","                      [[8.0145e+03]],\n","              \n","                      [[5.8535e+03]],\n","              \n","                      [[5.1542e+06]],\n","              \n","                      [[6.7710e+05]],\n","              \n","                      [[5.7589e+03]],\n","              \n","                      [[6.9151e+03]],\n","              \n","                      [[6.4133e+03]],\n","              \n","                      [[5.0760e+03]],\n","              \n","                      [[8.7885e+03]],\n","              \n","                      [[7.2973e+03]],\n","              \n","                      [[4.6897e+03]],\n","              \n","                      [[4.8861e+03]],\n","              \n","                      [[8.1914e+03]],\n","              \n","                      [[1.1765e+04]],\n","              \n","                      [[5.7947e+03]],\n","              \n","                      [[5.0353e+03]],\n","              \n","                      [[5.9354e+03]],\n","              \n","                      [[5.5960e+03]],\n","              \n","                      [[1.2249e+04]],\n","              \n","                      [[1.0111e+04]],\n","              \n","                      [[6.8603e+03]],\n","              \n","                      [[8.6143e+03]],\n","              \n","                      [[6.6025e+03]],\n","              \n","                      [[4.4827e+03]]], device='cuda:0')),\n","             ('module.layer2.8.conv1.is_simulated_quant_weight_shifted',\n","              tensor(False, device='cuda:0')),\n","             ('module.layer2.8.conv1.wrapped_module.weight',\n","              tensor([[[[39., 51., 42.],\n","                        [16., 26., 33.],\n","                        [ 0.,  2., 22.]],\n","              \n","                       [[25., 31., 22.],\n","                        [20., 22., 22.],\n","                        [30., 32., 37.]],\n","              \n","                       [[52., 27., 26.],\n","                        [41., 32., 31.],\n","                        [24., 23., 18.]],\n","              \n","                       ...,\n","              \n","                       [[29., 26.,  8.],\n","                        [26., 33., 16.],\n","                        [32., 27., 29.]],\n","              \n","                       [[20., 26., 42.],\n","                        [28., 39., 43.],\n","                        [30., 24., 19.]],\n","              \n","                       [[36., 40., 26.],\n","                        [28., 34., 29.],\n","                        [23., 22., 25.]]],\n","              \n","              \n","                      [[[30.,  8., 31.],\n","                        [15.,  6., 25.],\n","                        [20.,  6., 24.]],\n","              \n","                       [[21., 17., 27.],\n","                        [14.,  6., 17.],\n","                        [13.,  8., 24.]],\n","              \n","                       [[18., 20., 19.],\n","                        [18., 23., 18.],\n","                        [20., 28., 21.]],\n","              \n","                       ...,\n","              \n","                       [[21., 14., 20.],\n","                        [18., 12., 18.],\n","                        [19., 14., 23.]],\n","              \n","                       [[20., 49., 17.],\n","                        [38., 63., 35.],\n","                        [20., 47., 14.]],\n","              \n","                       [[13., 13., 12.],\n","                        [14., 18., 20.],\n","                        [ 4., 10., 20.]]],\n","              \n","              \n","                      [[[34., 24., 33.],\n","                        [30., 24., 35.],\n","                        [27., 32., 36.]],\n","              \n","                       [[30., 40., 23.],\n","                        [36., 54., 42.],\n","                        [45., 58., 45.]],\n","              \n","                       [[24., 41., 43.],\n","                        [27., 40., 40.],\n","                        [24., 37., 35.]],\n","              \n","                       ...,\n","              \n","                       [[27., 33., 28.],\n","                        [24., 35., 27.],\n","                        [25., 46., 22.]],\n","              \n","                       [[17., 41., 50.],\n","                        [38., 50., 50.],\n","                        [61., 55., 45.]],\n","              \n","                       [[27., 23., 16.],\n","                        [29., 22., 28.],\n","                        [26., 26., 34.]]],\n","              \n","              \n","                      ...,\n","              \n","              \n","                      [[[32., 38., 47.],\n","                        [40., 56., 50.],\n","                        [19., 47., 48.]],\n","              \n","                       [[34., 26., 25.],\n","                        [40., 40., 33.],\n","                        [23., 29., 20.]],\n","              \n","                       [[38., 43., 43.],\n","                        [38., 45., 47.],\n","                        [22., 20., 17.]],\n","              \n","                       ...,\n","              \n","                       [[17., 26., 17.],\n","                        [32., 29., 19.],\n","                        [42., 41., 37.]],\n","              \n","                       [[29., 18., 21.],\n","                        [31., 11., 14.],\n","                        [44., 27., 22.]],\n","              \n","                       [[40., 47., 38.],\n","                        [36., 44., 36.],\n","                        [33., 38., 29.]]],\n","              \n","              \n","                      [[[40., 24.,  3.],\n","                        [48., 40., 20.],\n","                        [31., 35., 28.]],\n","              \n","                       [[19., 20., 29.],\n","                        [25., 39., 41.],\n","                        [25., 53., 52.]],\n","              \n","                       [[23., 51., 48.],\n","                        [33., 35., 21.],\n","                        [36., 25., 11.]],\n","              \n","                       ...,\n","              \n","                       [[49., 50., 44.],\n","                        [40., 30., 20.],\n","                        [16., 13.,  8.]],\n","              \n","                       [[25., 48., 40.],\n","                        [33., 25.,  9.],\n","                        [54., 38.,  9.]],\n","              \n","                       [[21., 27., 23.],\n","                        [ 8., 16., 12.],\n","                        [27., 32., 21.]]],\n","              \n","              \n","                      [[[33., 31., 19.],\n","                        [28., 42., 23.],\n","                        [33., 44., 30.]],\n","              \n","                       [[33., 26., 18.],\n","                        [35., 30., 25.],\n","                        [36., 31., 25.]],\n","              \n","                       [[21., 21., 23.],\n","                        [19., 10., 14.],\n","                        [18., 11., 14.]],\n","              \n","                       ...,\n","              \n","                       [[ 4.,  4.,  2.],\n","                        [19., 11., 15.],\n","                        [25., 17., 20.]],\n","              \n","                       [[15.,  6., 24.],\n","                        [17.,  6., 31.],\n","                        [20.,  6., 27.]],\n","              \n","                       [[15., 16., 22.],\n","                        [24., 14., 18.],\n","                        [33., 17., 12.]]]], device='cuda:0')),\n","             ('module.layer2.8.conv1.wrapped_module.bias',\n","              tensor([  2641.,   6271., -19037.,   1133.,   1867.,   2021.,   -913.,   1185.,\n","                       -2790.,   1644., -25813., -17290.,   2211.,  -2968.,  -4084.,    268.,\n","                       -2528.,   1926.,   1262.,   -110.,   1467.,   1236.,   -429.,   -272.,\n","                        1121.,    770.,    200.,  -1981.,  -5258.,  -3758.,    807.,    562.],\n","                     device='cuda:0')),\n","             ('module.layer2.8.conv2.num_forwards',\n","              tensor([40], device='cuda:0')),\n","             ('module.layer2.8.conv2.force_readjust',\n","              tensor(False, device='cuda:0')),\n","             ('module.layer2.8.conv2.output_scale',\n","              tensor([17.3886], device='cuda:0')),\n","             ('module.layer2.8.conv2.output_zero_point',\n","              tensor([-27.], device='cuda:0')),\n","             ('module.layer2.8.conv2.w_scale', tensor([[[[117.3369]]],\n","              \n","              \n","                      [[[157.2137]]],\n","              \n","              \n","                      [[[ 82.6524]]],\n","              \n","              \n","                      [[[172.4266]]],\n","              \n","              \n","                      [[[ 94.3553]]],\n","              \n","              \n","                      [[[ 84.5767]]],\n","              \n","              \n","                      [[[ 72.4292]]],\n","              \n","              \n","                      [[[ 61.7430]]],\n","              \n","              \n","                      [[[ 68.6924]]],\n","              \n","              \n","                      [[[774.9667]]],\n","              \n","              \n","                      [[[ 97.0781]]],\n","              \n","              \n","                      [[[139.1402]]],\n","              \n","              \n","                      [[[108.5570]]],\n","              \n","              \n","                      [[[220.6399]]],\n","              \n","              \n","                      [[[ 96.0380]]],\n","              \n","              \n","                      [[[172.0067]]],\n","              \n","              \n","                      [[[218.6375]]],\n","              \n","              \n","                      [[[361.4660]]],\n","              \n","              \n","                      [[[ 60.7355]]],\n","              \n","              \n","                      [[[ 63.2904]]],\n","              \n","              \n","                      [[[ 43.7529]]],\n","              \n","              \n","                      [[[160.4833]]],\n","              \n","              \n","                      [[[ 79.5969]]],\n","              \n","              \n","                      [[[144.1982]]],\n","              \n","              \n","                      [[[144.1137]]],\n","              \n","              \n","                      [[[101.6086]]],\n","              \n","              \n","                      [[[ 81.4275]]],\n","              \n","              \n","                      [[[115.6586]]],\n","              \n","              \n","                      [[[188.3905]]],\n","              \n","              \n","                      [[[134.6227]]],\n","              \n","              \n","                      [[[119.8478]]],\n","              \n","              \n","                      [[[ 56.9548]]]], device='cuda:0')),\n","             ('module.layer2.8.conv2.w_zero_point', tensor([[[[-23.]]],\n","              \n","              \n","                      [[[-34.]]],\n","              \n","              \n","                      [[[-26.]]],\n","              \n","              \n","                      [[[-32.]]],\n","              \n","              \n","                      [[[-27.]]],\n","              \n","              \n","                      [[[-29.]]],\n","              \n","              \n","                      [[[-23.]]],\n","              \n","              \n","                      [[[-26.]]],\n","              \n","              \n","                      [[[-33.]]],\n","              \n","              \n","                      [[[-20.]]],\n","              \n","              \n","                      [[[-30.]]],\n","              \n","              \n","                      [[[-31.]]],\n","              \n","              \n","                      [[[-38.]]],\n","              \n","              \n","                      [[[-41.]]],\n","              \n","              \n","                      [[[-39.]]],\n","              \n","              \n","                      [[[-38.]]],\n","              \n","              \n","                      [[[-34.]]],\n","              \n","              \n","                      [[[-29.]]],\n","              \n","              \n","                      [[[-26.]]],\n","              \n","              \n","                      [[[-22.]]],\n","              \n","              \n","                      [[[-33.]]],\n","              \n","              \n","                      [[[-31.]]],\n","              \n","              \n","                      [[[-32.]]],\n","              \n","              \n","                      [[[-24.]]],\n","              \n","              \n","                      [[[-35.]]],\n","              \n","              \n","                      [[[-35.]]],\n","              \n","              \n","                      [[[-37.]]],\n","              \n","              \n","                      [[[-29.]]],\n","              \n","              \n","                      [[[-30.]]],\n","              \n","              \n","                      [[[-28.]]],\n","              \n","              \n","                      [[[-31.]]],\n","              \n","              \n","                      [[[-26.]]]], device='cuda:0')),\n","             ('module.layer2.8.conv2.fp_bias',\n","              tensor([-0.1355,  0.0399, -0.0077,  0.0819,  0.0535,  0.0909, -0.1797, -0.0798,\n","                       0.2253,  0.0063, -0.0349,  0.1800,  0.1691,  0.0383,  0.2159,  0.0548,\n","                       0.0935,  0.0583, -0.1207, -0.2450, -0.1043,  0.0907,  0.0173, -0.0114,\n","                       0.1104,  0.1016,  0.4128, -0.2306,  0.0059, -0.0403,  0.0176, -0.1674],\n","                     device='cuda:0')),\n","             ('module.layer2.8.conv2.accum_scale', tensor([[[ 6029.6621]],\n","              \n","                      [[ 8078.8330]],\n","              \n","                      [[ 4247.3057]],\n","              \n","                      [[ 8860.5879]],\n","              \n","                      [[ 4848.6895]],\n","              \n","                      [[ 4346.1909]],\n","              \n","                      [[ 3721.9597]],\n","              \n","                      [[ 3172.8228]],\n","              \n","                      [[ 3529.9346]],\n","              \n","                      [[39823.6680]],\n","              \n","                      [[ 4988.6089]],\n","              \n","                      [[ 7150.0771]],\n","              \n","                      [[ 5578.4819]],\n","              \n","                      [[11338.1514]],\n","              \n","                      [[ 4935.1611]],\n","              \n","                      [[ 8839.0068]],\n","              \n","                      [[11235.2520]],\n","              \n","                      [[18574.8633]],\n","              \n","                      [[ 3121.0505]],\n","              \n","                      [[ 3252.3398]],\n","              \n","                      [[ 2248.3582]],\n","              \n","                      [[ 8246.8496]],\n","              \n","                      [[ 4090.2937]],\n","              \n","                      [[ 7409.9956]],\n","              \n","                      [[ 7405.6553]],\n","              \n","                      [[ 5221.4229]],\n","              \n","                      [[ 4184.3608]],\n","              \n","                      [[ 5943.4146]],\n","              \n","                      [[ 9680.9346]],\n","              \n","                      [[ 6917.9360]],\n","              \n","                      [[ 6158.6880]],\n","              \n","                      [[ 2926.7688]]], device='cuda:0')),\n","             ('module.layer2.8.conv2.is_simulated_quant_weight_shifted',\n","              tensor(False, device='cuda:0')),\n","             ('module.layer2.8.conv2.wrapped_module.weight',\n","              tensor([[[[28., 29., 30.],\n","                        [33., 37., 34.],\n","                        [41., 46., 31.]],\n","              \n","                       [[17., 19., 17.],\n","                        [ 7., 12., 15.],\n","                        [ 7., 13., 11.]],\n","              \n","                       [[23., 22., 20.],\n","                        [24., 24., 23.],\n","                        [23., 25., 24.]],\n","              \n","                       ...,\n","              \n","                       [[34., 34., 31.],\n","                        [30., 34., 31.],\n","                        [26., 23., 24.]],\n","              \n","                       [[ 3., 35., 56.],\n","                        [ 7., 38., 52.],\n","                        [16., 28., 32.]],\n","              \n","                       [[38., 31., 38.],\n","                        [37., 25., 32.],\n","                        [42., 36., 38.]]],\n","              \n","              \n","                      [[[35., 41., 29.],\n","                        [21., 32., 30.],\n","                        [25., 36., 47.]],\n","              \n","                       [[34., 28., 30.],\n","                        [ 8.,  0.,  7.],\n","                        [20., 14., 24.]],\n","              \n","                       [[31., 32., 34.],\n","                        [32., 34., 35.],\n","                        [34., 36., 35.]],\n","              \n","                       ...,\n","              \n","                       [[29., 31., 30.],\n","                        [30., 31., 35.],\n","                        [23., 27., 31.]],\n","              \n","                       [[31., 29., 30.],\n","                        [20., 25., 21.],\n","                        [48., 34., 30.]],\n","              \n","                       [[24., 21., 33.],\n","                        [34., 25., 35.],\n","                        [31., 24., 32.]]],\n","              \n","              \n","                      [[[ 8., 12., 24.],\n","                        [ 6., 14., 21.],\n","                        [13.,  1., 10.]],\n","              \n","                       [[33., 38., 46.],\n","                        [46., 55., 63.],\n","                        [42., 52., 60.]],\n","              \n","                       [[26., 27., 27.],\n","                        [27., 27., 27.],\n","                        [26., 26., 26.]],\n","              \n","                       ...,\n","              \n","                       [[32., 26., 18.],\n","                        [34., 32., 27.],\n","                        [37., 35., 31.]],\n","              \n","                       [[15., 28., 33.],\n","                        [23., 36., 27.],\n","                        [32., 37., 34.]],\n","              \n","                       [[ 7.,  2., 24.],\n","                        [14., 12., 27.],\n","                        [13., 18., 31.]]],\n","              \n","              \n","                      ...,\n","              \n","              \n","                      [[[15., 21., 37.],\n","                        [ 8., 30., 32.],\n","                        [30., 33., 35.]],\n","              \n","                       [[28., 36., 29.],\n","                        [41., 47., 37.],\n","                        [37., 41., 25.]],\n","              \n","                       [[28., 29., 29.],\n","                        [28., 29., 29.],\n","                        [28., 28., 28.]],\n","              \n","                       ...,\n","              \n","                       [[23., 20., 25.],\n","                        [25., 22., 23.],\n","                        [21., 16., 16.]],\n","              \n","                       [[25., 16., 18.],\n","                        [42., 46., 34.],\n","                        [19., 26., 21.]],\n","              \n","                       [[44., 48., 34.],\n","                        [32., 47., 22.],\n","                        [23., 40., 11.]]],\n","              \n","              \n","                      [[[38., 38., 41.],\n","                        [33., 24., 31.],\n","                        [37., 31., 40.]],\n","              \n","                       [[13., 17., 46.],\n","                        [32., 33., 63.],\n","                        [30., 31., 61.]],\n","              \n","                       [[30., 31., 30.],\n","                        [30., 31., 30.],\n","                        [29., 29., 30.]],\n","              \n","                       ...,\n","              \n","                       [[33., 32., 28.],\n","                        [28., 29., 30.],\n","                        [20., 22., 23.]],\n","              \n","                       [[24., 39., 44.],\n","                        [21., 38., 43.],\n","                        [25., 36., 36.]],\n","              \n","                       [[38., 37., 27.],\n","                        [41., 41., 31.],\n","                        [32., 32., 20.]]],\n","              \n","              \n","                      [[[13.,  6.,  6.],\n","                        [28., 37., 46.],\n","                        [26., 39., 63.]],\n","              \n","                       [[26., 27., 25.],\n","                        [22., 16.,  9.],\n","                        [27., 17., 11.]],\n","              \n","                       [[26., 26., 26.],\n","                        [27., 26., 25.],\n","                        [26., 26., 25.]],\n","              \n","                       ...,\n","              \n","                       [[22., 25., 26.],\n","                        [24., 33., 32.],\n","                        [33., 33., 32.]],\n","              \n","                       [[16., 13., 12.],\n","                        [25., 25., 19.],\n","                        [39., 41., 21.]],\n","              \n","                       [[17., 23., 36.],\n","                        [14., 21., 32.],\n","                        [18., 26., 37.]]]], device='cuda:0')),\n","             ('module.layer2.8.conv2.wrapped_module.bias',\n","              tensor([ -817.,   322.,   -33.,   726.,   259.,   395.,  -669.,  -253.,   795.,\n","                        249.,  -174.,  1287.,   943.,   434.,  1065.,   485.,  1050.,  1083.,\n","                       -377.,  -797.,  -234.,   748.,    71.,   -85.,   818.,   530.,  1727.,\n","                      -1370.,    57.,  -279.,   108.,  -490.], device='cuda:0')),\n","             ('module.layer2.8.relu2.num_forwards',\n","              tensor([40], device='cuda:0')),\n","             ('module.layer2.8.relu2.force_readjust',\n","              tensor(False, device='cuda:0')),\n","             ('module.layer2.8.relu2.output_scale',\n","              tensor([6.5951], device='cuda:0')),\n","             ('module.layer2.8.relu2.output_zero_point',\n","              tensor([0.], device='cuda:0')),\n","             ('module.layer2.8.residual_eltwiseadd.num_forwards',\n","              tensor([40], device='cuda:0')),\n","             ('module.layer2.8.residual_eltwiseadd.force_readjust',\n","              tensor(False, device='cuda:0')),\n","             ('module.layer2.8.residual_eltwiseadd.output_scale',\n","              tensor([6.5951], device='cuda:0')),\n","             ('module.layer2.8.residual_eltwiseadd.output_zero_point',\n","              tensor([0.], device='cuda:0')),\n","             ('module.layer3.0.conv1.num_forwards',\n","              tensor([40], device='cuda:0')),\n","             ('module.layer3.0.conv1.force_readjust',\n","              tensor(False, device='cuda:0')),\n","             ('module.layer3.0.conv1.output_scale',\n","              tensor([23.3770], device='cuda:0')),\n","             ('module.layer3.0.conv1.output_zero_point',\n","              tensor([0.], device='cuda:0')),\n","             ('module.layer3.0.conv1.w_scale', tensor([[[[ 699.9203]]],\n","              \n","              \n","                      [[[ 831.1611]]],\n","              \n","              \n","                      [[[ 695.5723]]],\n","              \n","              \n","                      [[[ 587.4841]]],\n","              \n","              \n","                      [[[ 976.9715]]],\n","              \n","              \n","                      [[[ 555.4624]]],\n","              \n","              \n","                      [[[ 638.7562]]],\n","              \n","              \n","                      [[[ 732.4150]]],\n","              \n","              \n","                      [[[ 665.1956]]],\n","              \n","              \n","                      [[[1098.7120]]],\n","              \n","              \n","                      [[[ 785.9230]]],\n","              \n","              \n","                      [[[ 803.7724]]],\n","              \n","              \n","                      [[[ 631.2800]]],\n","              \n","              \n","                      [[[ 658.0287]]],\n","              \n","              \n","                      [[[ 582.5446]]],\n","              \n","              \n","                      [[[ 766.8358]]],\n","              \n","              \n","                      [[[ 774.2557]]],\n","              \n","              \n","                      [[[ 697.5840]]],\n","              \n","              \n","                      [[[1054.7063]]],\n","              \n","              \n","                      [[[ 660.7313]]],\n","              \n","              \n","                      [[[ 688.4863]]],\n","              \n","              \n","                      [[[ 625.9828]]],\n","              \n","              \n","                      [[[ 934.6357]]],\n","              \n","              \n","                      [[[ 709.0969]]],\n","              \n","              \n","                      [[[ 653.1683]]],\n","              \n","              \n","                      [[[ 903.4999]]],\n","              \n","              \n","                      [[[ 652.2180]]],\n","              \n","              \n","                      [[[ 522.1473]]],\n","              \n","              \n","                      [[[ 662.7170]]],\n","              \n","              \n","                      [[[ 809.6307]]],\n","              \n","              \n","                      [[[ 588.1210]]],\n","              \n","              \n","                      [[[ 807.3434]]],\n","              \n","              \n","                      [[[ 908.0031]]],\n","              \n","              \n","                      [[[ 638.1561]]],\n","              \n","              \n","                      [[[ 551.0894]]],\n","              \n","              \n","                      [[[ 759.9155]]],\n","              \n","              \n","                      [[[ 761.4387]]],\n","              \n","              \n","                      [[[ 741.1787]]],\n","              \n","              \n","                      [[[ 737.3540]]],\n","              \n","              \n","                      [[[ 791.9219]]],\n","              \n","              \n","                      [[[ 671.0999]]],\n","              \n","              \n","                      [[[ 943.1161]]],\n","              \n","              \n","                      [[[ 734.3787]]],\n","              \n","              \n","                      [[[ 601.4748]]],\n","              \n","              \n","                      [[[ 729.8494]]],\n","              \n","              \n","                      [[[ 618.0461]]],\n","              \n","              \n","                      [[[ 849.9097]]],\n","              \n","              \n","                      [[[ 692.0677]]],\n","              \n","              \n","                      [[[ 685.5725]]],\n","              \n","              \n","                      [[[ 818.8338]]],\n","              \n","              \n","                      [[[ 518.0534]]],\n","              \n","              \n","                      [[[ 676.8929]]],\n","              \n","              \n","                      [[[ 696.5886]]],\n","              \n","              \n","                      [[[ 731.2048]]],\n","              \n","              \n","                      [[[ 628.2000]]],\n","              \n","              \n","                      [[[ 720.9923]]],\n","              \n","              \n","                      [[[ 612.5234]]],\n","              \n","              \n","                      [[[ 661.2119]]],\n","              \n","              \n","                      [[[ 597.9496]]],\n","              \n","              \n","                      [[[ 765.2299]]],\n","              \n","              \n","                      [[[ 686.8361]]],\n","              \n","              \n","                      [[[ 636.0511]]],\n","              \n","              \n","                      [[[ 639.9579]]],\n","              \n","              \n","                      [[[ 463.7852]]]], device='cuda:0')),\n","             ('module.layer3.0.conv1.w_zero_point', tensor([[[[-26.]]],\n","              \n","              \n","                      [[[-34.]]],\n","              \n","              \n","                      [[[-27.]]],\n","              \n","              \n","                      [[[-26.]]],\n","              \n","              \n","                      [[[-28.]]],\n","              \n","              \n","                      [[[-33.]]],\n","              \n","              \n","                      [[[-26.]]],\n","              \n","              \n","                      [[[-31.]]],\n","              \n","              \n","                      [[[-22.]]],\n","              \n","              \n","                      [[[-29.]]],\n","              \n","              \n","                      [[[-38.]]],\n","              \n","              \n","                      [[[-28.]]],\n","              \n","              \n","                      [[[-30.]]],\n","              \n","              \n","                      [[[-26.]]],\n","              \n","              \n","                      [[[-28.]]],\n","              \n","              \n","                      [[[-32.]]],\n","              \n","              \n","                      [[[-28.]]],\n","              \n","              \n","                      [[[-26.]]],\n","              \n","              \n","                      [[[-23.]]],\n","              \n","              \n","                      [[[-27.]]],\n","              \n","              \n","                      [[[-31.]]],\n","              \n","              \n","                      [[[-24.]]],\n","              \n","              \n","                      [[[-35.]]],\n","              \n","              \n","                      [[[-31.]]],\n","              \n","              \n","                      [[[-26.]]],\n","              \n","              \n","                      [[[-28.]]],\n","              \n","              \n","                      [[[-29.]]],\n","              \n","              \n","                      [[[-22.]]],\n","              \n","              \n","                      [[[-34.]]],\n","              \n","              \n","                      [[[-26.]]],\n","              \n","              \n","                      [[[-25.]]],\n","              \n","              \n","                      [[[-25.]]],\n","              \n","              \n","                      [[[-28.]]],\n","              \n","              \n","                      [[[-29.]]],\n","              \n","              \n","                      [[[-23.]]],\n","              \n","              \n","                      [[[-29.]]],\n","              \n","              \n","                      [[[-33.]]],\n","              \n","              \n","                      [[[-32.]]],\n","              \n","              \n","                      [[[-33.]]],\n","              \n","              \n","                      [[[-32.]]],\n","              \n","              \n","                      [[[-33.]]],\n","              \n","              \n","                      [[[-27.]]],\n","              \n","              \n","                      [[[-26.]]],\n","              \n","              \n","                      [[[-30.]]],\n","              \n","              \n","                      [[[-25.]]],\n","              \n","              \n","                      [[[-29.]]],\n","              \n","              \n","                      [[[-25.]]],\n","              \n","              \n","                      [[[-27.]]],\n","              \n","              \n","                      [[[-36.]]],\n","              \n","              \n","                      [[[-40.]]],\n","              \n","              \n","                      [[[-24.]]],\n","              \n","              \n","                      [[[-27.]]],\n","              \n","              \n","                      [[[-34.]]],\n","              \n","              \n","                      [[[-26.]]],\n","              \n","              \n","                      [[[-31.]]],\n","              \n","              \n","                      [[[-28.]]],\n","              \n","              \n","                      [[[-30.]]],\n","              \n","              \n","                      [[[-31.]]],\n","              \n","              \n","                      [[[-27.]]],\n","              \n","              \n","                      [[[-24.]]],\n","              \n","              \n","                      [[[-28.]]],\n","              \n","              \n","                      [[[-32.]]],\n","              \n","              \n","                      [[[-28.]]],\n","              \n","              \n","                      [[[-19.]]]], device='cuda:0')),\n","             ('module.layer3.0.conv1.fp_bias',\n","              tensor([-1.3087,  0.3994,  0.4704, -0.0452,  0.7907, -0.3001, -0.7177, -0.0298,\n","                      -0.2321,  0.4260,  0.4874, -0.4519, -0.4781, -0.0421,  0.4106,  0.3920,\n","                      -0.9714, -0.1606, -0.6796,  0.1034,  0.4163, -0.0852,  0.9711,  0.2611,\n","                      -0.0993, -0.4703,  0.0657, -1.4273,  0.7409, -1.1488, -0.2981,  0.0588,\n","                      -0.6838,  0.0937, -0.2530,  0.6801,  0.8123, -0.0049,  0.5316, -0.7827,\n","                      -0.2588, -0.1922, -0.7491, -0.2128,  0.6914,  0.4302,  0.2299,  0.5350,\n","                       0.9258,  0.7856, -0.8005, -0.1179, -0.3720, -0.3614, -0.2464, -0.3836,\n","                       0.6962,  0.1610, -0.2807, -0.4706,  0.2289,  1.7385,  0.3865, -0.4275],\n","                     device='cuda:0')),\n","             ('module.layer3.0.conv1.accum_scale', tensor([[[4616.0142]],\n","              \n","                      [[5481.5547]],\n","              \n","                      [[4587.3389]],\n","              \n","                      [[3874.4910]],\n","              \n","                      [[6443.1821]],\n","              \n","                      [[3663.3059]],\n","              \n","                      [[4212.6333]],\n","              \n","                      [[4830.3184]],\n","              \n","                      [[4387.0024]],\n","              \n","                      [[7246.0679]],\n","              \n","                      [[5183.2065]],\n","              \n","                      [[5300.9243]],\n","              \n","                      [[4163.3271]],\n","              \n","                      [[4339.7363]],\n","              \n","                      [[3841.9148]],\n","              \n","                      [[5057.3257]],\n","              \n","                      [[5106.2598]],\n","              \n","                      [[4600.6060]],\n","              \n","                      [[6955.8477]],\n","              \n","                      [[4357.5605]],\n","              \n","                      [[4540.6064]],\n","              \n","                      [[4128.3921]],\n","              \n","                      [[6163.9756]],\n","              \n","                      [[4676.5342]],\n","              \n","                      [[4307.6821]],\n","              \n","                      [[5958.6333]],\n","              \n","                      [[4301.4146]],\n","              \n","                      [[3443.5913]],\n","              \n","                      [[4370.6558]],\n","              \n","                      [[5339.5605]],\n","              \n","                      [[3878.6912]],\n","              \n","                      [[5324.4751]],\n","              \n","                      [[5988.3320]],\n","              \n","                      [[4208.6753]],\n","              \n","                      [[3634.4658]],\n","              \n","                      [[5011.6860]],\n","              \n","                      [[5021.7310]],\n","              \n","                      [[4888.1157]],\n","              \n","                      [[4862.8911]],\n","              \n","                      [[5222.7700]],\n","              \n","                      [[4425.9414]],\n","              \n","                      [[6219.9038]],\n","              \n","                      [[4843.2686]],\n","              \n","                      [[3966.7603]],\n","              \n","                      [[4813.3984]],\n","              \n","                      [[4076.0493]],\n","              \n","                      [[5605.2021]],\n","              \n","                      [[4564.2256]],\n","              \n","                      [[4521.3896]],\n","              \n","                      [[5400.2554]],\n","              \n","                      [[3416.5916]],\n","              \n","                      [[4464.1470]],\n","              \n","                      [[4594.0410]],\n","              \n","                      [[4822.3369]],\n","              \n","                      [[4143.0142]],\n","              \n","                      [[4754.9849]],\n","              \n","                      [[4039.6262]],\n","              \n","                      [[4360.7300]],\n","              \n","                      [[3943.5117]],\n","              \n","                      [[5046.7344]],\n","              \n","                      [[4529.7227]],\n","              \n","                      [[4194.7935]],\n","              \n","                      [[4220.5591]],\n","              \n","                      [[3058.6899]]], device='cuda:0')),\n","             ('module.layer3.0.conv1.is_simulated_quant_weight_shifted',\n","              tensor(False, device='cuda:0')),\n","             ('module.layer3.0.conv1.wrapped_module.weight',\n","              tensor([[[[29., 18., 17.],\n","                        [28., 23., 20.],\n","                        [30., 31., 19.]],\n","              \n","                       [[32., 30., 28.],\n","                        [38., 32., 28.],\n","                        [36., 43., 36.]],\n","              \n","                       [[33., 37., 38.],\n","                        [32., 35., 33.],\n","                        [30., 33., 28.]],\n","              \n","                       ...,\n","              \n","                       [[18., 38., 39.],\n","                        [36., 34., 42.],\n","                        [42., 39., 33.]],\n","              \n","                       [[13., 37., 38.],\n","                        [19., 19., 21.],\n","                        [17.,  0., 11.]],\n","              \n","                       [[33., 33., 36.],\n","                        [37., 32., 37.],\n","                        [24., 18., 26.]]],\n","              \n","              \n","                      [[[19., 19., 17.],\n","                        [32., 28., 39.],\n","                        [33., 31., 43.]],\n","              \n","                       [[32., 31., 32.],\n","                        [26., 27., 31.],\n","                        [41., 41., 41.]],\n","              \n","                       [[29., 39., 34.],\n","                        [34., 33., 27.],\n","                        [30., 32., 30.]],\n","              \n","                       ...,\n","              \n","                       [[42., 42., 46.],\n","                        [50., 51., 46.],\n","                        [45., 48., 38.]],\n","              \n","                       [[40., 37., 35.],\n","                        [24., 27., 16.],\n","                        [33., 19., 28.]],\n","              \n","                       [[ 2., 16., 10.],\n","                        [12., 23., 18.],\n","                        [21., 25., 20.]]],\n","              \n","              \n","                      [[[22., 19., 22.],\n","                        [28., 26., 37.],\n","                        [28., 34., 33.]],\n","              \n","                       [[34., 18.,  7.],\n","                        [31., 16., 18.],\n","                        [39., 33., 43.]],\n","              \n","                       [[33., 20., 17.],\n","                        [20., 16., 18.],\n","                        [30., 23., 29.]],\n","              \n","                       ...,\n","              \n","                       [[33., 47., 37.],\n","                        [32., 37., 30.],\n","                        [28., 27., 24.]],\n","              \n","                       [[ 8.,  9., 16.],\n","                        [21., 27., 23.],\n","                        [32., 32., 40.]],\n","              \n","                       [[23., 33., 25.],\n","                        [16., 12., 21.],\n","                        [13., 18., 19.]]],\n","              \n","              \n","                      ...,\n","              \n","              \n","                      [[[39., 39., 47.],\n","                        [47., 32., 33.],\n","                        [42., 32., 27.]],\n","              \n","                       [[24., 22., 31.],\n","                        [26., 20., 33.],\n","                        [27., 16., 29.]],\n","              \n","                       [[37., 37., 33.],\n","                        [38., 32., 26.],\n","                        [37., 32., 26.]],\n","              \n","                       ...,\n","              \n","                       [[36., 35., 42.],\n","                        [32., 37., 29.],\n","                        [31., 32., 31.]],\n","              \n","                       [[42., 28., 22.],\n","                        [44., 34., 17.],\n","                        [48., 35., 23.]],\n","              \n","                       [[44., 34., 27.],\n","                        [36., 34., 22.],\n","                        [37., 36., 28.]]],\n","              \n","              \n","                      [[[14., 15., 16.],\n","                        [19., 23., 49.],\n","                        [28., 49., 55.]],\n","              \n","                       [[36., 23., 22.],\n","                        [37., 23., 24.],\n","                        [32., 11., 13.]],\n","              \n","                       [[ 8.,  5., 14.],\n","                        [ 6., 13., 11.],\n","                        [25., 15., 24.]],\n","              \n","                       ...,\n","              \n","                       [[22., 18., 22.],\n","                        [25., 13., 27.],\n","                        [33., 29., 35.]],\n","              \n","                       [[12., 16., 13.],\n","                        [32., 38., 39.],\n","                        [39., 53., 52.]],\n","              \n","                       [[40., 30., 34.],\n","                        [32., 29., 31.],\n","                        [27., 21., 28.]]],\n","              \n","              \n","                      [[[17., 23., 25.],\n","                        [27., 26., 25.],\n","                        [26., 28., 19.]],\n","              \n","                       [[ 8.,  9., 17.],\n","                        [20., 19., 22.],\n","                        [28., 29., 36.]],\n","              \n","                       [[37., 34., 32.],\n","                        [19., 17., 17.],\n","                        [11.,  7.,  9.]],\n","              \n","                       ...,\n","              \n","                       [[18., 13., 16.],\n","                        [14., 15., 15.],\n","                        [12., 17., 21.]],\n","              \n","                       [[18., 29., 27.],\n","                        [22., 22., 21.],\n","                        [22., 23., 18.]],\n","              \n","                       [[21., 22., 11.],\n","                        [27., 20., 15.],\n","                        [25., 15., 12.]]]], device='cuda:0')),\n","             ('module.layer3.0.conv1.wrapped_module.bias',\n","              tensor([-6041.,  2190.,  2158.,  -175.,  5095., -1099., -3023.,  -144., -1018.,\n","                       3087.,  2526., -2396., -1991.,  -183.,  1577.,  1983., -4960.,  -739.,\n","                      -4727.,   450.,  1890.,  -352.,  5986.,  1221.,  -428., -2802.,   282.,\n","                      -4915.,  3238., -6134., -1156.,   313., -4095.,   394.,  -920.,  3408.,\n","                       4079.,   -24.,  2585., -4088., -1145., -1195., -3628.,  -844.,  3328.,\n","                       1753.,  1288.,  2442.,  4186.,  4242., -2735.,  -526., -1709., -1743.,\n","                      -1021., -1824.,  2812.,   702., -1107., -2375.,  1037.,  7292.,  1631.,\n","                      -1308.], device='cuda:0')),\n","             ('module.layer3.0.conv2.num_forwards',\n","              tensor([40], device='cuda:0')),\n","             ('module.layer3.0.conv2.force_readjust',\n","              tensor(False, device='cuda:0')),\n","             ('module.layer3.0.conv2.output_scale',\n","              tensor([7.2768], device='cuda:0')),\n","             ('module.layer3.0.conv2.output_zero_point',\n","              tensor([-25.], device='cuda:0')),\n","             ('module.layer3.0.conv2.w_scale', tensor([[[[1.0261e+02]]],\n","              \n","              \n","                      [[[9.9004e+01]]],\n","              \n","              \n","                      [[[1.7155e+02]]],\n","              \n","              \n","                      [[[1.2436e+02]]],\n","              \n","              \n","                      [[[1.0701e+02]]],\n","              \n","              \n","                      [[[1.4740e+02]]],\n","              \n","              \n","                      [[[1.6092e+02]]],\n","              \n","              \n","                      [[[2.0237e+06]]],\n","              \n","              \n","                      [[[9.4414e+01]]],\n","              \n","              \n","                      [[[1.3352e+06]]],\n","              \n","              \n","                      [[[1.5874e+02]]],\n","              \n","              \n","                      [[[9.4438e+01]]],\n","              \n","              \n","                      [[[1.2554e+02]]],\n","              \n","              \n","                      [[[8.7795e+01]]],\n","              \n","              \n","                      [[[1.5198e+02]]],\n","              \n","              \n","                      [[[1.0490e+02]]],\n","              \n","              \n","                      [[[1.3790e+02]]],\n","              \n","              \n","                      [[[1.1181e+02]]],\n","              \n","              \n","                      [[[1.1730e+02]]],\n","              \n","              \n","                      [[[1.1878e+02]]],\n","              \n","              \n","                      [[[9.4013e+01]]],\n","              \n","              \n","                      [[[1.4449e+02]]],\n","              \n","              \n","                      [[[1.3666e+02]]],\n","              \n","              \n","                      [[[1.4581e+02]]],\n","              \n","              \n","                      [[[1.8217e+02]]],\n","              \n","              \n","                      [[[2.3470e+02]]],\n","              \n","              \n","                      [[[1.3412e+02]]],\n","              \n","              \n","                      [[[1.4548e+02]]],\n","              \n","              \n","                      [[[1.2769e+02]]],\n","              \n","              \n","                      [[[1.2188e+02]]],\n","              \n","              \n","                      [[[1.1303e+02]]],\n","              \n","              \n","                      [[[1.4731e+02]]],\n","              \n","              \n","                      [[[1.1695e+02]]],\n","              \n","              \n","                      [[[1.4001e+02]]],\n","              \n","              \n","                      [[[1.6151e+02]]],\n","              \n","              \n","                      [[[9.6631e+01]]],\n","              \n","              \n","                      [[[1.1009e+02]]],\n","              \n","              \n","                      [[[1.5575e+02]]],\n","              \n","              \n","                      [[[1.0969e+02]]],\n","              \n","              \n","                      [[[1.1761e+02]]],\n","              \n","              \n","                      [[[1.4497e+02]]],\n","              \n","              \n","                      [[[1.1769e+02]]],\n","              \n","              \n","                      [[[1.0430e+02]]],\n","              \n","              \n","                      [[[1.3751e+02]]],\n","              \n","              \n","                      [[[2.6877e+05]]],\n","              \n","              \n","                      [[[1.3344e+02]]],\n","              \n","              \n","                      [[[2.2294e+05]]],\n","              \n","              \n","                      [[[2.3537e+05]]],\n","              \n","              \n","                      [[[1.0859e+02]]],\n","              \n","              \n","                      [[[6.7059e+05]]],\n","              \n","              \n","                      [[[1.4087e+02]]],\n","              \n","              \n","                      [[[4.2464e+05]]],\n","              \n","              \n","                      [[[1.4809e+02]]],\n","              \n","              \n","                      [[[1.3929e+02]]],\n","              \n","              \n","                      [[[8.4695e+05]]],\n","              \n","              \n","                      [[[1.2095e+02]]],\n","              \n","              \n","                      [[[3.0836e+02]]],\n","              \n","              \n","                      [[[1.2997e+02]]],\n","              \n","              \n","                      [[[1.0451e+02]]],\n","              \n","              \n","                      [[[1.3231e+02]]],\n","              \n","              \n","                      [[[1.1682e+02]]],\n","              \n","              \n","                      [[[5.1268e+05]]],\n","              \n","              \n","                      [[[1.2640e+02]]],\n","              \n","              \n","                      [[[1.1699e+02]]]], device='cuda:0')),\n","             ('module.layer3.0.conv2.w_zero_point', tensor([[[[-26.]]],\n","              \n","              \n","                      [[[-24.]]],\n","              \n","              \n","                      [[[-31.]]],\n","              \n","              \n","                      [[[-25.]]],\n","              \n","              \n","                      [[[-23.]]],\n","              \n","              \n","                      [[[-31.]]],\n","              \n","              \n","                      [[[-27.]]],\n","              \n","              \n","                      [[[-28.]]],\n","              \n","              \n","                      [[[-22.]]],\n","              \n","              \n","                      [[[-23.]]],\n","              \n","              \n","                      [[[-25.]]],\n","              \n","              \n","                      [[[-21.]]],\n","              \n","              \n","                      [[[-25.]]],\n","              \n","              \n","                      [[[-26.]]],\n","              \n","              \n","                      [[[-25.]]],\n","              \n","              \n","                      [[[-31.]]],\n","              \n","              \n","                      [[[-32.]]],\n","              \n","              \n","                      [[[-25.]]],\n","              \n","              \n","                      [[[-30.]]],\n","              \n","              \n","                      [[[-31.]]],\n","              \n","              \n","                      [[[-27.]]],\n","              \n","              \n","                      [[[-22.]]],\n","              \n","              \n","                      [[[-29.]]],\n","              \n","              \n","                      [[[-31.]]],\n","              \n","              \n","                      [[[-39.]]],\n","              \n","              \n","                      [[[-32.]]],\n","              \n","              \n","                      [[[-31.]]],\n","              \n","              \n","                      [[[-27.]]],\n","              \n","              \n","                      [[[-26.]]],\n","              \n","              \n","                      [[[-31.]]],\n","              \n","              \n","                      [[[-26.]]],\n","              \n","              \n","                      [[[-31.]]],\n","              \n","              \n","                      [[[-34.]]],\n","              \n","              \n","                      [[[-31.]]],\n","              \n","              \n","                      [[[-32.]]],\n","              \n","              \n","                      [[[-23.]]],\n","              \n","              \n","                      [[[-27.]]],\n","              \n","              \n","                      [[[-33.]]],\n","              \n","              \n","                      [[[-28.]]],\n","              \n","              \n","                      [[[-30.]]],\n","              \n","              \n","                      [[[-28.]]],\n","              \n","              \n","                      [[[-25.]]],\n","              \n","              \n","                      [[[-28.]]],\n","              \n","              \n","                      [[[-29.]]],\n","              \n","              \n","                      [[[-24.]]],\n","              \n","              \n","                      [[[-29.]]],\n","              \n","              \n","                      [[[-36.]]],\n","              \n","              \n","                      [[[-40.]]],\n","              \n","              \n","                      [[[-30.]]],\n","              \n","              \n","                      [[[-28.]]],\n","              \n","              \n","                      [[[-32.]]],\n","              \n","              \n","                      [[[-24.]]],\n","              \n","              \n","                      [[[-30.]]],\n","              \n","              \n","                      [[[-24.]]],\n","              \n","              \n","                      [[[-19.]]],\n","              \n","              \n","                      [[[-31.]]],\n","              \n","              \n","                      [[[-28.]]],\n","              \n","              \n","                      [[[-25.]]],\n","              \n","              \n","                      [[[-29.]]],\n","              \n","              \n","                      [[[-26.]]],\n","              \n","              \n","                      [[[-24.]]],\n","              \n","              \n","                      [[[-24.]]],\n","              \n","              \n","                      [[[-22.]]],\n","              \n","              \n","                      [[[-22.]]]], device='cuda:0')),\n","             ('module.layer3.0.conv2.fp_bias',\n","              tensor([ 4.8027e-01, -9.3377e-02,  3.6498e-01,  4.8065e-01,  1.2731e-01,\n","                      -1.1368e-01,  2.6372e-02, -2.4309e-03,  6.3337e-01, -1.8282e-03,\n","                       1.3937e-01, -2.0918e-02,  3.3177e-01, -6.1819e-02, -2.0890e-01,\n","                       9.2682e-02,  7.7287e-01, -1.0127e-01,  6.5857e-02,  5.2935e-01,\n","                      -5.5540e-01,  3.4520e-01, -2.2132e-01, -2.5901e-01,  1.6120e+00,\n","                       8.3786e-01,  7.0218e-01,  3.2578e-01, -1.2312e-01,  6.9355e-01,\n","                      -1.0356e-01,  4.2654e-01,  3.6808e-01, -1.8496e-01,  3.4523e-01,\n","                       3.4904e-02,  3.4002e-01,  6.5843e-01,  8.0904e-02, -6.3028e-01,\n","                      -1.1723e-01,  1.0015e-01, -2.7914e-01,  3.3809e-01, -3.7148e-03,\n","                       2.5120e-01,  8.6007e-05,  1.1266e-03,  4.0108e-01, -1.9938e-03,\n","                       4.6657e-02, -2.1901e-03, -2.9864e-01,  6.8848e-01, -2.6391e-03,\n","                       4.5241e-01, -6.7968e-02,  3.0224e-01, -1.1730e-01,  1.1745e-01,\n","                       2.7839e-01, -2.2489e-03, -2.4756e-01, -1.2899e-01], device='cuda:0')),\n","             ('module.layer3.0.conv2.accum_scale', tensor([[[2.3988e+03]],\n","              \n","                      [[2.3144e+03]],\n","              \n","                      [[4.0103e+03]],\n","              \n","                      [[2.9071e+03]],\n","              \n","                      [[2.5017e+03]],\n","              \n","                      [[3.4458e+03]],\n","              \n","                      [[3.7618e+03]],\n","              \n","                      [[4.7308e+07]],\n","              \n","                      [[2.2071e+03]],\n","              \n","                      [[3.1214e+07]],\n","              \n","                      [[3.7110e+03]],\n","              \n","                      [[2.2077e+03]],\n","              \n","                      [[2.9346e+03]],\n","              \n","                      [[2.0524e+03]],\n","              \n","                      [[3.5527e+03]],\n","              \n","                      [[2.4523e+03]],\n","              \n","                      [[3.2236e+03]],\n","              \n","                      [[2.6137e+03]],\n","              \n","                      [[2.7421e+03]],\n","              \n","                      [[2.7768e+03]],\n","              \n","                      [[2.1977e+03]],\n","              \n","                      [[3.3778e+03]],\n","              \n","                      [[3.1947e+03]],\n","              \n","                      [[3.4085e+03]],\n","              \n","                      [[4.2586e+03]],\n","              \n","                      [[5.4865e+03]],\n","              \n","                      [[3.1354e+03]],\n","              \n","                      [[3.4009e+03]],\n","              \n","                      [[2.9851e+03]],\n","              \n","                      [[2.8491e+03]],\n","              \n","                      [[2.6423e+03]],\n","              \n","                      [[3.4437e+03]],\n","              \n","                      [[2.7339e+03]],\n","              \n","                      [[3.2731e+03]],\n","              \n","                      [[3.7756e+03]],\n","              \n","                      [[2.2590e+03]],\n","              \n","                      [[2.5736e+03]],\n","              \n","                      [[3.6409e+03]],\n","              \n","                      [[2.5642e+03]],\n","              \n","                      [[2.7493e+03]],\n","              \n","                      [[3.3889e+03]],\n","              \n","                      [[2.7513e+03]],\n","              \n","                      [[2.4381e+03]],\n","              \n","                      [[3.2145e+03]],\n","              \n","                      [[6.2831e+06]],\n","              \n","                      [[3.1193e+03]],\n","              \n","                      [[5.2116e+06]],\n","              \n","                      [[5.5022e+06]],\n","              \n","                      [[2.5386e+03]],\n","              \n","                      [[1.5676e+07]],\n","              \n","                      [[3.2930e+03]],\n","              \n","                      [[9.9269e+06]],\n","              \n","                      [[3.4619e+03]],\n","              \n","                      [[3.2562e+03]],\n","              \n","                      [[1.9799e+07]],\n","              \n","                      [[2.8275e+03]],\n","              \n","                      [[7.2086e+03]],\n","              \n","                      [[3.0382e+03]],\n","              \n","                      [[2.4431e+03]],\n","              \n","                      [[3.0931e+03]],\n","              \n","                      [[2.7309e+03]],\n","              \n","                      [[1.1985e+07]],\n","              \n","                      [[2.9548e+03]],\n","              \n","                      [[2.7349e+03]]], device='cuda:0')),\n","             ('module.layer3.0.conv2.is_simulated_quant_weight_shifted',\n","              tensor(False, device='cuda:0')),\n","             ('module.layer3.0.conv2.wrapped_module.weight',\n","              tensor([[[[32., 24., 25.],\n","                        [18., 21., 22.],\n","                        [21., 10., 22.]],\n","              \n","                       [[24., 15., 16.],\n","                        [23., 18., 26.],\n","                        [29., 24., 26.]],\n","              \n","                       [[42., 30., 25.],\n","                        [22., 22., 36.],\n","                        [30., 41., 32.]],\n","              \n","                       ...,\n","              \n","                       [[29., 25., 21.],\n","                        [ 8., 13., 16.],\n","                        [12., 13., 20.]],\n","              \n","                       [[17., 29., 27.],\n","                        [28., 35., 40.],\n","                        [40., 33., 37.]],\n","              \n","                       [[26., 26., 44.],\n","                        [26., 32., 35.],\n","                        [14., 31., 29.]]],\n","              \n","              \n","                      [[[32., 27., 23.],\n","                        [23., 22., 26.],\n","                        [12.,  9., 15.]],\n","              \n","                       [[25., 23., 10.],\n","                        [24., 32., 22.],\n","                        [10., 14., 17.]],\n","              \n","                       [[29., 34., 34.],\n","                        [37., 23., 14.],\n","                        [36., 43., 38.]],\n","              \n","                       ...,\n","              \n","                       [[ 7., 18., 24.],\n","                        [21., 37., 23.],\n","                        [36., 40., 28.]],\n","              \n","                       [[21., 32., 21.],\n","                        [26., 18., 16.],\n","                        [33., 28., 25.]],\n","              \n","                       [[35., 28., 22.],\n","                        [24., 21., 25.],\n","                        [14., 15., 26.]]],\n","              \n","              \n","                      [[[46., 38., 50.],\n","                        [26., 27., 20.],\n","                        [24., 34., 34.]],\n","              \n","                       [[39., 27., 28.],\n","                        [38., 22., 17.],\n","                        [37., 27., 21.]],\n","              \n","                       [[21., 20., 37.],\n","                        [12., 21., 55.],\n","                        [ 8., 39., 50.]],\n","              \n","                       ...,\n","              \n","                       [[33., 39., 27.],\n","                        [36., 24., 31.],\n","                        [45., 19., 33.]],\n","              \n","                       [[34., 36., 32.],\n","                        [15., 23., 42.],\n","                        [31., 38., 34.]],\n","              \n","                       [[25., 22., 29.],\n","                        [26., 44., 38.],\n","                        [26., 55., 34.]]],\n","              \n","              \n","                      ...,\n","              \n","              \n","                      [[[13., 16., 19.],\n","                        [20., 26., 23.],\n","                        [20., 21., 29.]],\n","              \n","                       [[39., 41., 32.],\n","                        [30., 49., 37.],\n","                        [24., 41., 34.]],\n","              \n","                       [[19., 11.,  4.],\n","                        [15., 14., 21.],\n","                        [16., 17., 25.]],\n","              \n","                       ...,\n","              \n","                       [[44., 33., 27.],\n","                        [13., 22., 27.],\n","                        [22., 32., 39.]],\n","              \n","                       [[28., 35., 37.],\n","                        [36., 36., 25.],\n","                        [24., 24., 27.]],\n","              \n","                       [[27., 35., 30.],\n","                        [18., 19., 33.],\n","                        [12., 19., 32.]]],\n","              \n","              \n","                      [[[14., 19., 25.],\n","                        [22., 10., 20.],\n","                        [12., 25., 23.]],\n","              \n","                       [[27., 45., 47.],\n","                        [20., 14., 17.],\n","                        [10.,  7., 18.]],\n","              \n","                       [[32., 29., 14.],\n","                        [22., 10., 11.],\n","                        [14., 24., 26.]],\n","              \n","                       ...,\n","              \n","                       [[41., 32., 27.],\n","                        [40., 35., 15.],\n","                        [23., 32., 23.]],\n","              \n","                       [[20., 29., 33.],\n","                        [11.,  5.,  6.],\n","                        [19., 11., 21.]],\n","              \n","                       [[ 9.,  8.,  7.],\n","                        [ 9., 17., 23.],\n","                        [ 9., 20., 10.]]],\n","              \n","              \n","                      [[[25., 14., 16.],\n","                        [31., 14., 19.],\n","                        [25.,  9., 19.]],\n","              \n","                       [[22., 28., 27.],\n","                        [25., 26., 18.],\n","                        [20., 17., 27.]],\n","              \n","                       [[42., 23.,  0.],\n","                        [27., 36., 13.],\n","                        [ 4., 31., 24.]],\n","              \n","                       ...,\n","              \n","                       [[23., 25., 32.],\n","                        [13., 23., 22.],\n","                        [ 8., 23., 11.]],\n","              \n","                       [[ 0., 25., 34.],\n","                        [ 6., 21., 23.],\n","                        [ 2., 30., 19.]],\n","              \n","                       [[16., 23., 20.],\n","                        [25., 49., 43.],\n","                        [38., 32., 51.]]]], device='cuda:0')),\n","             ('module.layer3.0.conv2.wrapped_module.bias',\n","              tensor([ 1.1520e+03, -2.1600e+02,  1.4640e+03,  1.3970e+03,  3.1800e+02,\n","                      -3.9200e+02,  9.9000e+01, -1.1500e+05,  1.3980e+03, -5.7065e+04,\n","                       5.1700e+02, -4.6000e+01,  9.7400e+02, -1.2700e+02, -7.4200e+02,\n","                       2.2700e+02,  2.4910e+03, -2.6500e+02,  1.8100e+02,  1.4700e+03,\n","                      -1.2210e+03,  1.1660e+03, -7.0700e+02, -8.8300e+02,  6.8650e+03,\n","                       4.5970e+03,  2.2020e+03,  1.1080e+03, -3.6800e+02,  1.9760e+03,\n","                      -2.7400e+02,  1.4690e+03,  1.0060e+03, -6.0500e+02,  1.3030e+03,\n","                       7.9000e+01,  8.7500e+02,  2.3970e+03,  2.0700e+02, -1.7330e+03,\n","                      -3.9700e+02,  2.7600e+02, -6.8100e+02,  1.0870e+03, -2.3340e+04,\n","                       7.8400e+02,  4.4800e+02,  6.1990e+03,  1.0180e+03, -3.1255e+04,\n","                       1.5400e+02, -2.1741e+04, -1.0340e+03,  2.2420e+03, -5.2251e+04,\n","                       1.2790e+03, -4.9000e+02,  9.1800e+02, -2.8700e+02,  3.6300e+02,\n","                       7.6000e+02, -2.6953e+04, -7.3200e+02, -3.5300e+02], device='cuda:0')),\n","             ('module.layer3.0.relu2.num_forwards',\n","              tensor([40], device='cuda:0')),\n","             ('module.layer3.0.relu2.force_readjust',\n","              tensor(False, device='cuda:0')),\n","             ('module.layer3.0.relu2.output_scale',\n","              tensor([9.2941], device='cuda:0')),\n","             ('module.layer3.0.relu2.output_zero_point',\n","              tensor([0.], device='cuda:0')),\n","             ('module.layer3.0.downsample.0.num_forwards',\n","              tensor([40], device='cuda:0')),\n","             ('module.layer3.0.downsample.0.force_readjust',\n","              tensor(False, device='cuda:0')),\n","             ('module.layer3.0.downsample.0.output_scale',\n","              tensor([12.2071], device='cuda:0')),\n","             ('module.layer3.0.downsample.0.output_zero_point',\n","              tensor([-23.], device='cuda:0')),\n","             ('module.layer3.0.downsample.0.w_scale', tensor([[[[2.3646e+02]]],\n","              \n","              \n","                      [[[4.4041e+02]]],\n","              \n","              \n","                      [[[2.2283e+02]]],\n","              \n","              \n","                      [[[2.2497e+02]]],\n","              \n","              \n","                      [[[2.8118e+02]]],\n","              \n","              \n","                      [[[1.9400e+02]]],\n","              \n","              \n","                      [[[2.5037e+02]]],\n","              \n","              \n","                      [[[2.4073e+05]]],\n","              \n","              \n","                      [[[2.2498e+02]]],\n","              \n","              \n","                      [[[1.9969e+05]]],\n","              \n","              \n","                      [[[4.4933e+02]]],\n","              \n","              \n","                      [[[2.1511e+02]]],\n","              \n","              \n","                      [[[1.9907e+02]]],\n","              \n","              \n","                      [[[2.8638e+02]]],\n","              \n","              \n","                      [[[2.4992e+02]]],\n","              \n","              \n","                      [[[2.0927e+02]]],\n","              \n","              \n","                      [[[1.7912e+02]]],\n","              \n","              \n","                      [[[1.7399e+02]]],\n","              \n","              \n","                      [[[3.0666e+02]]],\n","              \n","              \n","                      [[[1.5458e+02]]],\n","              \n","              \n","                      [[[2.4494e+02]]],\n","              \n","              \n","                      [[[1.0580e+02]]],\n","              \n","              \n","                      [[[3.0422e+02]]],\n","              \n","              \n","                      [[[2.1476e+02]]],\n","              \n","              \n","                      [[[1.4725e+02]]],\n","              \n","              \n","                      [[[1.0986e+02]]],\n","              \n","              \n","                      [[[2.0565e+02]]],\n","              \n","              \n","                      [[[1.6670e+02]]],\n","              \n","              \n","                      [[[1.7393e+02]]],\n","              \n","              \n","                      [[[2.0298e+02]]],\n","              \n","              \n","                      [[[4.5609e+02]]],\n","              \n","              \n","                      [[[3.6295e+02]]],\n","              \n","              \n","                      [[[1.4995e+02]]],\n","              \n","              \n","                      [[[2.4762e+02]]],\n","              \n","              \n","                      [[[4.7700e+02]]],\n","              \n","              \n","                      [[[2.0990e+02]]],\n","              \n","              \n","                      [[[4.2352e+02]]],\n","              \n","              \n","                      [[[1.2573e+02]]],\n","              \n","              \n","                      [[[2.6388e+02]]],\n","              \n","              \n","                      [[[3.8613e+02]]],\n","              \n","              \n","                      [[[1.0440e+02]]],\n","              \n","              \n","                      [[[1.6331e+02]]],\n","              \n","              \n","                      [[[2.2543e+02]]],\n","              \n","              \n","                      [[[1.5149e+02]]],\n","              \n","              \n","                      [[[6.1436e+05]]],\n","              \n","              \n","                      [[[3.4992e+02]]],\n","              \n","              \n","                      [[[5.1164e+05]]],\n","              \n","              \n","                      [[[2.8408e+05]]],\n","              \n","              \n","                      [[[2.0166e+02]]],\n","              \n","              \n","                      [[[3.9882e+05]]],\n","              \n","              \n","                      [[[2.5707e+02]]],\n","              \n","              \n","                      [[[7.8627e+05]]],\n","              \n","              \n","                      [[[1.6877e+02]]],\n","              \n","              \n","                      [[[2.7597e+02]]],\n","              \n","              \n","                      [[[7.0144e+05]]],\n","              \n","              \n","                      [[[1.4920e+02]]],\n","              \n","              \n","                      [[[1.3121e+03]]],\n","              \n","              \n","                      [[[4.1177e+02]]],\n","              \n","              \n","                      [[[2.6423e+02]]],\n","              \n","              \n","                      [[[4.9724e+02]]],\n","              \n","              \n","                      [[[3.2172e+02]]],\n","              \n","              \n","                      [[[3.1757e+05]]],\n","              \n","              \n","                      [[[3.5754e+02]]],\n","              \n","              \n","                      [[[2.0286e+02]]]], device='cuda:0')),\n","             ('module.layer3.0.downsample.0.w_zero_point', tensor([[[[-24.]]],\n","              \n","              \n","                      [[[-33.]]],\n","              \n","              \n","                      [[[-28.]]],\n","              \n","              \n","                      [[[-32.]]],\n","              \n","              \n","                      [[[-28.]]],\n","              \n","              \n","                      [[[-36.]]],\n","              \n","              \n","                      [[[-25.]]],\n","              \n","              \n","                      [[[-35.]]],\n","              \n","              \n","                      [[[-32.]]],\n","              \n","              \n","                      [[[-46.]]],\n","              \n","              \n","                      [[[-27.]]],\n","              \n","              \n","                      [[[-22.]]],\n","              \n","              \n","                      [[[-18.]]],\n","              \n","              \n","                      [[[-31.]]],\n","              \n","              \n","                      [[[-30.]]],\n","              \n","              \n","                      [[[-27.]]],\n","              \n","              \n","                      [[[-33.]]],\n","              \n","              \n","                      [[[-27.]]],\n","              \n","              \n","                      [[[-31.]]],\n","              \n","              \n","                      [[[-24.]]],\n","              \n","              \n","                      [[[-27.]]],\n","              \n","              \n","                      [[[-28.]]],\n","              \n","              \n","                      [[[-32.]]],\n","              \n","              \n","                      [[[-26.]]],\n","              \n","              \n","                      [[[-17.]]],\n","              \n","              \n","                      [[[-18.]]],\n","              \n","              \n","                      [[[-31.]]],\n","              \n","              \n","                      [[[-33.]]],\n","              \n","              \n","                      [[[-23.]]],\n","              \n","              \n","                      [[[-30.]]],\n","              \n","              \n","                      [[[-27.]]],\n","              \n","              \n","                      [[[-27.]]],\n","              \n","              \n","                      [[[-20.]]],\n","              \n","              \n","                      [[[-34.]]],\n","              \n","              \n","                      [[[-41.]]],\n","              \n","              \n","                      [[[-30.]]],\n","              \n","              \n","                      [[[-34.]]],\n","              \n","              \n","                      [[[-18.]]],\n","              \n","              \n","                      [[[-32.]]],\n","              \n","              \n","                      [[[-34.]]],\n","              \n","              \n","                      [[[-16.]]],\n","              \n","              \n","                      [[[-25.]]],\n","              \n","              \n","                      [[[-32.]]],\n","              \n","              \n","                      [[[-46.]]],\n","              \n","              \n","                      [[[-26.]]],\n","              \n","              \n","                      [[[-32.]]],\n","              \n","              \n","                      [[[-35.]]],\n","              \n","              \n","                      [[[-41.]]],\n","              \n","              \n","                      [[[-20.]]],\n","              \n","              \n","                      [[[-21.]]],\n","              \n","              \n","                      [[[-31.]]],\n","              \n","              \n","                      [[[-18.]]],\n","              \n","              \n","                      [[[-26.]]],\n","              \n","              \n","                      [[[-27.]]],\n","              \n","              \n","                      [[[-11.]]],\n","              \n","              \n","                      [[[-23.]]],\n","              \n","              \n","                      [[[-33.]]],\n","              \n","              \n","                      [[[-26.]]],\n","              \n","              \n","                      [[[-24.]]],\n","              \n","              \n","                      [[[-21.]]],\n","              \n","              \n","                      [[[-36.]]],\n","              \n","              \n","                      [[[-32.]]],\n","              \n","              \n","                      [[[-37.]]],\n","              \n","              \n","                      [[[-24.]]]], device='cuda:0')),\n","             ('module.layer3.0.downsample.0.fp_bias',\n","              tensor([-3.0078e-02, -3.2715e-01,  2.8255e-02,  4.6658e-01, -3.2473e-01,\n","                       4.2696e-01, -4.8205e-01, -9.8226e-04,  2.3097e-01,  1.6191e-04,\n","                      -3.5530e-01,  1.7635e-01, -5.1592e-02,  4.5442e-02, -3.0233e-01,\n","                      -2.2274e-01,  4.0453e-01, -1.3794e-01,  2.5057e-02,  1.3957e-01,\n","                      -2.2624e-01,  2.5613e-01, -4.1849e-02,  3.4257e-02, -9.8627e-02,\n","                      -1.4832e-01,  7.6346e-01,  7.4992e-01,  2.6611e-01,  4.9891e-01,\n","                      -3.7679e-01,  2.4973e-01, -4.5713e-01,  3.6466e-01,  3.4891e-01,\n","                      -1.5528e-01, -1.3418e-01, -2.9025e-01, -2.5998e-01, -1.0281e-01,\n","                      -1.4123e+00, -8.2708e-01,  8.9785e-02,  1.2946e+00, -2.6626e-03,\n","                       6.5163e-01, -1.5124e-03, -3.6953e-04, -3.7057e-01, -1.8839e-03,\n","                      -1.0888e-01, -2.0526e-03,  3.5680e-01,  2.5941e-01, -2.5732e-03,\n","                       9.4931e-02,  1.4432e-02, -1.1471e-01,  2.4775e-01,  5.9389e-02,\n","                       4.3024e-01, -5.2832e-04, -1.4939e-01, -2.7636e-01], device='cuda:0')),\n","             ('module.layer3.0.downsample.0.accum_scale',\n","              tensor([[[1.5595e+03]],\n","              \n","                      [[2.9045e+03]],\n","              \n","                      [[1.4696e+03]],\n","              \n","                      [[1.4837e+03]],\n","              \n","                      [[1.8544e+03]],\n","              \n","                      [[1.2795e+03]],\n","              \n","                      [[1.6512e+03]],\n","              \n","                      [[1.5876e+06]],\n","              \n","                      [[1.4838e+03]],\n","              \n","                      [[1.3170e+06]],\n","              \n","                      [[2.9633e+03]],\n","              \n","                      [[1.4187e+03]],\n","              \n","                      [[1.3128e+03]],\n","              \n","                      [[1.8887e+03]],\n","              \n","                      [[1.6483e+03]],\n","              \n","                      [[1.3801e+03]],\n","              \n","                      [[1.1813e+03]],\n","              \n","                      [[1.1475e+03]],\n","              \n","                      [[2.0225e+03]],\n","              \n","                      [[1.0195e+03]],\n","              \n","                      [[1.6154e+03]],\n","              \n","                      [[6.9773e+02]],\n","              \n","                      [[2.0064e+03]],\n","              \n","                      [[1.4163e+03]],\n","              \n","                      [[9.7111e+02]],\n","              \n","                      [[7.2450e+02]],\n","              \n","                      [[1.3563e+03]],\n","              \n","                      [[1.0994e+03]],\n","              \n","                      [[1.1471e+03]],\n","              \n","                      [[1.3386e+03]],\n","              \n","                      [[3.0080e+03]],\n","              \n","                      [[2.3937e+03]],\n","              \n","                      [[9.8891e+02]],\n","              \n","                      [[1.6331e+03]],\n","              \n","                      [[3.1458e+03]],\n","              \n","                      [[1.3843e+03]],\n","              \n","                      [[2.7932e+03]],\n","              \n","                      [[8.2922e+02]],\n","              \n","                      [[1.7403e+03]],\n","              \n","                      [[2.5465e+03]],\n","              \n","                      [[6.8852e+02]],\n","              \n","                      [[1.0770e+03]],\n","              \n","                      [[1.4867e+03]],\n","              \n","                      [[9.9911e+02]],\n","              \n","                      [[4.0517e+06]],\n","              \n","                      [[2.3078e+03]],\n","              \n","                      [[3.3743e+06]],\n","              \n","                      [[1.8735e+06]],\n","              \n","                      [[1.3300e+03]],\n","              \n","                      [[2.6302e+06]],\n","              \n","                      [[1.6954e+03]],\n","              \n","                      [[5.1855e+06]],\n","              \n","                      [[1.1130e+03]],\n","              \n","                      [[1.8201e+03]],\n","              \n","                      [[4.6260e+06]],\n","              \n","                      [[9.8401e+02]],\n","              \n","                      [[8.6535e+03]],\n","              \n","                      [[2.7156e+03]],\n","              \n","                      [[1.7426e+03]],\n","              \n","                      [[3.2793e+03]],\n","              \n","                      [[2.1218e+03]],\n","              \n","                      [[2.0944e+06]],\n","              \n","                      [[2.3580e+03]],\n","              \n","                      [[1.3379e+03]]], device='cuda:0')),\n","             ('module.layer3.0.downsample.0.is_simulated_quant_weight_shifted',\n","              tensor(False, device='cuda:0')),\n","             ('module.layer3.0.downsample.0.wrapped_module.weight',\n","              tensor([[[[13.]],\n","              \n","                       [[47.]],\n","              \n","                       [[ 0.]],\n","              \n","                       ...,\n","              \n","                       [[23.]],\n","              \n","                       [[31.]],\n","              \n","                       [[44.]]],\n","              \n","              \n","                      [[[48.]],\n","              \n","                       [[43.]],\n","              \n","                       [[33.]],\n","              \n","                       ...,\n","              \n","                       [[21.]],\n","              \n","                       [[ 2.]],\n","              \n","                       [[13.]]],\n","              \n","              \n","                      [[[38.]],\n","              \n","                       [[23.]],\n","              \n","                       [[16.]],\n","              \n","                       ...,\n","              \n","                       [[34.]],\n","              \n","                       [[ 7.]],\n","              \n","                       [[57.]]],\n","              \n","              \n","                      ...,\n","              \n","              \n","                      [[[44.]],\n","              \n","                       [[17.]],\n","              \n","                       [[16.]],\n","              \n","                       ...,\n","              \n","                       [[ 5.]],\n","              \n","                       [[24.]],\n","              \n","                       [[39.]]],\n","              \n","              \n","                      [[[35.]],\n","              \n","                       [[31.]],\n","              \n","                       [[56.]],\n","              \n","                       ...,\n","              \n","                       [[33.]],\n","              \n","                       [[28.]],\n","              \n","                       [[24.]]],\n","              \n","              \n","                      [[[27.]],\n","              \n","                       [[ 6.]],\n","              \n","                       [[33.]],\n","              \n","                       ...,\n","              \n","                       [[17.]],\n","              \n","                       [[10.]],\n","              \n","                       [[50.]]]], device='cuda:0')),\n","             ('module.layer3.0.downsample.0.wrapped_module.bias',\n","              tensor([   -47.,   -950.,     42.,    692.,   -602.,    546.,   -796.,  -1559.,\n","                         343.,    213.,  -1053.,    250.,    -68.,     86.,   -498.,   -307.,\n","                         478.,   -158.,     51.,    142.,   -365.,    179.,    -84.,     49.,\n","                         -96.,   -107.,   1035.,    824.,    305.,    668.,  -1133.,    598.,\n","                        -452.,    596.,   1098.,   -215.,   -375.,   -241.,   -452.,   -262.,\n","                        -972.,   -891.,    133.,   1293., -10788.,   1504.,  -5103.,   -692.,\n","                        -493.,  -4955.,   -185., -10644.,    397.,    472., -11904.,     93.,\n","                         125.,   -312.,    432.,    195.,    913.,  -1107.,   -352.,   -370.],\n","                     device='cuda:0')),\n","             ('module.layer3.0.residual_eltwiseadd.num_forwards',\n","              tensor([40], device='cuda:0')),\n","             ('module.layer3.0.residual_eltwiseadd.force_readjust',\n","              tensor(False, device='cuda:0')),\n","             ('module.layer3.0.residual_eltwiseadd.output_scale',\n","              tensor([9.2941], device='cuda:0')),\n","             ('module.layer3.0.residual_eltwiseadd.output_zero_point',\n","              tensor([0.], device='cuda:0')),\n","             ('module.layer3.1.conv1.num_forwards',\n","              tensor([40], device='cuda:0')),\n","             ('module.layer3.1.conv1.force_readjust',\n","              tensor(False, device='cuda:0')),\n","             ('module.layer3.1.conv1.output_scale',\n","              tensor([41.3269], device='cuda:0')),\n","             ('module.layer3.1.conv1.output_zero_point',\n","              tensor([0.], device='cuda:0')),\n","             ('module.layer3.1.conv1.w_scale', tensor([[[[ 733.1782]]],\n","              \n","              \n","                      [[[ 761.4932]]],\n","              \n","              \n","                      [[[ 711.0500]]],\n","              \n","              \n","                      [[[ 487.0605]]],\n","              \n","              \n","                      [[[ 607.9033]]],\n","              \n","              \n","                      [[[ 743.3663]]],\n","              \n","              \n","                      [[[ 605.3184]]],\n","              \n","              \n","                      [[[1050.7594]]],\n","              \n","              \n","                      [[[ 671.6401]]],\n","              \n","              \n","                      [[[ 750.7061]]],\n","              \n","              \n","                      [[[ 930.9886]]],\n","              \n","              \n","                      [[[ 582.5453]]],\n","              \n","              \n","                      [[[ 953.5449]]],\n","              \n","              \n","                      [[[ 526.7621]]],\n","              \n","              \n","                      [[[ 792.9932]]],\n","              \n","              \n","                      [[[ 452.4110]]],\n","              \n","              \n","                      [[[ 909.7255]]],\n","              \n","              \n","                      [[[ 784.4973]]],\n","              \n","              \n","                      [[[ 670.0807]]],\n","              \n","              \n","                      [[[ 871.6069]]],\n","              \n","              \n","                      [[[ 880.8615]]],\n","              \n","              \n","                      [[[ 758.5336]]],\n","              \n","              \n","                      [[[ 600.1679]]],\n","              \n","              \n","                      [[[ 773.2734]]],\n","              \n","              \n","                      [[[ 761.5024]]],\n","              \n","              \n","                      [[[ 745.2433]]],\n","              \n","              \n","                      [[[ 660.0005]]],\n","              \n","              \n","                      [[[ 703.6288]]],\n","              \n","              \n","                      [[[ 766.7767]]],\n","              \n","              \n","                      [[[1061.8628]]],\n","              \n","              \n","                      [[[ 605.0380]]],\n","              \n","              \n","                      [[[ 895.1711]]],\n","              \n","              \n","                      [[[ 827.5867]]],\n","              \n","              \n","                      [[[1128.9009]]],\n","              \n","              \n","                      [[[ 975.5566]]],\n","              \n","              \n","                      [[[ 854.9133]]],\n","              \n","              \n","                      [[[ 606.4557]]],\n","              \n","              \n","                      [[[ 791.5480]]],\n","              \n","              \n","                      [[[1013.2509]]],\n","              \n","              \n","                      [[[ 640.2595]]],\n","              \n","              \n","                      [[[1211.2413]]],\n","              \n","              \n","                      [[[ 855.4388]]],\n","              \n","              \n","                      [[[ 796.5673]]],\n","              \n","              \n","                      [[[ 623.0538]]],\n","              \n","              \n","                      [[[ 712.1272]]],\n","              \n","              \n","                      [[[ 642.3644]]],\n","              \n","              \n","                      [[[ 681.3182]]],\n","              \n","              \n","                      [[[ 673.1968]]],\n","              \n","              \n","                      [[[ 968.8781]]],\n","              \n","              \n","                      [[[ 666.3111]]],\n","              \n","              \n","                      [[[ 587.1928]]],\n","              \n","              \n","                      [[[ 658.5944]]],\n","              \n","              \n","                      [[[ 813.2965]]],\n","              \n","              \n","                      [[[ 738.1782]]],\n","              \n","              \n","                      [[[ 709.1090]]],\n","              \n","              \n","                      [[[ 938.1804]]],\n","              \n","              \n","                      [[[ 598.7402]]],\n","              \n","              \n","                      [[[ 675.1068]]],\n","              \n","              \n","                      [[[1301.7583]]],\n","              \n","              \n","                      [[[ 955.6688]]],\n","              \n","              \n","                      [[[ 589.8974]]],\n","              \n","              \n","                      [[[ 643.7397]]],\n","              \n","              \n","                      [[[ 743.3161]]],\n","              \n","              \n","                      [[[ 584.3572]]]], device='cuda:0')),\n","             ('module.layer3.1.conv1.w_zero_point', tensor([[[[-33.]]],\n","              \n","              \n","                      [[[-31.]]],\n","              \n","              \n","                      [[[-30.]]],\n","              \n","              \n","                      [[[-27.]]],\n","              \n","              \n","                      [[[-22.]]],\n","              \n","              \n","                      [[[-32.]]],\n","              \n","              \n","                      [[[-31.]]],\n","              \n","              \n","                      [[[-30.]]],\n","              \n","              \n","                      [[[-25.]]],\n","              \n","              \n","                      [[[-30.]]],\n","              \n","              \n","                      [[[-32.]]],\n","              \n","              \n","                      [[[-28.]]],\n","              \n","              \n","                      [[[-30.]]],\n","              \n","              \n","                      [[[-31.]]],\n","              \n","              \n","                      [[[-34.]]],\n","              \n","              \n","                      [[[-36.]]],\n","              \n","              \n","                      [[[-30.]]],\n","              \n","              \n","                      [[[-28.]]],\n","              \n","              \n","                      [[[-34.]]],\n","              \n","              \n","                      [[[-32.]]],\n","              \n","              \n","                      [[[-32.]]],\n","              \n","              \n","                      [[[-28.]]],\n","              \n","              \n","                      [[[-26.]]],\n","              \n","              \n","                      [[[-34.]]],\n","              \n","              \n","                      [[[-22.]]],\n","              \n","              \n","                      [[[-29.]]],\n","              \n","              \n","                      [[[-35.]]],\n","              \n","              \n","                      [[[-29.]]],\n","              \n","              \n","                      [[[-26.]]],\n","              \n","              \n","                      [[[-27.]]],\n","              \n","              \n","                      [[[-28.]]],\n","              \n","              \n","                      [[[-27.]]],\n","              \n","              \n","                      [[[-27.]]],\n","              \n","              \n","                      [[[-29.]]],\n","              \n","              \n","                      [[[-28.]]],\n","              \n","              \n","                      [[[-28.]]],\n","              \n","              \n","                      [[[-24.]]],\n","              \n","              \n","                      [[[-27.]]],\n","              \n","              \n","                      [[[-34.]]],\n","              \n","              \n","                      [[[-28.]]],\n","              \n","              \n","                      [[[-27.]]],\n","              \n","              \n","                      [[[-33.]]],\n","              \n","              \n","                      [[[-31.]]],\n","              \n","              \n","                      [[[-24.]]],\n","              \n","              \n","                      [[[-32.]]],\n","              \n","              \n","                      [[[-29.]]],\n","              \n","              \n","                      [[[-25.]]],\n","              \n","              \n","                      [[[-32.]]],\n","              \n","              \n","                      [[[-29.]]],\n","              \n","              \n","                      [[[-32.]]],\n","              \n","              \n","                      [[[-27.]]],\n","              \n","              \n","                      [[[-33.]]],\n","              \n","              \n","                      [[[-29.]]],\n","              \n","              \n","                      [[[-27.]]],\n","              \n","              \n","                      [[[-29.]]],\n","              \n","              \n","                      [[[-23.]]],\n","              \n","              \n","                      [[[-28.]]],\n","              \n","              \n","                      [[[-26.]]],\n","              \n","              \n","                      [[[-26.]]],\n","              \n","              \n","                      [[[-33.]]],\n","              \n","              \n","                      [[[-29.]]],\n","              \n","              \n","                      [[[-27.]]],\n","              \n","              \n","                      [[[-29.]]],\n","              \n","              \n","                      [[[-23.]]]], device='cuda:0')),\n","             ('module.layer3.1.conv1.fp_bias',\n","              tensor([-0.0683, -0.3784, -0.0934, -0.4602, -0.4025,  0.0845, -0.7780, -0.3072,\n","                      -0.2370, -0.0056,  0.1474, -0.2922, -0.2799, -0.5943,  0.3391, -0.0742,\n","                       0.0442, -0.2204, -0.2758,  0.2281, -0.1662,  0.0383,  0.0676, -0.1585,\n","                      -0.4809, -0.3251, -0.0848, -0.3105,  0.0150,  0.1239,  0.0022,  0.1646,\n","                      -0.4597, -0.1584,  0.1387, -0.3858, -0.1861,  0.2432,  0.0482,  0.2519,\n","                      -0.3508,  0.0650,  0.2869, -0.5372, -0.2361,  0.0028,  0.1021,  0.0195,\n","                      -0.6772, -0.2736, -0.3222,  0.0455, -0.1133, -0.4120, -0.6873, -0.3928,\n","                      -0.2711, -0.1811, -0.1826,  0.2752, -0.2782, -0.0836,  0.0216, -0.3421],\n","                     device='cuda:0')),\n","             ('module.layer3.1.conv1.accum_scale', tensor([[[ 6814.2378]],\n","              \n","                      [[ 7077.4004]],\n","              \n","                      [[ 6608.5757]],\n","              \n","                      [[ 4526.7935]],\n","              \n","                      [[ 5649.9194]],\n","              \n","                      [[ 6908.9272]],\n","              \n","                      [[ 5625.8950]],\n","              \n","                      [[ 9765.8721]],\n","              \n","                      [[ 6242.2964]],\n","              \n","                      [[ 6977.1436]],\n","              \n","                      [[ 8652.7090]],\n","              \n","                      [[ 5414.2393]],\n","              \n","                      [[ 8862.3496]],\n","              \n","                      [[ 4895.7837]],\n","              \n","                      [[ 7370.1650]],\n","              \n","                      [[ 4204.7573]],\n","              \n","                      [[ 8455.0879]],\n","              \n","                      [[ 7291.2031]],\n","              \n","                      [[ 6227.8032]],\n","              \n","                      [[ 8100.8091]],\n","              \n","                      [[ 8186.8218]],\n","              \n","                      [[ 7049.8936]],\n","              \n","                      [[ 5578.0254]],\n","              \n","                      [[ 7186.8872]],\n","              \n","                      [[ 7077.4863]],\n","              \n","                      [[ 6926.3721]],\n","              \n","                      [[ 6134.1167]],\n","              \n","                      [[ 6539.6021]],\n","              \n","                      [[ 7126.5059]],\n","              \n","                      [[ 9869.0684]],\n","              \n","                      [[ 5623.2886]],\n","              \n","                      [[ 8319.8174]],\n","              \n","                      [[ 7691.6807]],\n","              \n","                      [[10492.1270]],\n","              \n","                      [[ 9066.9287]],\n","              \n","                      [[ 7945.6572]],\n","              \n","                      [[ 5636.4653]],\n","              \n","                      [[ 7356.7334]],\n","              \n","                      [[ 9417.2637]],\n","              \n","                      [[ 5950.6416]],\n","              \n","                      [[11257.4082]],\n","              \n","                      [[ 7950.5415]],\n","              \n","                      [[ 7403.3828]],\n","              \n","                      [[ 5790.7300]],\n","              \n","                      [[ 6618.5874]],\n","              \n","                      [[ 5970.2046]],\n","              \n","                      [[ 6332.2451]],\n","              \n","                      [[ 6256.7637]],\n","              \n","                      [[ 9004.8574]],\n","              \n","                      [[ 6192.7676]],\n","              \n","                      [[ 5457.4336]],\n","              \n","                      [[ 6121.0479]],\n","              \n","                      [[ 7558.8657]],\n","              \n","                      [[ 6860.7080]],\n","              \n","                      [[ 6590.5361]],\n","              \n","                      [[ 8719.5508]],\n","              \n","                      [[ 5564.7568]],\n","              \n","                      [[ 6274.5161]],\n","              \n","                      [[12098.6826]],\n","              \n","                      [[ 8882.0898]],\n","              \n","                      [[ 5482.5703]],\n","              \n","                      [[ 5982.9868]],\n","              \n","                      [[ 6908.4604]],\n","              \n","                      [[ 5431.0796]]], device='cuda:0')),\n","             ('module.layer3.1.conv1.is_simulated_quant_weight_shifted',\n","              tensor(False, device='cuda:0')),\n","             ('module.layer3.1.conv1.wrapped_module.weight',\n","              tensor([[[[29., 36., 30.],\n","                        [20., 31., 27.],\n","                        [17., 25., 21.]],\n","              \n","                       [[33., 35., 33.],\n","                        [30., 35., 38.],\n","                        [31., 32., 37.]],\n","              \n","                       [[31., 37., 38.],\n","                        [39., 36., 34.],\n","                        [41., 38., 48.]],\n","              \n","                       ...,\n","              \n","                       [[33., 33., 33.],\n","                        [33., 33., 33.],\n","                        [33., 33., 33.]],\n","              \n","                       [[23., 27., 35.],\n","                        [33., 33., 41.],\n","                        [29., 26., 39.]],\n","              \n","                       [[26., 28., 38.],\n","                        [21., 41., 35.],\n","                        [31., 35., 36.]]],\n","              \n","              \n","                      [[[27., 33., 29.],\n","                        [33., 34., 32.],\n","                        [18., 19.,  9.]],\n","              \n","                       [[20., 24., 27.],\n","                        [27., 29., 29.],\n","                        [26., 24., 24.]],\n","              \n","                       [[28., 35., 48.],\n","                        [26., 41., 29.],\n","                        [63., 60., 58.]],\n","              \n","                       ...,\n","              \n","                       [[31., 31., 31.],\n","                        [31., 31., 31.],\n","                        [31., 31., 31.]],\n","              \n","                       [[35., 25., 25.],\n","                        [37., 33., 29.],\n","                        [44., 37., 33.]],\n","              \n","                       [[31., 30., 18.],\n","                        [41., 20.,  5.],\n","                        [54., 41., 24.]]],\n","              \n","              \n","                      [[[28., 29., 18.],\n","                        [24., 34., 25.],\n","                        [25., 37., 37.]],\n","              \n","                       [[31., 28., 28.],\n","                        [21., 25., 29.],\n","                        [27., 30., 26.]],\n","              \n","                       [[31., 37., 26.],\n","                        [37., 30., 23.],\n","                        [63., 50., 24.]],\n","              \n","                       ...,\n","              \n","                       [[30., 30., 30.],\n","                        [30., 30., 30.],\n","                        [30., 30., 30.]],\n","              \n","                       [[32., 26., 19.],\n","                        [25., 37., 36.],\n","                        [17., 22., 27.]],\n","              \n","                       [[29., 38.,  5.],\n","                        [24., 32., 23.],\n","                        [23., 20., 39.]]],\n","              \n","              \n","                      ...,\n","              \n","              \n","                      [[[ 0.,  5., 23.],\n","                        [20., 27., 45.],\n","                        [27., 42., 55.]],\n","              \n","                       [[16., 26., 25.],\n","                        [25., 19., 20.],\n","                        [30., 19., 21.]],\n","              \n","                       [[42., 28., 49.],\n","                        [46., 42., 46.],\n","                        [11., 28., 24.]],\n","              \n","                       ...,\n","              \n","                       [[27., 27., 27.],\n","                        [27., 27., 27.],\n","                        [27., 27., 27.]],\n","              \n","                       [[15., 19., 19.],\n","                        [19., 19., 27.],\n","                        [25., 20., 43.]],\n","              \n","                       [[11., 29., 35.],\n","                        [23., 22., 38.],\n","                        [40., 33., 42.]]],\n","              \n","              \n","                      [[[25., 38., 35.],\n","                        [21., 37., 25.],\n","                        [31., 54., 49.]],\n","              \n","                       [[22., 22., 30.],\n","                        [25., 23., 27.],\n","                        [41., 33., 26.]],\n","              \n","                       [[25., 38., 33.],\n","                        [41., 38., 23.],\n","                        [52., 13.,  5.]],\n","              \n","                       ...,\n","              \n","                       [[29., 29., 29.],\n","                        [29., 29., 29.],\n","                        [29., 29., 29.]],\n","              \n","                       [[28., 23., 24.],\n","                        [22., 23., 25.],\n","                        [16., 30., 34.]],\n","              \n","                       [[42., 39., 22.],\n","                        [35., 43., 14.],\n","                        [32., 27., 14.]]],\n","              \n","              \n","                      [[[24., 27., 32.],\n","                        [22., 21., 30.],\n","                        [22., 12., 21.]],\n","              \n","                       [[23., 21., 22.],\n","                        [22., 24., 25.],\n","                        [27., 25., 17.]],\n","              \n","                       [[ 8., 22., 32.],\n","                        [30., 30., 28.],\n","                        [31., 12.,  5.]],\n","              \n","                       ...,\n","              \n","                       [[23., 23., 23.],\n","                        [23., 23., 23.],\n","                        [23., 23., 23.]],\n","              \n","                       [[41., 23., 19.],\n","                        [28., 21., 20.],\n","                        [21., 28., 35.]],\n","              \n","                       [[17., 27., 18.],\n","                        [17., 32., 28.],\n","                        [ 9., 27., 38.]]]], device='cuda:0')),\n","             ('module.layer3.1.conv1.wrapped_module.bias',\n","              tensor([ -466., -2678.,  -617., -2083., -2274.,   584., -4377., -3000., -1479.,\n","                        -39.,  1275., -1582., -2481., -2910.,  2499.,  -312.,   374., -1607.,\n","                      -1718.,  1848., -1361.,   270.,   377., -1139., -3404., -2252.,  -520.,\n","                      -2031.,   107.,  1223.,    12.,  1369., -3536., -1662.,  1258., -3065.,\n","                      -1049.,  1789.,   454.,  1499., -3949.,   516.,  2124., -3111., -1563.,\n","                         17.,   646.,   122., -6098., -1694., -1758.,   278.,  -857., -2827.,\n","                      -4530., -3425., -1508., -1136., -2209.,  2445., -1525.,  -500.,   150.,\n","                      -1858.], device='cuda:0')),\n","             ('module.layer3.1.conv2.num_forwards',\n","              tensor([40], device='cuda:0')),\n","             ('module.layer3.1.conv2.force_readjust',\n","              tensor(False, device='cuda:0')),\n","             ('module.layer3.1.conv2.output_scale',\n","              tensor([11.4896], device='cuda:0')),\n","             ('module.layer3.1.conv2.output_zero_point',\n","              tensor([-30.], device='cuda:0')),\n","             ('module.layer3.1.conv2.w_scale', tensor([[[[  68.1979]]],\n","              \n","              \n","                      [[[  91.1788]]],\n","              \n","              \n","                      [[[  70.5251]]],\n","              \n","              \n","                      [[[ 100.8580]]],\n","              \n","              \n","                      [[[  64.2790]]],\n","              \n","              \n","                      [[[ 136.8747]]],\n","              \n","              \n","                      [[[ 104.4568]]],\n","              \n","              \n","                      [[[  77.3708]]],\n","              \n","              \n","                      [[[ 101.6609]]],\n","              \n","              \n","                      [[[  57.0503]]],\n","              \n","              \n","                      [[[  76.4855]]],\n","              \n","              \n","                      [[[  96.6654]]],\n","              \n","              \n","                      [[[ 262.8869]]],\n","              \n","              \n","                      [[[  88.4039]]],\n","              \n","              \n","                      [[[  98.4271]]],\n","              \n","              \n","                      [[[ 130.5314]]],\n","              \n","              \n","                      [[[ 133.1042]]],\n","              \n","              \n","                      [[[ 122.5308]]],\n","              \n","              \n","                      [[[ 152.1539]]],\n","              \n","              \n","                      [[[  94.8472]]],\n","              \n","              \n","                      [[[  96.0473]]],\n","              \n","              \n","                      [[[ 377.5494]]],\n","              \n","              \n","                      [[[ 111.0622]]],\n","              \n","              \n","                      [[[ 108.1260]]],\n","              \n","              \n","                      [[[ 123.8410]]],\n","              \n","              \n","                      [[[ 197.8947]]],\n","              \n","              \n","                      [[[  96.8433]]],\n","              \n","              \n","                      [[[ 189.5581]]],\n","              \n","              \n","                      [[[ 107.7686]]],\n","              \n","              \n","                      [[[ 202.5518]]],\n","              \n","              \n","                      [[[  67.2407]]],\n","              \n","              \n","                      [[[  68.5826]]],\n","              \n","              \n","                      [[[ 114.6576]]],\n","              \n","              \n","                      [[[ 116.9375]]],\n","              \n","              \n","                      [[[  53.5978]]],\n","              \n","              \n","                      [[[ 104.0172]]],\n","              \n","              \n","                      [[[  82.1804]]],\n","              \n","              \n","                      [[[  80.7457]]],\n","              \n","              \n","                      [[[ 103.8157]]],\n","              \n","              \n","                      [[[  91.4676]]],\n","              \n","              \n","                      [[[ 161.1329]]],\n","              \n","              \n","                      [[[ 117.6393]]],\n","              \n","              \n","                      [[[ 126.4221]]],\n","              \n","              \n","                      [[[ 117.3863]]],\n","              \n","              \n","                      [[[  43.8678]]],\n","              \n","              \n","                      [[[ 288.9059]]],\n","              \n","              \n","                      [[[1438.0642]]],\n","              \n","              \n","                      [[[  82.5306]]],\n","              \n","              \n","                      [[[  98.5501]]],\n","              \n","              \n","                      [[[ 179.2976]]],\n","              \n","              \n","                      [[[  72.4456]]],\n","              \n","              \n","                      [[[  97.6307]]],\n","              \n","              \n","                      [[[ 107.1718]]],\n","              \n","              \n","                      [[[  69.2447]]],\n","              \n","              \n","                      [[[  58.9528]]],\n","              \n","              \n","                      [[[ 106.8501]]],\n","              \n","              \n","                      [[[  79.9638]]],\n","              \n","              \n","                      [[[ 140.8915]]],\n","              \n","              \n","                      [[[ 104.0506]]],\n","              \n","              \n","                      [[[  66.2783]]],\n","              \n","              \n","                      [[[  96.9597]]],\n","              \n","              \n","                      [[[  60.6573]]],\n","              \n","              \n","                      [[[  81.8712]]],\n","              \n","              \n","                      [[[ 140.4134]]]], device='cuda:0')),\n","             ('module.layer3.1.conv2.w_zero_point', tensor([[[[-32.]]],\n","              \n","              \n","                      [[[-25.]]],\n","              \n","              \n","                      [[[-36.]]],\n","              \n","              \n","                      [[[-36.]]],\n","              \n","              \n","                      [[[-31.]]],\n","              \n","              \n","                      [[[-31.]]],\n","              \n","              \n","                      [[[-29.]]],\n","              \n","              \n","                      [[[-23.]]],\n","              \n","              \n","                      [[[-35.]]],\n","              \n","              \n","                      [[[-27.]]],\n","              \n","              \n","                      [[[-29.]]],\n","              \n","              \n","                      [[[-30.]]],\n","              \n","              \n","                      [[[-39.]]],\n","              \n","              \n","                      [[[-24.]]],\n","              \n","              \n","                      [[[-24.]]],\n","              \n","              \n","                      [[[-35.]]],\n","              \n","              \n","                      [[[-33.]]],\n","              \n","              \n","                      [[[-31.]]],\n","              \n","              \n","                      [[[-31.]]],\n","              \n","              \n","                      [[[-32.]]],\n","              \n","              \n","                      [[[-29.]]],\n","              \n","              \n","                      [[[-37.]]],\n","              \n","              \n","                      [[[-25.]]],\n","              \n","              \n","                      [[[-26.]]],\n","              \n","              \n","                      [[[-30.]]],\n","              \n","              \n","                      [[[-41.]]],\n","              \n","              \n","                      [[[-27.]]],\n","              \n","              \n","                      [[[-31.]]],\n","              \n","              \n","                      [[[-32.]]],\n","              \n","              \n","                      [[[-39.]]],\n","              \n","              \n","                      [[[-28.]]],\n","              \n","              \n","                      [[[-27.]]],\n","              \n","              \n","                      [[[-32.]]],\n","              \n","              \n","                      [[[-27.]]],\n","              \n","              \n","                      [[[-31.]]],\n","              \n","              \n","                      [[[-30.]]],\n","              \n","              \n","                      [[[-29.]]],\n","              \n","              \n","                      [[[-20.]]],\n","              \n","              \n","                      [[[-28.]]],\n","              \n","              \n","                      [[[-33.]]],\n","              \n","              \n","                      [[[-26.]]],\n","              \n","              \n","                      [[[-30.]]],\n","              \n","              \n","                      [[[-31.]]],\n","              \n","              \n","                      [[[-32.]]],\n","              \n","              \n","                      [[[-14.]]],\n","              \n","              \n","                      [[[-35.]]],\n","              \n","              \n","                      [[[-18.]]],\n","              \n","              \n","                      [[[-23.]]],\n","              \n","              \n","                      [[[-36.]]],\n","              \n","              \n","                      [[[-27.]]],\n","              \n","              \n","                      [[[-31.]]],\n","              \n","              \n","                      [[[-28.]]],\n","              \n","              \n","                      [[[-31.]]],\n","              \n","              \n","                      [[[-28.]]],\n","              \n","              \n","                      [[[-25.]]],\n","              \n","              \n","                      [[[-31.]]],\n","              \n","              \n","                      [[[-28.]]],\n","              \n","              \n","                      [[[-25.]]],\n","              \n","              \n","                      [[[-30.]]],\n","              \n","              \n","                      [[[-29.]]],\n","              \n","              \n","                      [[[-29.]]],\n","              \n","              \n","                      [[[-23.]]],\n","              \n","              \n","                      [[[-26.]]],\n","              \n","              \n","                      [[[-28.]]]], device='cuda:0')),\n","             ('module.layer3.1.conv2.fp_bias',\n","              tensor([ 0.4030,  0.0572,  0.7478, -0.1776,  0.4480,  0.3364,  0.6157, -0.1972,\n","                       0.2759,  0.8537,  0.0760,  0.0517,  0.1529, -0.2723, -0.5562,  0.2344,\n","                      -0.1440, -0.2076, -0.1909,  0.0117, -0.2534,  0.2383, -0.0924,  0.1400,\n","                       0.1572,  0.2883,  0.3270,  0.1106,  0.1449,  0.2695,  0.2193,  0.3214,\n","                      -0.1354, -0.0788,  0.8408, -0.0209,  0.0752,  0.3268,  0.5286,  0.7334,\n","                       0.2401,  0.1599, -0.1206,  0.3481, -0.2789,  0.2322, -0.0215,  0.1377,\n","                       0.0045, -0.0019,  0.3009,  0.4957,  0.0472, -0.0166,  1.0126, -0.3167,\n","                       0.6662, -0.1901, -0.0385,  0.3535,  0.1972, -0.2702,  0.0243, -0.1085],\n","                     device='cuda:0')),\n","             ('module.layer3.1.conv2.accum_scale', tensor([[[ 2818.4060]],\n","              \n","                      [[ 3768.1360]],\n","              \n","                      [[ 2914.5833]],\n","              \n","                      [[ 4168.1489]],\n","              \n","                      [[ 2656.4519]],\n","              \n","                      [[ 5656.6064]],\n","              \n","                      [[ 4316.8770]],\n","              \n","                      [[ 3197.4968]],\n","              \n","                      [[ 4201.3311]],\n","              \n","                      [[ 2357.7136]],\n","              \n","                      [[ 3160.9062]],\n","              \n","                      [[ 3994.8818]],\n","              \n","                      [[10864.3008]],\n","              \n","                      [[ 3653.4607]],\n","              \n","                      [[ 4067.6860]],\n","              \n","                      [[ 5394.4580]],\n","              \n","                      [[ 5500.7832]],\n","              \n","                      [[ 5063.8188]],\n","              \n","                      [[ 6288.0483]],\n","              \n","                      [[ 3919.7419]],\n","              \n","                      [[ 3969.3369]],\n","              \n","                      [[15602.9463]],\n","              \n","                      [[ 4589.8569]],\n","              \n","                      [[ 4468.5122]],\n","              \n","                      [[ 5117.9658]],\n","              \n","                      [[ 8178.3721]],\n","              \n","                      [[ 4002.2332]],\n","              \n","                      [[ 7833.8496]],\n","              \n","                      [[ 4453.7422]],\n","              \n","                      [[ 8370.8379]],\n","              \n","                      [[ 2778.8477]],\n","              \n","                      [[ 2834.3049]],\n","              \n","                      [[ 4738.4424]],\n","              \n","                      [[ 4832.6660]],\n","              \n","                      [[ 2215.0322]],\n","              \n","                      [[ 4298.7095]],\n","              \n","                      [[ 3396.2627]],\n","              \n","                      [[ 3336.9707]],\n","              \n","                      [[ 4290.3813]],\n","              \n","                      [[ 3780.0720]],\n","              \n","                      [[ 6659.1250]],\n","              \n","                      [[ 4861.6689]],\n","              \n","                      [[ 5224.6313]],\n","              \n","                      [[ 4851.2100]],\n","              \n","                      [[ 1812.9182]],\n","              \n","                      [[11939.5840]],\n","              \n","                      [[59430.7305]],\n","              \n","                      [[ 3410.7351]],\n","              \n","                      [[ 4072.7693]],\n","              \n","                      [[ 7409.8120]],\n","              \n","                      [[ 2993.9507]],\n","              \n","                      [[ 4034.7732]],\n","              \n","                      [[ 4429.0781]],\n","              \n","                      [[ 2861.6699]],\n","              \n","                      [[ 2436.3364]],\n","              \n","                      [[ 4415.7847]],\n","              \n","                      [[ 3304.6570]],\n","              \n","                      [[ 5822.6069]],\n","              \n","                      [[ 4300.0879]],\n","              \n","                      [[ 2739.0767]],\n","              \n","                      [[ 4007.0449]],\n","              \n","                      [[ 2506.7786]],\n","              \n","                      [[ 3383.4819]],\n","              \n","                      [[ 5802.8491]]], device='cuda:0')),\n","             ('module.layer3.1.conv2.is_simulated_quant_weight_shifted',\n","              tensor(False, device='cuda:0')),\n","             ('module.layer3.1.conv2.wrapped_module.weight',\n","              tensor([[[[20., 33., 38.],\n","                        [16., 28., 29.],\n","                        [15., 23., 29.]],\n","              \n","                       [[48., 51., 33.],\n","                        [28., 35., 18.],\n","                        [25., 32., 28.]],\n","              \n","                       [[47., 30., 29.],\n","                        [34., 26., 30.],\n","                        [28., 32., 35.]],\n","              \n","                       ...,\n","              \n","                       [[32., 36., 14.],\n","                        [38., 34.,  8.],\n","                        [25., 22., 15.]],\n","              \n","                       [[31., 31., 30.],\n","                        [15., 26., 19.],\n","                        [31., 48., 35.]],\n","              \n","                       [[32., 18., 21.],\n","                        [25., 20., 24.],\n","                        [19., 26., 30.]]],\n","              \n","              \n","                      [[[18., 14., 24.],\n","                        [21., 23., 27.],\n","                        [16., 20., 19.]],\n","              \n","                       [[21., 19., 20.],\n","                        [21., 18., 18.],\n","                        [17., 13., 17.]],\n","              \n","                       [[25., 19., 26.],\n","                        [27., 26., 20.],\n","                        [11., 29., 27.]],\n","              \n","                       ...,\n","              \n","                       [[18., 25., 29.],\n","                        [ 8., 22., 28.],\n","                        [25., 32., 40.]],\n","              \n","                       [[34., 32., 32.],\n","                        [23., 23., 20.],\n","                        [18., 24., 18.]],\n","              \n","                       [[34., 31., 33.],\n","                        [35., 28., 26.],\n","                        [23., 29., 28.]]],\n","              \n","              \n","                      [[[29., 27., 35.],\n","                        [30., 27., 40.],\n","                        [30., 31., 41.]],\n","              \n","                       [[37., 35., 30.],\n","                        [29., 29., 24.],\n","                        [26., 29., 29.]],\n","              \n","                       [[26., 30., 33.],\n","                        [30., 37., 44.],\n","                        [42., 44., 37.]],\n","              \n","                       ...,\n","              \n","                       [[39., 41., 38.],\n","                        [36., 37., 29.],\n","                        [37., 40., 26.]],\n","              \n","                       [[28., 34., 34.],\n","                        [25., 35., 25.],\n","                        [36., 40., 23.]],\n","              \n","                       [[29., 41., 40.],\n","                        [28., 43., 55.],\n","                        [35., 36., 50.]]],\n","              \n","              \n","                      ...,\n","              \n","              \n","                      [[[19., 22., 21.],\n","                        [23., 28., 30.],\n","                        [25., 21., 33.]],\n","              \n","                       [[38., 37., 36.],\n","                        [28., 33., 25.],\n","                        [19., 30., 26.]],\n","              \n","                       [[30., 20., 23.],\n","                        [31., 19., 20.],\n","                        [23., 30., 36.]],\n","              \n","                       ...,\n","              \n","                       [[20., 28., 26.],\n","                        [20., 16., 15.],\n","                        [27., 23., 17.]],\n","              \n","                       [[26., 18., 18.],\n","                        [24., 19., 17.],\n","                        [24., 21., 24.]],\n","              \n","                       [[29., 21., 31.],\n","                        [21., 19., 36.],\n","                        [16., 22., 37.]]],\n","              \n","              \n","                      [[[43., 32., 32.],\n","                        [33., 23., 38.],\n","                        [23., 17., 40.]],\n","              \n","                       [[43., 31., 26.],\n","                        [35., 22., 19.],\n","                        [22., 17., 26.]],\n","              \n","                       [[ 9., 25., 34.],\n","                        [17., 31., 36.],\n","                        [34., 36., 38.]],\n","              \n","                       ...,\n","              \n","                       [[46., 39., 28.],\n","                        [28.,  5., 16.],\n","                        [23., 15., 32.]],\n","              \n","                       [[16., 24., 29.],\n","                        [24., 16., 13.],\n","                        [44., 31., 21.]],\n","              \n","                       [[33., 27., 28.],\n","                        [34., 20., 36.],\n","                        [36., 22., 30.]]],\n","              \n","              \n","                      [[[14., 32., 46.],\n","                        [23., 21., 36.],\n","                        [27.,  7., 29.]],\n","              \n","                       [[17., 22., 26.],\n","                        [41., 37., 35.],\n","                        [38., 29., 33.]],\n","              \n","                       [[44., 43., 18.],\n","                        [42., 44., 33.],\n","                        [33., 43., 43.]],\n","              \n","                       ...,\n","              \n","                       [[30.,  3.,  3.],\n","                        [27., 33., 15.],\n","                        [15., 63., 43.]],\n","              \n","                       [[30., 32., 32.],\n","                        [35., 34., 36.],\n","                        [23., 28., 35.]],\n","              \n","                       [[29.,  3.,  9.],\n","                        [39., 17., 18.],\n","                        [43., 37., 46.]]]], device='cuda:0')),\n","             ('module.layer3.1.conv2.wrapped_module.bias',\n","              tensor([ 1136.,   216.,  2179.,  -740.,  1190.,  1903.,  2658.,  -630.,  1159.,\n","                       2013.,   240.,   207.,  1661.,  -995., -2262.,  1264.,  -792., -1051.,\n","                      -1200.,    46., -1006.,  3718.,  -424.,   625.,   805.,  2358.,  1309.,\n","                        866.,   646.,  2256.,   609.,   911.,  -641.,  -381.,  1862.,   -90.,\n","                        256.,  1091.,  2268.,  2772.,  1599.,   777.,  -630.,  1689.,  -506.,\n","                       2773., -1277.,   470.,    18.,   -14.,   901.,  2000.,   209.,   -48.,\n","                       2467., -1399.,  2202., -1107.,  -165.,   968.,   790.,  -677.,    82.,\n","                       -630.], device='cuda:0')),\n","             ('module.layer3.1.relu2.num_forwards',\n","              tensor([40], device='cuda:0')),\n","             ('module.layer3.1.relu2.force_readjust',\n","              tensor(False, device='cuda:0')),\n","             ('module.layer3.1.relu2.output_scale',\n","              tensor([8.4933], device='cuda:0')),\n","             ('module.layer3.1.relu2.output_zero_point',\n","              tensor([0.], device='cuda:0')),\n","             ('module.layer3.1.residual_eltwiseadd.num_forwards',\n","              tensor([40], device='cuda:0')),\n","             ('module.layer3.1.residual_eltwiseadd.force_readjust',\n","              tensor(False, device='cuda:0')),\n","             ('module.layer3.1.residual_eltwiseadd.output_scale',\n","              tensor([8.4933], device='cuda:0')),\n","             ('module.layer3.1.residual_eltwiseadd.output_zero_point',\n","              tensor([0.], device='cuda:0')),\n","             ('module.layer3.2.conv1.num_forwards',\n","              tensor([40], device='cuda:0')),\n","             ('module.layer3.2.conv1.force_readjust',\n","              tensor(False, device='cuda:0')),\n","             ('module.layer3.2.conv1.output_scale',\n","              tensor([51.7011], device='cuda:0')),\n","             ('module.layer3.2.conv1.output_zero_point',\n","              tensor([0.], device='cuda:0')),\n","             ('module.layer3.2.conv1.w_scale', tensor([[[[ 808.3528]]],\n","              \n","              \n","                      [[[ 782.7614]]],\n","              \n","              \n","                      [[[ 714.2666]]],\n","              \n","              \n","                      [[[1000.1960]]],\n","              \n","              \n","                      [[[1002.4632]]],\n","              \n","              \n","                      [[[ 958.6052]]],\n","              \n","              \n","                      [[[1067.1232]]],\n","              \n","              \n","                      [[[ 822.8804]]],\n","              \n","              \n","                      [[[1020.9127]]],\n","              \n","              \n","                      [[[ 818.6893]]],\n","              \n","              \n","                      [[[ 656.0067]]],\n","              \n","              \n","                      [[[ 953.3514]]],\n","              \n","              \n","                      [[[1039.3196]]],\n","              \n","              \n","                      [[[ 959.0934]]],\n","              \n","              \n","                      [[[2933.0447]]],\n","              \n","              \n","                      [[[ 853.5982]]],\n","              \n","              \n","                      [[[ 945.6200]]],\n","              \n","              \n","                      [[[ 820.6896]]],\n","              \n","              \n","                      [[[ 972.7319]]],\n","              \n","              \n","                      [[[2072.0154]]],\n","              \n","              \n","                      [[[1238.3284]]],\n","              \n","              \n","                      [[[ 851.5513]]],\n","              \n","              \n","                      [[[1321.1869]]],\n","              \n","              \n","                      [[[ 939.1535]]],\n","              \n","              \n","                      [[[ 784.0386]]],\n","              \n","              \n","                      [[[1061.7517]]],\n","              \n","              \n","                      [[[1445.1637]]],\n","              \n","              \n","                      [[[ 534.2825]]],\n","              \n","              \n","                      [[[ 795.3912]]],\n","              \n","              \n","                      [[[ 967.8775]]],\n","              \n","              \n","                      [[[1384.8540]]],\n","              \n","              \n","                      [[[1101.0214]]],\n","              \n","              \n","                      [[[1422.6123]]],\n","              \n","              \n","                      [[[ 825.5899]]],\n","              \n","              \n","                      [[[1449.5823]]],\n","              \n","              \n","                      [[[ 909.6096]]],\n","              \n","              \n","                      [[[ 735.9279]]],\n","              \n","              \n","                      [[[1225.8094]]],\n","              \n","              \n","                      [[[ 998.6589]]],\n","              \n","              \n","                      [[[ 833.6625]]],\n","              \n","              \n","                      [[[ 533.2772]]],\n","              \n","              \n","                      [[[ 624.1984]]],\n","              \n","              \n","                      [[[ 668.2469]]],\n","              \n","              \n","                      [[[ 877.1954]]],\n","              \n","              \n","                      [[[1144.9463]]],\n","              \n","              \n","                      [[[ 832.5092]]],\n","              \n","              \n","                      [[[ 748.8777]]],\n","              \n","              \n","                      [[[ 888.5724]]],\n","              \n","              \n","                      [[[ 928.9999]]],\n","              \n","              \n","                      [[[ 857.2182]]],\n","              \n","              \n","                      [[[ 660.2131]]],\n","              \n","              \n","                      [[[ 670.7459]]],\n","              \n","              \n","                      [[[ 760.0797]]],\n","              \n","              \n","                      [[[1102.1550]]],\n","              \n","              \n","                      [[[ 789.5296]]],\n","              \n","              \n","                      [[[1044.8981]]],\n","              \n","              \n","                      [[[ 767.7552]]],\n","              \n","              \n","                      [[[ 738.2330]]],\n","              \n","              \n","                      [[[ 741.5301]]],\n","              \n","              \n","                      [[[1005.9962]]],\n","              \n","              \n","                      [[[1013.9716]]],\n","              \n","              \n","                      [[[1034.9933]]],\n","              \n","              \n","                      [[[ 892.8278]]],\n","              \n","              \n","                      [[[ 909.0342]]]], device='cuda:0')),\n","             ('module.layer3.2.conv1.w_zero_point', tensor([[[[-29.]]],\n","              \n","              \n","                      [[[-32.]]],\n","              \n","              \n","                      [[[-27.]]],\n","              \n","              \n","                      [[[-27.]]],\n","              \n","              \n","                      [[[-31.]]],\n","              \n","              \n","                      [[[-34.]]],\n","              \n","              \n","                      [[[-31.]]],\n","              \n","              \n","                      [[[-29.]]],\n","              \n","              \n","                      [[[-28.]]],\n","              \n","              \n","                      [[[-28.]]],\n","              \n","              \n","                      [[[-34.]]],\n","              \n","              \n","                      [[[-28.]]],\n","              \n","              \n","                      [[[-27.]]],\n","              \n","              \n","                      [[[-27.]]],\n","              \n","              \n","                      [[[-22.]]],\n","              \n","              \n","                      [[[-26.]]],\n","              \n","              \n","                      [[[-34.]]],\n","              \n","              \n","                      [[[-30.]]],\n","              \n","              \n","                      [[[-30.]]],\n","              \n","              \n","                      [[[-26.]]],\n","              \n","              \n","                      [[[-33.]]],\n","              \n","              \n","                      [[[-28.]]],\n","              \n","              \n","                      [[[-26.]]],\n","              \n","              \n","                      [[[-24.]]],\n","              \n","              \n","                      [[[-33.]]],\n","              \n","              \n","                      [[[-27.]]],\n","              \n","              \n","                      [[[-31.]]],\n","              \n","              \n","                      [[[-30.]]],\n","              \n","              \n","                      [[[-33.]]],\n","              \n","              \n","                      [[[-37.]]],\n","              \n","              \n","                      [[[-31.]]],\n","              \n","              \n","                      [[[-26.]]],\n","              \n","              \n","                      [[[-34.]]],\n","              \n","              \n","                      [[[-30.]]],\n","              \n","              \n","                      [[[-31.]]],\n","              \n","              \n","                      [[[-22.]]],\n","              \n","              \n","                      [[[-23.]]],\n","              \n","              \n","                      [[[-27.]]],\n","              \n","              \n","                      [[[-28.]]],\n","              \n","              \n","                      [[[-28.]]],\n","              \n","              \n","                      [[[-28.]]],\n","              \n","              \n","                      [[[-30.]]],\n","              \n","              \n","                      [[[-28.]]],\n","              \n","              \n","                      [[[-30.]]],\n","              \n","              \n","                      [[[-30.]]],\n","              \n","              \n","                      [[[-31.]]],\n","              \n","              \n","                      [[[-28.]]],\n","              \n","              \n","                      [[[-26.]]],\n","              \n","              \n","                      [[[-36.]]],\n","              \n","              \n","                      [[[-24.]]],\n","              \n","              \n","                      [[[-29.]]],\n","              \n","              \n","                      [[[-30.]]],\n","              \n","              \n","                      [[[-29.]]],\n","              \n","              \n","                      [[[-28.]]],\n","              \n","              \n","                      [[[-25.]]],\n","              \n","              \n","                      [[[-32.]]],\n","              \n","              \n","                      [[[-25.]]],\n","              \n","              \n","                      [[[-32.]]],\n","              \n","              \n","                      [[[-28.]]],\n","              \n","              \n","                      [[[-30.]]],\n","              \n","              \n","                      [[[-33.]]],\n","              \n","              \n","                      [[[-32.]]],\n","              \n","              \n","                      [[[-27.]]],\n","              \n","              \n","                      [[[-29.]]]], device='cuda:0')),\n","             ('module.layer3.2.conv1.fp_bias',\n","              tensor([-0.3388, -0.2158, -0.2754, -0.3570,  0.0587,  0.4261,  0.3613, -0.1590,\n","                       0.1134, -0.0039, -0.3000, -0.5024, -0.0249, -0.0773, -0.3444, -0.0224,\n","                       0.0835, -0.2082, -0.4694, -0.3234, -0.3973,  0.1611, -0.2650, -0.2048,\n","                       0.0111, -0.1394,  0.0653, -0.4308,  0.0911, -0.2290, -0.0737, -0.2002,\n","                      -0.3416, -0.7604, -0.3290, -0.1455, -0.2194, -0.0637, -0.2134, -0.2856,\n","                      -0.2453,  0.0012,  0.1843, -0.0747, -0.0016, -0.1557, -0.0147, -0.0842,\n","                       0.0029, -0.2075, -0.0429, -0.1244, -0.1531, -0.0810, -0.2563, -0.3678,\n","                      -0.0808, -0.4053, -0.2112, -0.2587, -0.2455, -0.0929, -0.1123, -0.3790],\n","                     device='cuda:0')),\n","             ('module.layer3.2.conv1.accum_scale', tensor([[[ 6865.5776]],\n","              \n","                      [[ 6648.2222]],\n","              \n","                      [[ 6066.4761]],\n","              \n","                      [[ 8494.9580]],\n","              \n","                      [[ 8514.2148]],\n","              \n","                      [[ 8141.7158]],\n","              \n","                      [[ 9063.3906]],\n","              \n","                      [[ 6988.9653]],\n","              \n","                      [[ 8670.9121]],\n","              \n","                      [[ 6953.3687]],\n","              \n","                      [[ 5571.6572]],\n","              \n","                      [[ 8097.0933]],\n","              \n","                      [[ 8827.2461]],\n","              \n","                      [[ 8145.8623]],\n","              \n","                      [[24911.2109]],\n","              \n","                      [[ 7249.8604]],\n","              \n","                      [[ 8031.4282]],\n","              \n","                      [[ 6970.3574]],\n","              \n","                      [[ 8261.6973]],\n","              \n","                      [[17598.2344]],\n","              \n","                      [[10517.4863]],\n","              \n","                      [[ 7232.4756]],\n","              \n","                      [[11221.2285]],\n","              \n","                      [[ 7976.5068]],\n","              \n","                      [[ 6659.0698]],\n","              \n","                      [[ 9017.7695]],\n","              \n","                      [[12274.2002]],\n","              \n","                      [[ 4537.8179]],\n","              \n","                      [[ 6755.4907]],\n","              \n","                      [[ 8220.4678]],\n","              \n","                      [[11761.9717]],\n","              \n","                      [[ 9351.2979]],\n","              \n","                      [[12082.6641]],\n","              \n","                      [[ 7011.9775]],\n","              \n","                      [[12311.7285]],\n","              \n","                      [[ 7725.5811]],\n","              \n","                      [[ 6250.4517]],\n","              \n","                      [[10411.1602]],\n","              \n","                      [[ 8481.9033]],\n","              \n","                      [[ 7080.5405]],\n","              \n","                      [[ 4529.2798]],\n","              \n","                      [[ 5301.5000]],\n","              \n","                      [[ 5675.6177]],\n","              \n","                      [[ 7450.2783]],\n","              \n","                      [[ 9724.3652]],\n","              \n","                      [[ 7070.7446]],\n","              \n","                      [[ 6360.4385]],\n","              \n","                      [[ 7546.9062]],\n","              \n","                      [[ 7890.2690]],\n","              \n","                      [[ 7280.6060]],\n","              \n","                      [[ 5607.3838]],\n","              \n","                      [[ 5696.8423]],\n","              \n","                      [[ 6455.5796]],\n","              \n","                      [[ 9360.9268]],\n","              \n","                      [[ 6705.7070]],\n","              \n","                      [[ 8874.6260]],\n","              \n","                      [[ 6520.7705]],\n","              \n","                      [[ 6270.0293]],\n","              \n","                      [[ 6298.0327]],\n","              \n","                      [[ 8544.2207]],\n","              \n","                      [[ 8611.9590]],\n","              \n","                      [[ 8790.5020]],\n","              \n","                      [[ 7583.0488]],\n","              \n","                      [[ 7720.6948]]], device='cuda:0')),\n","             ('module.layer3.2.conv1.is_simulated_quant_weight_shifted',\n","              tensor(False, device='cuda:0')),\n","             ('module.layer3.2.conv1.wrapped_module.weight',\n","              tensor([[[[32., 24., 32.],\n","                        [27., 25., 23.],\n","                        [24., 34., 20.]],\n","              \n","                       [[29., 31., 39.],\n","                        [32., 29., 32.],\n","                        [23., 25., 30.]],\n","              \n","                       [[38., 30., 44.],\n","                        [45., 40., 31.],\n","                        [50., 39., 27.]],\n","              \n","                       ...,\n","              \n","                       [[27., 27., 30.],\n","                        [24., 23., 27.],\n","                        [29., 26., 24.]],\n","              \n","                       [[50., 37., 32.],\n","                        [45., 29., 29.],\n","                        [19., 25., 44.]],\n","              \n","                       [[26., 26., 52.],\n","                        [20., 16., 22.],\n","                        [38., 34., 21.]]],\n","              \n","              \n","                      [[[28., 24., 16.],\n","                        [37., 42., 15.],\n","                        [34., 41., 24.]],\n","              \n","                       [[36., 32., 46.],\n","                        [33., 26., 29.],\n","                        [24., 26., 26.]],\n","              \n","                       [[48., 47., 25.],\n","                        [49., 45., 41.],\n","                        [34., 37., 29.]],\n","              \n","                       ...,\n","              \n","                       [[26., 30., 32.],\n","                        [25., 27., 31.],\n","                        [31., 31., 30.]],\n","              \n","                       [[27., 31., 38.],\n","                        [23., 25., 39.],\n","                        [25., 31., 23.]],\n","              \n","                       [[23., 46., 37.],\n","                        [31., 28., 36.],\n","                        [30., 32., 40.]]],\n","              \n","              \n","                      [[[37., 47., 33.],\n","                        [28., 34., 33.],\n","                        [ 6.,  9., 20.]],\n","              \n","                       [[27., 19., 22.],\n","                        [32., 25., 26.],\n","                        [22., 27., 24.]],\n","              \n","                       [[18., 10., 22.],\n","                        [34., 29., 39.],\n","                        [40., 46., 45.]],\n","              \n","                       ...,\n","              \n","                       [[31., 28., 28.],\n","                        [31., 27., 27.],\n","                        [30., 30., 28.]],\n","              \n","                       [[28., 31., 39.],\n","                        [13.,  3.,  7.],\n","                        [19., 13., 16.]],\n","              \n","                       [[40., 25., 27.],\n","                        [35., 23., 19.],\n","                        [30., 25., 24.]]],\n","              \n","              \n","                      ...,\n","              \n","              \n","                      [[[35., 28., 19.],\n","                        [45., 31., 32.],\n","                        [41., 39., 37.]],\n","              \n","                       [[21., 25., 35.],\n","                        [27., 30., 26.],\n","                        [33., 26., 24.]],\n","              \n","                       [[21., 35., 50.],\n","                        [25., 30., 28.],\n","                        [41., 56., 42.]],\n","              \n","                       ...,\n","              \n","                       [[35., 35., 33.],\n","                        [30., 33., 31.],\n","                        [31., 34., 32.]],\n","              \n","                       [[29., 20., 23.],\n","                        [30., 21., 27.],\n","                        [26., 22., 41.]],\n","              \n","                       [[23., 30., 31.],\n","                        [25., 36., 44.],\n","                        [20., 27., 36.]]],\n","              \n","              \n","                      [[[15., 12., 26.],\n","                        [ 9., 12., 23.],\n","                        [ 7., 12.,  4.]],\n","              \n","                       [[14., 11., 22.],\n","                        [14., 17., 29.],\n","                        [20., 25., 29.]],\n","              \n","                       [[ 6., 15., 15.],\n","                        [17., 26., 20.],\n","                        [29., 36., 29.]],\n","              \n","                       ...,\n","              \n","                       [[29., 22., 21.],\n","                        [30., 26., 26.],\n","                        [31., 31., 31.]],\n","              \n","                       [[33., 14., 19.],\n","                        [25., 10., 19.],\n","                        [19., 14., 24.]],\n","              \n","                       [[42., 39., 40.],\n","                        [48., 43., 28.],\n","                        [26., 26., 20.]]],\n","              \n","              \n","                      [[[38., 30., 24.],\n","                        [33., 25., 18.],\n","                        [60., 57., 38.]],\n","              \n","                       [[28., 23., 28.],\n","                        [25., 27., 34.],\n","                        [31., 36., 46.]],\n","              \n","                       [[39., 42., 30.],\n","                        [48., 37., 15.],\n","                        [21.,  9., 26.]],\n","              \n","                       ...,\n","              \n","                       [[25., 27., 28.],\n","                        [27., 26., 28.],\n","                        [32., 28., 28.]],\n","              \n","                       [[17., 16., 21.],\n","                        [21., 34., 25.],\n","                        [12., 30., 33.]],\n","              \n","                       [[33., 29., 23.],\n","                        [20., 29., 24.],\n","                        [ 3., 11.,  9.]]]], device='cuda:0')),\n","             ('module.layer3.2.conv1.wrapped_module.bias',\n","              tensor([-2.3260e+03, -1.4350e+03, -1.6710e+03, -3.0330e+03,  5.0000e+02,\n","                       3.4690e+03,  3.2750e+03, -1.1110e+03,  9.8400e+02, -2.7000e+01,\n","                      -1.6720e+03, -4.0680e+03, -2.2000e+02, -6.3000e+02, -8.5800e+03,\n","                      -1.6200e+02,  6.7100e+02, -1.4510e+03, -3.8780e+03, -5.6920e+03,\n","                      -4.1790e+03,  1.1650e+03, -2.9730e+03, -1.6340e+03,  7.4000e+01,\n","                      -1.2570e+03,  8.0200e+02, -1.9550e+03,  6.1500e+02, -1.8830e+03,\n","                      -8.6700e+02, -1.8720e+03, -4.1280e+03, -5.3320e+03, -4.0500e+03,\n","                      -1.1240e+03, -1.3710e+03, -6.6300e+02, -1.8100e+03, -2.0220e+03,\n","                      -1.1110e+03,  6.0000e+00,  1.0460e+03, -5.5600e+02, -1.5000e+01,\n","                      -1.1010e+03, -9.3000e+01, -6.3500e+02,  2.3000e+01, -1.5110e+03,\n","                      -2.4000e+02, -7.0900e+02, -9.8800e+02, -7.5800e+02, -1.7190e+03,\n","                      -3.2640e+03, -5.2700e+02, -2.5410e+03, -1.3300e+03, -2.2100e+03,\n","                      -2.1140e+03, -8.1600e+02, -8.5100e+02, -2.9260e+03], device='cuda:0')),\n","             ('module.layer3.2.conv2.num_forwards',\n","              tensor([40], device='cuda:0')),\n","             ('module.layer3.2.conv2.force_readjust',\n","              tensor(False, device='cuda:0')),\n","             ('module.layer3.2.conv2.output_scale',\n","              tensor([13.5600], device='cuda:0')),\n","             ('module.layer3.2.conv2.output_zero_point',\n","              tensor([-32.], device='cuda:0')),\n","             ('module.layer3.2.conv2.w_scale', tensor([[[[ 106.3055]]],\n","              \n","              \n","                      [[[  59.9982]]],\n","              \n","              \n","                      [[[ 101.7906]]],\n","              \n","              \n","                      [[[  81.4895]]],\n","              \n","              \n","                      [[[ 113.5761]]],\n","              \n","              \n","                      [[[  74.0178]]],\n","              \n","              \n","                      [[[  68.8432]]],\n","              \n","              \n","                      [[[  95.9906]]],\n","              \n","              \n","                      [[[  50.5056]]],\n","              \n","              \n","                      [[[  74.3117]]],\n","              \n","              \n","                      [[[  63.7273]]],\n","              \n","              \n","                      [[[  39.2068]]],\n","              \n","              \n","                      [[[ 217.1371]]],\n","              \n","              \n","                      [[[  50.4333]]],\n","              \n","              \n","                      [[[  61.7928]]],\n","              \n","              \n","                      [[[  82.3664]]],\n","              \n","              \n","                      [[[ 143.5733]]],\n","              \n","              \n","                      [[[  91.0085]]],\n","              \n","              \n","                      [[[  71.0092]]],\n","              \n","              \n","                      [[[ 111.7383]]],\n","              \n","              \n","                      [[[  45.1170]]],\n","              \n","              \n","                      [[[ 311.0742]]],\n","              \n","              \n","                      [[[  70.0720]]],\n","              \n","              \n","                      [[[  58.8890]]],\n","              \n","              \n","                      [[[ 101.4243]]],\n","              \n","              \n","                      [[[  99.9300]]],\n","              \n","              \n","                      [[[  79.0796]]],\n","              \n","              \n","                      [[[ 112.1098]]],\n","              \n","              \n","                      [[[  74.8080]]],\n","              \n","              \n","                      [[[ 298.5858]]],\n","              \n","              \n","                      [[[  41.0367]]],\n","              \n","              \n","                      [[[  46.4077]]],\n","              \n","              \n","                      [[[1635.8756]]],\n","              \n","              \n","                      [[[ 118.9474]]],\n","              \n","              \n","                      [[[  54.6869]]],\n","              \n","              \n","                      [[[  75.6935]]],\n","              \n","              \n","                      [[[  95.1777]]],\n","              \n","              \n","                      [[[  62.0869]]],\n","              \n","              \n","                      [[[  55.2533]]],\n","              \n","              \n","                      [[[  58.1819]]],\n","              \n","              \n","                      [[[ 151.2699]]],\n","              \n","              \n","                      [[[  89.0949]]],\n","              \n","              \n","                      [[[ 128.5846]]],\n","              \n","              \n","                      [[[ 129.4213]]],\n","              \n","              \n","                      [[[ 158.9042]]],\n","              \n","              \n","                      [[[ 111.3529]]],\n","              \n","              \n","                      [[[9348.9834]]],\n","              \n","              \n","                      [[[ 146.6469]]],\n","              \n","              \n","                      [[[  99.9495]]],\n","              \n","              \n","                      [[[ 270.9348]]],\n","              \n","              \n","                      [[[ 182.5647]]],\n","              \n","              \n","                      [[[  67.4918]]],\n","              \n","              \n","                      [[[ 113.1259]]],\n","              \n","              \n","                      [[[  46.4104]]],\n","              \n","              \n","                      [[[  78.2595]]],\n","              \n","              \n","                      [[[ 104.7391]]],\n","              \n","              \n","                      [[[  74.9809]]],\n","              \n","              \n","                      [[[  53.1792]]],\n","              \n","              \n","                      [[[  58.9367]]],\n","              \n","              \n","                      [[[ 147.2626]]],\n","              \n","              \n","                      [[[  88.2174]]],\n","              \n","              \n","                      [[[  51.6007]]],\n","              \n","              \n","                      [[[  86.5089]]],\n","              \n","              \n","                      [[[ 587.8951]]]], device='cuda:0')),\n","             ('module.layer3.2.conv2.w_zero_point', tensor([[[[-33.]]],\n","              \n","              \n","                      [[[-22.]]],\n","              \n","              \n","                      [[[-40.]]],\n","              \n","              \n","                      [[[-30.]]],\n","              \n","              \n","                      [[[-32.]]],\n","              \n","              \n","                      [[[-33.]]],\n","              \n","              \n","                      [[[-30.]]],\n","              \n","              \n","                      [[[-29.]]],\n","              \n","              \n","                      [[[-29.]]],\n","              \n","              \n","                      [[[-37.]]],\n","              \n","              \n","                      [[[-28.]]],\n","              \n","              \n","                      [[[-29.]]],\n","              \n","              \n","                      [[[-27.]]],\n","              \n","              \n","                      [[[-25.]]],\n","              \n","              \n","                      [[[-29.]]],\n","              \n","              \n","                      [[[-35.]]],\n","              \n","              \n","                      [[[-29.]]],\n","              \n","              \n","                      [[[-30.]]],\n","              \n","              \n","                      [[[-26.]]],\n","              \n","              \n","                      [[[-38.]]],\n","              \n","              \n","                      [[[-29.]]],\n","              \n","              \n","                      [[[-30.]]],\n","              \n","              \n","                      [[[-32.]]],\n","              \n","              \n","                      [[[-31.]]],\n","              \n","              \n","                      [[[-32.]]],\n","              \n","              \n","                      [[[-31.]]],\n","              \n","              \n","                      [[[-26.]]],\n","              \n","              \n","                      [[[-29.]]],\n","              \n","              \n","                      [[[-25.]]],\n","              \n","              \n","                      [[[-30.]]],\n","              \n","              \n","                      [[[-24.]]],\n","              \n","              \n","                      [[[-21.]]],\n","              \n","              \n","                      [[[-34.]]],\n","              \n","              \n","                      [[[-30.]]],\n","              \n","              \n","                      [[[-27.]]],\n","              \n","              \n","                      [[[-26.]]],\n","              \n","              \n","                      [[[-34.]]],\n","              \n","              \n","                      [[[-23.]]],\n","              \n","              \n","                      [[[-34.]]],\n","              \n","              \n","                      [[[-33.]]],\n","              \n","              \n","                      [[[-27.]]],\n","              \n","              \n","                      [[[-28.]]],\n","              \n","              \n","                      [[[-33.]]],\n","              \n","              \n","                      [[[-31.]]],\n","              \n","              \n","                      [[[-31.]]],\n","              \n","              \n","                      [[[-35.]]],\n","              \n","              \n","                      [[[-39.]]],\n","              \n","              \n","                      [[[-28.]]],\n","              \n","              \n","                      [[[-33.]]],\n","              \n","              \n","                      [[[-26.]]],\n","              \n","              \n","                      [[[-35.]]],\n","              \n","              \n","                      [[[-26.]]],\n","              \n","              \n","                      [[[-28.]]],\n","              \n","              \n","                      [[[-21.]]],\n","              \n","              \n","                      [[[-32.]]],\n","              \n","              \n","                      [[[-31.]]],\n","              \n","              \n","                      [[[-31.]]],\n","              \n","              \n","                      [[[-33.]]],\n","              \n","              \n","                      [[[-29.]]],\n","              \n","              \n","                      [[[-37.]]],\n","              \n","              \n","                      [[[-34.]]],\n","              \n","              \n","                      [[[-22.]]],\n","              \n","              \n","                      [[[-32.]]],\n","              \n","              \n","                      [[[-34.]]]], device='cuda:0')),\n","             ('module.layer3.2.conv2.fp_bias',\n","              tensor([-0.2059, -0.2472,  0.2186, -0.0752,  0.1994,  0.1399,  0.1550, -0.1801,\n","                      -0.0773,  0.4704,  0.1039, -0.1053,  0.0391,  0.0027, -0.5230, -0.1828,\n","                      -0.1625,  0.0026,  0.0113,  0.2150, -0.2189,  0.1285,  0.0159,  0.3251,\n","                       0.4370,  0.1244, -0.0622, -0.0730, -0.1323, -0.1336,  0.0135, -0.3554,\n","                      -0.0788, -0.1458,  0.3106, -0.2850,  0.0122, -0.1214,  0.3200,  0.1259,\n","                       0.1324, -0.0735, -0.0719,  0.2313,  0.0082,  0.1164, -0.0086,  0.0419,\n","                      -0.2008,  0.0281, -0.1118,  0.0217, -0.1971,  0.0251,  0.0904, -0.0752,\n","                       0.5737, -0.1405, -0.0754,  0.0359,  0.3031, -0.4865,  0.0746, -0.0312],\n","                     device='cuda:0')),\n","             ('module.layer3.2.conv2.accum_scale', tensor([[[  5496.1128]],\n","              \n","                      [[  3101.9751]],\n","              \n","                      [[  5262.6865]],\n","              \n","                      [[  4213.0957]],\n","              \n","                      [[  5872.0083]],\n","              \n","                      [[  3826.8005]],\n","              \n","                      [[  3559.2678]],\n","              \n","                      [[  4962.8184]],\n","              \n","                      [[  2611.1960]],\n","              \n","                      [[  3841.9983]],\n","              \n","                      [[  3294.7708]],\n","              \n","                      [[  2027.0359]],\n","              \n","                      [[ 11226.2275]],\n","              \n","                      [[  2607.4561]],\n","              \n","                      [[  3194.7573]],\n","              \n","                      [[  4258.4316]],\n","              \n","                      [[  7422.8955]],\n","              \n","                      [[  4705.2397]],\n","              \n","                      [[  3671.2532]],\n","              \n","                      [[  5776.9917]],\n","              \n","                      [[  2332.5977]],\n","              \n","                      [[ 16082.8779]],\n","              \n","                      [[  3622.8000]],\n","              \n","                      [[  3044.6235]],\n","              \n","                      [[  5243.7480]],\n","              \n","                      [[  5166.4897]],\n","              \n","                      [[  4088.5039]],\n","              \n","                      [[  5796.2012]],\n","              \n","                      [[  3867.6543]],\n","              \n","                      [[ 15437.2100]],\n","              \n","                      [[  2121.6426]],\n","              \n","                      [[  2399.3269]],\n","              \n","                      [[ 84576.5547]],\n","              \n","                      [[  6149.7114]],\n","              \n","                      [[  2827.3726]],\n","              \n","                      [[  3913.4380]],\n","              \n","                      [[  4920.7905]],\n","              \n","                      [[  3209.9600]],\n","              \n","                      [[  2856.6575]],\n","              \n","                      [[  3008.0654]],\n","              \n","                      [[  7820.8213]],\n","              \n","                      [[  4606.3062]],\n","              \n","                      [[  6647.9653]],\n","              \n","                      [[  6691.2231]],\n","              \n","                      [[  8215.5225]],\n","              \n","                      [[  5757.0664]],\n","              \n","                      [[483352.6562]],\n","              \n","                      [[  7581.8032]],\n","              \n","                      [[  5167.4961]],\n","              \n","                      [[ 14007.6240]],\n","              \n","                      [[  9438.7930]],\n","              \n","                      [[  3489.4021]],\n","              \n","                      [[  5848.7319]],\n","              \n","                      [[  2399.4705]],\n","              \n","                      [[  4046.0996]],\n","              \n","                      [[  5415.1255]],\n","              \n","                      [[  3876.5955]],\n","              \n","                      [[  2749.4207]],\n","              \n","                      [[  3047.0942]],\n","              \n","                      [[  7613.6392]],\n","              \n","                      [[  4560.9351]],\n","              \n","                      [[  2667.8101]],\n","              \n","                      [[  4472.6060]],\n","              \n","                      [[ 30394.8203]]], device='cuda:0')),\n","             ('module.layer3.2.conv2.is_simulated_quant_weight_shifted',\n","              tensor(False, device='cuda:0')),\n","             ('module.layer3.2.conv2.wrapped_module.weight',\n","              tensor([[[[36., 47., 43.],\n","                        [32., 38., 35.],\n","                        [35., 29., 25.]],\n","              \n","                       [[25., 52., 54.],\n","                        [28., 42., 43.],\n","                        [25., 29., 32.]],\n","              \n","                       [[30., 30., 27.],\n","                        [20., 24., 23.],\n","                        [20., 35., 39.]],\n","              \n","                       ...,\n","              \n","                       [[29., 43., 43.],\n","                        [19., 35., 35.],\n","                        [20., 31., 29.]],\n","              \n","                       [[30., 35., 32.],\n","                        [20., 23., 31.],\n","                        [22., 24., 37.]],\n","              \n","                       [[35., 45., 63.],\n","                        [35., 31., 39.],\n","                        [31., 29., 34.]]],\n","              \n","              \n","                      [[[26., 18., 19.],\n","                        [32., 19., 20.],\n","                        [31., 23., 26.]],\n","              \n","                       [[12., 13., 17.],\n","                        [33., 15.,  7.],\n","                        [50., 46., 22.]],\n","              \n","                       [[26., 26., 29.],\n","                        [21., 10., 23.],\n","                        [27., 18., 23.]],\n","              \n","                       ...,\n","              \n","                       [[13., 19., 20.],\n","                        [26., 24., 25.],\n","                        [27., 23., 20.]],\n","              \n","                       [[19., 20., 18.],\n","                        [16., 21., 24.],\n","                        [22., 23., 32.]],\n","              \n","                       [[14., 18., 26.],\n","                        [25., 18., 20.],\n","                        [26., 30., 20.]]],\n","              \n","              \n","                      [[[37., 31., 29.],\n","                        [32., 33., 37.],\n","                        [28., 26., 32.]],\n","              \n","                       [[18., 40., 51.],\n","                        [21., 46., 63.],\n","                        [33., 46., 53.]],\n","              \n","                       [[57., 43., 36.],\n","                        [43., 31., 34.],\n","                        [46., 45., 52.]],\n","              \n","                       ...,\n","              \n","                       [[36., 39., 41.],\n","                        [34., 35., 38.],\n","                        [25., 30., 34.]],\n","              \n","                       [[58., 37., 23.],\n","                        [50., 41., 33.],\n","                        [38., 40., 47.]],\n","              \n","                       [[22., 36., 51.],\n","                        [37., 44., 56.],\n","                        [30., 36., 43.]]],\n","              \n","              \n","                      ...,\n","              \n","              \n","                      [[[27., 14., 16.],\n","                        [38., 29., 25.],\n","                        [33., 27., 26.]],\n","              \n","                       [[16., 16., 16.],\n","                        [17., 22., 18.],\n","                        [17., 28., 20.]],\n","              \n","                       [[23., 22., 22.],\n","                        [26., 20., 20.],\n","                        [20., 22., 25.]],\n","              \n","                       ...,\n","              \n","                       [[35., 28., 19.],\n","                        [25., 27., 17.],\n","                        [19., 24., 17.]],\n","              \n","                       [[46., 45., 40.],\n","                        [42., 44., 36.],\n","                        [20., 32., 33.]],\n","              \n","                       [[14., 22., 18.],\n","                        [29., 26., 19.],\n","                        [33., 18., 17.]]],\n","              \n","              \n","                      [[[26., 37., 37.],\n","                        [20., 37., 32.],\n","                        [30., 38., 27.]],\n","              \n","                       [[29., 35., 42.],\n","                        [42., 40., 33.],\n","                        [35., 26., 21.]],\n","              \n","                       [[34., 27., 24.],\n","                        [41., 33., 25.],\n","                        [40., 35., 36.]],\n","              \n","                       ...,\n","              \n","                       [[40., 42., 42.],\n","                        [42., 40., 37.],\n","                        [29., 26., 33.]],\n","              \n","                       [[34., 32., 16.],\n","                        [38., 46., 34.],\n","                        [38., 28., 18.]],\n","              \n","                       [[43., 44., 27.],\n","                        [40., 50., 26.],\n","                        [24., 38., 29.]]],\n","              \n","              \n","                      [[[31., 21., 22.],\n","                        [32., 35., 40.],\n","                        [30., 37., 42.]],\n","              \n","                       [[53., 54., 42.],\n","                        [30., 45., 45.],\n","                        [29., 40., 41.]],\n","              \n","                       [[32., 33., 30.],\n","                        [30., 37., 37.],\n","                        [38., 35., 40.]],\n","              \n","                       ...,\n","              \n","                       [[36., 39., 36.],\n","                        [42., 43., 40.],\n","                        [45., 43., 37.]],\n","              \n","                       [[46., 51., 36.],\n","                        [46., 47., 34.],\n","                        [48., 36., 22.]],\n","              \n","                       [[30., 26., 23.],\n","                        [47., 34., 34.],\n","                        [40., 44., 46.]]]], device='cuda:0')),\n","             ('module.layer3.2.conv2.wrapped_module.bias',\n","              tensor([-1132.,  -767.,  1150.,  -317.,  1171.,   536.,   552.,  -894.,  -202.,\n","                       1807.,   342.,  -213.,   439.,     7., -1671.,  -778., -1206.,    12.,\n","                         42.,  1242.,  -511.,  2067.,    58.,   990.,  2292.,   643.,  -254.,\n","                       -423.,  -512., -2063.,    29.,  -853., -6661.,  -896.,   878., -1115.,\n","                         60.,  -390.,   914.,   379.,  1035.,  -338.,  -478.,  1548.,    67.,\n","                        670., -4148.,   317., -1038.,   393., -1055.,    76., -1153.,    60.,\n","                        366.,  -407.,  2224.,  -386.,  -230.,   273.,  1382., -1298.,   334.,\n","                       -948.], device='cuda:0')),\n","             ('module.layer3.2.relu2.num_forwards',\n","              tensor([40], device='cuda:0')),\n","             ('module.layer3.2.relu2.force_readjust',\n","              tensor(False, device='cuda:0')),\n","             ('module.layer3.2.relu2.output_scale',\n","              tensor([8.0033], device='cuda:0')),\n","             ('module.layer3.2.relu2.output_zero_point',\n","              tensor([0.], device='cuda:0')),\n","             ('module.layer3.2.residual_eltwiseadd.num_forwards',\n","              tensor([40], device='cuda:0')),\n","             ('module.layer3.2.residual_eltwiseadd.force_readjust',\n","              tensor(False, device='cuda:0')),\n","             ('module.layer3.2.residual_eltwiseadd.output_scale',\n","              tensor([8.0033], device='cuda:0')),\n","             ('module.layer3.2.residual_eltwiseadd.output_zero_point',\n","              tensor([0.], device='cuda:0')),\n","             ('module.layer3.3.conv1.num_forwards',\n","              tensor([40], device='cuda:0')),\n","             ('module.layer3.3.conv1.force_readjust',\n","              tensor(False, device='cuda:0')),\n","             ('module.layer3.3.conv1.output_scale',\n","              tensor([55.1522], device='cuda:0')),\n","             ('module.layer3.3.conv1.output_zero_point',\n","              tensor([0.], device='cuda:0')),\n","             ('module.layer3.3.conv1.w_scale', tensor([[[[ 908.5154]]],\n","              \n","              \n","                      [[[ 891.0162]]],\n","              \n","              \n","                      [[[1023.8630]]],\n","              \n","              \n","                      [[[ 739.9661]]],\n","              \n","              \n","                      [[[ 667.7540]]],\n","              \n","              \n","                      [[[ 944.5425]]],\n","              \n","              \n","                      [[[1047.7515]]],\n","              \n","              \n","                      [[[ 758.1315]]],\n","              \n","              \n","                      [[[ 841.1680]]],\n","              \n","              \n","                      [[[1054.6639]]],\n","              \n","              \n","                      [[[1202.7361]]],\n","              \n","              \n","                      [[[1414.1263]]],\n","              \n","              \n","                      [[[ 919.6120]]],\n","              \n","              \n","                      [[[ 721.5673]]],\n","              \n","              \n","                      [[[ 691.1212]]],\n","              \n","              \n","                      [[[ 691.3174]]],\n","              \n","              \n","                      [[[1347.4722]]],\n","              \n","              \n","                      [[[ 740.6889]]],\n","              \n","              \n","                      [[[ 960.2222]]],\n","              \n","              \n","                      [[[1145.8525]]],\n","              \n","              \n","                      [[[ 898.6411]]],\n","              \n","              \n","                      [[[1091.2194]]],\n","              \n","              \n","                      [[[1036.6271]]],\n","              \n","              \n","                      [[[1661.5829]]],\n","              \n","              \n","                      [[[ 734.5513]]],\n","              \n","              \n","                      [[[ 845.7755]]],\n","              \n","              \n","                      [[[ 956.4942]]],\n","              \n","              \n","                      [[[1260.5044]]],\n","              \n","              \n","                      [[[ 937.9489]]],\n","              \n","              \n","                      [[[ 941.4136]]],\n","              \n","              \n","                      [[[ 529.3248]]],\n","              \n","              \n","                      [[[ 790.4395]]],\n","              \n","              \n","                      [[[ 758.4711]]],\n","              \n","              \n","                      [[[ 902.6600]]],\n","              \n","              \n","                      [[[1509.6302]]],\n","              \n","              \n","                      [[[ 976.7942]]],\n","              \n","              \n","                      [[[1022.4617]]],\n","              \n","              \n","                      [[[ 980.2966]]],\n","              \n","              \n","                      [[[ 876.9093]]],\n","              \n","              \n","                      [[[ 704.3967]]],\n","              \n","              \n","                      [[[ 802.3898]]],\n","              \n","              \n","                      [[[ 952.1700]]],\n","              \n","              \n","                      [[[ 865.6267]]],\n","              \n","              \n","                      [[[ 872.5966]]],\n","              \n","              \n","                      [[[1033.9359]]],\n","              \n","              \n","                      [[[ 767.9905]]],\n","              \n","              \n","                      [[[1307.2399]]],\n","              \n","              \n","                      [[[ 749.4178]]],\n","              \n","              \n","                      [[[1059.8340]]],\n","              \n","              \n","                      [[[1609.7823]]],\n","              \n","              \n","                      [[[1007.6554]]],\n","              \n","              \n","                      [[[ 989.8579]]],\n","              \n","              \n","                      [[[1084.5385]]],\n","              \n","              \n","                      [[[ 719.1033]]],\n","              \n","              \n","                      [[[1852.3955]]],\n","              \n","              \n","                      [[[ 593.8835]]],\n","              \n","              \n","                      [[[1166.9039]]],\n","              \n","              \n","                      [[[1102.3920]]],\n","              \n","              \n","                      [[[ 943.6158]]],\n","              \n","              \n","                      [[[ 709.8474]]],\n","              \n","              \n","                      [[[ 880.5104]]],\n","              \n","              \n","                      [[[1236.9772]]],\n","              \n","              \n","                      [[[ 978.7702]]],\n","              \n","              \n","                      [[[1274.2351]]]], device='cuda:0')),\n","             ('module.layer3.3.conv1.w_zero_point', tensor([[[[-29.]]],\n","              \n","              \n","                      [[[-30.]]],\n","              \n","              \n","                      [[[-29.]]],\n","              \n","              \n","                      [[[-33.]]],\n","              \n","              \n","                      [[[-23.]]],\n","              \n","              \n","                      [[[-30.]]],\n","              \n","              \n","                      [[[-29.]]],\n","              \n","              \n","                      [[[-25.]]],\n","              \n","              \n","                      [[[-26.]]],\n","              \n","              \n","                      [[[-27.]]],\n","              \n","              \n","                      [[[-26.]]],\n","              \n","              \n","                      [[[-22.]]],\n","              \n","              \n","                      [[[-28.]]],\n","              \n","              \n","                      [[[-27.]]],\n","              \n","              \n","                      [[[-28.]]],\n","              \n","              \n","                      [[[-27.]]],\n","              \n","              \n","                      [[[-26.]]],\n","              \n","              \n","                      [[[-31.]]],\n","              \n","              \n","                      [[[-24.]]],\n","              \n","              \n","                      [[[-24.]]],\n","              \n","              \n","                      [[[-27.]]],\n","              \n","              \n","                      [[[-29.]]],\n","              \n","              \n","                      [[[-34.]]],\n","              \n","              \n","                      [[[-30.]]],\n","              \n","              \n","                      [[[-28.]]],\n","              \n","              \n","                      [[[-30.]]],\n","              \n","              \n","                      [[[-35.]]],\n","              \n","              \n","                      [[[-32.]]],\n","              \n","              \n","                      [[[-27.]]],\n","              \n","              \n","                      [[[-31.]]],\n","              \n","              \n","                      [[[-27.]]],\n","              \n","              \n","                      [[[-33.]]],\n","              \n","              \n","                      [[[-30.]]],\n","              \n","              \n","                      [[[-30.]]],\n","              \n","              \n","                      [[[-23.]]],\n","              \n","              \n","                      [[[-23.]]],\n","              \n","              \n","                      [[[-23.]]],\n","              \n","              \n","                      [[[-30.]]],\n","              \n","              \n","                      [[[-21.]]],\n","              \n","              \n","                      [[[-25.]]],\n","              \n","              \n","                      [[[-24.]]],\n","              \n","              \n","                      [[[-30.]]],\n","              \n","              \n","                      [[[-28.]]],\n","              \n","              \n","                      [[[-33.]]],\n","              \n","              \n","                      [[[-28.]]],\n","              \n","              \n","                      [[[-22.]]],\n","              \n","              \n","                      [[[-31.]]],\n","              \n","              \n","                      [[[-30.]]],\n","              \n","              \n","                      [[[-29.]]],\n","              \n","              \n","                      [[[-26.]]],\n","              \n","              \n","                      [[[-27.]]],\n","              \n","              \n","                      [[[-34.]]],\n","              \n","              \n","                      [[[-27.]]],\n","              \n","              \n","                      [[[-38.]]],\n","              \n","              \n","                      [[[-25.]]],\n","              \n","              \n","                      [[[-27.]]],\n","              \n","              \n","                      [[[-27.]]],\n","              \n","              \n","                      [[[-22.]]],\n","              \n","              \n","                      [[[-23.]]],\n","              \n","              \n","                      [[[-30.]]],\n","              \n","              \n","                      [[[-27.]]],\n","              \n","              \n","                      [[[-34.]]],\n","              \n","              \n","                      [[[-29.]]],\n","              \n","              \n","                      [[[-29.]]]], device='cuda:0')),\n","             ('module.layer3.3.conv1.fp_bias',\n","              tensor([-0.3682, -0.1407, -0.3667, -0.0442, -0.2503, -0.1010, -0.1762, -0.5606,\n","                      -0.0877, -0.1655, -0.2651, -0.5302, -0.2517, -0.4622, -0.2941, -0.2012,\n","                      -0.8060, -0.3055, -0.3999, -0.3193,  0.1920, -0.4377, -0.1739, -0.2451,\n","                      -0.0071, -0.3293,  0.5274, -0.1586, -0.2565, -0.0672, -0.0563, -0.0676,\n","                       0.1023, -0.1386, -0.1668, -0.5481, -0.5388, -0.3834, -0.0365, -0.3284,\n","                      -0.2257, -0.0228, -0.1626, -0.0223, -0.3858, -0.3569, -0.2117,  0.0460,\n","                      -0.4867, -0.0238, -0.1591,  0.0179, -0.3352, -0.1401,  0.0024,  0.2392,\n","                       0.0132, -0.1945,  0.0391, -0.0319, -0.4206,  0.1600, -0.3570, -0.3280],\n","                     device='cuda:0')),\n","             ('module.layer3.3.conv1.accum_scale', tensor([[[ 7271.1104]],\n","              \n","                      [[ 7131.0586]],\n","              \n","                      [[ 8194.2695]],\n","              \n","                      [[ 5922.1616]],\n","              \n","                      [[ 5344.2271]],\n","              \n","                      [[ 7559.4448]],\n","              \n","                      [[ 8385.4561]],\n","              \n","                      [[ 6067.5444]],\n","              \n","                      [[ 6732.1094]],\n","              \n","                      [[ 8440.7783]],\n","              \n","                      [[ 9625.8428]],\n","              \n","                      [[11317.6592]],\n","              \n","                      [[ 7359.9189]],\n","              \n","                      [[ 5774.9106]],\n","              \n","                      [[ 5531.2417]],\n","              \n","                      [[ 5532.8115]],\n","              \n","                      [[10784.2070]],\n","              \n","                      [[ 5927.9463]],\n","              \n","                      [[ 7684.9346]],\n","              \n","                      [[ 9170.5869]],\n","              \n","                      [[ 7192.0830]],\n","              \n","                      [[ 8733.3418]],\n","              \n","                      [[ 8296.4248]],\n","              \n","                      [[13298.1250]],\n","              \n","                      [[ 5878.8247]],\n","              \n","                      [[ 6768.9839]],\n","              \n","                      [[ 7655.0981]],\n","              \n","                      [[10088.1787]],\n","              \n","                      [[ 7506.6743]],\n","              \n","                      [[ 7534.4038]],\n","              \n","                      [[ 4236.3384]],\n","              \n","                      [[ 6326.1143]],\n","              \n","                      [[ 6070.2622]],\n","              \n","                      [[ 7224.2471]],\n","              \n","                      [[12082.0049]],\n","              \n","                      [[ 7817.5645]],\n","              \n","                      [[ 8183.0552]],\n","              \n","                      [[ 7845.5957]],\n","              \n","                      [[ 7018.1572]],\n","              \n","                      [[ 5637.4888]],\n","              \n","                      [[ 6421.7563]],\n","              \n","                      [[ 7620.4902]],\n","              \n","                      [[ 6927.8594]],\n","              \n","                      [[ 6983.6411]],\n","              \n","                      [[ 8274.8857]],\n","              \n","                      [[ 6146.4487]],\n","              \n","                      [[10462.2158]],\n","              \n","                      [[ 5997.8057]],\n","              \n","                      [[ 8482.1562]],\n","              \n","                      [[12883.5508]],\n","              \n","                      [[ 8064.5557]],\n","              \n","                      [[ 7922.1172]],\n","              \n","                      [[ 8679.8730]],\n","              \n","                      [[ 5755.1899]],\n","              \n","                      [[14825.2539]],\n","              \n","                      [[ 4753.0205]],\n","              \n","                      [[ 9339.0674]],\n","              \n","                      [[ 8822.7598]],\n","              \n","                      [[ 7552.0288]],\n","              \n","                      [[ 5681.1123]],\n","              \n","                      [[ 7046.9775]],\n","              \n","                      [[ 9899.8838]],\n","              \n","                      [[ 7833.3789]],\n","              \n","                      [[10198.0693]]], device='cuda:0')),\n","             ('module.layer3.3.conv1.is_simulated_quant_weight_shifted',\n","              tensor(False, device='cuda:0')),\n","             ('module.layer3.3.conv1.wrapped_module.weight',\n","              tensor([[[[43., 28., 31.],\n","                        [32., 15., 18.],\n","                        [20., 17., 27.]],\n","              \n","                       [[34., 37., 34.],\n","                        [28., 39., 37.],\n","                        [28., 29., 29.]],\n","              \n","                       [[24., 31., 31.],\n","                        [29., 33., 36.],\n","                        [36., 26., 34.]],\n","              \n","                       ...,\n","              \n","                       [[27., 31., 34.],\n","                        [24., 30., 35.],\n","                        [24., 28., 32.]],\n","              \n","                       [[28., 19., 23.],\n","                        [33., 29., 30.],\n","                        [43., 36., 33.]],\n","              \n","                       [[39., 31., 32.],\n","                        [34., 37., 26.],\n","                        [36., 35., 31.]]],\n","              \n","              \n","                      [[[37., 40., 26.],\n","                        [22., 34., 19.],\n","                        [16., 30., 20.]],\n","              \n","                       [[30., 30., 39.],\n","                        [35., 31., 26.],\n","                        [35., 32., 18.]],\n","              \n","                       [[27., 33., 35.],\n","                        [15.,  7., 26.],\n","                        [16., 13., 32.]],\n","              \n","                       ...,\n","              \n","                       [[30., 27., 30.],\n","                        [29., 26., 26.],\n","                        [27., 28., 28.]],\n","              \n","                       [[24., 36., 51.],\n","                        [21., 19., 46.],\n","                        [43., 41., 40.]],\n","              \n","                       [[29., 20., 18.],\n","                        [25., 23., 11.],\n","                        [29., 29., 18.]]],\n","              \n","              \n","                      [[[23., 24.,  6.],\n","                        [26., 23., 17.],\n","                        [50., 24., 42.]],\n","              \n","                       [[35., 36., 32.],\n","                        [28., 30., 36.],\n","                        [30., 36., 31.]],\n","              \n","                       [[39., 29., 11.],\n","                        [34., 32., 19.],\n","                        [29., 24., 18.]],\n","              \n","                       ...,\n","              \n","                       [[30., 27., 29.],\n","                        [31., 27., 31.],\n","                        [35., 34., 34.]],\n","              \n","                       [[11., 30., 39.],\n","                        [ 8., 34., 49.],\n","                        [28., 45., 45.]],\n","              \n","                       [[10., 11., 28.],\n","                        [20., 20., 31.],\n","                        [56., 55., 41.]]],\n","              \n","              \n","                      ...,\n","              \n","              \n","                      [[[17., 26., 24.],\n","                        [18., 25., 29.],\n","                        [41., 31., 36.]],\n","              \n","                       [[34., 32., 38.],\n","                        [35., 26., 29.],\n","                        [34., 27., 28.]],\n","              \n","                       [[50., 38., 46.],\n","                        [43., 38., 40.],\n","                        [32., 40., 47.]],\n","              \n","                       ...,\n","              \n","                       [[32., 30., 28.],\n","                        [37., 36., 34.],\n","                        [33., 31., 31.]],\n","              \n","                       [[27., 27., 30.],\n","                        [31., 18., 24.],\n","                        [44., 21., 22.]],\n","              \n","                       [[40., 19., 18.],\n","                        [40., 14., 27.],\n","                        [43., 27., 44.]]],\n","              \n","              \n","                      [[[19., 27., 35.],\n","                        [ 6., 21., 35.],\n","                        [ 6., 21., 33.]],\n","              \n","                       [[21., 19., 20.],\n","                        [34., 25., 21.],\n","                        [29., 34., 34.]],\n","              \n","                       [[26., 28., 17.],\n","                        [42., 48., 42.],\n","                        [63., 55., 45.]],\n","              \n","                       ...,\n","              \n","                       [[34., 26., 25.],\n","                        [40., 31., 24.],\n","                        [36., 28., 20.]],\n","              \n","                       [[45., 35., 29.],\n","                        [44., 33., 32.],\n","                        [37., 26., 30.]],\n","              \n","                       [[48., 33., 25.],\n","                        [55., 27., 30.],\n","                        [32., 39., 44.]]],\n","              \n","              \n","                      [[[16., 18., 16.],\n","                        [20., 23., 37.],\n","                        [23., 13., 31.]],\n","              \n","                       [[33., 23., 22.],\n","                        [46., 41., 29.],\n","                        [41., 35., 30.]],\n","              \n","                       [[37., 23., 20.],\n","                        [24., 37., 37.],\n","                        [31., 27., 26.]],\n","              \n","                       ...,\n","              \n","                       [[30., 32., 32.],\n","                        [26., 24., 24.],\n","                        [27., 28., 26.]],\n","              \n","                       [[29., 25., 25.],\n","                        [22., 16., 20.],\n","                        [39., 37., 22.]],\n","              \n","                       [[41., 35., 28.],\n","                        [40., 49., 31.],\n","                        [35., 34., 39.]]]], device='cuda:0')),\n","             ('module.layer3.3.conv1.wrapped_module.bias',\n","              tensor([-2678., -1003., -3005.,  -262., -1338.,  -764., -1478., -3401.,  -590.,\n","                      -1397., -2552., -6001., -1853., -2669., -1627., -1113., -8692., -1811.,\n","                      -3074., -2928.,  1381., -3823., -1442., -3259.,   -42., -2229.,  4038.,\n","                      -1600., -1925.,  -506.,  -238.,  -427.,   621., -1001., -2015., -4285.,\n","                      -4409., -3008.,  -256., -1851., -1449.,  -174., -1126.,  -155., -3192.,\n","                      -2194., -2215.,   276., -4128.,  -306., -1283.,   142., -2909.,  -806.,\n","                         36.,  1137.,   124., -1716.,   296.,  -181., -2964.,  1584., -2797.,\n","                      -3345.], device='cuda:0')),\n","             ('module.layer3.3.conv2.num_forwards',\n","              tensor([40], device='cuda:0')),\n","             ('module.layer3.3.conv2.force_readjust',\n","              tensor(False, device='cuda:0')),\n","             ('module.layer3.3.conv2.output_scale',\n","              tensor([11.7229], device='cuda:0')),\n","             ('module.layer3.3.conv2.output_zero_point',\n","              tensor([-34.], device='cuda:0')),\n","             ('module.layer3.3.conv2.w_scale', tensor([[[[  37.0289]]],\n","              \n","              \n","                      [[[  87.1098]]],\n","              \n","              \n","                      [[[  79.0536]]],\n","              \n","              \n","                      [[[  37.2162]]],\n","              \n","              \n","                      [[[ 105.9180]]],\n","              \n","              \n","                      [[[  77.0008]]],\n","              \n","              \n","                      [[[  67.9587]]],\n","              \n","              \n","                      [[[ 112.7960]]],\n","              \n","              \n","                      [[[  61.8521]]],\n","              \n","              \n","                      [[[  60.5238]]],\n","              \n","              \n","                      [[[  92.0132]]],\n","              \n","              \n","                      [[[  32.3670]]],\n","              \n","              \n","                      [[[  73.4577]]],\n","              \n","              \n","                      [[[  61.2981]]],\n","              \n","              \n","                      [[[  66.9899]]],\n","              \n","              \n","                      [[[ 137.9315]]],\n","              \n","              \n","                      [[[  44.2016]]],\n","              \n","              \n","                      [[[  99.7818]]],\n","              \n","              \n","                      [[[ 104.1738]]],\n","              \n","              \n","                      [[[ 106.1807]]],\n","              \n","              \n","                      [[[  92.0078]]],\n","              \n","              \n","                      [[[ 646.1292]]],\n","              \n","              \n","                      [[[  83.5974]]],\n","              \n","              \n","                      [[[  80.4837]]],\n","              \n","              \n","                      [[[ 166.8369]]],\n","              \n","              \n","                      [[[ 151.6317]]],\n","              \n","              \n","                      [[[  74.5993]]],\n","              \n","              \n","                      [[[ 101.4123]]],\n","              \n","              \n","                      [[[ 133.3089]]],\n","              \n","              \n","                      [[[  76.0058]]],\n","              \n","              \n","                      [[[  91.3967]]],\n","              \n","              \n","                      [[[  62.0255]]],\n","              \n","              \n","                      [[[ 124.2860]]],\n","              \n","              \n","                      [[[ 129.0155]]],\n","              \n","              \n","                      [[[  64.4002]]],\n","              \n","              \n","                      [[[  54.9010]]],\n","              \n","              \n","                      [[[ 105.3317]]],\n","              \n","              \n","                      [[[  62.8335]]],\n","              \n","              \n","                      [[[  46.1709]]],\n","              \n","              \n","                      [[[  55.7344]]],\n","              \n","              \n","                      [[[  96.0053]]],\n","              \n","              \n","                      [[[  67.9107]]],\n","              \n","              \n","                      [[[ 474.9359]]],\n","              \n","              \n","                      [[[ 129.1559]]],\n","              \n","              \n","                      [[[ 246.5462]]],\n","              \n","              \n","                      [[[  90.8956]]],\n","              \n","              \n","                      [[[8137.1226]]],\n","              \n","              \n","                      [[[ 383.1017]]],\n","              \n","              \n","                      [[[  75.2587]]],\n","              \n","              \n","                      [[[ 297.4073]]],\n","              \n","              \n","                      [[[  40.1757]]],\n","              \n","              \n","                      [[[ 114.8309]]],\n","              \n","              \n","                      [[[  83.3820]]],\n","              \n","              \n","                      [[[ 106.7602]]],\n","              \n","              \n","                      [[[ 172.9898]]],\n","              \n","              \n","                      [[[ 116.7870]]],\n","              \n","              \n","                      [[[ 144.2399]]],\n","              \n","              \n","                      [[[  67.3066]]],\n","              \n","              \n","                      [[[  47.2725]]],\n","              \n","              \n","                      [[[  56.9906]]],\n","              \n","              \n","                      [[[  67.5550]]],\n","              \n","              \n","                      [[[ 152.2583]]],\n","              \n","              \n","                      [[[  98.6761]]],\n","              \n","              \n","                      [[[ 401.9215]]]], device='cuda:0')),\n","             ('module.layer3.3.conv2.w_zero_point', tensor([[[[-36.]]],\n","              \n","              \n","                      [[[-29.]]],\n","              \n","              \n","                      [[[-33.]]],\n","              \n","              \n","                      [[[-26.]]],\n","              \n","              \n","                      [[[-35.]]],\n","              \n","              \n","                      [[[-30.]]],\n","              \n","              \n","                      [[[-25.]]],\n","              \n","              \n","                      [[[-28.]]],\n","              \n","              \n","                      [[[-28.]]],\n","              \n","              \n","                      [[[-25.]]],\n","              \n","              \n","                      [[[-36.]]],\n","              \n","              \n","                      [[[-19.]]],\n","              \n","              \n","                      [[[-31.]]],\n","              \n","              \n","                      [[[-24.]]],\n","              \n","              \n","                      [[[-29.]]],\n","              \n","              \n","                      [[[-32.]]],\n","              \n","              \n","                      [[[-29.]]],\n","              \n","              \n","                      [[[-27.]]],\n","              \n","              \n","                      [[[-32.]]],\n","              \n","              \n","                      [[[-28.]]],\n","              \n","              \n","                      [[[-39.]]],\n","              \n","              \n","                      [[[-34.]]],\n","              \n","              \n","                      [[[-35.]]],\n","              \n","              \n","                      [[[-31.]]],\n","              \n","              \n","                      [[[-33.]]],\n","              \n","              \n","                      [[[-35.]]],\n","              \n","              \n","                      [[[-36.]]],\n","              \n","              \n","                      [[[-29.]]],\n","              \n","              \n","                      [[[-32.]]],\n","              \n","              \n","                      [[[-31.]]],\n","              \n","              \n","                      [[[-30.]]],\n","              \n","              \n","                      [[[-30.]]],\n","              \n","              \n","                      [[[-29.]]],\n","              \n","              \n","                      [[[-32.]]],\n","              \n","              \n","                      [[[-28.]]],\n","              \n","              \n","                      [[[-21.]]],\n","              \n","              \n","                      [[[-31.]]],\n","              \n","              \n","                      [[[-27.]]],\n","              \n","              \n","                      [[[-32.]]],\n","              \n","              \n","                      [[[-31.]]],\n","              \n","              \n","                      [[[-36.]]],\n","              \n","              \n","                      [[[-33.]]],\n","              \n","              \n","                      [[[-39.]]],\n","              \n","              \n","                      [[[-40.]]],\n","              \n","              \n","                      [[[-25.]]],\n","              \n","              \n","                      [[[-31.]]],\n","              \n","              \n","                      [[[-35.]]],\n","              \n","              \n","                      [[[-36.]]],\n","              \n","              \n","                      [[[-31.]]],\n","              \n","              \n","                      [[[-32.]]],\n","              \n","              \n","                      [[[-30.]]],\n","              \n","              \n","                      [[[-28.]]],\n","              \n","              \n","                      [[[-31.]]],\n","              \n","              \n","                      [[[-29.]]],\n","              \n","              \n","                      [[[-30.]]],\n","              \n","              \n","                      [[[-38.]]],\n","              \n","              \n","                      [[[-32.]]],\n","              \n","              \n","                      [[[-29.]]],\n","              \n","              \n","                      [[[-25.]]],\n","              \n","              \n","                      [[[-24.]]],\n","              \n","              \n","                      [[[-28.]]],\n","              \n","              \n","                      [[[-28.]]],\n","              \n","              \n","                      [[[-28.]]],\n","              \n","              \n","                      [[[-32.]]]], device='cuda:0')),\n","             ('module.layer3.3.conv2.fp_bias',\n","              tensor([-0.4332, -0.1276,  0.4311,  0.3234,  0.0409,  0.0595, -0.0275, -0.0249,\n","                       0.1238,  0.4257,  0.1737, -0.3459,  0.0529,  0.2112, -0.4575,  0.0386,\n","                      -0.1484,  0.0623, -0.1164, -0.1051,  0.0131, -0.0384, -0.1161,  0.0799,\n","                      -0.0075,  0.1208,  0.2637, -0.0861, -0.1664, -0.0246, -0.1371, -0.0197,\n","                      -0.1343, -0.2693,  0.3239, -0.2847, -0.0511,  0.0513,  0.2001,  0.0482,\n","                       0.0567, -0.0392, -0.1193,  0.4102,  0.0453,  0.1830, -0.0089, -0.0770,\n","                      -0.1311,  0.0545,  0.7579,  0.1150,  0.0031, -0.1330, -0.0098,  0.0432,\n","                       0.2441, -0.4763, -0.3627,  0.0403, -0.0305, -0.1679, -0.0449,  0.0616],\n","                     device='cuda:0')),\n","             ('module.layer3.3.conv2.accum_scale', tensor([[[  2042.2233]],\n","              \n","                      [[  4804.2969]],\n","              \n","                      [[  4359.9756]],\n","              \n","                      [[  2052.5552]],\n","              \n","                      [[  5841.6074]],\n","              \n","                      [[  4246.7612]],\n","              \n","                      [[  3748.0671]],\n","              \n","                      [[  6220.9453]],\n","              \n","                      [[  3411.2754]],\n","              \n","                      [[  3338.0173]],\n","              \n","                      [[  5074.7280]],\n","              \n","                      [[  1785.1082]],\n","              \n","                      [[  4051.3508]],\n","              \n","                      [[  3380.7224]],\n","              \n","                      [[  3694.6382]],\n","              \n","                      [[  7607.2188]],\n","              \n","                      [[  2437.8145]],\n","              \n","                      [[  5503.1802]],\n","              \n","                      [[  5745.4131]],\n","              \n","                      [[  5856.0962]],\n","              \n","                      [[  5074.4312]],\n","              \n","                      [[ 35635.4219]],\n","              \n","                      [[  4610.5757]],\n","              \n","                      [[  4438.8521]],\n","              \n","                      [[  9201.4141]],\n","              \n","                      [[  8362.8145]],\n","              \n","                      [[  4114.3145]],\n","              \n","                      [[  5593.1089]],\n","              \n","                      [[  7352.2764]],\n","              \n","                      [[  4191.8848]],\n","              \n","                      [[  5040.7261]],\n","              \n","                      [[  3420.8433]],\n","              \n","                      [[  6854.6406]],\n","              \n","                      [[  7115.4839]],\n","              \n","                      [[  3551.8105]],\n","              \n","                      [[  3027.9080]],\n","              \n","                      [[  5809.2695]],\n","              \n","                      [[  3465.4021]],\n","              \n","                      [[  2546.4241]],\n","              \n","                      [[  3073.8713]],\n","              \n","                      [[  5294.8979]],\n","              \n","                      [[  3745.4221]],\n","              \n","                      [[ 26193.7441]],\n","              \n","                      [[  7123.2280]],\n","              \n","                      [[ 13597.5566]],\n","              \n","                      [[  5013.0918]],\n","              \n","                      [[448779.9375]],\n","              \n","                      [[ 21128.8867]],\n","              \n","                      [[  4150.6826]],\n","              \n","                      [[ 16402.6562]],\n","              \n","                      [[  2215.7769]],\n","              \n","                      [[  6333.1743]],\n","              \n","                      [[  4598.6953]],\n","              \n","                      [[  5888.0542]],\n","              \n","                      [[  9540.7646]],\n","              \n","                      [[  6441.0566]],\n","              \n","                      [[  7955.1455]],\n","              \n","                      [[  3712.1077]],\n","              \n","                      [[  2607.1816]],\n","              \n","                      [[  3143.1565]],\n","              \n","                      [[  3725.8044]],\n","              \n","                      [[  8397.3730]],\n","              \n","                      [[  5442.2026]],\n","              \n","                      [[ 22166.8418]]], device='cuda:0')),\n","             ('module.layer3.3.conv2.is_simulated_quant_weight_shifted',\n","              tensor(False, device='cuda:0')),\n","             ('module.layer3.3.conv2.wrapped_module.weight',\n","              tensor([[[[40., 32., 23.],\n","                        [37., 31., 32.],\n","                        [23., 25., 34.]],\n","              \n","                       [[43., 40., 32.],\n","                        [28., 27., 26.],\n","                        [33., 27., 25.]],\n","              \n","                       [[55., 50., 36.],\n","                        [37., 39., 37.],\n","                        [24., 35., 40.]],\n","              \n","                       ...,\n","              \n","                       [[29., 31., 34.],\n","                        [35., 36., 34.],\n","                        [35., 35., 32.]],\n","              \n","                       [[29., 34., 40.],\n","                        [35., 35., 37.],\n","                        [36., 30., 29.]],\n","              \n","                       [[40., 33., 30.],\n","                        [34., 26., 29.],\n","                        [35., 32., 29.]]],\n","              \n","              \n","                      [[[25., 17., 19.],\n","                        [32., 28., 27.],\n","                        [27., 33., 46.]],\n","              \n","                       [[19., 15., 23.],\n","                        [19., 22., 26.],\n","                        [15., 28., 36.]],\n","              \n","                       [[24., 24., 28.],\n","                        [48., 32., 22.],\n","                        [31.,  8., 10.]],\n","              \n","                       ...,\n","              \n","                       [[28., 27., 22.],\n","                        [24., 22., 18.],\n","                        [24., 20., 24.]],\n","              \n","                       [[28., 31., 23.],\n","                        [22., 30., 33.],\n","                        [10., 14., 32.]],\n","              \n","                       [[42., 37., 33.],\n","                        [36., 42., 38.],\n","                        [30., 23., 22.]]],\n","              \n","              \n","                      [[[29., 33., 27.],\n","                        [30., 30., 34.],\n","                        [29., 29., 34.]],\n","              \n","                       [[45., 31., 27.],\n","                        [45., 34., 33.],\n","                        [40., 28., 34.]],\n","              \n","                       [[57., 24., 19.],\n","                        [34., 16., 18.],\n","                        [32., 24., 18.]],\n","              \n","                       ...,\n","              \n","                       [[19., 16., 16.],\n","                        [22., 24.,  7.],\n","                        [30., 27., 23.]],\n","              \n","                       [[11., 21., 16.],\n","                        [21., 18., 10.],\n","                        [31., 27., 28.]],\n","              \n","                       [[32., 26., 25.],\n","                        [22., 22., 30.],\n","                        [14., 21., 27.]]],\n","              \n","              \n","                      ...,\n","              \n","              \n","                      [[[13.,  5., 13.],\n","                        [21., 11., 17.],\n","                        [15., 17., 27.]],\n","              \n","                       [[27., 23., 23.],\n","                        [14., 25., 27.],\n","                        [20., 36., 32.]],\n","              \n","                       [[30., 25., 27.],\n","                        [45., 28., 28.],\n","                        [30., 30., 18.]],\n","              \n","                       ...,\n","              \n","                       [[28., 18., 16.],\n","                        [26., 28., 23.],\n","                        [28., 32., 31.]],\n","              \n","                       [[30., 35., 27.],\n","                        [21., 44., 52.],\n","                        [23., 40., 51.]],\n","              \n","                       [[27., 10.,  8.],\n","                        [28., 18., 25.],\n","                        [29., 25., 35.]]],\n","              \n","              \n","                      [[[40., 38., 37.],\n","                        [29., 22., 30.],\n","                        [32., 28., 40.]],\n","              \n","                       [[33., 16., 25.],\n","                        [33., 32., 35.],\n","                        [22., 27., 28.]],\n","              \n","                       [[26., 23., 18.],\n","                        [38., 37., 19.],\n","                        [26., 31., 25.]],\n","              \n","                       ...,\n","              \n","                       [[16., 19., 28.],\n","                        [26., 23., 32.],\n","                        [29., 26., 27.]],\n","              \n","                       [[ 9., 10., 11.],\n","                        [12.,  5., 20.],\n","                        [13.,  9., 23.]],\n","              \n","                       [[13., 33., 33.],\n","                        [12., 17., 18.],\n","                        [20., 19., 24.]]],\n","              \n","              \n","                      [[[26., 31., 53.],\n","                        [27., 23., 27.],\n","                        [23., 23., 20.]],\n","              \n","                       [[22., 17., 27.],\n","                        [36., 20., 21.],\n","                        [37., 11., 12.]],\n","              \n","                       [[29., 20., 27.],\n","                        [23.,  7.,  5.],\n","                        [39., 10., 20.]],\n","              \n","                       ...,\n","              \n","                       [[30., 11., 12.],\n","                        [28., 27., 39.],\n","                        [28., 34., 39.]],\n","              \n","                       [[32., 20., 25.],\n","                        [39., 32., 33.],\n","                        [29., 30., 36.]],\n","              \n","                       [[23., 29., 30.],\n","                        [20., 37., 33.],\n","                        [23., 30., 30.]]]], device='cuda:0')),\n","             ('module.layer3.3.conv2.wrapped_module.bias',\n","              tensor([ -885.,  -613.,  1880.,   664.,   239.,   253.,  -103.,  -155.,   422.,\n","                       1421.,   881.,  -618.,   214.,   714., -1690.,   294.,  -362.,   343.,\n","                       -669.,  -616.,    66., -1370.,  -535.,   355.,   -69.,  1010.,  1085.,\n","                       -481., -1224.,  -103.,  -691.,   -67.,  -921., -1916.,  1150.,  -862.,\n","                       -297.,   178.,   510.,   148.,   300.,  -147., -3124.,  2922.,   616.,\n","                        917., -4013., -1628.,  -544.,   895.,  1679.,   728.,    14.,  -783.,\n","                        -94.,   278.,  1942., -1768.,  -945.,   127.,  -114., -1410.,  -244.,\n","                       1365.], device='cuda:0')),\n","             ('module.layer3.3.relu2.num_forwards',\n","              tensor([40], device='cuda:0')),\n","             ('module.layer3.3.relu2.force_readjust',\n","              tensor(False, device='cuda:0')),\n","             ('module.layer3.3.relu2.output_scale',\n","              tensor([7.3286], device='cuda:0')),\n","             ('module.layer3.3.relu2.output_zero_point',\n","              tensor([0.], device='cuda:0')),\n","             ('module.layer3.3.residual_eltwiseadd.num_forwards',\n","              tensor([40], device='cuda:0')),\n","             ('module.layer3.3.residual_eltwiseadd.force_readjust',\n","              tensor(False, device='cuda:0')),\n","             ('module.layer3.3.residual_eltwiseadd.output_scale',\n","              tensor([7.3286], device='cuda:0')),\n","             ('module.layer3.3.residual_eltwiseadd.output_zero_point',\n","              tensor([0.], device='cuda:0')),\n","             ('module.layer3.4.conv1.num_forwards',\n","              tensor([40], device='cuda:0')),\n","             ('module.layer3.4.conv1.force_readjust',\n","              tensor(False, device='cuda:0')),\n","             ('module.layer3.4.conv1.output_scale',\n","              tensor([55.3895], device='cuda:0')),\n","             ('module.layer3.4.conv1.output_zero_point',\n","              tensor([0.], device='cuda:0')),\n","             ('module.layer3.4.conv1.w_scale', tensor([[[[ 864.6849]]],\n","              \n","              \n","                      [[[ 906.3506]]],\n","              \n","              \n","                      [[[ 803.5900]]],\n","              \n","              \n","                      [[[ 657.4529]]],\n","              \n","              \n","                      [[[ 905.2128]]],\n","              \n","              \n","                      [[[1157.9263]]],\n","              \n","              \n","                      [[[ 592.8797]]],\n","              \n","              \n","                      [[[ 773.3240]]],\n","              \n","              \n","                      [[[2129.9192]]],\n","              \n","              \n","                      [[[ 975.4256]]],\n","              \n","              \n","                      [[[1205.4647]]],\n","              \n","              \n","                      [[[1396.4620]]],\n","              \n","              \n","                      [[[ 883.0910]]],\n","              \n","              \n","                      [[[ 611.4755]]],\n","              \n","              \n","                      [[[ 975.2389]]],\n","              \n","              \n","                      [[[ 911.6287]]],\n","              \n","              \n","                      [[[ 685.2977]]],\n","              \n","              \n","                      [[[ 800.9575]]],\n","              \n","              \n","                      [[[ 836.2493]]],\n","              \n","              \n","                      [[[ 693.9875]]],\n","              \n","              \n","                      [[[ 766.3307]]],\n","              \n","              \n","                      [[[ 745.4708]]],\n","              \n","              \n","                      [[[ 736.8265]]],\n","              \n","              \n","                      [[[1013.8743]]],\n","              \n","              \n","                      [[[ 794.2328]]],\n","              \n","              \n","                      [[[ 664.0339]]],\n","              \n","              \n","                      [[[1071.7207]]],\n","              \n","              \n","                      [[[ 885.5724]]],\n","              \n","              \n","                      [[[ 576.9355]]],\n","              \n","              \n","                      [[[ 922.3066]]],\n","              \n","              \n","                      [[[ 659.1068]]],\n","              \n","              \n","                      [[[ 716.1748]]],\n","              \n","              \n","                      [[[ 821.4333]]],\n","              \n","              \n","                      [[[ 891.7694]]],\n","              \n","              \n","                      [[[1228.6801]]],\n","              \n","              \n","                      [[[ 912.7252]]],\n","              \n","              \n","                      [[[ 840.2556]]],\n","              \n","              \n","                      [[[ 729.8525]]],\n","              \n","              \n","                      [[[ 999.4225]]],\n","              \n","              \n","                      [[[ 753.8346]]],\n","              \n","              \n","                      [[[1122.2034]]],\n","              \n","              \n","                      [[[ 711.5897]]],\n","              \n","              \n","                      [[[ 976.1647]]],\n","              \n","              \n","                      [[[1337.9541]]],\n","              \n","              \n","                      [[[1180.7097]]],\n","              \n","              \n","                      [[[ 808.1246]]],\n","              \n","              \n","                      [[[ 786.0357]]],\n","              \n","              \n","                      [[[ 917.7534]]],\n","              \n","              \n","                      [[[1142.6560]]],\n","              \n","              \n","                      [[[1124.1226]]],\n","              \n","              \n","                      [[[3339.4119]]],\n","              \n","              \n","                      [[[1139.4596]]],\n","              \n","              \n","                      [[[1031.7224]]],\n","              \n","              \n","                      [[[1282.7167]]],\n","              \n","              \n","                      [[[1116.5562]]],\n","              \n","              \n","                      [[[ 945.4046]]],\n","              \n","              \n","                      [[[ 922.1133]]],\n","              \n","              \n","                      [[[1118.3004]]],\n","              \n","              \n","                      [[[ 648.9517]]],\n","              \n","              \n","                      [[[1307.9141]]],\n","              \n","              \n","                      [[[ 888.7306]]],\n","              \n","              \n","                      [[[1169.5913]]],\n","              \n","              \n","                      [[[ 882.1979]]],\n","              \n","              \n","                      [[[ 941.5288]]]], device='cuda:0')),\n","             ('module.layer3.4.conv1.w_zero_point', tensor([[[[-28.]]],\n","              \n","              \n","                      [[[-28.]]],\n","              \n","              \n","                      [[[-31.]]],\n","              \n","              \n","                      [[[-29.]]],\n","              \n","              \n","                      [[[-27.]]],\n","              \n","              \n","                      [[[-32.]]],\n","              \n","              \n","                      [[[-23.]]],\n","              \n","              \n","                      [[[-30.]]],\n","              \n","              \n","                      [[[-30.]]],\n","              \n","              \n","                      [[[-30.]]],\n","              \n","              \n","                      [[[-29.]]],\n","              \n","              \n","                      [[[-23.]]],\n","              \n","              \n","                      [[[-31.]]],\n","              \n","              \n","                      [[[-31.]]],\n","              \n","              \n","                      [[[-29.]]],\n","              \n","              \n","                      [[[-32.]]],\n","              \n","              \n","                      [[[-30.]]],\n","              \n","              \n","                      [[[-29.]]],\n","              \n","              \n","                      [[[-30.]]],\n","              \n","              \n","                      [[[-33.]]],\n","              \n","              \n","                      [[[-34.]]],\n","              \n","              \n","                      [[[-28.]]],\n","              \n","              \n","                      [[[-28.]]],\n","              \n","              \n","                      [[[-24.]]],\n","              \n","              \n","                      [[[-23.]]],\n","              \n","              \n","                      [[[-32.]]],\n","              \n","              \n","                      [[[-28.]]],\n","              \n","              \n","                      [[[-33.]]],\n","              \n","              \n","                      [[[-36.]]],\n","              \n","              \n","                      [[[-28.]]],\n","              \n","              \n","                      [[[-36.]]],\n","              \n","              \n","                      [[[-29.]]],\n","              \n","              \n","                      [[[-29.]]],\n","              \n","              \n","                      [[[-26.]]],\n","              \n","              \n","                      [[[-31.]]],\n","              \n","              \n","                      [[[-32.]]],\n","              \n","              \n","                      [[[-36.]]],\n","              \n","              \n","                      [[[-29.]]],\n","              \n","              \n","                      [[[-28.]]],\n","              \n","              \n","                      [[[-26.]]],\n","              \n","              \n","                      [[[-27.]]],\n","              \n","              \n","                      [[[-31.]]],\n","              \n","              \n","                      [[[-24.]]],\n","              \n","              \n","                      [[[-27.]]],\n","              \n","              \n","                      [[[-32.]]],\n","              \n","              \n","                      [[[-26.]]],\n","              \n","              \n","                      [[[-25.]]],\n","              \n","              \n","                      [[[-26.]]],\n","              \n","              \n","                      [[[-33.]]],\n","              \n","              \n","                      [[[-31.]]],\n","              \n","              \n","                      [[[-27.]]],\n","              \n","              \n","                      [[[-27.]]],\n","              \n","              \n","                      [[[-29.]]],\n","              \n","              \n","                      [[[-26.]]],\n","              \n","              \n","                      [[[-32.]]],\n","              \n","              \n","                      [[[-26.]]],\n","              \n","              \n","                      [[[-26.]]],\n","              \n","              \n","                      [[[-30.]]],\n","              \n","              \n","                      [[[-26.]]],\n","              \n","              \n","                      [[[-26.]]],\n","              \n","              \n","                      [[[-29.]]],\n","              \n","              \n","                      [[[-25.]]],\n","              \n","              \n","                      [[[-26.]]],\n","              \n","              \n","                      [[[-33.]]]], device='cuda:0')),\n","             ('module.layer3.4.conv1.fp_bias',\n","              tensor([ 0.0281,  0.0592, -0.0217, -0.3808, -0.2562, -0.0859,  0.0195, -0.0513,\n","                      -0.1568, -0.2343, -0.1962, -0.2959, -0.2855, -0.2351, -0.0486, -0.1972,\n","                      -0.1806, -0.5252, -0.4962, -0.3040, -0.3126, -0.0707, -0.1191, -0.1374,\n","                       0.0111, -0.2119, -0.2836, -0.1770, -0.3748, -0.0087,  0.0833, -0.3857,\n","                      -0.4539, -0.1601, -0.1864, -0.2435, -0.2898, -0.2661, -0.2470, -0.5460,\n","                      -0.1476, -0.1661, -0.1880, -0.2882, -0.1974, -0.4193, -0.6230,  0.0949,\n","                      -0.0303,  0.0871,  0.0504, -0.2127, -0.2550, -0.2372, -0.2858, -0.2786,\n","                      -0.2513, -0.2163, -0.0584, -0.1543, -0.2130, -0.3508, -0.3467, -0.1953],\n","                     device='cuda:0')),\n","             ('module.layer3.4.conv1.accum_scale', tensor([[[ 6336.8970]],\n","              \n","                      [[ 6642.2471]],\n","              \n","                      [[ 5889.1597]],\n","              \n","                      [[ 4818.1846]],\n","              \n","                      [[ 6633.9082]],\n","              \n","                      [[ 8485.9346]],\n","              \n","                      [[ 4344.9556]],\n","              \n","                      [[ 5667.3535]],\n","              \n","                      [[15609.2451]],\n","              \n","                      [[ 7148.4673]],\n","              \n","                      [[ 8834.3232]],\n","              \n","                      [[10234.0586]],\n","              \n","                      [[ 6471.7876]],\n","              \n","                      [[ 4481.2363]],\n","              \n","                      [[ 7147.0991]],\n","              \n","                      [[ 6680.9272]],\n","              \n","                      [[ 5022.2466]],\n","              \n","                      [[ 5869.8672]],\n","              \n","                      [[ 6128.5049]],\n","              \n","                      [[ 5085.9307]],\n","              \n","                      [[ 5616.1025]],\n","              \n","                      [[ 5463.2290]],\n","              \n","                      [[ 5399.8794]],\n","              \n","                      [[ 7430.2407]],\n","              \n","                      [[ 5820.5845]],\n","              \n","                      [[ 4866.4141]],\n","              \n","                      [[ 7854.1719]],\n","              \n","                      [[ 6489.9722]],\n","              \n","                      [[ 4228.1074]],\n","              \n","                      [[ 6759.1812]],\n","              \n","                      [[ 4830.3047]],\n","              \n","                      [[ 5248.5317]],\n","              \n","                      [[ 6019.9248]],\n","              \n","                      [[ 6535.3877]],\n","              \n","                      [[ 9004.4580]],\n","              \n","                      [[ 6688.9634]],\n","              \n","                      [[ 6157.8652]],\n","              \n","                      [[ 5348.7695]],\n","              \n","                      [[ 7324.3301]],\n","              \n","                      [[ 5524.5239]],\n","              \n","                      [[ 8224.1377]],\n","              \n","                      [[ 5214.9292]],\n","              \n","                      [[ 7153.8838]],\n","              \n","                      [[ 9805.2803]],\n","              \n","                      [[ 8652.9043]],\n","              \n","                      [[ 5922.3916]],\n","              \n","                      [[ 5760.5117]],\n","              \n","                      [[ 6725.8125]],\n","              \n","                      [[ 8374.0254]],\n","              \n","                      [[ 8238.2021]],\n","              \n","                      [[24473.0879]],\n","              \n","                      [[ 8350.6006]],\n","              \n","                      [[ 7561.0420]],\n","              \n","                      [[ 9400.4688]],\n","              \n","                      [[ 8182.7515]],\n","              \n","                      [[ 6928.4565]],\n","              \n","                      [[ 6757.7651]],\n","              \n","                      [[ 8195.5342]],\n","              \n","                      [[ 4755.8828]],\n","              \n","                      [[ 9585.1299]],\n","              \n","                      [[ 6513.1177]],\n","              \n","                      [[ 8571.4229]],\n","              \n","                      [[ 6465.2427]],\n","              \n","                      [[ 6900.0527]]], device='cuda:0')),\n","             ('module.layer3.4.conv1.is_simulated_quant_weight_shifted',\n","              tensor(False, device='cuda:0')),\n","             ('module.layer3.4.conv1.wrapped_module.weight',\n","              tensor([[[[33., 26., 24.],\n","                        [28., 29., 18.],\n","                        [25., 36., 26.]],\n","              \n","                       [[26., 42., 33.],\n","                        [29., 37., 25.],\n","                        [29., 24., 15.]],\n","              \n","                       [[25., 36., 45.],\n","                        [12., 27., 43.],\n","                        [20., 35., 36.]],\n","              \n","                       ...,\n","              \n","                       [[30., 27., 30.],\n","                        [30., 31., 33.],\n","                        [25., 23., 30.]],\n","              \n","                       [[14., 18., 20.],\n","                        [39., 24., 14.],\n","                        [57., 22., 10.]],\n","              \n","                       [[40., 30.,  3.],\n","                        [21., 16., 10.],\n","                        [ 3., 24., 21.]]],\n","              \n","              \n","                      [[[18., 43., 63.],\n","                        [27., 31., 32.],\n","                        [28., 30., 20.]],\n","              \n","                       [[26., 23., 21.],\n","                        [24., 26., 30.],\n","                        [25., 29., 29.]],\n","              \n","                       [[20., 28., 28.],\n","                        [30., 21., 22.],\n","                        [40., 35., 33.]],\n","              \n","                       ...,\n","              \n","                       [[31., 27., 24.],\n","                        [33., 29., 26.],\n","                        [29., 26., 27.]],\n","              \n","                       [[33., 25., 28.],\n","                        [27., 26., 35.],\n","                        [15., 19., 32.]],\n","              \n","                       [[29., 27., 30.],\n","                        [21., 25., 15.],\n","                        [31., 36., 30.]]],\n","              \n","              \n","                      [[[28., 33., 32.],\n","                        [19., 18., 23.],\n","                        [14.,  4.,  9.]],\n","              \n","                       [[28., 24., 27.],\n","                        [22., 23., 31.],\n","                        [32., 30., 32.]],\n","              \n","                       [[33., 46., 47.],\n","                        [14., 23., 36.],\n","                        [25., 31., 25.]],\n","              \n","                       ...,\n","              \n","                       [[29., 34., 30.],\n","                        [38., 36., 33.],\n","                        [38., 36., 30.]],\n","              \n","                       [[39., 32., 26.],\n","                        [52., 39., 36.],\n","                        [47., 46., 40.]],\n","              \n","                       [[25.,  9.,  4.],\n","                        [27., 12.,  0.],\n","                        [49., 29., 32.]]],\n","              \n","              \n","                      ...,\n","              \n","              \n","                      [[[18., 17., 20.],\n","                        [13., 17., 20.],\n","                        [ 8., 14., 20.]],\n","              \n","                       [[33., 27., 21.],\n","                        [24., 16., 18.],\n","                        [17., 16., 17.]],\n","              \n","                       [[22., 27., 27.],\n","                        [20., 17., 27.],\n","                        [14., 16., 30.]],\n","              \n","                       ...,\n","              \n","                       [[22., 26., 36.],\n","                        [23., 23., 33.],\n","                        [26., 28., 33.]],\n","              \n","                       [[30., 27., 29.],\n","                        [ 9., 16., 23.],\n","                        [26., 21., 17.]],\n","              \n","                       [[21.,  3., 19.],\n","                        [14.,  0., 11.],\n","                        [15., 14., 19.]]],\n","              \n","              \n","                      [[[30., 32., 27.],\n","                        [26., 29., 19.],\n","                        [26., 27., 26.]],\n","              \n","                       [[20., 29., 24.],\n","                        [30., 28., 21.],\n","                        [38., 30., 24.]],\n","              \n","                       [[38., 38., 41.],\n","                        [30., 30., 23.],\n","                        [28., 33., 22.]],\n","              \n","                       ...,\n","              \n","                       [[21., 29., 31.],\n","                        [24., 24., 30.],\n","                        [25., 21., 30.]],\n","              \n","                       [[26., 26., 23.],\n","                        [15., 16., 19.],\n","                        [ 6., 15., 23.]],\n","              \n","                       [[26., 35., 28.],\n","                        [17., 19., 12.],\n","                        [ 8., 19., 33.]]],\n","              \n","              \n","                      [[[31., 22., 29.],\n","                        [19., 28., 44.],\n","                        [23., 40., 36.]],\n","              \n","                       [[29., 37., 31.],\n","                        [29., 33., 35.],\n","                        [41., 46., 34.]],\n","              \n","                       [[36., 34., 34.],\n","                        [40., 47., 30.],\n","                        [60., 59., 24.]],\n","              \n","                       ...,\n","              \n","                       [[36., 35., 30.],\n","                        [36., 33., 31.],\n","                        [26., 26., 36.]],\n","              \n","                       [[33., 16., 29.],\n","                        [24., 21., 47.],\n","                        [37., 33., 53.]],\n","              \n","                       [[24., 27., 58.],\n","                        [20., 23., 47.],\n","                        [33., 18., 24.]]]], device='cuda:0')),\n","             ('module.layer3.4.conv1.wrapped_module.bias',\n","              tensor([  178.,   393.,  -128., -1835., -1700.,  -729.,    85.,  -291., -2448.,\n","                      -1675., -1733., -3028., -1847., -1054.,  -348., -1318.,  -907., -3083.,\n","                      -3041., -1546., -1755.,  -386.,  -643., -1021.,    65., -1031., -2228.,\n","                      -1149., -1585.,   -59.,   402., -2024., -2733., -1046., -1679., -1629.,\n","                      -1784., -1424., -1809., -3017., -1214.,  -866., -1345., -2826., -1708.,\n","                      -2483., -3589.,   638.,  -254.,   718.,  1235., -1776., -1928., -2230.,\n","                      -2339., -1930., -1698., -1773.,  -278., -1479., -1388., -3006., -2241.,\n","                      -1348.], device='cuda:0')),\n","             ('module.layer3.4.conv2.num_forwards',\n","              tensor([40], device='cuda:0')),\n","             ('module.layer3.4.conv2.force_readjust',\n","              tensor(False, device='cuda:0')),\n","             ('module.layer3.4.conv2.output_scale',\n","              tensor([9.2633], device='cuda:0')),\n","             ('module.layer3.4.conv2.output_zero_point',\n","              tensor([-35.], device='cuda:0')),\n","             ('module.layer3.4.conv2.w_scale', tensor([[[[4.8111e+01]]],\n","              \n","              \n","                      [[[9.0223e+01]]],\n","              \n","              \n","                      [[[7.5301e+04]]],\n","              \n","              \n","                      [[[4.4893e+01]]],\n","              \n","              \n","                      [[[1.3005e+02]]],\n","              \n","              \n","                      [[[1.3048e+02]]],\n","              \n","              \n","                      [[[1.2039e+02]]],\n","              \n","              \n","                      [[[3.6964e+02]]],\n","              \n","              \n","                      [[[1.0329e+02]]],\n","              \n","              \n","                      [[[1.0574e+02]]],\n","              \n","              \n","                      [[[5.2648e+01]]],\n","              \n","              \n","                      [[[1.5348e+02]]],\n","              \n","              \n","                      [[[9.2588e+01]]],\n","              \n","              \n","                      [[[2.1247e+02]]],\n","              \n","              \n","                      [[[8.5741e+01]]],\n","              \n","              \n","                      [[[1.2043e+02]]],\n","              \n","              \n","                      [[[9.8636e+01]]],\n","              \n","              \n","                      [[[1.1941e+02]]],\n","              \n","              \n","                      [[[1.5968e+02]]],\n","              \n","              \n","                      [[[6.8878e+01]]],\n","              \n","              \n","                      [[[2.7629e+02]]],\n","              \n","              \n","                      [[[1.0367e+02]]],\n","              \n","              \n","                      [[[9.0167e+01]]],\n","              \n","              \n","                      [[[6.6271e+01]]],\n","              \n","              \n","                      [[[1.4191e+02]]],\n","              \n","              \n","                      [[[1.0332e+02]]],\n","              \n","              \n","                      [[[1.2848e+02]]],\n","              \n","              \n","                      [[[7.0526e+01]]],\n","              \n","              \n","                      [[[7.6644e+01]]],\n","              \n","              \n","                      [[[1.2625e+02]]],\n","              \n","              \n","                      [[[1.5952e+02]]],\n","              \n","              \n","                      [[[7.2172e+01]]],\n","              \n","              \n","                      [[[9.4670e+01]]],\n","              \n","              \n","                      [[[7.2722e+01]]],\n","              \n","              \n","                      [[[2.0392e+02]]],\n","              \n","              \n","                      [[[5.9263e+01]]],\n","              \n","              \n","                      [[[5.3521e+01]]],\n","              \n","              \n","                      [[[5.2544e+01]]],\n","              \n","              \n","                      [[[9.1127e+01]]],\n","              \n","              \n","                      [[[2.6250e+02]]],\n","              \n","              \n","                      [[[9.2354e+01]]],\n","              \n","              \n","                      [[[1.6541e+02]]],\n","              \n","              \n","                      [[[1.9509e+01]]],\n","              \n","              \n","                      [[[1.9945e+02]]],\n","              \n","              \n","                      [[[1.4569e+02]]],\n","              \n","              \n","                      [[[9.8842e+01]]],\n","              \n","              \n","                      [[[1.1023e+04]]],\n","              \n","              \n","                      [[[1.0358e+02]]],\n","              \n","              \n","                      [[[7.3890e+01]]],\n","              \n","              \n","                      [[[3.0683e+02]]],\n","              \n","              \n","                      [[[7.3680e+02]]],\n","              \n","              \n","                      [[[6.0184e+01]]],\n","              \n","              \n","                      [[[9.6816e+01]]],\n","              \n","              \n","                      [[[9.6555e+01]]],\n","              \n","              \n","                      [[[1.1305e+02]]],\n","              \n","              \n","                      [[[1.3183e+02]]],\n","              \n","              \n","                      [[[9.6873e+01]]],\n","              \n","              \n","                      [[[8.2493e+01]]],\n","              \n","              \n","                      [[[7.0725e+01]]],\n","              \n","              \n","                      [[[7.5045e+01]]],\n","              \n","              \n","                      [[[5.4687e+01]]],\n","              \n","              \n","                      [[[1.0623e+02]]],\n","              \n","              \n","                      [[[6.8895e+01]]],\n","              \n","              \n","                      [[[4.1937e+01]]]], device='cuda:0')),\n","             ('module.layer3.4.conv2.w_zero_point', tensor([[[[-30.]]],\n","              \n","              \n","                      [[[-25.]]],\n","              \n","              \n","                      [[[-33.]]],\n","              \n","              \n","                      [[[-30.]]],\n","              \n","              \n","                      [[[-32.]]],\n","              \n","              \n","                      [[[-37.]]],\n","              \n","              \n","                      [[[-31.]]],\n","              \n","              \n","                      [[[-27.]]],\n","              \n","              \n","                      [[[-32.]]],\n","              \n","              \n","                      [[[-26.]]],\n","              \n","              \n","                      [[[-23.]]],\n","              \n","              \n","                      [[[-28.]]],\n","              \n","              \n","                      [[[-29.]]],\n","              \n","              \n","                      [[[-25.]]],\n","              \n","              \n","                      [[[-31.]]],\n","              \n","              \n","                      [[[-35.]]],\n","              \n","              \n","                      [[[-30.]]],\n","              \n","              \n","                      [[[-31.]]],\n","              \n","              \n","                      [[[-32.]]],\n","              \n","              \n","                      [[[-27.]]],\n","              \n","              \n","                      [[[-33.]]],\n","              \n","              \n","                      [[[-36.]]],\n","              \n","              \n","                      [[[-25.]]],\n","              \n","              \n","                      [[[-31.]]],\n","              \n","              \n","                      [[[-36.]]],\n","              \n","              \n","                      [[[-32.]]],\n","              \n","              \n","                      [[[-30.]]],\n","              \n","              \n","                      [[[-32.]]],\n","              \n","              \n","                      [[[-29.]]],\n","              \n","              \n","                      [[[-31.]]],\n","              \n","              \n","                      [[[-30.]]],\n","              \n","              \n","                      [[[-29.]]],\n","              \n","              \n","                      [[[-29.]]],\n","              \n","              \n","                      [[[-24.]]],\n","              \n","              \n","                      [[[-27.]]],\n","              \n","              \n","                      [[[-26.]]],\n","              \n","              \n","                      [[[-31.]]],\n","              \n","              \n","                      [[[-23.]]],\n","              \n","              \n","                      [[[-31.]]],\n","              \n","              \n","                      [[[-32.]]],\n","              \n","              \n","                      [[[-29.]]],\n","              \n","              \n","                      [[[-36.]]],\n","              \n","              \n","                      [[[-32.]]],\n","              \n","              \n","                      [[[-27.]]],\n","              \n","              \n","                      [[[-21.]]],\n","              \n","              \n","                      [[[-36.]]],\n","              \n","              \n","                      [[[-35.]]],\n","              \n","              \n","                      [[[-28.]]],\n","              \n","              \n","                      [[[-31.]]],\n","              \n","              \n","                      [[[-32.]]],\n","              \n","              \n","                      [[[-28.]]],\n","              \n","              \n","                      [[[-26.]]],\n","              \n","              \n","                      [[[-32.]]],\n","              \n","              \n","                      [[[-26.]]],\n","              \n","              \n","                      [[[-32.]]],\n","              \n","              \n","                      [[[-32.]]],\n","              \n","              \n","                      [[[-26.]]],\n","              \n","              \n","                      [[[-33.]]],\n","              \n","              \n","                      [[[-26.]]],\n","              \n","              \n","                      [[[-37.]]],\n","              \n","              \n","                      [[[-29.]]],\n","              \n","              \n","                      [[[-27.]]],\n","              \n","              \n","                      [[[-27.]]],\n","              \n","              \n","                      [[[-30.]]]], device='cuda:0')),\n","             ('module.layer3.4.conv2.fp_bias',\n","              tensor([ 0.4362, -0.3877, -0.1893,  0.1008, -0.0959, -0.0836,  0.0564, -0.0694,\n","                      -0.2559, -0.1668, -0.4285, -0.1020,  0.0415, -0.0368, -0.5924,  0.0083,\n","                      -0.1761,  0.0064, -0.0811, -0.2730, -0.1443,  0.2292, -0.1381, -0.2571,\n","                      -0.0234,  0.0365, -0.1513, -0.0431, -0.1890,  0.0699, -0.0566, -0.2072,\n","                      -0.0183, -0.3016, -0.1358, -0.3822, -0.1995,  0.0073, -0.0079, -0.1303,\n","                       0.0476, -0.0811,  0.1438, -0.0465, -0.1089,  0.0219, -0.0086, -0.2670,\n","                      -0.0433, -0.0527, -0.4054, -0.1394, -0.1018, -0.0659,  0.0821, -0.0824,\n","                      -0.0376, -0.0609, -0.0475, -0.1982, -0.2405,  0.1148, -0.1415, -0.0392],\n","                     device='cuda:0')),\n","             ('module.layer3.4.conv2.accum_scale', tensor([[[2.6649e+03]],\n","              \n","                      [[4.9974e+03]],\n","              \n","                      [[4.1709e+06]],\n","              \n","                      [[2.4866e+03]],\n","              \n","                      [[7.2034e+03]],\n","              \n","                      [[7.2272e+03]],\n","              \n","                      [[6.6683e+03]],\n","              \n","                      [[2.0474e+04]],\n","              \n","                      [[5.7214e+03]],\n","              \n","                      [[5.8566e+03]],\n","              \n","                      [[2.9161e+03]],\n","              \n","                      [[8.5014e+03]],\n","              \n","                      [[5.1284e+03]],\n","              \n","                      [[1.1769e+04]],\n","              \n","                      [[4.7491e+03]],\n","              \n","                      [[6.6708e+03]],\n","              \n","                      [[5.4634e+03]],\n","              \n","                      [[6.6139e+03]],\n","              \n","                      [[8.8448e+03]],\n","              \n","                      [[3.8151e+03]],\n","              \n","                      [[1.5303e+04]],\n","              \n","                      [[5.7423e+03]],\n","              \n","                      [[4.9943e+03]],\n","              \n","                      [[3.6707e+03]],\n","              \n","                      [[7.8604e+03]],\n","              \n","                      [[5.7227e+03]],\n","              \n","                      [[7.1164e+03]],\n","              \n","                      [[3.9064e+03]],\n","              \n","                      [[4.2453e+03]],\n","              \n","                      [[6.9928e+03]],\n","              \n","                      [[8.8356e+03]],\n","              \n","                      [[3.9976e+03]],\n","              \n","                      [[5.2437e+03]],\n","              \n","                      [[4.0280e+03]],\n","              \n","                      [[1.1295e+04]],\n","              \n","                      [[3.2826e+03]],\n","              \n","                      [[2.9645e+03]],\n","              \n","                      [[2.9104e+03]],\n","              \n","                      [[5.0475e+03]],\n","              \n","                      [[1.4540e+04]],\n","              \n","                      [[5.1154e+03]],\n","              \n","                      [[9.1620e+03]],\n","              \n","                      [[1.0806e+03]],\n","              \n","                      [[1.1048e+04]],\n","              \n","                      [[8.0694e+03]],\n","              \n","                      [[5.4748e+03]],\n","              \n","                      [[6.1059e+05]],\n","              \n","                      [[5.7371e+03]],\n","              \n","                      [[4.0927e+03]],\n","              \n","                      [[1.6995e+04]],\n","              \n","                      [[4.0811e+04]],\n","              \n","                      [[3.3335e+03]],\n","              \n","                      [[5.3626e+03]],\n","              \n","                      [[5.3482e+03]],\n","              \n","                      [[6.2618e+03]],\n","              \n","                      [[7.3022e+03]],\n","              \n","                      [[5.3658e+03]],\n","              \n","                      [[4.5692e+03]],\n","              \n","                      [[3.9174e+03]],\n","              \n","                      [[4.1567e+03]],\n","              \n","                      [[3.0291e+03]],\n","              \n","                      [[5.8842e+03]],\n","              \n","                      [[3.8160e+03]],\n","              \n","                      [[2.3229e+03]]], device='cuda:0')),\n","             ('module.layer3.4.conv2.is_simulated_quant_weight_shifted',\n","              tensor(False, device='cuda:0')),\n","             ('module.layer3.4.conv2.wrapped_module.weight',\n","              tensor([[[[37., 28., 23.],\n","                        [28., 23., 24.],\n","                        [32., 30., 28.]],\n","              \n","                       [[17., 23., 15.],\n","                        [34., 33., 24.],\n","                        [39., 33., 36.]],\n","              \n","                       [[56., 43., 23.],\n","                        [33., 21., 24.],\n","                        [30., 22., 26.]],\n","              \n","                       ...,\n","              \n","                       [[20., 20., 20.],\n","                        [23., 19., 25.],\n","                        [35., 32., 28.]],\n","              \n","                       [[21., 14., 22.],\n","                        [34., 30., 37.],\n","                        [43., 38., 37.]],\n","              \n","                       [[28., 45., 48.],\n","                        [19., 30., 30.],\n","                        [15., 19., 15.]]],\n","              \n","              \n","                      [[[31., 33., 28.],\n","                        [14., 26., 35.],\n","                        [18., 18., 19.]],\n","              \n","                       [[24., 23., 21.],\n","                        [22., 20., 22.],\n","                        [12., 19., 29.]],\n","              \n","                       [[21., 29., 27.],\n","                        [24., 28., 34.],\n","                        [20., 25., 32.]],\n","              \n","                       ...,\n","              \n","                       [[23., 26., 26.],\n","                        [30., 28., 24.],\n","                        [33., 29., 29.]],\n","              \n","                       [[22., 15., 25.],\n","                        [34., 21., 16.],\n","                        [47., 31., 24.]],\n","              \n","                       [[19., 22., 27.],\n","                        [24., 20., 17.],\n","                        [36., 25., 27.]]],\n","              \n","              \n","                      [[[15., 20., 18.],\n","                        [25., 31., 18.],\n","                        [29., 44., 28.]],\n","              \n","                       [[28., 31., 27.],\n","                        [19., 23., 22.],\n","                        [26., 24., 30.]],\n","              \n","                       [[21., 32., 27.],\n","                        [23., 29., 21.],\n","                        [40., 40., 25.]],\n","              \n","                       ...,\n","              \n","                       [[29., 24., 37.],\n","                        [27., 25., 35.],\n","                        [38., 37., 41.]],\n","              \n","                       [[46., 33., 41.],\n","                        [29., 23., 29.],\n","                        [37., 39., 41.]],\n","              \n","                       [[24., 27., 44.],\n","                        [23., 19., 29.],\n","                        [23., 18., 27.]]],\n","              \n","              \n","                      ...,\n","              \n","              \n","                      [[[31., 30., 34.],\n","                        [30., 21., 21.],\n","                        [28., 17., 17.]],\n","              \n","                       [[36., 26., 28.],\n","                        [33., 21., 22.],\n","                        [28., 22., 27.]],\n","              \n","                       [[24., 26., 18.],\n","                        [20., 21., 15.],\n","                        [36., 25., 13.]],\n","              \n","                       ...,\n","              \n","                       [[39., 31., 20.],\n","                        [37., 25., 21.],\n","                        [48., 35., 26.]],\n","              \n","                       [[25., 23.,  6.],\n","                        [18., 20.,  4.],\n","                        [29., 35., 23.]],\n","              \n","                       [[27., 38., 50.],\n","                        [15., 22., 28.],\n","                        [27., 37., 31.]]],\n","              \n","              \n","                      [[[26., 32., 32.],\n","                        [34., 42., 34.],\n","                        [30., 39., 36.]],\n","              \n","                       [[35., 31., 27.],\n","                        [32., 27., 11.],\n","                        [25., 17.,  5.]],\n","              \n","                       [[43., 28., 32.],\n","                        [35., 21., 19.],\n","                        [36., 35., 24.]],\n","              \n","                       ...,\n","              \n","                       [[21., 17., 23.],\n","                        [27., 28., 28.],\n","                        [29., 28., 28.]],\n","              \n","                       [[18., 24., 31.],\n","                        [23., 30., 26.],\n","                        [35., 38., 31.]],\n","              \n","                       [[36., 44., 46.],\n","                        [35., 40., 37.],\n","                        [29., 25., 28.]]],\n","              \n","              \n","                      [[[32., 34., 38.],\n","                        [34., 56., 57.],\n","                        [28., 44., 39.]],\n","              \n","                       [[36., 31., 31.],\n","                        [38., 23., 15.],\n","                        [38., 17., 14.]],\n","              \n","                       [[21., 23., 30.],\n","                        [20., 15., 24.],\n","                        [25., 23., 12.]],\n","              \n","                       ...,\n","              \n","                       [[26., 20., 31.],\n","                        [32., 23., 34.],\n","                        [37., 34., 39.]],\n","              \n","                       [[37., 33., 36.],\n","                        [34., 25., 29.],\n","                        [35., 23., 28.]],\n","              \n","                       [[14., 23., 38.],\n","                        [20., 31., 55.],\n","                        [38., 34., 39.]]]], device='cuda:0')),\n","             ('module.layer3.4.conv2.wrapped_module.bias',\n","              tensor([ 1.1620e+03, -1.9370e+03, -7.8954e+05,  2.5100e+02, -6.9100e+02,\n","                      -6.0400e+02,  3.7600e+02, -1.4220e+03, -1.4640e+03, -9.7700e+02,\n","                      -1.2500e+03, -8.6700e+02,  2.1300e+02, -4.3300e+02, -2.8140e+03,\n","                       5.5000e+01, -9.6200e+02,  4.2000e+01, -7.1800e+02, -1.0410e+03,\n","                      -2.2080e+03,  1.3160e+03, -6.9000e+02, -9.4400e+02, -1.8400e+02,\n","                       2.0900e+02, -1.0770e+03, -1.6800e+02, -8.0200e+02,  4.8900e+02,\n","                      -5.0000e+02, -8.2800e+02, -9.6000e+01, -1.2150e+03, -1.5340e+03,\n","                      -1.2550e+03, -5.9100e+02,  2.1000e+01, -4.0000e+01, -1.8940e+03,\n","                       2.4300e+02, -7.4300e+02,  1.5500e+02, -5.1400e+02, -8.7800e+02,\n","                       1.2000e+02, -5.2280e+03, -1.5320e+03, -1.7700e+02, -8.9600e+02,\n","                      -1.6544e+04, -4.6500e+02, -5.4600e+02, -3.5200e+02,  5.1400e+02,\n","                      -6.0200e+02, -2.0200e+02, -2.7800e+02, -1.8600e+02, -8.2400e+02,\n","                      -7.2900e+02,  6.7500e+02, -5.4000e+02, -9.1000e+01], device='cuda:0')),\n","             ('module.layer3.4.relu2.num_forwards',\n","              tensor([40], device='cuda:0')),\n","             ('module.layer3.4.relu2.force_readjust',\n","              tensor(False, device='cuda:0')),\n","             ('module.layer3.4.relu2.output_scale',\n","              tensor([7.0210], device='cuda:0')),\n","             ('module.layer3.4.relu2.output_zero_point',\n","              tensor([0.], device='cuda:0')),\n","             ('module.layer3.4.residual_eltwiseadd.num_forwards',\n","              tensor([40], device='cuda:0')),\n","             ('module.layer3.4.residual_eltwiseadd.force_readjust',\n","              tensor(False, device='cuda:0')),\n","             ('module.layer3.4.residual_eltwiseadd.output_scale',\n","              tensor([7.0210], device='cuda:0')),\n","             ('module.layer3.4.residual_eltwiseadd.output_zero_point',\n","              tensor([0.], device='cuda:0')),\n","             ('module.layer3.5.conv1.num_forwards',\n","              tensor([40], device='cuda:0')),\n","             ('module.layer3.5.conv1.force_readjust',\n","              tensor(False, device='cuda:0')),\n","             ('module.layer3.5.conv1.output_scale',\n","              tensor([54.4232], device='cuda:0')),\n","             ('module.layer3.5.conv1.output_zero_point',\n","              tensor([0.], device='cuda:0')),\n","             ('module.layer3.5.conv1.w_scale', tensor([[[[  641.6212]]],\n","              \n","              \n","                      [[[  628.0576]]],\n","              \n","              \n","                      [[[  663.2089]]],\n","              \n","              \n","                      [[[  761.4233]]],\n","              \n","              \n","                      [[[ 1124.2479]]],\n","              \n","              \n","                      [[[  590.0541]]],\n","              \n","              \n","                      [[[  798.4448]]],\n","              \n","              \n","                      [[[88132.8203]]],\n","              \n","              \n","                      [[[ 1211.7025]]],\n","              \n","              \n","                      [[[  941.0748]]],\n","              \n","              \n","                      [[[  760.8676]]],\n","              \n","              \n","                      [[[  722.6941]]],\n","              \n","              \n","                      [[[  910.8420]]],\n","              \n","              \n","                      [[[  929.3247]]],\n","              \n","              \n","                      [[[ 1332.7292]]],\n","              \n","              \n","                      [[[ 1359.5214]]],\n","              \n","              \n","                      [[[  848.9177]]],\n","              \n","              \n","                      [[[  827.3448]]],\n","              \n","              \n","                      [[[  708.3356]]],\n","              \n","              \n","                      [[[  735.7823]]],\n","              \n","              \n","                      [[[  945.0423]]],\n","              \n","              \n","                      [[[  823.1260]]],\n","              \n","              \n","                      [[[ 2443.8499]]],\n","              \n","              \n","                      [[[  766.1225]]],\n","              \n","              \n","                      [[[  846.9232]]],\n","              \n","              \n","                      [[[  669.2340]]],\n","              \n","              \n","                      [[[  639.9919]]],\n","              \n","              \n","                      [[[ 1154.7700]]],\n","              \n","              \n","                      [[[  908.7961]]],\n","              \n","              \n","                      [[[  911.7734]]],\n","              \n","              \n","                      [[[  846.7484]]],\n","              \n","              \n","                      [[[  678.5519]]],\n","              \n","              \n","                      [[[  680.2520]]],\n","              \n","              \n","                      [[[ 1162.2329]]],\n","              \n","              \n","                      [[[  752.7310]]],\n","              \n","              \n","                      [[[  901.6625]]],\n","              \n","              \n","                      [[[  701.1595]]],\n","              \n","              \n","                      [[[  831.7625]]],\n","              \n","              \n","                      [[[ 1305.3002]]],\n","              \n","              \n","                      [[[  845.9285]]],\n","              \n","              \n","                      [[[  707.5833]]],\n","              \n","              \n","                      [[[  858.7781]]],\n","              \n","              \n","                      [[[  853.0845]]],\n","              \n","              \n","                      [[[ 1822.5935]]],\n","              \n","              \n","                      [[[  761.9998]]],\n","              \n","              \n","                      [[[  783.3316]]],\n","              \n","              \n","                      [[[ 1211.3352]]],\n","              \n","              \n","                      [[[ 1085.6614]]],\n","              \n","              \n","                      [[[  825.7087]]],\n","              \n","              \n","                      [[[ 1771.0752]]],\n","              \n","              \n","                      [[[  736.0789]]],\n","              \n","              \n","                      [[[ 1372.2963]]],\n","              \n","              \n","                      [[[  776.5731]]],\n","              \n","              \n","                      [[[  873.9153]]],\n","              \n","              \n","                      [[[ 1015.1737]]],\n","              \n","              \n","                      [[[ 1533.9980]]],\n","              \n","              \n","                      [[[  760.8528]]],\n","              \n","              \n","                      [[[ 1884.9001]]],\n","              \n","              \n","                      [[[  849.3094]]],\n","              \n","              \n","                      [[[  842.7381]]],\n","              \n","              \n","                      [[[  641.7441]]],\n","              \n","              \n","                      [[[  868.2341]]],\n","              \n","              \n","                      [[[ 2029.6467]]],\n","              \n","              \n","                      [[[  676.7543]]]], device='cuda:0')),\n","             ('module.layer3.5.conv1.w_zero_point', tensor([[[[-28.]]],\n","              \n","              \n","                      [[[-31.]]],\n","              \n","              \n","                      [[[-22.]]],\n","              \n","              \n","                      [[[-26.]]],\n","              \n","              \n","                      [[[-31.]]],\n","              \n","              \n","                      [[[-26.]]],\n","              \n","              \n","                      [[[-24.]]],\n","              \n","              \n","                      [[[-32.]]],\n","              \n","              \n","                      [[[-30.]]],\n","              \n","              \n","                      [[[-29.]]],\n","              \n","              \n","                      [[[-25.]]],\n","              \n","              \n","                      [[[-26.]]],\n","              \n","              \n","                      [[[-26.]]],\n","              \n","              \n","                      [[[-27.]]],\n","              \n","              \n","                      [[[-28.]]],\n","              \n","              \n","                      [[[-31.]]],\n","              \n","              \n","                      [[[-28.]]],\n","              \n","              \n","                      [[[-27.]]],\n","              \n","              \n","                      [[[-32.]]],\n","              \n","              \n","                      [[[-27.]]],\n","              \n","              \n","                      [[[-27.]]],\n","              \n","              \n","                      [[[-23.]]],\n","              \n","              \n","                      [[[-32.]]],\n","              \n","              \n","                      [[[-24.]]],\n","              \n","              \n","                      [[[-23.]]],\n","              \n","              \n","                      [[[-35.]]],\n","              \n","              \n","                      [[[-34.]]],\n","              \n","              \n","                      [[[-34.]]],\n","              \n","              \n","                      [[[-23.]]],\n","              \n","              \n","                      [[[-22.]]],\n","              \n","              \n","                      [[[-25.]]],\n","              \n","              \n","                      [[[-25.]]],\n","              \n","              \n","                      [[[-27.]]],\n","              \n","              \n","                      [[[-24.]]],\n","              \n","              \n","                      [[[-25.]]],\n","              \n","              \n","                      [[[-28.]]],\n","              \n","              \n","                      [[[-31.]]],\n","              \n","              \n","                      [[[-29.]]],\n","              \n","              \n","                      [[[-29.]]],\n","              \n","              \n","                      [[[-31.]]],\n","              \n","              \n","                      [[[-27.]]],\n","              \n","              \n","                      [[[-25.]]],\n","              \n","              \n","                      [[[-28.]]],\n","              \n","              \n","                      [[[-26.]]],\n","              \n","              \n","                      [[[-23.]]],\n","              \n","              \n","                      [[[-30.]]],\n","              \n","              \n","                      [[[-27.]]],\n","              \n","              \n","                      [[[-32.]]],\n","              \n","              \n","                      [[[-25.]]],\n","              \n","              \n","                      [[[-29.]]],\n","              \n","              \n","                      [[[-26.]]],\n","              \n","              \n","                      [[[-32.]]],\n","              \n","              \n","                      [[[-25.]]],\n","              \n","              \n","                      [[[-30.]]],\n","              \n","              \n","                      [[[-27.]]],\n","              \n","              \n","                      [[[-28.]]],\n","              \n","              \n","                      [[[-26.]]],\n","              \n","              \n","                      [[[-27.]]],\n","              \n","              \n","                      [[[-26.]]],\n","              \n","              \n","                      [[[-28.]]],\n","              \n","              \n","                      [[[-30.]]],\n","              \n","              \n","                      [[[-32.]]],\n","              \n","              \n","                      [[[-29.]]],\n","              \n","              \n","                      [[[-25.]]]], device='cuda:0')),\n","             ('module.layer3.5.conv1.fp_bias',\n","              tensor([-0.2421, -0.0781,  0.1405,  0.0821, -0.0612, -0.4580, -0.1070, -0.0279,\n","                      -0.0695, -0.3479, -0.1755, -0.3235, -0.0228, -0.4900, -0.0906, -0.2032,\n","                      -0.3410, -0.1245, -0.1039, -0.1896, -0.2678, -0.2493, -0.1130, -0.0021,\n","                      -0.3444,  0.1694,  0.0226,  0.1957, -0.3563, -0.1862, -0.1338, -0.0554,\n","                      -0.2093,  0.0318, -0.1275,  0.2162, -0.2791,  0.0706, -0.1288, -0.2010,\n","                       0.1370,  0.0899, -0.4615, -0.0756, -0.1868,  0.0305, -0.0162, -0.1262,\n","                      -0.3932, -0.1019, -0.3384, -0.0972, -0.1188, -0.1392, -0.0237, -0.1331,\n","                      -0.4411, -0.1710,  0.2028, -0.0274, -0.3046,  0.3547, -0.2764,  0.3233],\n","                     device='cuda:0')),\n","             ('module.layer3.5.conv1.accum_scale', tensor([[[  4504.8247]],\n","              \n","                      [[  4409.5947]],\n","              \n","                      [[  4656.3921]],\n","              \n","                      [[  5345.9556]],\n","              \n","                      [[  7893.3481]],\n","              \n","                      [[  4142.7715]],\n","              \n","                      [[  5605.8833]],\n","              \n","                      [[618780.8125]],\n","              \n","                      [[  8507.3672]],\n","              \n","                      [[  6607.2891]],\n","              \n","                      [[  5342.0542]],\n","              \n","                      [[  5074.0376]],\n","              \n","                      [[  6395.0244]],\n","              \n","                      [[  6524.7920]],\n","              \n","                      [[  9357.0967]],\n","              \n","                      [[  9545.2041]],\n","              \n","                      [[  5960.2539]],\n","              \n","                      [[  5808.7910]],\n","              \n","                      [[  4973.2266]],\n","              \n","                      [[  5165.9302]],\n","              \n","                      [[  6635.1450]],\n","              \n","                      [[  5779.1699]],\n","              \n","                      [[ 17158.2773]],\n","              \n","                      [[  5378.9487]],\n","              \n","                      [[  5946.2505]],\n","              \n","                      [[  4698.6943]],\n","              \n","                      [[  4493.3853]],\n","              \n","                      [[  8107.6440]],\n","              \n","                      [[  6380.6602]],\n","              \n","                      [[  6401.5640]],\n","              \n","                      [[  5945.0229]],\n","              \n","                      [[  4764.1152]],\n","              \n","                      [[  4776.0518]],\n","              \n","                      [[  8160.0410]],\n","              \n","                      [[  5284.9268]],\n","              \n","                      [[  6330.5757]],\n","              \n","                      [[  4922.8433]],\n","              \n","                      [[  5839.8066]],\n","              \n","                      [[  9164.5166]],\n","              \n","                      [[  5939.2671]],\n","              \n","                      [[  4967.9448]],\n","              \n","                      [[  6029.4839]],\n","              \n","                      [[  5989.5088]],\n","              \n","                      [[ 12796.4346]],\n","              \n","                      [[  5350.0034]],\n","              \n","                      [[  5499.7739]],\n","              \n","                      [[  8504.7881]],\n","              \n","                      [[  7622.4321]],\n","              \n","                      [[  5797.3032]],\n","              \n","                      [[ 12434.7246]],\n","              \n","                      [[  5168.0127]],\n","              \n","                      [[  9634.8965]],\n","              \n","                      [[  5452.3223]],\n","              \n","                      [[  6135.7627]],\n","              \n","                      [[  7127.5381]],\n","              \n","                      [[ 10770.2051]],\n","              \n","                      [[  5341.9502]],\n","              \n","                      [[ 13233.8896]],\n","              \n","                      [[  5963.0044]],\n","              \n","                      [[  5916.8667]],\n","              \n","                      [[  4505.6875]],\n","              \n","                      [[  6095.8745]],\n","              \n","                      [[ 14250.1562]],\n","              \n","                      [[  4751.4941]]], device='cuda:0')),\n","             ('module.layer3.5.conv1.is_simulated_quant_weight_shifted',\n","              tensor(False, device='cuda:0')),\n","             ('module.layer3.5.conv1.wrapped_module.weight',\n","              tensor([[[[33., 25., 18.],\n","                        [26., 36., 14.],\n","                        [43., 38., 15.]],\n","              \n","                       [[25., 21., 33.],\n","                        [24., 26., 31.],\n","                        [17., 32., 35.]],\n","              \n","                       [[37., 25.,  9.],\n","                        [46., 28., 31.],\n","                        [22., 18., 34.]],\n","              \n","                       ...,\n","              \n","                       [[21., 29., 29.],\n","                        [27., 37., 30.],\n","                        [26., 36., 30.]],\n","              \n","                       [[19., 36., 38.],\n","                        [38., 42., 29.],\n","                        [ 8., 13., 24.]],\n","              \n","                       [[29., 26., 35.],\n","                        [23., 37., 34.],\n","                        [24., 31., 38.]]],\n","              \n","              \n","                      [[[25., 27., 27.],\n","                        [38., 30., 27.],\n","                        [24., 45., 34.]],\n","              \n","                       [[24., 25., 26.],\n","                        [32., 30., 31.],\n","                        [36., 31., 32.]],\n","              \n","                       [[29., 35., 27.],\n","                        [33., 33., 39.],\n","                        [31., 34., 40.]],\n","              \n","                       ...,\n","              \n","                       [[35., 32., 37.],\n","                        [37., 36., 38.],\n","                        [34., 29., 31.]],\n","              \n","                       [[46., 53., 55.],\n","                        [27., 43., 43.],\n","                        [17., 28., 12.]],\n","              \n","                       [[23., 24., 20.],\n","                        [20., 21., 16.],\n","                        [32., 31., 33.]]],\n","              \n","              \n","                      [[[18., 10.,  7.],\n","                        [31., 29.,  5.],\n","                        [41., 36., 31.]],\n","              \n","                       [[24., 18., 21.],\n","                        [17., 12., 16.],\n","                        [21., 21., 14.]],\n","              \n","                       [[23., 23., 28.],\n","                        [ 8., 15., 21.],\n","                        [ 4., 10., 15.]],\n","              \n","                       ...,\n","              \n","                       [[17., 16., 26.],\n","                        [21., 18., 27.],\n","                        [22., 17., 25.]],\n","              \n","                       [[11., 10., 21.],\n","                        [50., 29., 16.],\n","                        [63., 32.,  3.]],\n","              \n","                       [[52., 33.,  4.],\n","                        [13., 27.,  6.],\n","                        [16., 18., 15.]]],\n","              \n","              \n","                      ...,\n","              \n","              \n","                      [[[33., 35., 27.],\n","                        [28., 35., 32.],\n","                        [40., 42., 32.]],\n","              \n","                       [[26., 23., 27.],\n","                        [27., 22., 22.],\n","                        [27., 27., 29.]],\n","              \n","                       [[26., 20., 32.],\n","                        [36., 26., 24.],\n","                        [30., 16., 38.]],\n","              \n","                       ...,\n","              \n","                       [[36., 26., 29.],\n","                        [35., 32., 31.],\n","                        [29., 33., 32.]],\n","              \n","                       [[24., 16., 44.],\n","                        [35., 39., 38.],\n","                        [38., 44., 45.]],\n","              \n","                       [[25., 26., 32.],\n","                        [20., 63., 46.],\n","                        [18., 52., 43.]]],\n","              \n","              \n","                      [[[27., 31., 28.],\n","                        [25., 40., 44.],\n","                        [53., 63., 43.]],\n","              \n","                       [[29., 28., 43.],\n","                        [22., 37., 53.],\n","                        [35., 38., 39.]],\n","              \n","                       [[16., 44., 54.],\n","                        [14., 40., 51.],\n","                        [10., 33., 45.]],\n","              \n","                       ...,\n","              \n","                       [[20., 25., 33.],\n","                        [18., 24., 35.],\n","                        [26., 30., 40.]],\n","              \n","                       [[32., 24., 34.],\n","                        [21., 17., 30.],\n","                        [10., 20., 27.]],\n","              \n","                       [[14., 14., 20.],\n","                        [15., 12., 31.],\n","                        [26., 28., 33.]]],\n","              \n","              \n","                      [[[24., 16., 23.],\n","                        [23., 11., 20.],\n","                        [13.,  7., 11.]],\n","              \n","                       [[28., 30., 29.],\n","                        [27., 31., 30.],\n","                        [24., 25., 24.]],\n","              \n","                       [[20., 24., 28.],\n","                        [17., 32., 36.],\n","                        [17., 33., 29.]],\n","              \n","                       ...,\n","              \n","                       [[25., 20., 23.],\n","                        [25., 21., 23.],\n","                        [27., 22., 23.]],\n","              \n","                       [[14., 24., 19.],\n","                        [15., 21., 15.],\n","                        [15., 23., 22.]],\n","              \n","                       [[37., 23., 42.],\n","                        [31., 29., 32.],\n","                        [33., 27., 23.]]]], device='cuda:0')),\n","             ('module.layer3.5.conv1.wrapped_module.bias',\n","              tensor([-1.0910e+03, -3.4400e+02,  6.5400e+02,  4.3900e+02, -4.8300e+02,\n","                      -1.8980e+03, -6.0000e+02, -1.7246e+04, -5.9100e+02, -2.2990e+03,\n","                      -9.3800e+02, -1.6420e+03, -1.4600e+02, -3.1970e+03, -8.4800e+02,\n","                      -1.9400e+03, -2.0320e+03, -7.2300e+02, -5.1600e+02, -9.8000e+02,\n","                      -1.7770e+03, -1.4410e+03, -1.9390e+03, -1.1000e+01, -2.0480e+03,\n","                       7.9600e+02,  1.0100e+02,  1.5870e+03, -2.2730e+03, -1.1920e+03,\n","                      -7.9500e+02, -2.6400e+02, -1.0000e+03,  2.6000e+02, -6.7400e+02,\n","                       1.3690e+03, -1.3740e+03,  4.1200e+02, -1.1800e+03, -1.1940e+03,\n","                       6.8100e+02,  5.4200e+02, -2.7640e+03, -9.6800e+02, -9.9900e+02,\n","                       1.6800e+02, -1.3800e+02, -9.6200e+02, -2.2790e+03, -1.2670e+03,\n","                      -1.7490e+03, -9.3600e+02, -6.4800e+02, -8.5400e+02, -1.6900e+02,\n","                      -1.4340e+03, -2.3560e+03, -2.2630e+03,  1.2090e+03, -1.6200e+02,\n","                      -1.3720e+03,  2.1620e+03, -3.9390e+03,  1.5360e+03], device='cuda:0')),\n","             ('module.layer3.5.conv2.num_forwards',\n","              tensor([40], device='cuda:0')),\n","             ('module.layer3.5.conv2.force_readjust',\n","              tensor(False, device='cuda:0')),\n","             ('module.layer3.5.conv2.output_scale',\n","              tensor([8.9535], device='cuda:0')),\n","             ('module.layer3.5.conv2.output_zero_point',\n","              tensor([-24.], device='cuda:0')),\n","             ('module.layer3.5.conv2.w_scale', tensor([[[[194.4189]]],\n","              \n","              \n","                      [[[ 38.6862]]],\n","              \n","              \n","                      [[[ 49.6983]]],\n","              \n","              \n","                      [[[ 51.0324]]],\n","              \n","              \n","                      [[[ 30.9831]]],\n","              \n","              \n","                      [[[352.5360]]],\n","              \n","              \n","                      [[[ 59.9359]]],\n","              \n","              \n","                      [[[201.4167]]],\n","              \n","              \n","                      [[[ 72.0689]]],\n","              \n","              \n","                      [[[ 85.3882]]],\n","              \n","              \n","                      [[[815.7324]]],\n","              \n","              \n","                      [[[ 50.3303]]],\n","              \n","              \n","                      [[[ 62.7384]]],\n","              \n","              \n","                      [[[ 42.1445]]],\n","              \n","              \n","                      [[[167.4520]]],\n","              \n","              \n","                      [[[ 73.4837]]],\n","              \n","              \n","                      [[[ 58.2543]]],\n","              \n","              \n","                      [[[ 97.7199]]],\n","              \n","              \n","                      [[[ 51.4218]]],\n","              \n","              \n","                      [[[114.2482]]],\n","              \n","              \n","                      [[[356.6700]]],\n","              \n","              \n","                      [[[173.2752]]],\n","              \n","              \n","                      [[[100.1321]]],\n","              \n","              \n","                      [[[233.5562]]],\n","              \n","              \n","                      [[[ 42.8062]]],\n","              \n","              \n","                      [[[121.3485]]],\n","              \n","              \n","                      [[[137.6576]]],\n","              \n","              \n","                      [[[ 81.0110]]],\n","              \n","              \n","                      [[[ 88.6923]]],\n","              \n","              \n","                      [[[ 99.2328]]],\n","              \n","              \n","                      [[[ 52.1263]]],\n","              \n","              \n","                      [[[ 76.0860]]],\n","              \n","              \n","                      [[[ 97.0660]]],\n","              \n","              \n","                      [[[ 74.9239]]],\n","              \n","              \n","                      [[[261.7843]]],\n","              \n","              \n","                      [[[111.6973]]],\n","              \n","              \n","                      [[[ 72.6810]]],\n","              \n","              \n","                      [[[127.9628]]],\n","              \n","              \n","                      [[[ 62.0964]]],\n","              \n","              \n","                      [[[ 80.4164]]],\n","              \n","              \n","                      [[[ 98.8830]]],\n","              \n","              \n","                      [[[855.3613]]],\n","              \n","              \n","                      [[[ 94.1888]]],\n","              \n","              \n","                      [[[386.1578]]],\n","              \n","              \n","                      [[[353.7337]]],\n","              \n","              \n","                      [[[140.1090]]],\n","              \n","              \n","                      [[[ 50.9247]]],\n","              \n","              \n","                      [[[ 35.4041]]],\n","              \n","              \n","                      [[[ 76.0752]]],\n","              \n","              \n","                      [[[564.4968]]],\n","              \n","              \n","                      [[[104.2064]]],\n","              \n","              \n","                      [[[160.5137]]],\n","              \n","              \n","                      [[[ 42.1810]]],\n","              \n","              \n","                      [[[197.3370]]],\n","              \n","              \n","                      [[[389.9692]]],\n","              \n","              \n","                      [[[ 82.1994]]],\n","              \n","              \n","                      [[[166.3450]]],\n","              \n","              \n","                      [[[ 56.9568]]],\n","              \n","              \n","                      [[[141.6521]]],\n","              \n","              \n","                      [[[ 80.8736]]],\n","              \n","              \n","                      [[[ 57.9902]]],\n","              \n","              \n","                      [[[ 27.8172]]],\n","              \n","              \n","                      [[[ 84.3241]]],\n","              \n","              \n","                      [[[ 41.7940]]]], device='cuda:0')),\n","             ('module.layer3.5.conv2.w_zero_point', tensor([[[[-22.]]],\n","              \n","              \n","                      [[[-27.]]],\n","              \n","              \n","                      [[[-31.]]],\n","              \n","              \n","                      [[[-28.]]],\n","              \n","              \n","                      [[[-21.]]],\n","              \n","              \n","                      [[[-30.]]],\n","              \n","              \n","                      [[[-27.]]],\n","              \n","              \n","                      [[[-26.]]],\n","              \n","              \n","                      [[[-26.]]],\n","              \n","              \n","                      [[[-25.]]],\n","              \n","              \n","                      [[[-31.]]],\n","              \n","              \n","                      [[[-27.]]],\n","              \n","              \n","                      [[[-37.]]],\n","              \n","              \n","                      [[[-28.]]],\n","              \n","              \n","                      [[[-26.]]],\n","              \n","              \n","                      [[[-23.]]],\n","              \n","              \n","                      [[[-34.]]],\n","              \n","              \n","                      [[[-31.]]],\n","              \n","              \n","                      [[[-28.]]],\n","              \n","              \n","                      [[[-27.]]],\n","              \n","              \n","                      [[[-32.]]],\n","              \n","              \n","                      [[[-33.]]],\n","              \n","              \n","                      [[[-26.]]],\n","              \n","              \n","                      [[[-39.]]],\n","              \n","              \n","                      [[[-28.]]],\n","              \n","              \n","                      [[[-34.]]],\n","              \n","              \n","                      [[[-34.]]],\n","              \n","              \n","                      [[[-27.]]],\n","              \n","              \n","                      [[[-33.]]],\n","              \n","              \n","                      [[[-29.]]],\n","              \n","              \n","                      [[[-38.]]],\n","              \n","              \n","                      [[[-24.]]],\n","              \n","              \n","                      [[[-26.]]],\n","              \n","              \n","                      [[[-29.]]],\n","              \n","              \n","                      [[[-31.]]],\n","              \n","              \n","                      [[[-36.]]],\n","              \n","              \n","                      [[[-27.]]],\n","              \n","              \n","                      [[[-34.]]],\n","              \n","              \n","                      [[[-32.]]],\n","              \n","              \n","                      [[[-31.]]],\n","              \n","              \n","                      [[[-34.]]],\n","              \n","              \n","                      [[[-31.]]],\n","              \n","              \n","                      [[[-33.]]],\n","              \n","              \n","                      [[[-33.]]],\n","              \n","              \n","                      [[[-33.]]],\n","              \n","              \n","                      [[[-28.]]],\n","              \n","              \n","                      [[[-24.]]],\n","              \n","              \n","                      [[[-27.]]],\n","              \n","              \n","                      [[[-37.]]],\n","              \n","              \n","                      [[[-32.]]],\n","              \n","              \n","                      [[[-29.]]],\n","              \n","              \n","                      [[[-34.]]],\n","              \n","              \n","                      [[[-28.]]],\n","              \n","              \n","                      [[[-34.]]],\n","              \n","              \n","                      [[[-31.]]],\n","              \n","              \n","                      [[[-29.]]],\n","              \n","              \n","                      [[[-33.]]],\n","              \n","              \n","                      [[[-25.]]],\n","              \n","              \n","                      [[[-32.]]],\n","              \n","              \n","                      [[[-35.]]],\n","              \n","              \n","                      [[[-26.]]],\n","              \n","              \n","                      [[[-12.]]],\n","              \n","              \n","                      [[[-34.]]],\n","              \n","              \n","                      [[[-38.]]]], device='cuda:0')),\n","             ('module.layer3.5.conv2.fp_bias',\n","              tensor([-0.2179, -0.7575,  0.0059, -0.6007,  0.1979, -0.0687, -0.0384,  0.0300,\n","                      -0.1891, -0.1459, -0.0910, -0.3259, -0.1689,  0.4759, -0.2313,  0.0163,\n","                       0.2572,  0.0421,  0.0735, -0.1273, -0.1875, -0.0052, -0.1973,  0.0287,\n","                      -0.1244,  0.1709, -0.0544, -0.2683, -0.1392,  0.1934,  0.0090, -0.3371,\n","                      -0.1243, -0.2371, -0.0250,  0.0057, -0.2492,  0.2866, -0.0475, -0.0698,\n","                      -0.0507, -0.2286, -0.1862,  0.0251, -0.0405, -0.0571, -1.1059, -0.6912,\n","                      -0.1208,  0.0252, -0.3960,  0.0156,  0.1294, -0.1049,  0.0209, -0.1954,\n","                       0.2125, -0.1858, -0.1488, -0.0234,  0.1882, -0.0098, -0.0272,  0.4460],\n","                     device='cuda:0')),\n","             ('module.layer3.5.conv2.accum_scale', tensor([[[10580.8916]],\n","              \n","                      [[ 2105.4236]],\n","              \n","                      [[ 2704.7402]],\n","              \n","                      [[ 2777.3442]],\n","              \n","                      [[ 1686.1971]],\n","              \n","                      [[19186.1230]],\n","              \n","                      [[ 3261.9011]],\n","              \n","                      [[10961.7324]],\n","              \n","                      [[ 3922.2148]],\n","              \n","                      [[ 4647.0972]],\n","              \n","                      [[44394.7344]],\n","              \n","                      [[ 2739.1367]],\n","              \n","                      [[ 3414.4197]],\n","              \n","                      [[ 2293.6387]],\n","              \n","                      [[ 9113.2695]],\n","              \n","                      [[ 3999.2153]],\n","              \n","                      [[ 3170.3840]],\n","              \n","                      [[ 5318.2261]],\n","              \n","                      [[ 2798.5391]],\n","              \n","                      [[ 6217.7490]],\n","              \n","                      [[19411.1113]],\n","              \n","                      [[ 9430.1855]],\n","              \n","                      [[ 5449.5049]],\n","              \n","                      [[12710.8672]],\n","              \n","                      [[ 2329.6487]],\n","              \n","                      [[ 6604.1675]],\n","              \n","                      [[ 7491.7627]],\n","              \n","                      [[ 4408.8745]],\n","              \n","                      [[ 4826.9155]],\n","              \n","                      [[ 5400.5640]],\n","              \n","                      [[ 2836.8770]],\n","              \n","                      [[ 4140.8423]],\n","              \n","                      [[ 5282.6396]],\n","              \n","                      [[ 4077.5928]],\n","              \n","                      [[14247.1309]],\n","              \n","                      [[ 6078.9209]],\n","              \n","                      [[ 3955.5276]],\n","              \n","                      [[ 6964.1406]],\n","              \n","                      [[ 3379.4832]],\n","              \n","                      [[ 4376.5151]],\n","              \n","                      [[ 5381.5249]],\n","              \n","                      [[46551.4688]],\n","              \n","                      [[ 5126.0503]],\n","              \n","                      [[21015.9258]],\n","              \n","                      [[19251.3066]],\n","              \n","                      [[ 7625.1743]],\n","              \n","                      [[ 2771.4819]],\n","              \n","                      [[ 1926.8016]],\n","              \n","                      [[ 4140.2524]],\n","              \n","                      [[30721.7012]],\n","              \n","                      [[ 5671.2393]],\n","              \n","                      [[ 8735.6650]],\n","              \n","                      [[ 2295.6238]],\n","              \n","                      [[10739.7051]],\n","              \n","                      [[21223.3555]],\n","              \n","                      [[ 4473.5508]],\n","              \n","                      [[ 9053.0195]],\n","              \n","                      [[ 3099.7666]],\n","              \n","                      [[ 7709.1543]],\n","              \n","                      [[ 4401.3955]],\n","              \n","                      [[ 3156.0090]],\n","              \n","                      [[ 1513.9023]],\n","              \n","                      [[ 4589.1851]],\n","              \n","                      [[ 2274.5613]]], device='cuda:0')),\n","             ('module.layer3.5.conv2.is_simulated_quant_weight_shifted',\n","              tensor(False, device='cuda:0')),\n","             ('module.layer3.5.conv2.wrapped_module.weight',\n","              tensor([[[[16., 35., 55.],\n","                        [27., 30., 24.],\n","                        [27., 27., 16.]],\n","              \n","                       [[ 8.,  9., 17.],\n","                        [19., 18., 27.],\n","                        [24., 27., 22.]],\n","              \n","                       [[34., 35., 26.],\n","                        [30., 25., 19.],\n","                        [23., 14.,  4.]],\n","              \n","                       ...,\n","              \n","                       [[17., 15., 12.],\n","                        [31., 23., 13.],\n","                        [24., 15., 11.]],\n","              \n","                       [[19., 24., 25.],\n","                        [17., 16., 16.],\n","                        [19., 18., 20.]],\n","              \n","                       [[10., 15., 19.],\n","                        [22., 27., 25.],\n","                        [27., 27., 27.]]],\n","              \n","              \n","                      [[[24., 28., 31.],\n","                        [28., 30., 27.],\n","                        [26., 14., 17.]],\n","              \n","                       [[27., 26., 21.],\n","                        [36., 27., 20.],\n","                        [35., 16., 14.]],\n","              \n","                       [[17., 24., 19.],\n","                        [28., 33., 27.],\n","                        [23., 16.,  5.]],\n","              \n","                       ...,\n","              \n","                       [[24., 36., 34.],\n","                        [16., 23., 20.],\n","                        [29., 19., 15.]],\n","              \n","                       [[32., 21., 21.],\n","                        [45., 45., 54.],\n","                        [26., 33., 40.]],\n","              \n","                       [[26., 24., 25.],\n","                        [30., 30., 26.],\n","                        [25., 34., 35.]]],\n","              \n","              \n","                      [[[31., 28., 35.],\n","                        [25., 37., 58.],\n","                        [22., 31., 38.]],\n","              \n","                       [[30., 40., 36.],\n","                        [23., 29., 23.],\n","                        [17., 11., 15.]],\n","              \n","                       [[29., 34., 36.],\n","                        [28., 26., 24.],\n","                        [30., 23., 21.]],\n","              \n","                       ...,\n","              \n","                       [[36., 34., 41.],\n","                        [39., 39., 41.],\n","                        [50., 38., 40.]],\n","              \n","                       [[39., 32., 21.],\n","                        [38., 34., 27.],\n","                        [28., 26., 27.]],\n","              \n","                       [[43., 36., 38.],\n","                        [27., 22., 41.],\n","                        [25., 18., 24.]]],\n","              \n","              \n","                      ...,\n","              \n","              \n","                      [[[24., 14., 17.],\n","                        [18., 22., 24.],\n","                        [ 5.,  8.,  0.]],\n","              \n","                       [[ 5.,  4., 11.],\n","                        [16., 16., 16.],\n","                        [29., 26., 19.]],\n","              \n","                       [[ 6., 14., 14.],\n","                        [10., 13.,  8.],\n","                        [ 9., 14., 10.]],\n","              \n","                       ...,\n","              \n","                       [[10.,  5.,  5.],\n","                        [ 8.,  7., 13.],\n","                        [ 5., 11., 20.]],\n","              \n","                       [[13., 12., 10.],\n","                        [12., 14., 13.],\n","                        [ 7.,  9., 10.]],\n","              \n","                       [[ 8.,  8.,  5.],\n","                        [ 8.,  8.,  9.],\n","                        [11., 13., 14.]]],\n","              \n","              \n","                      [[[39., 37., 24.],\n","                        [28., 37., 30.],\n","                        [20., 20., 32.]],\n","              \n","                       [[49., 15., 11.],\n","                        [46., 21., 18.],\n","                        [21., 17., 35.]],\n","              \n","                       [[31., 44., 58.],\n","                        [18., 25., 45.],\n","                        [11., 15., 27.]],\n","              \n","                       ...,\n","              \n","                       [[38., 46., 26.],\n","                        [49., 53., 34.],\n","                        [51., 52., 30.]],\n","              \n","                       [[24., 24., 32.],\n","                        [36., 38., 44.],\n","                        [35., 39., 41.]],\n","              \n","                       [[35., 31., 33.],\n","                        [32., 31., 33.],\n","                        [35., 35., 24.]]],\n","              \n","              \n","                      [[[47., 20., 16.],\n","                        [39., 39., 40.],\n","                        [48., 43., 31.]],\n","              \n","                       [[43., 40., 30.],\n","                        [40., 38., 29.],\n","                        [24., 35., 41.]],\n","              \n","                       [[40., 37., 18.],\n","                        [37., 52., 40.],\n","                        [36., 50., 43.]],\n","              \n","                       ...,\n","              \n","                       [[39., 32., 35.],\n","                        [31., 21., 32.],\n","                        [41., 42., 37.]],\n","              \n","                       [[48., 40., 28.],\n","                        [37., 37., 35.],\n","                        [35., 34., 35.]],\n","              \n","                       [[29., 35., 43.],\n","                        [30., 40., 34.],\n","                        [36., 38., 24.]]]], device='cuda:0')),\n","             ('module.layer3.5.conv2.wrapped_module.bias',\n","              tensor([ -2306.,  -1595.,     16.,  -1668.,    334.,  -1319.,   -125.,    329.,\n","                        -742.,   -678.,  -4041.,   -893.,   -577.,   1092.,  -2108.,     65.,\n","                         815.,    224.,    206.,   -792.,  -3640.,    -49.,  -1075.,    365.,\n","                        -290.,   1129.,   -407.,  -1183.,   -672.,   1045.,     26.,  -1396.,\n","                        -657.,   -967.,   -356.,     35.,   -986.,   1996.,   -160.,   -306.,\n","                        -273., -10644.,   -955.,    528.,   -779.,   -435.,  -3065.,  -1332.,\n","                        -500.,    774.,  -2246.,    136.,    297.,  -1127.,    445.,   -874.,\n","                        1924.,   -576.,  -1147.,   -103.,    594.,    -15.,   -125.,   1014.],\n","                     device='cuda:0')),\n","             ('module.layer3.5.relu2.num_forwards',\n","              tensor([40], device='cuda:0')),\n","             ('module.layer3.5.relu2.force_readjust',\n","              tensor(False, device='cuda:0')),\n","             ('module.layer3.5.relu2.output_scale',\n","              tensor([6.4157], device='cuda:0')),\n","             ('module.layer3.5.relu2.output_zero_point',\n","              tensor([0.], device='cuda:0')),\n","             ('module.layer3.5.residual_eltwiseadd.num_forwards',\n","              tensor([40], device='cuda:0')),\n","             ('module.layer3.5.residual_eltwiseadd.force_readjust',\n","              tensor(False, device='cuda:0')),\n","             ('module.layer3.5.residual_eltwiseadd.output_scale',\n","              tensor([6.4157], device='cuda:0')),\n","             ('module.layer3.5.residual_eltwiseadd.output_zero_point',\n","              tensor([0.], device='cuda:0')),\n","             ('module.layer3.6.conv1.num_forwards',\n","              tensor([40], device='cuda:0')),\n","             ('module.layer3.6.conv1.force_readjust',\n","              tensor(False, device='cuda:0')),\n","             ('module.layer3.6.conv1.output_scale',\n","              tensor([36.7640], device='cuda:0')),\n","             ('module.layer3.6.conv1.output_zero_point',\n","              tensor([0.], device='cuda:0')),\n","             ('module.layer3.6.conv1.w_scale', tensor([[[[ 892.8488]]],\n","              \n","              \n","                      [[[ 859.7339]]],\n","              \n","              \n","                      [[[ 627.2791]]],\n","              \n","              \n","                      [[[ 838.1286]]],\n","              \n","              \n","                      [[[1270.7378]]],\n","              \n","              \n","                      [[[1390.9584]]],\n","              \n","              \n","                      [[[1267.1581]]],\n","              \n","              \n","                      [[[ 631.0789]]],\n","              \n","              \n","                      [[[ 977.3986]]],\n","              \n","              \n","                      [[[ 590.7607]]],\n","              \n","              \n","                      [[[ 594.3497]]],\n","              \n","              \n","                      [[[ 759.0135]]],\n","              \n","              \n","                      [[[ 670.7761]]],\n","              \n","              \n","                      [[[ 837.3560]]],\n","              \n","              \n","                      [[[ 537.7389]]],\n","              \n","              \n","                      [[[ 779.0126]]],\n","              \n","              \n","                      [[[ 828.3985]]],\n","              \n","              \n","                      [[[ 565.9987]]],\n","              \n","              \n","                      [[[ 677.9540]]],\n","              \n","              \n","                      [[[1820.7915]]],\n","              \n","              \n","                      [[[ 852.7751]]],\n","              \n","              \n","                      [[[ 981.0956]]],\n","              \n","              \n","                      [[[ 503.9626]]],\n","              \n","              \n","                      [[[ 464.7492]]],\n","              \n","              \n","                      [[[ 628.7049]]],\n","              \n","              \n","                      [[[ 616.8916]]],\n","              \n","              \n","                      [[[ 713.3991]]],\n","              \n","              \n","                      [[[1372.6515]]],\n","              \n","              \n","                      [[[1013.7443]]],\n","              \n","              \n","                      [[[ 787.3166]]],\n","              \n","              \n","                      [[[ 502.2029]]],\n","              \n","              \n","                      [[[ 607.5986]]],\n","              \n","              \n","                      [[[2130.3967]]],\n","              \n","              \n","                      [[[ 509.3235]]],\n","              \n","              \n","                      [[[ 893.2934]]],\n","              \n","              \n","                      [[[1045.8484]]],\n","              \n","              \n","                      [[[ 806.5132]]],\n","              \n","              \n","                      [[[ 582.4673]]],\n","              \n","              \n","                      [[[ 594.3641]]],\n","              \n","              \n","                      [[[ 608.3917]]],\n","              \n","              \n","                      [[[1260.7614]]],\n","              \n","              \n","                      [[[ 735.2036]]],\n","              \n","              \n","                      [[[ 822.6882]]],\n","              \n","              \n","                      [[[ 543.0355]]],\n","              \n","              \n","                      [[[ 771.3521]]],\n","              \n","              \n","                      [[[ 611.0117]]],\n","              \n","              \n","                      [[[ 719.8297]]],\n","              \n","              \n","                      [[[ 986.2808]]],\n","              \n","              \n","                      [[[ 457.8791]]],\n","              \n","              \n","                      [[[ 592.5153]]],\n","              \n","              \n","                      [[[ 664.8643]]],\n","              \n","              \n","                      [[[ 478.9453]]],\n","              \n","              \n","                      [[[ 692.5255]]],\n","              \n","              \n","                      [[[1059.0806]]],\n","              \n","              \n","                      [[[1022.5824]]],\n","              \n","              \n","                      [[[1061.2419]]],\n","              \n","              \n","                      [[[1023.8994]]],\n","              \n","              \n","                      [[[1077.1484]]],\n","              \n","              \n","                      [[[ 962.8342]]],\n","              \n","              \n","                      [[[ 630.1578]]],\n","              \n","              \n","                      [[[ 580.3558]]],\n","              \n","              \n","                      [[[ 605.3518]]],\n","              \n","              \n","                      [[[ 921.2346]]],\n","              \n","              \n","                      [[[ 740.1015]]]], device='cuda:0')),\n","             ('module.layer3.6.conv1.w_zero_point', tensor([[[[-26.]]],\n","              \n","              \n","                      [[[-27.]]],\n","              \n","              \n","                      [[[-26.]]],\n","              \n","              \n","                      [[[-26.]]],\n","              \n","              \n","                      [[[-29.]]],\n","              \n","              \n","                      [[[-25.]]],\n","              \n","              \n","                      [[[-26.]]],\n","              \n","              \n","                      [[[-24.]]],\n","              \n","              \n","                      [[[-29.]]],\n","              \n","              \n","                      [[[-27.]]],\n","              \n","              \n","                      [[[-26.]]],\n","              \n","              \n","                      [[[-30.]]],\n","              \n","              \n","                      [[[-29.]]],\n","              \n","              \n","                      [[[-25.]]],\n","              \n","              \n","                      [[[-28.]]],\n","              \n","              \n","                      [[[-28.]]],\n","              \n","              \n","                      [[[-33.]]],\n","              \n","              \n","                      [[[-21.]]],\n","              \n","              \n","                      [[[-22.]]],\n","              \n","              \n","                      [[[-27.]]],\n","              \n","              \n","                      [[[-28.]]],\n","              \n","              \n","                      [[[-28.]]],\n","              \n","              \n","                      [[[-27.]]],\n","              \n","              \n","                      [[[-25.]]],\n","              \n","              \n","                      [[[-26.]]],\n","              \n","              \n","                      [[[-29.]]],\n","              \n","              \n","                      [[[-29.]]],\n","              \n","              \n","                      [[[-26.]]],\n","              \n","              \n","                      [[[-31.]]],\n","              \n","              \n","                      [[[-29.]]],\n","              \n","              \n","                      [[[-25.]]],\n","              \n","              \n","                      [[[-28.]]],\n","              \n","              \n","                      [[[-22.]]],\n","              \n","              \n","                      [[[-26.]]],\n","              \n","              \n","                      [[[-29.]]],\n","              \n","              \n","                      [[[-30.]]],\n","              \n","              \n","                      [[[-35.]]],\n","              \n","              \n","                      [[[-33.]]],\n","              \n","              \n","                      [[[-17.]]],\n","              \n","              \n","                      [[[-25.]]],\n","              \n","              \n","                      [[[-30.]]],\n","              \n","              \n","                      [[[-25.]]],\n","              \n","              \n","                      [[[-33.]]],\n","              \n","              \n","                      [[[-29.]]],\n","              \n","              \n","                      [[[-31.]]],\n","              \n","              \n","                      [[[-28.]]],\n","              \n","              \n","                      [[[-29.]]],\n","              \n","              \n","                      [[[-29.]]],\n","              \n","              \n","                      [[[-37.]]],\n","              \n","              \n","                      [[[-24.]]],\n","              \n","              \n","                      [[[-26.]]],\n","              \n","              \n","                      [[[-27.]]],\n","              \n","              \n","                      [[[-20.]]],\n","              \n","              \n","                      [[[-24.]]],\n","              \n","              \n","                      [[[-27.]]],\n","              \n","              \n","                      [[[-29.]]],\n","              \n","              \n","                      [[[-26.]]],\n","              \n","              \n","                      [[[-27.]]],\n","              \n","              \n","                      [[[-31.]]],\n","              \n","              \n","                      [[[-28.]]],\n","              \n","              \n","                      [[[-30.]]],\n","              \n","              \n","                      [[[-27.]]],\n","              \n","              \n","                      [[[-29.]]],\n","              \n","              \n","                      [[[-25.]]]], device='cuda:0')),\n","             ('module.layer3.6.conv1.fp_bias',\n","              tensor([-0.0639, -0.1586, -0.1174, -0.1785, -0.2036, -0.1114, -0.0606, -0.0937,\n","                      -0.2508, -0.3548, -0.1263, -0.1535,  0.0266, -0.1215, -0.1828, -0.2766,\n","                      -0.0923, -0.5072, -0.3017,  0.0420, -0.1552, -0.0576, -0.1898, -0.3873,\n","                      -0.0132, -0.3040, -0.1307, -0.1622,  0.2160, -0.2444, -0.0119, -0.2714,\n","                      -0.0485, -0.0587,  0.0467, -0.3063, -0.0489, -0.3003, -0.3103, -0.1403,\n","                      -0.0727, -0.3094, -0.2159, -0.0764, -0.2862, -0.3549, -0.1253, -0.1990,\n","                      -0.0434, -0.2021, -0.3523, -0.1334, -0.5031, -0.0298, -0.0618,  0.3560,\n","                      -0.4056, -0.3298,  0.2244, -0.1524, -0.1732, -0.1338, -0.0053,  0.2595],\n","                     device='cuda:0')),\n","             ('module.layer3.6.conv1.accum_scale', tensor([[[ 5728.2573]],\n","              \n","                      [[ 5515.8022]],\n","              \n","                      [[ 4024.4399]],\n","              \n","                      [[ 5377.1890]],\n","              \n","                      [[ 8152.6831]],\n","              \n","                      [[ 8923.9834]],\n","              \n","                      [[ 8129.7168]],\n","              \n","                      [[ 4048.8181]],\n","              \n","                      [[ 6270.7046]],\n","              \n","                      [[ 3790.1484]],\n","              \n","                      [[ 3813.1746]],\n","              \n","                      [[ 4869.6094]],\n","              \n","                      [[ 4303.5039]],\n","              \n","                      [[ 5372.2319]],\n","              \n","                      [[ 3449.9761]],\n","              \n","                      [[ 4997.9175]],\n","              \n","                      [[ 5314.7632]],\n","              \n","                      [[ 3631.2827]],\n","              \n","                      [[ 4349.5552]],\n","              \n","                      [[11681.6680]],\n","              \n","                      [[ 5471.1562]],\n","              \n","                      [[ 6294.4238]],\n","              \n","                      [[ 3233.2773]],\n","              \n","                      [[ 2981.6956]],\n","              \n","                      [[ 4033.5874]],\n","              \n","                      [[ 3957.7966]],\n","              \n","                      [[ 4576.9609]],\n","              \n","                      [[ 8806.5322]],\n","              \n","                      [[ 6503.8877]],\n","              \n","                      [[ 5051.1938]],\n","              \n","                      [[ 3221.9871]],\n","              \n","                      [[ 3898.1753]],\n","              \n","                      [[13668.0049]],\n","              \n","                      [[ 3267.6709]],\n","              \n","                      [[ 5731.1099]],\n","              \n","                      [[ 6709.8584]],\n","              \n","                      [[ 5174.3535]],\n","              \n","                      [[ 3736.9407]],\n","              \n","                      [[ 3813.2671]],\n","              \n","                      [[ 3903.2639]],\n","              \n","                      [[ 8088.6772]],\n","              \n","                      [[ 4716.8516]],\n","              \n","                      [[ 5278.1279]],\n","              \n","                      [[ 3483.9573]],\n","              \n","                      [[ 4948.7700]],\n","              \n","                      [[ 3920.0730]],\n","              \n","                      [[ 4618.2178]],\n","              \n","                      [[ 6327.6904]],\n","              \n","                      [[ 2937.6189]],\n","              \n","                      [[ 3801.4055]],\n","              \n","                      [[ 4265.5752]],\n","              \n","                      [[ 3072.7734]],\n","              \n","                      [[ 4443.0420]],\n","              \n","                      [[ 6794.7524]],\n","              \n","                      [[ 6560.5908]],\n","              \n","                      [[ 6808.6191]],\n","              \n","                      [[ 6569.0400]],\n","              \n","                      [[ 6910.6704]],\n","              \n","                      [[ 6177.2637]],\n","              \n","                      [[ 4042.9087]],\n","              \n","                      [[ 3723.3936]],\n","              \n","                      [[ 3883.7607]],\n","              \n","                      [[ 5910.3730]],\n","              \n","                      [[ 4748.2754]]], device='cuda:0')),\n","             ('module.layer3.6.conv1.is_simulated_quant_weight_shifted',\n","              tensor(False, device='cuda:0')),\n","             ('module.layer3.6.conv1.wrapped_module.weight',\n","              tensor([[[[28., 25., 22.],\n","                        [28., 19., 17.],\n","                        [25., 13.,  8.]],\n","              \n","                       [[40., 38., 19.],\n","                        [32., 33., 24.],\n","                        [27., 32., 33.]],\n","              \n","                       [[31., 24., 26.],\n","                        [30., 26., 17.],\n","                        [51., 45., 31.]],\n","              \n","                       ...,\n","              \n","                       [[18., 21., 22.],\n","                        [17., 31., 36.],\n","                        [20., 35., 40.]],\n","              \n","                       [[19., 19., 11.],\n","                        [16., 16., 13.],\n","                        [11., 31., 35.]],\n","              \n","                       [[37., 33., 28.],\n","                        [29., 15., 12.],\n","                        [28., 13., 14.]]],\n","              \n","              \n","                      [[[27., 21., 17.],\n","                        [29., 32., 14.],\n","                        [35., 44.,  9.]],\n","              \n","                       [[20., 16., 19.],\n","                        [23., 15., 27.],\n","                        [27., 25., 30.]],\n","              \n","                       [[ 6.,  4.,  5.],\n","                        [ 5., 17., 19.],\n","                        [24., 20., 31.]],\n","              \n","                       ...,\n","              \n","                       [[14., 31., 40.],\n","                        [15., 25., 26.],\n","                        [30., 26., 22.]],\n","              \n","                       [[21., 11., 12.],\n","                        [26., 18., 22.],\n","                        [23., 21., 11.]],\n","              \n","                       [[46., 35., 33.],\n","                        [39., 39., 22.],\n","                        [38., 39., 20.]]],\n","              \n","              \n","                      [[[36., 37., 37.],\n","                        [42., 32., 19.],\n","                        [39., 32., 26.]],\n","              \n","                       [[26., 33., 38.],\n","                        [31., 34., 34.],\n","                        [26., 20., 22.]],\n","              \n","                       [[24.,  9.,  4.],\n","                        [45., 38., 45.],\n","                        [23., 45., 39.]],\n","              \n","                       ...,\n","              \n","                       [[28., 25., 22.],\n","                        [17., 16., 20.],\n","                        [11., 15., 20.]],\n","              \n","                       [[24., 31., 28.],\n","                        [20., 21., 21.],\n","                        [19.,  7., 10.]],\n","              \n","                       [[43., 32., 23.],\n","                        [31., 24.,  9.],\n","                        [ 3.,  2.,  8.]]],\n","              \n","              \n","                      ...,\n","              \n","              \n","                      [[[35., 29., 27.],\n","                        [17., 20., 19.],\n","                        [15.,  9.,  9.]],\n","              \n","                       [[27., 33., 29.],\n","                        [24., 27., 24.],\n","                        [30., 26., 26.]],\n","              \n","                       [[32., 33., 28.],\n","                        [19., 21., 27.],\n","                        [22., 26., 38.]],\n","              \n","                       ...,\n","              \n","                       [[33., 34., 33.],\n","                        [28., 26., 29.],\n","                        [29., 18., 19.]],\n","              \n","                       [[25., 30., 25.],\n","                        [38., 47., 37.],\n","                        [29., 37., 30.]],\n","              \n","                       [[12.,  0., 14.],\n","                        [15., 21., 26.],\n","                        [40., 41., 28.]]],\n","              \n","              \n","                      [[[20., 27., 18.],\n","                        [24., 27., 18.],\n","                        [18., 12., 17.]],\n","              \n","                       [[15., 10., 22.],\n","                        [29., 24., 24.],\n","                        [23., 23., 21.]],\n","              \n","                       [[39., 26., 15.],\n","                        [29., 16., 23.],\n","                        [17., 16., 23.]],\n","              \n","                       ...,\n","              \n","                       [[26., 35., 35.],\n","                        [37., 46., 39.],\n","                        [34., 38., 23.]],\n","              \n","                       [[25., 39., 35.],\n","                        [24., 13., 17.],\n","                        [20., 11., 16.]],\n","              \n","                       [[33., 25., 28.],\n","                        [26., 13., 20.],\n","                        [23., 17., 21.]]],\n","              \n","              \n","                      [[[24., 28., 25.],\n","                        [19., 28., 20.],\n","                        [ 7., 26., 24.]],\n","              \n","                       [[22., 13.,  5.],\n","                        [22., 24., 19.],\n","                        [11., 21., 24.]],\n","              \n","                       [[24., 18., 15.],\n","                        [35., 30., 20.],\n","                        [36., 35., 13.]],\n","              \n","                       ...,\n","              \n","                       [[20., 17., 14.],\n","                        [24., 21., 11.],\n","                        [22., 19., 18.]],\n","              \n","                       [[24., 21., 20.],\n","                        [15., 20., 19.],\n","                        [ 8., 12., 18.]],\n","              \n","                       [[58., 32., 22.],\n","                        [63., 37., 27.],\n","                        [35., 35., 26.]]]], device='cuda:0')),\n","             ('module.layer3.6.conv1.wrapped_module.bias',\n","              tensor([ -366.,  -875.,  -472.,  -960., -1660.,  -994.,  -492.,  -379., -1572.,\n","                      -1345.,  -482.,  -747.,   115.,  -653.,  -631., -1383.,  -490., -1842.,\n","                      -1312.,   490.,  -849.,  -362.,  -614., -1155.,   -53., -1203.,  -598.,\n","                      -1428.,  1405., -1234.,   -38., -1058.,  -663.,  -192.,   267., -2055.,\n","                       -253., -1122., -1183.,  -547.,  -588., -1459., -1139.,  -266., -1416.,\n","                      -1391.,  -579., -1260.,  -127.,  -768., -1503.,  -410., -2235.,  -202.,\n","                       -405.,  2424., -2665., -2279.,  1386.,  -616.,  -645.,  -519.,   -31.,\n","                       1232.], device='cuda:0')),\n","             ('module.layer3.6.conv2.num_forwards',\n","              tensor([40], device='cuda:0')),\n","             ('module.layer3.6.conv2.force_readjust',\n","              tensor(False, device='cuda:0')),\n","             ('module.layer3.6.conv2.output_scale',\n","              tensor([5.4861], device='cuda:0')),\n","             ('module.layer3.6.conv2.output_zero_point',\n","              tensor([-22.], device='cuda:0')),\n","             ('module.layer3.6.conv2.w_scale', tensor([[[[  36.9233]]],\n","              \n","              \n","                      [[[  40.2510]]],\n","              \n","              \n","                      [[[  57.5248]]],\n","              \n","              \n","                      [[[  41.8581]]],\n","              \n","              \n","                      [[[  55.8814]]],\n","              \n","              \n","                      [[[ 128.8732]]],\n","              \n","              \n","                      [[[  54.6547]]],\n","              \n","              \n","                      [[[ 211.8515]]],\n","              \n","              \n","                      [[[  36.3644]]],\n","              \n","              \n","                      [[[ 102.6508]]],\n","              \n","              \n","                      [[[ 125.4642]]],\n","              \n","              \n","                      [[[  54.8838]]],\n","              \n","              \n","                      [[[  83.4361]]],\n","              \n","              \n","                      [[[  60.0728]]],\n","              \n","              \n","                      [[[  49.7218]]],\n","              \n","              \n","                      [[[  72.9970]]],\n","              \n","              \n","                      [[[ 101.3394]]],\n","              \n","              \n","                      [[[  79.3834]]],\n","              \n","              \n","                      [[[  74.2572]]],\n","              \n","              \n","                      [[[  75.8559]]],\n","              \n","              \n","                      [[[  48.1011]]],\n","              \n","              \n","                      [[[  79.7404]]],\n","              \n","              \n","                      [[[ 272.5271]]],\n","              \n","              \n","                      [[[  73.4273]]],\n","              \n","              \n","                      [[[  39.2820]]],\n","              \n","              \n","                      [[[ 103.0205]]],\n","              \n","              \n","                      [[[  77.8145]]],\n","              \n","              \n","                      [[[ 124.0250]]],\n","              \n","              \n","                      [[[ 121.1509]]],\n","              \n","              \n","                      [[[  99.5302]]],\n","              \n","              \n","                      [[[  41.6275]]],\n","              \n","              \n","                      [[[  91.0110]]],\n","              \n","              \n","                      [[[  85.9119]]],\n","              \n","              \n","                      [[[ 157.9873]]],\n","              \n","              \n","                      [[[ 101.3691]]],\n","              \n","              \n","                      [[[  71.1308]]],\n","              \n","              \n","                      [[[  53.0686]]],\n","              \n","              \n","                      [[[  81.0010]]],\n","              \n","              \n","                      [[[  45.3275]]],\n","              \n","              \n","                      [[[  69.0363]]],\n","              \n","              \n","                      [[[  83.0083]]],\n","              \n","              \n","                      [[[  96.2755]]],\n","              \n","              \n","                      [[[  39.0120]]],\n","              \n","              \n","                      [[[  93.3288]]],\n","              \n","              \n","                      [[[ 169.6510]]],\n","              \n","              \n","                      [[[ 170.9629]]],\n","              \n","              \n","                      [[[ 324.8968]]],\n","              \n","              \n","                      [[[  42.2226]]],\n","              \n","              \n","                      [[[  57.3515]]],\n","              \n","              \n","                      [[[2145.4614]]],\n","              \n","              \n","                      [[[  42.9532]]],\n","              \n","              \n","                      [[[ 242.4504]]],\n","              \n","              \n","                      [[[  94.6668]]],\n","              \n","              \n","                      [[[  56.8827]]],\n","              \n","              \n","                      [[[ 601.0925]]],\n","              \n","              \n","                      [[[  91.4432]]],\n","              \n","              \n","                      [[[ 295.9408]]],\n","              \n","              \n","                      [[[ 107.6432]]],\n","              \n","              \n","                      [[[  70.7079]]],\n","              \n","              \n","                      [[[  79.8206]]],\n","              \n","              \n","                      [[[  97.9876]]],\n","              \n","              \n","                      [[[ 157.6136]]],\n","              \n","              \n","                      [[[  49.6996]]],\n","              \n","              \n","                      [[[ 132.8677]]]], device='cuda:0')),\n","             ('module.layer3.6.conv2.w_zero_point', tensor([[[[-27.]]],\n","              \n","              \n","                      [[[-26.]]],\n","              \n","              \n","                      [[[-25.]]],\n","              \n","              \n","                      [[[-24.]]],\n","              \n","              \n","                      [[[-21.]]],\n","              \n","              \n","                      [[[-28.]]],\n","              \n","              \n","                      [[[-25.]]],\n","              \n","              \n","                      [[[-25.]]],\n","              \n","              \n","                      [[[-22.]]],\n","              \n","              \n","                      [[[-29.]]],\n","              \n","              \n","                      [[[-31.]]],\n","              \n","              \n","                      [[[-24.]]],\n","              \n","              \n","                      [[[-28.]]],\n","              \n","              \n","                      [[[-32.]]],\n","              \n","              \n","                      [[[-22.]]],\n","              \n","              \n","                      [[[-31.]]],\n","              \n","              \n","                      [[[-31.]]],\n","              \n","              \n","                      [[[-27.]]],\n","              \n","              \n","                      [[[-29.]]],\n","              \n","              \n","                      [[[-27.]]],\n","              \n","              \n","                      [[[-28.]]],\n","              \n","              \n","                      [[[-26.]]],\n","              \n","              \n","                      [[[-30.]]],\n","              \n","              \n","                      [[[-26.]]],\n","              \n","              \n","                      [[[-22.]]],\n","              \n","              \n","                      [[[-27.]]],\n","              \n","              \n","                      [[[-33.]]],\n","              \n","              \n","                      [[[-30.]]],\n","              \n","              \n","                      [[[-30.]]],\n","              \n","              \n","                      [[[-26.]]],\n","              \n","              \n","                      [[[-27.]]],\n","              \n","              \n","                      [[[-28.]]],\n","              \n","              \n","                      [[[-24.]]],\n","              \n","              \n","                      [[[-35.]]],\n","              \n","              \n","                      [[[-21.]]],\n","              \n","              \n","                      [[[-22.]]],\n","              \n","              \n","                      [[[-25.]]],\n","              \n","              \n","                      [[[-30.]]],\n","              \n","              \n","                      [[[-26.]]],\n","              \n","              \n","                      [[[-28.]]],\n","              \n","              \n","                      [[[-19.]]],\n","              \n","              \n","                      [[[-30.]]],\n","              \n","              \n","                      [[[-28.]]],\n","              \n","              \n","                      [[[-31.]]],\n","              \n","              \n","                      [[[-17.]]],\n","              \n","              \n","                      [[[-33.]]],\n","              \n","              \n","                      [[[-20.]]],\n","              \n","              \n","                      [[[-19.]]],\n","              \n","              \n","                      [[[-27.]]],\n","              \n","              \n","                      [[[-27.]]],\n","              \n","              \n","                      [[[-23.]]],\n","              \n","              \n","                      [[[-28.]]],\n","              \n","              \n","                      [[[-30.]]],\n","              \n","              \n","                      [[[-26.]]],\n","              \n","              \n","                      [[[-33.]]],\n","              \n","              \n","                      [[[-27.]]],\n","              \n","              \n","                      [[[-29.]]],\n","              \n","              \n","                      [[[-28.]]],\n","              \n","              \n","                      [[[-25.]]],\n","              \n","              \n","                      [[[-34.]]],\n","              \n","              \n","                      [[[-33.]]],\n","              \n","              \n","                      [[[-27.]]],\n","              \n","              \n","                      [[[-24.]]],\n","              \n","              \n","                      [[[-22.]]]], device='cuda:0')),\n","             ('module.layer3.6.conv2.fp_bias',\n","              tensor([-0.1645, -0.5019,  0.3573,  0.0137, -0.3104, -0.2346, -0.2460,  0.0415,\n","                      -0.7425, -0.0976,  0.0583, -0.1467, -0.0418, -0.1442, -0.4395, -0.0910,\n","                      -0.1014, -0.1291, -0.4214,  0.1471, -0.2627, -0.4744,  0.0785, -0.3285,\n","                      -0.6951, -0.2827, -0.2000,  0.1535, -0.2903, -0.1486, -0.2774, -0.2515,\n","                       0.1117, -0.1024, -0.3017, -0.2587, -1.1960,  0.1613, -0.0073, -0.3262,\n","                      -0.3486, -0.1668, -0.8430, -0.0037, -0.0224,  0.0693, -0.2473, -0.6596,\n","                      -0.1305, -0.0090, -0.9160,  0.0145,  0.0835, -0.7019, -0.0281,  0.1888,\n","                      -0.0334, -0.2370, -0.2475,  0.0286,  0.1470,  0.0750, -0.0771, -0.0980],\n","                     device='cuda:0')),\n","             ('module.layer3.6.conv2.accum_scale', tensor([[[ 1357.4474]],\n","              \n","                      [[ 1479.7863]],\n","              \n","                      [[ 2114.8418]],\n","              \n","                      [[ 1538.8712]],\n","              \n","                      [[ 2054.4224]],\n","              \n","                      [[ 4737.8911]],\n","              \n","                      [[ 2009.3254]],\n","              \n","                      [[ 7788.5054]],\n","              \n","                      [[ 1336.8994]],\n","              \n","                      [[ 3773.8533]],\n","              \n","                      [[ 4612.5615]],\n","              \n","                      [[ 2017.7463]],\n","              \n","                      [[ 3067.4441]],\n","              \n","                      [[ 2208.5156]],\n","              \n","                      [[ 1827.9695]],\n","              \n","                      [[ 2683.6599]],\n","              \n","                      [[ 3725.6389]],\n","              \n","                      [[ 2918.4480]],\n","              \n","                      [[ 2729.9917]],\n","              \n","                      [[ 2788.7642]],\n","              \n","                      [[ 1768.3871]],\n","              \n","                      [[ 2931.5752]],\n","              \n","                      [[10019.1816]],\n","              \n","                      [[ 2699.4778]],\n","              \n","                      [[ 1444.1609]],\n","              \n","                      [[ 3787.4431]],\n","              \n","                      [[ 2860.7698]],\n","              \n","                      [[ 4559.6538]],\n","              \n","                      [[ 4453.9893]],\n","              \n","                      [[ 3659.1250]],\n","              \n","                      [[ 1530.3929]],\n","              \n","                      [[ 3345.9263]],\n","              \n","                      [[ 3158.4622]],\n","              \n","                      [[ 5808.2422]],\n","              \n","                      [[ 3726.7310]],\n","              \n","                      [[ 2615.0493]],\n","              \n","                      [[ 1951.0138]],\n","              \n","                      [[ 2977.9189]],\n","              \n","                      [[ 1666.4175]],\n","              \n","                      [[ 2538.0505]],\n","              \n","                      [[ 3051.7161]],\n","              \n","                      [[ 3539.4697]],\n","              \n","                      [[ 1434.2357]],\n","              \n","                      [[ 3431.1367]],\n","              \n","                      [[ 6237.0474]],\n","              \n","                      [[ 6285.2773]],\n","              \n","                      [[11944.4990]],\n","              \n","                      [[ 1552.2710]],\n","              \n","                      [[ 2108.4675]],\n","              \n","                      [[78875.6953]],\n","              \n","                      [[ 1579.1292]],\n","              \n","                      [[ 8913.4404]],\n","              \n","                      [[ 3480.3274]],\n","              \n","                      [[ 2091.2341]],\n","              \n","                      [[22098.5488]],\n","              \n","                      [[ 3361.8157]],\n","              \n","                      [[10879.9600]],\n","              \n","                      [[ 3957.3923]],\n","              \n","                      [[ 2599.5034]],\n","              \n","                      [[ 2934.5215]],\n","              \n","                      [[ 3602.4146]],\n","              \n","                      [[ 5794.5034]],\n","              \n","                      [[ 1827.1537]],\n","              \n","                      [[ 4884.7461]]], device='cuda:0')),\n","             ('module.layer3.6.conv2.is_simulated_quant_weight_shifted',\n","              tensor(False, device='cuda:0')),\n","             ('module.layer3.6.conv2.wrapped_module.weight',\n","              tensor([[[[23., 21., 23.],\n","                        [21., 26., 31.],\n","                        [23., 26., 29.]],\n","              \n","                       [[20., 32., 32.],\n","                        [21., 25., 25.],\n","                        [27., 24., 25.]],\n","              \n","                       [[20., 19., 29.],\n","                        [22., 21., 24.],\n","                        [25., 23., 20.]],\n","              \n","                       ...,\n","              \n","                       [[21., 31., 33.],\n","                        [15., 18., 19.],\n","                        [15., 23., 23.]],\n","              \n","                       [[30., 27., 30.],\n","                        [27., 24., 26.],\n","                        [30., 26., 28.]],\n","              \n","                       [[25., 20., 29.],\n","                        [24., 19., 21.],\n","                        [26., 23., 20.]]],\n","              \n","              \n","                      [[[34., 33., 30.],\n","                        [36., 32., 31.],\n","                        [36., 32., 30.]],\n","              \n","                       [[27., 32., 34.],\n","                        [21., 18., 20.],\n","                        [12.,  6., 13.]],\n","              \n","                       [[20., 23., 24.],\n","                        [17., 20., 25.],\n","                        [22., 29., 30.]],\n","              \n","                       ...,\n","              \n","                       [[34., 34., 31.],\n","                        [39., 36., 30.],\n","                        [35., 27., 25.]],\n","              \n","                       [[22., 23., 20.],\n","                        [22., 25., 23.],\n","                        [24., 25., 24.]],\n","              \n","                       [[29., 25., 16.],\n","                        [31., 30., 25.],\n","                        [21., 28., 26.]]],\n","              \n","              \n","                      [[[35., 35., 41.],\n","                        [30., 29., 33.],\n","                        [30., 31., 32.]],\n","              \n","                       [[19., 30., 37.],\n","                        [18., 28., 38.],\n","                        [22., 24., 35.]],\n","              \n","                       [[19., 19., 22.],\n","                        [32., 29., 26.],\n","                        [51., 44., 36.]],\n","              \n","                       ...,\n","              \n","                       [[43., 40., 32.],\n","                        [35., 30., 26.],\n","                        [19., 19., 25.]],\n","              \n","                       [[19., 16., 22.],\n","                        [25., 24., 30.],\n","                        [30., 36., 40.]],\n","              \n","                       [[26., 21., 25.],\n","                        [19., 18., 21.],\n","                        [20., 20., 24.]]],\n","              \n","              \n","                      ...,\n","              \n","              \n","                      [[[28., 28., 36.],\n","                        [20., 17., 27.],\n","                        [17., 18., 32.]],\n","              \n","                       [[33., 31., 34.],\n","                        [37., 29., 26.],\n","                        [46., 37., 35.]],\n","              \n","                       [[22., 34., 43.],\n","                        [20., 29., 42.],\n","                        [29., 22., 28.]],\n","              \n","                       ...,\n","              \n","                       [[14., 19., 16.],\n","                        [15., 22., 16.],\n","                        [15., 14., 10.]],\n","              \n","                       [[33., 39., 37.],\n","                        [38., 44., 43.],\n","                        [39., 48., 39.]],\n","              \n","                       [[ 2.,  4., 18.],\n","                        [ 6.,  4.,  9.],\n","                        [12., 17., 17.]]],\n","              \n","              \n","                      [[[29., 25., 21.],\n","                        [26., 23., 15.],\n","                        [22., 18., 13.]],\n","              \n","                       [[29., 32., 31.],\n","                        [28., 28., 34.],\n","                        [23., 23., 29.]],\n","              \n","                       [[24., 25., 13.],\n","                        [13., 11., 10.],\n","                        [15., 16., 15.]],\n","              \n","                       ...,\n","              \n","                       [[10.,  6.,  7.],\n","                        [13., 11., 15.],\n","                        [23., 25., 26.]],\n","              \n","                       [[21., 21., 27.],\n","                        [16., 17., 18.],\n","                        [19., 20., 19.]],\n","              \n","                       [[20., 19., 22.],\n","                        [17., 12., 16.],\n","                        [22., 18., 17.]]],\n","              \n","              \n","                      [[[32., 22., 17.],\n","                        [22., 14., 11.],\n","                        [12.,  7.,  9.]],\n","              \n","                       [[18., 11., 22.],\n","                        [23., 17., 26.],\n","                        [19., 20., 21.]],\n","              \n","                       [[27., 21., 31.],\n","                        [25., 23., 24.],\n","                        [17., 17., 15.]],\n","              \n","                       ...,\n","              \n","                       [[29., 25., 22.],\n","                        [21., 17., 16.],\n","                        [15., 16., 15.]],\n","              \n","                       [[25., 27., 21.],\n","                        [30., 27., 25.],\n","                        [23., 16., 19.]],\n","              \n","                       [[23., 28., 28.],\n","                        [21., 26., 35.],\n","                        [27., 31., 39.]]]], device='cuda:0')),\n","             ('module.layer3.6.conv2.wrapped_module.bias',\n","              tensor([ -223.,  -743.,   756.,    21.,  -638., -1111.,  -494.,   323.,  -993.,\n","                       -368.,   269.,  -296.,  -128.,  -318.,  -803.,  -244.,  -378.,  -377.,\n","                      -1151.,   410.,  -465., -1391.,   786.,  -887., -1004., -1071.,  -572.,\n","                        700., -1293.,  -544.,  -425.,  -842.,   353.,  -595., -1125.,  -677.,\n","                      -2333.,   480.,   -12.,  -828., -1064.,  -591., -1209.,   -13.,  -139.,\n","                        436., -2954., -1024.,  -275.,  -709., -1446.,   130.,   291., -1468.,\n","                       -621.,   635.,  -363.,  -938.,  -643.,    84.,   529.,   435.,  -141.,\n","                       -479.], device='cuda:0')),\n","             ('module.layer3.6.relu2.num_forwards',\n","              tensor([40], device='cuda:0')),\n","             ('module.layer3.6.relu2.force_readjust',\n","              tensor(False, device='cuda:0')),\n","             ('module.layer3.6.relu2.output_scale',\n","              tensor([4.1175], device='cuda:0')),\n","             ('module.layer3.6.relu2.output_zero_point',\n","              tensor([0.], device='cuda:0')),\n","             ('module.layer3.6.residual_eltwiseadd.num_forwards',\n","              tensor([40], device='cuda:0')),\n","             ('module.layer3.6.residual_eltwiseadd.force_readjust',\n","              tensor(False, device='cuda:0')),\n","             ('module.layer3.6.residual_eltwiseadd.output_scale',\n","              tensor([4.1175], device='cuda:0')),\n","             ('module.layer3.6.residual_eltwiseadd.output_zero_point',\n","              tensor([0.], device='cuda:0')),\n","             ('module.layer3.7.conv1.num_forwards',\n","              tensor([40], device='cuda:0')),\n","             ('module.layer3.7.conv1.force_readjust',\n","              tensor(False, device='cuda:0')),\n","             ('module.layer3.7.conv1.output_scale',\n","              tensor([48.3927], device='cuda:0')),\n","             ('module.layer3.7.conv1.output_zero_point',\n","              tensor([0.], device='cuda:0')),\n","             ('module.layer3.7.conv1.w_scale', tensor([[[[  4207.9009]]],\n","              \n","              \n","                      [[[  1148.1770]]],\n","              \n","              \n","                      [[[  1629.3521]]],\n","              \n","              \n","                      [[[181580.0938]]],\n","              \n","              \n","                      [[[  1447.5048]]],\n","              \n","              \n","                      [[[  1423.0845]]],\n","              \n","              \n","                      [[[  2200.6479]]],\n","              \n","              \n","                      [[[  2062.4583]]],\n","              \n","              \n","                      [[[  2157.6511]]],\n","              \n","              \n","                      [[[   834.8406]]],\n","              \n","              \n","                      [[[  1529.5592]]],\n","              \n","              \n","                      [[[  2155.3132]]],\n","              \n","              \n","                      [[[  1097.4210]]],\n","              \n","              \n","                      [[[  3008.8201]]],\n","              \n","              \n","                      [[[  1887.4889]]],\n","              \n","              \n","                      [[[  2144.3298]]],\n","              \n","              \n","                      [[[  2156.1570]]],\n","              \n","              \n","                      [[[  5324.6543]]],\n","              \n","              \n","                      [[[  2213.3040]]],\n","              \n","              \n","                      [[[  1198.4276]]],\n","              \n","              \n","                      [[[  1290.7142]]],\n","              \n","              \n","                      [[[  1228.6810]]],\n","              \n","              \n","                      [[[  2005.3817]]],\n","              \n","              \n","                      [[[  2671.3835]]],\n","              \n","              \n","                      [[[  1269.2358]]],\n","              \n","              \n","                      [[[  1009.5328]]],\n","              \n","              \n","                      [[[  1122.3503]]],\n","              \n","              \n","                      [[[  2701.7395]]],\n","              \n","              \n","                      [[[  2598.3972]]],\n","              \n","              \n","                      [[[  2305.4165]]],\n","              \n","              \n","                      [[[  1902.2869]]],\n","              \n","              \n","                      [[[  2645.1682]]],\n","              \n","              \n","                      [[[  2065.7258]]],\n","              \n","              \n","                      [[[  1299.0914]]],\n","              \n","              \n","                      [[[  2222.1348]]],\n","              \n","              \n","                      [[[  1589.4934]]],\n","              \n","              \n","                      [[[  1682.1024]]],\n","              \n","              \n","                      [[[  1173.3706]]],\n","              \n","              \n","                      [[[  1639.1464]]],\n","              \n","              \n","                      [[[  2599.5552]]],\n","              \n","              \n","                      [[[  1479.2181]]],\n","              \n","              \n","                      [[[  2060.0449]]],\n","              \n","              \n","                      [[[  2449.1323]]],\n","              \n","              \n","                      [[[  2873.1091]]],\n","              \n","              \n","                      [[[  2965.9155]]],\n","              \n","              \n","                      [[[  2176.1272]]],\n","              \n","              \n","                      [[[  1241.1991]]],\n","              \n","              \n","                      [[[  1578.2922]]],\n","              \n","              \n","                      [[[  2170.5505]]],\n","              \n","              \n","                      [[[  1150.6992]]],\n","              \n","              \n","                      [[[  1289.0693]]],\n","              \n","              \n","                      [[[  1724.9099]]],\n","              \n","              \n","                      [[[  1364.4435]]],\n","              \n","              \n","                      [[[  2249.7532]]],\n","              \n","              \n","                      [[[  3203.4106]]],\n","              \n","              \n","                      [[[  2208.7393]]],\n","              \n","              \n","                      [[[  2928.1455]]],\n","              \n","              \n","                      [[[  1916.5760]]],\n","              \n","              \n","                      [[[  1701.3120]]],\n","              \n","              \n","                      [[[  3095.7549]]],\n","              \n","              \n","                      [[[  1332.2993]]],\n","              \n","              \n","                      [[[  2427.9805]]],\n","              \n","              \n","                      [[[  1204.5422]]],\n","              \n","              \n","                      [[[  1611.0845]]]], device='cuda:0')),\n","             ('module.layer3.7.conv1.w_zero_point', tensor([[[[-28.]]],\n","              \n","              \n","                      [[[-20.]]],\n","              \n","              \n","                      [[[-22.]]],\n","              \n","              \n","                      [[[-24.]]],\n","              \n","              \n","                      [[[-35.]]],\n","              \n","              \n","                      [[[-27.]]],\n","              \n","              \n","                      [[[-27.]]],\n","              \n","              \n","                      [[[-28.]]],\n","              \n","              \n","                      [[[-21.]]],\n","              \n","              \n","                      [[[-25.]]],\n","              \n","              \n","                      [[[-21.]]],\n","              \n","              \n","                      [[[-27.]]],\n","              \n","              \n","                      [[[-25.]]],\n","              \n","              \n","                      [[[-28.]]],\n","              \n","              \n","                      [[[-20.]]],\n","              \n","              \n","                      [[[-26.]]],\n","              \n","              \n","                      [[[-30.]]],\n","              \n","              \n","                      [[[-35.]]],\n","              \n","              \n","                      [[[-30.]]],\n","              \n","              \n","                      [[[-26.]]],\n","              \n","              \n","                      [[[-20.]]],\n","              \n","              \n","                      [[[-20.]]],\n","              \n","              \n","                      [[[-26.]]],\n","              \n","              \n","                      [[[-32.]]],\n","              \n","              \n","                      [[[-30.]]],\n","              \n","              \n","                      [[[-21.]]],\n","              \n","              \n","                      [[[-20.]]],\n","              \n","              \n","                      [[[-28.]]],\n","              \n","              \n","                      [[[-23.]]],\n","              \n","              \n","                      [[[-26.]]],\n","              \n","              \n","                      [[[-27.]]],\n","              \n","              \n","                      [[[-29.]]],\n","              \n","              \n","                      [[[-25.]]],\n","              \n","              \n","                      [[[-25.]]],\n","              \n","              \n","                      [[[-27.]]],\n","              \n","              \n","                      [[[-25.]]],\n","              \n","              \n","                      [[[-29.]]],\n","              \n","              \n","                      [[[-21.]]],\n","              \n","              \n","                      [[[-26.]]],\n","              \n","              \n","                      [[[-22.]]],\n","              \n","              \n","                      [[[-28.]]],\n","              \n","              \n","                      [[[-22.]]],\n","              \n","              \n","                      [[[-30.]]],\n","              \n","              \n","                      [[[-28.]]],\n","              \n","              \n","                      [[[-26.]]],\n","              \n","              \n","                      [[[-26.]]],\n","              \n","              \n","                      [[[-24.]]],\n","              \n","              \n","                      [[[-20.]]],\n","              \n","              \n","                      [[[-24.]]],\n","              \n","              \n","                      [[[-26.]]],\n","              \n","              \n","                      [[[-23.]]],\n","              \n","              \n","                      [[[-26.]]],\n","              \n","              \n","                      [[[-25.]]],\n","              \n","              \n","                      [[[-28.]]],\n","              \n","              \n","                      [[[-27.]]],\n","              \n","              \n","                      [[[-25.]]],\n","              \n","              \n","                      [[[-26.]]],\n","              \n","              \n","                      [[[-24.]]],\n","              \n","              \n","                      [[[-30.]]],\n","              \n","              \n","                      [[[-25.]]],\n","              \n","              \n","                      [[[-25.]]],\n","              \n","              \n","                      [[[-31.]]],\n","              \n","              \n","                      [[[-25.]]],\n","              \n","              \n","                      [[[-24.]]]], device='cuda:0')),\n","             ('module.layer3.7.conv1.fp_bias',\n","              tensor([-0.0313, -0.1054, -0.1110, -0.0247, -0.0306, -0.1726,  0.1844,  0.0058,\n","                      -0.0391,  0.0114, -0.0282,  0.3042, -0.1371, -0.0203, -0.0455, -0.0640,\n","                      -0.0253,  0.3039,  0.0620, -0.1484, -0.0596,  0.0113, -0.1371,  0.0794,\n","                      -0.0199, -0.1360, -0.0858,  0.2590,  0.0049, -0.0859, -0.1622,  0.3109,\n","                       0.0965, -0.2625, -0.0657, -0.1001,  0.0657, -0.0777, -0.0281, -0.0415,\n","                      -0.0436,  0.1029,  0.0416, -0.1317, -0.1222, -0.0153, -0.1663, -0.2551,\n","                       0.1998,  0.0640, -0.0888, -0.0767, -0.2589, -0.1321, -0.0515,  0.0342,\n","                      -0.0304,  0.0391, -0.2560,  0.1383, -0.0439,  0.3423, -0.1264, -0.1423],\n","                     device='cuda:0')),\n","             ('module.layer3.7.conv1.accum_scale', tensor([[[ 17326.0254]],\n","              \n","                      [[  4727.6172]],\n","              \n","                      [[  6708.8545]],\n","              \n","                      [[747655.7500]],\n","              \n","                      [[  5960.0986]],\n","              \n","                      [[  5859.5479]],\n","              \n","                      [[  9061.1641]],\n","              \n","                      [[  8492.1689]],\n","              \n","                      [[  8884.1250]],\n","              \n","                      [[  3437.4551]],\n","              \n","                      [[  6297.9575]],\n","              \n","                      [[  8874.4990]],\n","              \n","                      [[  4518.6294]],\n","              \n","                      [[ 12388.8115]],\n","              \n","                      [[  7771.7324]],\n","              \n","                      [[  8829.2744]],\n","              \n","                      [[  8877.9727]],\n","              \n","                      [[ 21924.2559]],\n","              \n","                      [[  9113.2754]],\n","              \n","                      [[  4934.5239]],\n","              \n","                      [[  5314.5137]],\n","              \n","                      [[  5059.0923]],\n","              \n","                      [[  8257.1562]],\n","              \n","                      [[ 10999.4170]],\n","              \n","                      [[  5226.0767]],\n","              \n","                      [[  4156.7495]],\n","              \n","                      [[  4621.2759]],\n","              \n","                      [[ 11124.4082]],\n","              \n","                      [[ 10698.8965]],\n","              \n","                      [[  9492.5488]],\n","              \n","                      [[  7832.6631]],\n","              \n","                      [[ 10891.4756]],\n","              \n","                      [[  8505.6230]],\n","              \n","                      [[  5349.0068]],\n","              \n","                      [[  9149.6367]],\n","              \n","                      [[  6544.7363]],\n","              \n","                      [[  6926.0542]],\n","              \n","                      [[  4831.3516]],\n","              \n","                      [[  6749.1826]],\n","              \n","                      [[ 10703.6641]],\n","              \n","                      [[  6090.6782]],\n","              \n","                      [[  8482.2314]],\n","              \n","                      [[ 10084.2988]],\n","              \n","                      [[ 11830.0225]],\n","              \n","                      [[ 12212.1523]],\n","              \n","                      [[  8960.2002]],\n","              \n","                      [[  5110.6353]],\n","              \n","                      [[  6498.6157]],\n","              \n","                      [[  8937.2383]],\n","              \n","                      [[  4738.0020]],\n","              \n","                      [[  5307.7407]],\n","              \n","                      [[  7102.3140]],\n","              \n","                      [[  5618.0938]],\n","              \n","                      [[  9263.3555]],\n","              \n","                      [[ 13190.0381]],\n","              \n","                      [[  9094.4805]],\n","              \n","                      [[ 12056.6348]],\n","              \n","                      [[  7891.4990]],\n","              \n","                      [[  7005.1494]],\n","              \n","                      [[ 12746.7656]],\n","              \n","                      [[  5485.7402]],\n","              \n","                      [[  9997.2061]],\n","              \n","                      [[  4959.7007]],\n","              \n","                      [[  6633.6377]]], device='cuda:0')),\n","             ('module.layer3.7.conv1.is_simulated_quant_weight_shifted',\n","              tensor(False, device='cuda:0')),\n","             ('module.layer3.7.conv1.wrapped_module.weight',\n","              tensor([[[[18., 37., 52.],\n","                        [33., 30., 35.],\n","                        [25., 32., 29.]],\n","              \n","                       [[28., 28., 24.],\n","                        [17., 22., 23.],\n","                        [21., 23., 25.]],\n","              \n","                       [[18., 16., 19.],\n","                        [17., 16., 19.],\n","                        [23., 20., 19.]],\n","              \n","                       ...,\n","              \n","                       [[24., 21., 22.],\n","                        [26., 28., 32.],\n","                        [27., 28., 30.]],\n","              \n","                       [[44., 41., 38.],\n","                        [35., 40., 50.],\n","                        [24., 27., 36.]],\n","              \n","                       [[10., 39., 47.],\n","                        [23., 36., 40.],\n","                        [25., 24., 25.]]],\n","              \n","              \n","                      [[[16., 27., 26.],\n","                        [11., 12., 16.],\n","                        [20., 13., 18.]],\n","              \n","                       [[11., 28., 43.],\n","                        [11., 14., 20.],\n","                        [21., 17., 14.]],\n","              \n","                       [[35., 24., 10.],\n","                        [25., 25., 17.],\n","                        [12., 16., 21.]],\n","              \n","                       ...,\n","              \n","                       [[24., 29., 28.],\n","                        [28., 29., 33.],\n","                        [22., 22., 25.]],\n","              \n","                       [[22., 17., 18.],\n","                        [31., 14.,  9.],\n","                        [22., 23., 22.]],\n","              \n","                       [[ 7., 16., 56.],\n","                        [ 3.,  4., 63.],\n","                        [17., 19., 62.]]],\n","              \n","              \n","                      [[[11., 15., 24.],\n","                        [14., 19., 27.],\n","                        [11., 32., 45.]],\n","              \n","                       [[22., 14.,  6.],\n","                        [23., 18.,  8.],\n","                        [24., 25., 20.]],\n","              \n","                       [[25., 17., 16.],\n","                        [20., 16.,  9.],\n","                        [12., 18., 10.]],\n","              \n","                       ...,\n","              \n","                       [[14., 19., 33.],\n","                        [12., 17., 26.],\n","                        [ 5.,  3.,  9.]],\n","              \n","                       [[12., 14., 23.],\n","                        [32., 29., 28.],\n","                        [56., 59., 50.]],\n","              \n","                       [[51., 57., 63.],\n","                        [46., 44., 46.],\n","                        [24., 25., 26.]]],\n","              \n","              \n","                      ...,\n","              \n","              \n","                      [[[31., 27., 18.],\n","                        [22., 27., 17.],\n","                        [20., 25., 12.]],\n","              \n","                       [[18., 25., 21.],\n","                        [18., 27., 28.],\n","                        [22., 25., 25.]],\n","              \n","                       [[31., 24., 35.],\n","                        [29., 29., 33.],\n","                        [33., 28., 33.]],\n","              \n","                       ...,\n","              \n","                       [[12., 13., 14.],\n","                        [15., 19., 21.],\n","                        [19., 25., 27.]],\n","              \n","                       [[24., 24., 27.],\n","                        [22., 30., 31.],\n","                        [18., 35., 29.]],\n","              \n","                       [[24., 43., 39.],\n","                        [25., 40., 48.],\n","                        [24., 26., 43.]]],\n","              \n","              \n","                      [[[31., 26., 27.],\n","                        [21., 28., 29.],\n","                        [ 4., 11., 14.]],\n","              \n","                       [[27., 23., 26.],\n","                        [34., 25., 22.],\n","                        [17., 14., 21.]],\n","              \n","                       [[ 9., 12., 19.],\n","                        [19., 11., 17.],\n","                        [23., 18., 25.]],\n","              \n","                       ...,\n","              \n","                       [[28., 29., 29.],\n","                        [26., 27., 28.],\n","                        [20., 15., 18.]],\n","              \n","                       [[17., 22., 23.],\n","                        [27., 27., 16.],\n","                        [30., 21., 12.]],\n","              \n","                       [[13.,  7., 16.],\n","                        [15.,  9.,  6.],\n","                        [42., 51., 25.]]],\n","              \n","              \n","                      [[[41., 32., 23.],\n","                        [44., 29., 20.],\n","                        [17., 10., 10.]],\n","              \n","                       [[26., 26., 25.],\n","                        [26., 23., 20.],\n","                        [24., 24., 23.]],\n","              \n","                       [[17., 19., 12.],\n","                        [29., 24., 20.],\n","                        [31., 26., 30.]],\n","              \n","                       ...,\n","              \n","                       [[26., 28., 25.],\n","                        [24., 24., 23.],\n","                        [23., 26., 26.]],\n","              \n","                       [[47., 44., 45.],\n","                        [26., 28., 36.],\n","                        [11., 12., 16.]],\n","              \n","                       [[22., 22., 16.],\n","                        [24., 28., 28.],\n","                        [20., 24., 28.]]]], device='cuda:0')),\n","             ('module.layer3.7.conv1.wrapped_module.bias',\n","              tensor([  -542.,   -498.,   -745., -18431.,   -182.,  -1012.,   1671.,     49.,\n","                        -347.,     39.,   -177.,   2700.,   -620.,   -251.,   -354.,   -565.,\n","                        -225.,   6663.,    565.,   -732.,   -317.,     57.,  -1132.,    873.,\n","                        -104.,   -565.,   -396.,   2881.,     52.,   -816.,  -1270.,   3387.,\n","                         821.,  -1404.,   -601.,   -655.,    455.,   -375.,   -189.,   -444.,\n","                        -265.,    873.,    420.,  -1558.,  -1493.,   -137.,   -850.,  -1658.,\n","                        1786.,    303.,   -471.,   -545.,  -1454.,  -1223.,   -679.,    311.,\n","                        -367.,    308.,  -1793.,   1763.,   -241.,   3422.,   -627.,   -944.],\n","                     device='cuda:0')),\n","             ('module.layer3.7.conv2.num_forwards',\n","              tensor([40], device='cuda:0')),\n","             ('module.layer3.7.conv2.force_readjust',\n","              tensor(False, device='cuda:0')),\n","             ('module.layer3.7.conv2.output_scale',\n","              tensor([7.7571], device='cuda:0')),\n","             ('module.layer3.7.conv2.output_zero_point',\n","              tensor([-21.], device='cuda:0')),\n","             ('module.layer3.7.conv2.w_scale', tensor([[[[  42.4313]]],\n","              \n","              \n","                      [[[ 105.3209]]],\n","              \n","              \n","                      [[[  53.6624]]],\n","              \n","              \n","                      [[[ 271.4506]]],\n","              \n","              \n","                      [[[ 120.9666]]],\n","              \n","              \n","                      [[[ 189.1693]]],\n","              \n","              \n","                      [[[ 132.6146]]],\n","              \n","              \n","                      [[[ 323.4216]]],\n","              \n","              \n","                      [[[  63.8621]]],\n","              \n","              \n","                      [[[ 153.4495]]],\n","              \n","              \n","                      [[[  81.1714]]],\n","              \n","              \n","                      [[[ 329.7894]]],\n","              \n","              \n","                      [[[  73.4670]]],\n","              \n","              \n","                      [[[  52.1070]]],\n","              \n","              \n","                      [[[ 146.1884]]],\n","              \n","              \n","                      [[[  65.9169]]],\n","              \n","              \n","                      [[[  48.1818]]],\n","              \n","              \n","                      [[[ 206.9994]]],\n","              \n","              \n","                      [[[  78.5342]]],\n","              \n","              \n","                      [[[ 144.7510]]],\n","              \n","              \n","                      [[[ 110.7441]]],\n","              \n","              \n","                      [[[ 158.6138]]],\n","              \n","              \n","                      [[[ 141.6032]]],\n","              \n","              \n","                      [[[ 103.7503]]],\n","              \n","              \n","                      [[[  69.5612]]],\n","              \n","              \n","                      [[[ 109.8992]]],\n","              \n","              \n","                      [[[  83.1858]]],\n","              \n","              \n","                      [[[ 184.6390]]],\n","              \n","              \n","                      [[[ 126.7010]]],\n","              \n","              \n","                      [[[ 163.6499]]],\n","              \n","              \n","                      [[[ 136.6047]]],\n","              \n","              \n","                      [[[ 183.9586]]],\n","              \n","              \n","                      [[[ 119.6312]]],\n","              \n","              \n","                      [[[ 243.4860]]],\n","              \n","              \n","                      [[[ 124.3416]]],\n","              \n","              \n","                      [[[ 161.7083]]],\n","              \n","              \n","                      [[[ 130.0388]]],\n","              \n","              \n","                      [[[  98.2138]]],\n","              \n","              \n","                      [[[  55.7323]]],\n","              \n","              \n","                      [[[ 139.5281]]],\n","              \n","              \n","                      [[[ 137.0878]]],\n","              \n","              \n","                      [[[ 106.1524]]],\n","              \n","              \n","                      [[[ 140.9791]]],\n","              \n","              \n","                      [[[  82.9643]]],\n","              \n","              \n","                      [[[ 816.5945]]],\n","              \n","              \n","                      [[[ 236.9619]]],\n","              \n","              \n","                      [[[ 271.0898]]],\n","              \n","              \n","                      [[[ 214.8917]]],\n","              \n","              \n","                      [[[ 138.7304]]],\n","              \n","              \n","                      [[[1093.0928]]],\n","              \n","              \n","                      [[[  76.5799]]],\n","              \n","              \n","                      [[[ 149.7930]]],\n","              \n","              \n","                      [[[  51.5801]]],\n","              \n","              \n","                      [[[ 127.9750]]],\n","              \n","              \n","                      [[[ 792.4454]]],\n","              \n","              \n","                      [[[ 108.7595]]],\n","              \n","              \n","                      [[[ 238.9039]]],\n","              \n","              \n","                      [[[ 105.7989]]],\n","              \n","              \n","                      [[[  92.2071]]],\n","              \n","              \n","                      [[[ 115.6310]]],\n","              \n","              \n","                      [[[  78.5215]]],\n","              \n","              \n","                      [[[ 169.2437]]],\n","              \n","              \n","                      [[[  74.9948]]],\n","              \n","              \n","                      [[[  51.6750]]]], device='cuda:0')),\n","             ('module.layer3.7.conv2.w_zero_point', tensor([[[[-19.]]],\n","              \n","              \n","                      [[[-31.]]],\n","              \n","              \n","                      [[[-18.]]],\n","              \n","              \n","                      [[[-27.]]],\n","              \n","              \n","                      [[[-23.]]],\n","              \n","              \n","                      [[[-32.]]],\n","              \n","              \n","                      [[[-35.]]],\n","              \n","              \n","                      [[[-35.]]],\n","              \n","              \n","                      [[[-21.]]],\n","              \n","              \n","                      [[[-23.]]],\n","              \n","              \n","                      [[[-39.]]],\n","              \n","              \n","                      [[[-23.]]],\n","              \n","              \n","                      [[[-34.]]],\n","              \n","              \n","                      [[[-21.]]],\n","              \n","              \n","                      [[[-27.]]],\n","              \n","              \n","                      [[[-22.]]],\n","              \n","              \n","                      [[[-23.]]],\n","              \n","              \n","                      [[[-31.]]],\n","              \n","              \n","                      [[[-27.]]],\n","              \n","              \n","                      [[[-28.]]],\n","              \n","              \n","                      [[[-31.]]],\n","              \n","              \n","                      [[[-27.]]],\n","              \n","              \n","                      [[[-29.]]],\n","              \n","              \n","                      [[[-42.]]],\n","              \n","              \n","                      [[[-29.]]],\n","              \n","              \n","                      [[[-23.]]],\n","              \n","              \n","                      [[[-34.]]],\n","              \n","              \n","                      [[[-30.]]],\n","              \n","              \n","                      [[[-22.]]],\n","              \n","              \n","                      [[[-32.]]],\n","              \n","              \n","                      [[[-35.]]],\n","              \n","              \n","                      [[[-21.]]],\n","              \n","              \n","                      [[[-31.]]],\n","              \n","              \n","                      [[[-31.]]],\n","              \n","              \n","                      [[[-19.]]],\n","              \n","              \n","                      [[[-23.]]],\n","              \n","              \n","                      [[[-37.]]],\n","              \n","              \n","                      [[[-29.]]],\n","              \n","              \n","                      [[[-23.]]],\n","              \n","              \n","                      [[[-25.]]],\n","              \n","              \n","                      [[[-27.]]],\n","              \n","              \n","                      [[[-21.]]],\n","              \n","              \n","                      [[[-31.]]],\n","              \n","              \n","                      [[[-22.]]],\n","              \n","              \n","                      [[[-20.]]],\n","              \n","              \n","                      [[[-31.]]],\n","              \n","              \n","                      [[[-33.]]],\n","              \n","              \n","                      [[[-27.]]],\n","              \n","              \n","                      [[[-31.]]],\n","              \n","              \n","                      [[[-32.]]],\n","              \n","              \n","                      [[[-29.]]],\n","              \n","              \n","                      [[[-22.]]],\n","              \n","              \n","                      [[[-24.]]],\n","              \n","              \n","                      [[[-24.]]],\n","              \n","              \n","                      [[[-39.]]],\n","              \n","              \n","                      [[[-24.]]],\n","              \n","              \n","                      [[[-31.]]],\n","              \n","              \n","                      [[[-21.]]],\n","              \n","              \n","                      [[[-24.]]],\n","              \n","              \n","                      [[[-30.]]],\n","              \n","              \n","                      [[[-26.]]],\n","              \n","              \n","                      [[[-22.]]],\n","              \n","              \n","                      [[[-28.]]],\n","              \n","              \n","                      [[[-19.]]]], device='cuda:0')),\n","             ('module.layer3.7.conv2.fp_bias',\n","              tensor([ 0.2048,  0.4032, -0.8588, -0.1518,  0.3428,  0.2586,  0.8078,  0.2184,\n","                      -0.3362, -0.1526,  0.0841, -0.1999,  0.3261, -0.4162,  0.0466,  0.0954,\n","                      -0.2865,  0.0722, -0.2951,  0.3124,  0.2698, -0.2092,  0.0194,  0.7213,\n","                      -0.0968,  0.0219,  1.1313,  0.2237,  0.0631,  0.2349,  0.2427, -0.2088,\n","                       0.3004, -0.0245, -0.6136,  0.1897,  0.3101,  0.1313, -0.6758,  0.1905,\n","                      -0.1277, -0.0657,  0.0471, -0.3930, -0.0382,  0.1870,  0.0211, -0.0154,\n","                       0.1685,  0.0587,  0.2975, -0.2818, -0.1782,  0.3070, -0.0078, -0.2794,\n","                       0.1333, -0.0109,  0.0909,  0.1268, -0.2341,  0.0901,  0.3701, -0.0862],\n","                     device='cuda:0')),\n","             ('module.layer3.7.conv2.accum_scale', tensor([[[ 2053.3684]],\n","              \n","                      [[ 5096.7632]],\n","              \n","                      [[ 2596.8682]],\n","              \n","                      [[13136.2324]],\n","              \n","                      [[ 5853.9038]],\n","              \n","                      [[ 9154.4160]],\n","              \n","                      [[ 6417.5825]],\n","              \n","                      [[15651.2529]],\n","              \n","                      [[ 3090.4626]],\n","              \n","                      [[ 7425.8418]],\n","              \n","                      [[ 3928.1067]],\n","              \n","                      [[15959.4082]],\n","              \n","                      [[ 3555.2664]],\n","              \n","                      [[ 2521.6018]],\n","              \n","                      [[ 7074.4570]],\n","              \n","                      [[ 3189.8970]],\n","              \n","                      [[ 2331.6492]],\n","              \n","                      [[10017.2637]],\n","              \n","                      [[ 3800.4841]],\n","              \n","                      [[ 7004.8975]],\n","              \n","                      [[ 5359.2085]],\n","              \n","                      [[ 7675.7529]],\n","              \n","                      [[ 6852.5640]],\n","              \n","                      [[ 5020.7583]],\n","              \n","                      [[ 3366.2566]],\n","              \n","                      [[ 5318.3223]],\n","              \n","                      [[ 4025.5886]],\n","              \n","                      [[ 8935.1826]],\n","              \n","                      [[ 6131.4087]],\n","              \n","                      [[ 7919.4634]],\n","              \n","                      [[ 6610.6748]],\n","              \n","                      [[ 8902.2559]],\n","              \n","                      [[ 5789.2798]],\n","              \n","                      [[11782.9521]],\n","              \n","                      [[ 6017.2280]],\n","              \n","                      [[ 7825.5054]],\n","              \n","                      [[ 6292.9307]],\n","              \n","                      [[ 4752.8345]],\n","              \n","                      [[ 2697.0374]],\n","              \n","                      [[ 6752.1470]],\n","              \n","                      [[ 6634.0508]],\n","              \n","                      [[ 5137.0044]],\n","              \n","                      [[ 6822.3643]],\n","              \n","                      [[ 4014.8677]],\n","              \n","                      [[39517.2383]],\n","              \n","                      [[11467.2344]],\n","              \n","                      [[13118.7754]],\n","              \n","                      [[10399.1973]],\n","              \n","                      [[ 6713.5444]],\n","              \n","                      [[52897.7383]],\n","              \n","                      [[ 3705.9097]],\n","              \n","                      [[ 7248.8931]],\n","              \n","                      [[ 2496.1038]],\n","              \n","                      [[ 6193.0571]],\n","              \n","                      [[38348.5938]],\n","              \n","                      [[ 5263.1689]],\n","              \n","                      [[11561.2109]],\n","              \n","                      [[ 5119.8984]],\n","              \n","                      [[ 4462.1514]],\n","              \n","                      [[ 5595.6987]],\n","              \n","                      [[ 3799.8701]],\n","              \n","                      [[ 8190.1626]],\n","              \n","                      [[ 3629.2019]],\n","              \n","                      [[ 2500.6936]]], device='cuda:0')),\n","             ('module.layer3.7.conv2.is_simulated_quant_weight_shifted',\n","              tensor(False, device='cuda:0')),\n","             ('module.layer3.7.conv2.wrapped_module.weight',\n","              tensor([[[[17., 13., 13.],\n","                        [23., 18., 13.],\n","                        [28., 23., 19.]],\n","              \n","                       [[21., 18., 16.],\n","                        [25., 26., 26.],\n","                        [25., 27., 23.]],\n","              \n","                       [[20., 15., 13.],\n","                        [21., 19., 20.],\n","                        [20., 20., 19.]],\n","              \n","                       ...,\n","              \n","                       [[ 7.,  6., 18.],\n","                        [ 2.,  0., 10.],\n","                        [11.,  9.,  9.]],\n","              \n","                       [[21., 24., 25.],\n","                        [16., 18., 20.],\n","                        [17., 19., 21.]],\n","              \n","                       [[ 9., 15., 12.],\n","                        [17., 18., 14.],\n","                        [18., 23., 19.]]],\n","              \n","              \n","                      [[[27., 25., 24.],\n","                        [27., 24., 24.],\n","                        [27., 27., 26.]],\n","              \n","                       [[31., 30., 29.],\n","                        [39., 37., 38.],\n","                        [41., 42., 44.]],\n","              \n","                       [[26., 26., 25.],\n","                        [21., 24., 22.],\n","                        [10., 10.,  9.]],\n","              \n","                       ...,\n","              \n","                       [[30., 22., 33.],\n","                        [19.,  8., 22.],\n","                        [37., 24., 29.]],\n","              \n","                       [[49., 46., 44.],\n","                        [53., 59., 62.],\n","                        [37., 41., 45.]],\n","              \n","                       [[31., 29., 28.],\n","                        [32., 31., 29.],\n","                        [35., 35., 31.]]],\n","              \n","              \n","                      [[[17., 16., 15.],\n","                        [18., 18., 17.],\n","                        [17., 18., 17.]],\n","              \n","                       [[ 9.,  8.,  0.],\n","                        [16., 15., 15.],\n","                        [29., 28., 30.]],\n","              \n","                       [[10., 12., 12.],\n","                        [12., 13., 15.],\n","                        [ 9.,  8., 11.]],\n","              \n","                       ...,\n","              \n","                       [[20., 15., 23.],\n","                        [14., 10., 16.],\n","                        [ 5.,  1.,  7.]],\n","              \n","                       [[17., 13., 10.],\n","                        [24., 19., 19.],\n","                        [38., 33., 30.]],\n","              \n","                       [[13., 12., 12.],\n","                        [10., 10., 10.],\n","                        [11.,  8.,  5.]]],\n","              \n","              \n","                      ...,\n","              \n","              \n","                      [[[22., 18., 17.],\n","                        [22., 19., 15.],\n","                        [25., 20., 16.]],\n","              \n","                       [[33., 19., 26.],\n","                        [38., 24., 26.],\n","                        [38., 23., 22.]],\n","              \n","                       [[18., 20., 20.],\n","                        [20., 17., 17.],\n","                        [25., 21., 18.]],\n","              \n","                       ...,\n","              \n","                       [[15., 23., 29.],\n","                        [ 6., 10., 17.],\n","                        [17., 17., 24.]],\n","              \n","                       [[12., 20., 27.],\n","                        [ 9., 13., 12.],\n","                        [10., 11., 10.]],\n","              \n","                       [[18., 24., 24.],\n","                        [14., 20., 22.],\n","                        [14., 22., 25.]]],\n","              \n","              \n","                      [[[23., 21., 26.],\n","                        [32., 33., 33.],\n","                        [35., 38., 37.]],\n","              \n","                       [[30., 39., 38.],\n","                        [27., 33., 22.],\n","                        [10., 10., 10.]],\n","              \n","                       [[36., 37., 33.],\n","                        [39., 43., 41.],\n","                        [33., 38., 39.]],\n","              \n","                       ...,\n","              \n","                       [[21.,  9., 14.],\n","                        [23., 12., 22.],\n","                        [34., 21., 30.]],\n","              \n","                       [[16.,  8.,  9.],\n","                        [ 8.,  1.,  0.],\n","                        [ 9., 12., 13.]],\n","              \n","                       [[17., 15., 14.],\n","                        [27., 32., 40.],\n","                        [37., 52., 63.]]],\n","              \n","              \n","                      [[[22., 22., 20.],\n","                        [19., 20., 20.],\n","                        [21., 22., 22.]],\n","              \n","                       [[49., 23.,  8.],\n","                        [44., 44., 16.],\n","                        [36., 38., 14.]],\n","              \n","                       [[21., 19., 21.],\n","                        [11., 23., 33.],\n","                        [15., 28., 35.]],\n","              \n","                       ...,\n","              \n","                       [[24., 16., 29.],\n","                        [16.,  5., 20.],\n","                        [16.,  8., 22.]],\n","              \n","                       [[28., 30., 30.],\n","                        [23., 25., 24.],\n","                        [22., 20., 20.]],\n","              \n","                       [[17., 22., 19.],\n","                        [11., 21., 14.],\n","                        [24., 27., 15.]]]], device='cuda:0')),\n","             ('module.layer3.7.conv2.wrapped_module.bias',\n","              tensor([  421.,  2055., -2230., -1994.,  2006.,  2368.,  5184.,  3418., -1039.,\n","                      -1133.,   330., -3190.,  1160., -1049.,   330.,   304.,  -668.,   723.,\n","                      -1121.,  2188.,  1446., -1606.,   133.,  3622.,  -326.,   116.,  4554.,\n","                       1999.,   387.,  1860.,  1605., -1859.,  1739.,  -288., -3692.,  1484.,\n","                       1952.,   624., -1823.,  1286.,  -847.,  -338.,   321., -1578., -1509.,\n","                       2144.,   276.,  -160.,  1131.,  3105.,  1103., -2043.,  -445.,  1901.,\n","                       -299., -1471.,  1541.,   -56.,   406.,   710.,  -890.,   738.,  1343.,\n","                       -216.], device='cuda:0')),\n","             ('module.layer3.7.relu2.num_forwards',\n","              tensor([40], device='cuda:0')),\n","             ('module.layer3.7.relu2.force_readjust',\n","              tensor(False, device='cuda:0')),\n","             ('module.layer3.7.relu2.output_scale',\n","              tensor([3.3503], device='cuda:0')),\n","             ('module.layer3.7.relu2.output_zero_point',\n","              tensor([0.], device='cuda:0')),\n","             ('module.layer3.7.residual_eltwiseadd.num_forwards',\n","              tensor([40], device='cuda:0')),\n","             ('module.layer3.7.residual_eltwiseadd.force_readjust',\n","              tensor(False, device='cuda:0')),\n","             ('module.layer3.7.residual_eltwiseadd.output_scale',\n","              tensor([3.3503], device='cuda:0')),\n","             ('module.layer3.7.residual_eltwiseadd.output_zero_point',\n","              tensor([0.], device='cuda:0')),\n","             ('module.layer3.8.conv1.num_forwards',\n","              tensor([40], device='cuda:0')),\n","             ('module.layer3.8.conv1.force_readjust',\n","              tensor(False, device='cuda:0')),\n","             ('module.layer3.8.conv1.output_scale',\n","              tensor([61.3919], device='cuda:0')),\n","             ('module.layer3.8.conv1.output_zero_point',\n","              tensor([0.], device='cuda:0')),\n","             ('module.layer3.8.conv1.w_scale', tensor([[[[4462.8940]]],\n","              \n","              \n","                      [[[7611.6050]]],\n","              \n","              \n","                      [[[4661.6855]]],\n","              \n","              \n","                      [[[5720.2412]]],\n","              \n","              \n","                      [[[4273.7275]]],\n","              \n","              \n","                      [[[3839.9275]]],\n","              \n","              \n","                      [[[4968.1226]]],\n","              \n","              \n","                      [[[5116.8374]]],\n","              \n","              \n","                      [[[4650.5410]]],\n","              \n","              \n","                      [[[3743.1653]]],\n","              \n","              \n","                      [[[2354.3560]]],\n","              \n","              \n","                      [[[5280.3018]]],\n","              \n","              \n","                      [[[4666.2461]]],\n","              \n","              \n","                      [[[7999.2251]]],\n","              \n","              \n","                      [[[2084.7327]]],\n","              \n","              \n","                      [[[3140.6707]]],\n","              \n","              \n","                      [[[4439.5776]]],\n","              \n","              \n","                      [[[5816.6382]]],\n","              \n","              \n","                      [[[2921.1873]]],\n","              \n","              \n","                      [[[1637.1986]]],\n","              \n","              \n","                      [[[3984.8767]]],\n","              \n","              \n","                      [[[2677.3838]]],\n","              \n","              \n","                      [[[2216.0603]]],\n","              \n","              \n","                      [[[3182.1460]]],\n","              \n","              \n","                      [[[2963.5508]]],\n","              \n","              \n","                      [[[3455.3999]]],\n","              \n","              \n","                      [[[2019.1074]]],\n","              \n","              \n","                      [[[2103.6765]]],\n","              \n","              \n","                      [[[4232.7344]]],\n","              \n","              \n","                      [[[4047.8682]]],\n","              \n","              \n","                      [[[4735.8579]]],\n","              \n","              \n","                      [[[3250.7883]]],\n","              \n","              \n","                      [[[1538.0361]]],\n","              \n","              \n","                      [[[6354.4751]]],\n","              \n","              \n","                      [[[3258.6917]]],\n","              \n","              \n","                      [[[3376.4702]]],\n","              \n","              \n","                      [[[4071.8508]]],\n","              \n","              \n","                      [[[5142.3145]]],\n","              \n","              \n","                      [[[2067.6458]]],\n","              \n","              \n","                      [[[4725.4966]]],\n","              \n","              \n","                      [[[3952.1875]]],\n","              \n","              \n","                      [[[2704.5959]]],\n","              \n","              \n","                      [[[2930.5422]]],\n","              \n","              \n","                      [[[2275.0269]]],\n","              \n","              \n","                      [[[4564.7593]]],\n","              \n","              \n","                      [[[3262.2192]]],\n","              \n","              \n","                      [[[2539.6082]]],\n","              \n","              \n","                      [[[2641.4309]]],\n","              \n","              \n","                      [[[3052.0972]]],\n","              \n","              \n","                      [[[4587.7783]]],\n","              \n","              \n","                      [[[2323.4736]]],\n","              \n","              \n","                      [[[3676.5571]]],\n","              \n","              \n","                      [[[4087.6296]]],\n","              \n","              \n","                      [[[3098.0417]]],\n","              \n","              \n","                      [[[5240.4375]]],\n","              \n","              \n","                      [[[4356.8735]]],\n","              \n","              \n","                      [[[5028.7666]]],\n","              \n","              \n","                      [[[3003.0076]]],\n","              \n","              \n","                      [[[1523.7371]]],\n","              \n","              \n","                      [[[5217.0464]]],\n","              \n","              \n","                      [[[6391.5879]]],\n","              \n","              \n","                      [[[4364.7095]]],\n","              \n","              \n","                      [[[4457.9326]]],\n","              \n","              \n","                      [[[3826.5474]]]], device='cuda:0')),\n","             ('module.layer3.8.conv1.w_zero_point', tensor([[[[-30.]]],\n","              \n","              \n","                      [[[-39.]]],\n","              \n","              \n","                      [[[-34.]]],\n","              \n","              \n","                      [[[-38.]]],\n","              \n","              \n","                      [[[-28.]]],\n","              \n","              \n","                      [[[-21.]]],\n","              \n","              \n","                      [[[-30.]]],\n","              \n","              \n","                      [[[-30.]]],\n","              \n","              \n","                      [[[-24.]]],\n","              \n","              \n","                      [[[-24.]]],\n","              \n","              \n","                      [[[-18.]]],\n","              \n","              \n","                      [[[-27.]]],\n","              \n","              \n","                      [[[-25.]]],\n","              \n","              \n","                      [[[-33.]]],\n","              \n","              \n","                      [[[-18.]]],\n","              \n","              \n","                      [[[-22.]]],\n","              \n","              \n","                      [[[-29.]]],\n","              \n","              \n","                      [[[-24.]]],\n","              \n","              \n","                      [[[-18.]]],\n","              \n","              \n","                      [[[-24.]]],\n","              \n","              \n","                      [[[-21.]]],\n","              \n","              \n","                      [[[-31.]]],\n","              \n","              \n","                      [[[-21.]]],\n","              \n","              \n","                      [[[-25.]]],\n","              \n","              \n","                      [[[-23.]]],\n","              \n","              \n","                      [[[-30.]]],\n","              \n","              \n","                      [[[-30.]]],\n","              \n","              \n","                      [[[-23.]]],\n","              \n","              \n","                      [[[-26.]]],\n","              \n","              \n","                      [[[-26.]]],\n","              \n","              \n","                      [[[-29.]]],\n","              \n","              \n","                      [[[-23.]]],\n","              \n","              \n","                      [[[-20.]]],\n","              \n","              \n","                      [[[-23.]]],\n","              \n","              \n","                      [[[-25.]]],\n","              \n","              \n","                      [[[-22.]]],\n","              \n","              \n","                      [[[-23.]]],\n","              \n","              \n","                      [[[-31.]]],\n","              \n","              \n","                      [[[-18.]]],\n","              \n","              \n","                      [[[-24.]]],\n","              \n","              \n","                      [[[-31.]]],\n","              \n","              \n","                      [[[-27.]]],\n","              \n","              \n","                      [[[-23.]]],\n","              \n","              \n","                      [[[-28.]]],\n","              \n","              \n","                      [[[-33.]]],\n","              \n","              \n","                      [[[-25.]]],\n","              \n","              \n","                      [[[-21.]]],\n","              \n","              \n","                      [[[-20.]]],\n","              \n","              \n","                      [[[-25.]]],\n","              \n","              \n","                      [[[-27.]]],\n","              \n","              \n","                      [[[-28.]]],\n","              \n","              \n","                      [[[-34.]]],\n","              \n","              \n","                      [[[-25.]]],\n","              \n","              \n","                      [[[-23.]]],\n","              \n","              \n","                      [[[-19.]]],\n","              \n","              \n","                      [[[-30.]]],\n","              \n","              \n","                      [[[-27.]]],\n","              \n","              \n","                      [[[-34.]]],\n","              \n","              \n","                      [[[-22.]]],\n","              \n","              \n","                      [[[-25.]]],\n","              \n","              \n","                      [[[-33.]]],\n","              \n","              \n","                      [[[-22.]]],\n","              \n","              \n","                      [[[-35.]]],\n","              \n","              \n","                      [[[-32.]]]], device='cuda:0')),\n","             ('module.layer3.8.conv1.fp_bias',\n","              tensor([ 0.1747,  0.2082,  0.2661,  0.1903,  0.1028, -0.1064,  0.2414,  0.0681,\n","                       0.0449, -0.1080, -0.1051,  0.1799, -0.0794,  0.2072, -0.0921,  0.0074,\n","                      -0.0013, -0.0546,  0.1833, -0.0505, -0.2758,  0.0620, -0.0804, -0.0280,\n","                       0.0689,  0.0235, -0.0144,  0.0388,  0.0131,  0.2219,  0.1321, -0.0909,\n","                       0.0514,  0.0081, -0.0029, -0.0294, -0.0282,  0.1405, -0.0914, -0.0115,\n","                       0.2809, -0.0897, -0.1800,  0.1784,  0.3077,  0.0234, -0.0828, -0.0538,\n","                      -0.1445, -0.0256, -0.1615,  0.1817,  0.1238,  0.0108,  0.0404,  0.0625,\n","                      -0.1515,  0.1363, -0.0756, -0.0011,  0.2078, -0.0568,  0.3332,  0.2600],\n","                     device='cuda:0')),\n","             ('module.layer3.8.conv1.accum_scale', tensor([[[14952.0557]],\n","              \n","                      [[25501.1973]],\n","              \n","                      [[15618.0674]],\n","              \n","                      [[19164.5527]],\n","              \n","                      [[14318.2900]],\n","              \n","                      [[12864.9277]],\n","              \n","                      [[16644.7246]],\n","              \n","                      [[17142.9648]],\n","              \n","                      [[15580.7305]],\n","              \n","                      [[12540.7451]],\n","              \n","                      [[ 7887.8101]],\n","              \n","                      [[17690.6211]],\n","              \n","                      [[15633.3467]],\n","              \n","                      [[26799.8418]],\n","              \n","                      [[ 6984.4897]],\n","              \n","                      [[10522.2041]],\n","              \n","                      [[14873.9385]],\n","              \n","                      [[19487.5117]],\n","              \n","                      [[ 9786.8682]],\n","              \n","                      [[ 5485.1143]],\n","              \n","                      [[13350.5518]],\n","              \n","                      [[ 8970.0518]],\n","              \n","                      [[ 7424.4775]],\n","              \n","                      [[10661.1592]],\n","              \n","                      [[ 9928.7988]],\n","              \n","                      [[11576.6426]],\n","              \n","                      [[ 6764.6255]],\n","              \n","                      [[ 7047.9575]],\n","              \n","                      [[14180.9502]],\n","              \n","                      [[13561.5928]],\n","              \n","                      [[15866.5674]],\n","              \n","                      [[10891.1318]],\n","              \n","                      [[ 5152.8901]],\n","              \n","                      [[21289.4277]],\n","              \n","                      [[10917.6104]],\n","              \n","                      [[11312.2041]],\n","              \n","                      [[13641.9414]],\n","              \n","                      [[17228.3203]],\n","              \n","                      [[ 6927.2437]],\n","              \n","                      [[15831.8545]],\n","              \n","                      [[13241.0332]],\n","              \n","                      [[ 9061.2207]],\n","              \n","                      [[ 9818.2100]],\n","              \n","                      [[ 7622.0337]],\n","              \n","                      [[15293.3350]],\n","              \n","                      [[10929.4287]],\n","              \n","                      [[ 8508.4619]],\n","              \n","                      [[ 8849.5986]],\n","              \n","                      [[10225.4561]],\n","              \n","                      [[15370.4561]],\n","              \n","                      [[ 7784.3447]],\n","              \n","                      [[12317.5869]],\n","              \n","                      [[13694.8057]],\n","              \n","                      [[10379.3838]],\n","              \n","                      [[17557.0625]],\n","              \n","                      [[14596.8545]],\n","              \n","                      [[16847.9004]],\n","              \n","                      [[10060.9912]],\n","              \n","                      [[ 5104.9839]],\n","              \n","                      [[17478.6953]],\n","              \n","                      [[21413.7676]],\n","              \n","                      [[14623.1074]],\n","              \n","                      [[14935.4336]],\n","              \n","                      [[12820.1006]]], device='cuda:0')),\n","             ('module.layer3.8.conv1.is_simulated_quant_weight_shifted',\n","              tensor(False, device='cuda:0')),\n","             ('module.layer3.8.conv1.wrapped_module.weight',\n","              tensor([[[[36., 31., 27.],\n","                        [31., 26., 25.],\n","                        [21., 22., 22.]],\n","              \n","                       [[30., 37., 35.],\n","                        [39., 45., 32.],\n","                        [25., 35., 32.]],\n","              \n","                       [[36., 39., 35.],\n","                        [40., 42., 38.],\n","                        [37., 43., 47.]],\n","              \n","                       ...,\n","              \n","                       [[22., 21., 20.],\n","                        [23., 31., 31.],\n","                        [29., 38., 37.]],\n","              \n","                       [[19., 15., 13.],\n","                        [10., 10., 10.],\n","                        [20., 16., 10.]],\n","              \n","                       [[44., 41., 42.],\n","                        [41., 37., 27.],\n","                        [43., 40., 34.]]],\n","              \n","              \n","                      [[[31., 33., 21.],\n","                        [35., 42., 35.],\n","                        [28., 33., 28.]],\n","              \n","                       [[40., 46., 35.],\n","                        [42., 42., 35.],\n","                        [38., 44., 46.]],\n","              \n","                       [[57., 43., 41.],\n","                        [57., 40., 32.],\n","                        [52., 37., 38.]],\n","              \n","                       ...,\n","              \n","                       [[30., 31., 30.],\n","                        [34., 35., 33.],\n","                        [42., 40., 37.]],\n","              \n","                       [[24., 24., 23.],\n","                        [18., 21., 17.],\n","                        [20., 22., 30.]],\n","              \n","                       [[30., 34., 29.],\n","                        [36., 33., 34.],\n","                        [39., 33., 32.]]],\n","              \n","              \n","                      [[[ 9., 12., 11.],\n","                        [23., 31., 33.],\n","                        [22., 43., 56.]],\n","              \n","                       [[20., 19.,  8.],\n","                        [15., 19., 12.],\n","                        [ 9., 11., 13.]],\n","              \n","                       [[44., 40., 40.],\n","                        [46., 46., 48.],\n","                        [19., 18., 24.]],\n","              \n","                       ...,\n","              \n","                       [[34., 40., 36.],\n","                        [32., 39., 39.],\n","                        [28., 34., 37.]],\n","              \n","                       [[21., 28., 35.],\n","                        [29., 38., 44.],\n","                        [26., 30., 33.]],\n","              \n","                       [[22., 22., 33.],\n","                        [35., 38., 39.],\n","                        [34., 38., 38.]]],\n","              \n","              \n","                      ...,\n","              \n","              \n","                      [[[11.,  6., 20.],\n","                        [35., 36., 39.],\n","                        [32., 40., 35.]],\n","              \n","                       [[22., 19., 10.],\n","                        [19., 19., 17.],\n","                        [19., 20., 24.]],\n","              \n","                       [[28., 20., 13.],\n","                        [46., 47., 31.],\n","                        [23., 28., 21.]],\n","              \n","                       ...,\n","              \n","                       [[27., 29., 35.],\n","                        [20., 21., 26.],\n","                        [17., 18., 23.]],\n","              \n","                       [[21., 17., 13.],\n","                        [ 6.,  5.,  9.],\n","                        [ 0.,  2., 14.]],\n","              \n","                       [[ 7.,  5.,  3.],\n","                        [11.,  6., 14.],\n","                        [21., 11., 24.]]],\n","              \n","              \n","                      [[[37., 52., 59.],\n","                        [20., 14., 19.],\n","                        [27., 20., 12.]],\n","              \n","                       [[23., 25., 22.],\n","                        [24., 28., 26.],\n","                        [29., 29., 28.]],\n","              \n","                       [[10., 18., 17.],\n","                        [ 3., 13., 13.],\n","                        [ 2.,  9., 11.]],\n","              \n","                       ...,\n","              \n","                       [[33., 31., 28.],\n","                        [29., 31., 27.],\n","                        [25., 29., 29.]],\n","              \n","                       [[13., 11., 13.],\n","                        [22., 27., 21.],\n","                        [25., 34., 24.]],\n","              \n","                       [[50., 47., 42.],\n","                        [38., 38., 27.],\n","                        [41., 43., 29.]]],\n","              \n","              \n","                      [[[15., 16., 14.],\n","                        [24., 28., 27.],\n","                        [24., 31., 36.]],\n","              \n","                       [[32., 24., 15.],\n","                        [19., 16., 13.],\n","                        [24., 25., 23.]],\n","              \n","                       [[43., 38., 26.],\n","                        [55., 41., 28.],\n","                        [51., 41., 30.]],\n","              \n","                       ...,\n","              \n","                       [[39., 45., 44.],\n","                        [37., 43., 43.],\n","                        [32., 36., 41.]],\n","              \n","                       [[46., 39., 29.],\n","                        [43., 36., 33.],\n","                        [32., 30., 30.]],\n","              \n","                       [[22., 24., 16.],\n","                        [15., 22., 19.],\n","                        [ 8., 17., 21.]]]], device='cuda:0')),\n","             ('module.layer3.8.conv1.wrapped_module.bias',\n","              tensor([ 2612.,  5309.,  4156.,  3648.,  1472., -1369.,  4018.,  1168.,   700.,\n","                      -1355.,  -829.,  3183., -1241.,  5552.,  -643.,    78.,   -19., -1065.,\n","                       1794.,  -277., -3682.,   556.,  -597.,  -299.,   684.,   272.,   -97.,\n","                        273.,   186.,  3010.,  2096.,  -990.,   265.,   173.,   -31.,  -332.,\n","                       -384.,  2421.,  -633.,  -182.,  3719.,  -813., -1767.,  1360.,  4705.,\n","                        256.,  -705.,  -477., -1478.,  -393., -1257.,  2238.,  1695.,   112.,\n","                        710.,   913., -2552.,  1372.,  -386.,   -20.,  4451.,  -831.,  4976.,\n","                       3333.], device='cuda:0')),\n","             ('module.layer3.8.conv2.num_forwards',\n","              tensor([40], device='cuda:0')),\n","             ('module.layer3.8.conv2.force_readjust',\n","              tensor(False, device='cuda:0')),\n","             ('module.layer3.8.conv2.output_scale',\n","              tensor([8.1991], device='cuda:0')),\n","             ('module.layer3.8.conv2.output_zero_point',\n","              tensor([-20.], device='cuda:0')),\n","             ('module.layer3.8.conv2.w_scale', tensor([[[[  88.9413]]],\n","              \n","              \n","                      [[[  97.5285]]],\n","              \n","              \n","                      [[[  40.2894]]],\n","              \n","              \n","                      [[[  84.5095]]],\n","              \n","              \n","                      [[[  58.7493]]],\n","              \n","              \n","                      [[[  76.8704]]],\n","              \n","              \n","                      [[[ 142.7644]]],\n","              \n","              \n","                      [[[ 530.8938]]],\n","              \n","              \n","                      [[[ 210.3333]]],\n","              \n","              \n","                      [[[ 434.8908]]],\n","              \n","              \n","                      [[[  79.3857]]],\n","              \n","              \n","                      [[[ 189.8353]]],\n","              \n","              \n","                      [[[  66.1513]]],\n","              \n","              \n","                      [[[ 100.1372]]],\n","              \n","              \n","                      [[[ 155.5779]]],\n","              \n","              \n","                      [[[ 114.3984]]],\n","              \n","              \n","                      [[[1874.6819]]],\n","              \n","              \n","                      [[[ 152.7239]]],\n","              \n","              \n","                      [[[ 206.1891]]],\n","              \n","              \n","                      [[[ 160.8600]]],\n","              \n","              \n","                      [[[ 102.2971]]],\n","              \n","              \n","                      [[[ 261.4674]]],\n","              \n","              \n","                      [[[ 187.6679]]],\n","              \n","              \n","                      [[[ 185.1596]]],\n","              \n","              \n","                      [[[  69.7164]]],\n","              \n","              \n","                      [[[ 139.3167]]],\n","              \n","              \n","                      [[[ 160.2758]]],\n","              \n","              \n","                      [[[ 149.4065]]],\n","              \n","              \n","                      [[[ 217.3785]]],\n","              \n","              \n","                      [[[ 133.8514]]],\n","              \n","              \n","                      [[[ 386.1165]]],\n","              \n","              \n","                      [[[ 548.6407]]],\n","              \n","              \n","                      [[[ 135.0907]]],\n","              \n","              \n","                      [[[ 593.6791]]],\n","              \n","              \n","                      [[[ 472.1833]]],\n","              \n","              \n","                      [[[ 233.9875]]],\n","              \n","              \n","                      [[[ 155.2073]]],\n","              \n","              \n","                      [[[ 186.9355]]],\n","              \n","              \n","                      [[[ 168.0260]]],\n","              \n","              \n","                      [[[ 122.0478]]],\n","              \n","              \n","                      [[[ 108.3959]]],\n","              \n","              \n","                      [[[ 186.0306]]],\n","              \n","              \n","                      [[[ 109.1568]]],\n","              \n","              \n","                      [[[ 226.2564]]],\n","              \n","              \n","                      [[[1962.5015]]],\n","              \n","              \n","                      [[[ 333.4498]]],\n","              \n","              \n","                      [[[ 644.1456]]],\n","              \n","              \n","                      [[[1057.8033]]],\n","              \n","              \n","                      [[[ 142.0948]]],\n","              \n","              \n","                      [[[1237.5308]]],\n","              \n","              \n","                      [[[ 181.7058]]],\n","              \n","              \n","                      [[[ 876.7694]]],\n","              \n","              \n","                      [[[ 156.5383]]],\n","              \n","              \n","                      [[[ 175.2928]]],\n","              \n","              \n","                      [[[1793.4575]]],\n","              \n","              \n","                      [[[ 428.1795]]],\n","              \n","              \n","                      [[[ 622.9511]]],\n","              \n","              \n","                      [[[ 109.2517]]],\n","              \n","              \n","                      [[[  67.3318]]],\n","              \n","              \n","                      [[[ 103.1232]]],\n","              \n","              \n","                      [[[ 226.8802]]],\n","              \n","              \n","                      [[[ 240.8294]]],\n","              \n","              \n","                      [[[ 183.9554]]],\n","              \n","              \n","                      [[[ 160.9537]]]], device='cuda:0')),\n","             ('module.layer3.8.conv2.w_zero_point', tensor([[[[-28.]]],\n","              \n","              \n","                      [[[-40.]]],\n","              \n","              \n","                      [[[-26.]]],\n","              \n","              \n","                      [[[-33.]]],\n","              \n","              \n","                      [[[-24.]]],\n","              \n","              \n","                      [[[-33.]]],\n","              \n","              \n","                      [[[-30.]]],\n","              \n","              \n","                      [[[-24.]]],\n","              \n","              \n","                      [[[-38.]]],\n","              \n","              \n","                      [[[-27.]]],\n","              \n","              \n","                      [[[-23.]]],\n","              \n","              \n","                      [[[-28.]]],\n","              \n","              \n","                      [[[-22.]]],\n","              \n","              \n","                      [[[-33.]]],\n","              \n","              \n","                      [[[-38.]]],\n","              \n","              \n","                      [[[-25.]]],\n","              \n","              \n","                      [[[-35.]]],\n","              \n","              \n","                      [[[-19.]]],\n","              \n","              \n","                      [[[-29.]]],\n","              \n","              \n","                      [[[-24.]]],\n","              \n","              \n","                      [[[-30.]]],\n","              \n","              \n","                      [[[-27.]]],\n","              \n","              \n","                      [[[-33.]]],\n","              \n","              \n","                      [[[-28.]]],\n","              \n","              \n","                      [[[-33.]]],\n","              \n","              \n","                      [[[-33.]]],\n","              \n","              \n","                      [[[-28.]]],\n","              \n","              \n","                      [[[-26.]]],\n","              \n","              \n","                      [[[-29.]]],\n","              \n","              \n","                      [[[-31.]]],\n","              \n","              \n","                      [[[-23.]]],\n","              \n","              \n","                      [[[-26.]]],\n","              \n","              \n","                      [[[-25.]]],\n","              \n","              \n","                      [[[-26.]]],\n","              \n","              \n","                      [[[-20.]]],\n","              \n","              \n","                      [[[-36.]]],\n","              \n","              \n","                      [[[-34.]]],\n","              \n","              \n","                      [[[-29.]]],\n","              \n","              \n","                      [[[-30.]]],\n","              \n","              \n","                      [[[-35.]]],\n","              \n","              \n","                      [[[-27.]]],\n","              \n","              \n","                      [[[-24.]]],\n","              \n","              \n","                      [[[-24.]]],\n","              \n","              \n","                      [[[-31.]]],\n","              \n","              \n","                      [[[-28.]]],\n","              \n","              \n","                      [[[-30.]]],\n","              \n","              \n","                      [[[-35.]]],\n","              \n","              \n","                      [[[-28.]]],\n","              \n","              \n","                      [[[-29.]]],\n","              \n","              \n","                      [[[-28.]]],\n","              \n","              \n","                      [[[-28.]]],\n","              \n","              \n","                      [[[-31.]]],\n","              \n","              \n","                      [[[-22.]]],\n","              \n","              \n","                      [[[-31.]]],\n","              \n","              \n","                      [[[-31.]]],\n","              \n","              \n","                      [[[-30.]]],\n","              \n","              \n","                      [[[-26.]]],\n","              \n","              \n","                      [[[-28.]]],\n","              \n","              \n","                      [[[-22.]]],\n","              \n","              \n","                      [[[-20.]]],\n","              \n","              \n","                      [[[-34.]]],\n","              \n","              \n","                      [[[-24.]]],\n","              \n","              \n","                      [[[-29.]]],\n","              \n","              \n","                      [[[-29.]]]], device='cuda:0')),\n","             ('module.layer3.8.conv2.fp_bias',\n","              tensor([ 8.1727e-01,  8.5649e-01, -8.4451e-01,  7.0041e-01,  4.4967e-01,\n","                       6.7411e-01,  6.0290e-01,  1.2894e-02,  4.3725e-01, -1.3663e-04,\n","                      -1.3134e-01,  8.2572e-02,  6.1982e-02,  2.5464e-01,  5.0888e-01,\n","                       3.9109e-01, -1.5843e-01, -1.4457e-01,  4.1171e-02,  3.7240e-01,\n","                       2.4342e-02,  3.4995e-02, -7.6947e-02,  1.6564e-01,  8.6376e-01,\n","                       4.0951e-01,  2.3556e-01,  2.9943e-01,  1.0196e-01,  7.1574e-02,\n","                      -1.1360e-02, -5.2575e-02,  1.7855e-01, -6.5539e-02, -1.7127e-01,\n","                       4.9062e-02,  4.4079e-01,  8.3113e-02,  1.4252e-02,  3.2113e-01,\n","                       2.5253e-01, -2.6794e-02,  3.2971e-01,  2.2469e-01,  1.5501e-02,\n","                      -8.1888e-02,  1.4668e-01, -1.2635e-01,  8.4136e-02,  3.1103e-02,\n","                       1.6736e-01, -3.4224e-02,  2.2126e-02,  4.4411e-01, -6.3725e-02,\n","                      -9.5593e-02, -9.9483e-02,  3.5902e-01,  4.7350e-01, -4.6346e-02,\n","                      -1.6203e-01, -2.9086e-02,  1.3863e-01, -6.1095e-02], device='cuda:0')),\n","             ('module.layer3.8.conv2.accum_scale', tensor([[[  5460.2720]],\n","              \n","                      [[  5987.4546]],\n","              \n","                      [[  2473.4404]],\n","              \n","                      [[  5188.1934]],\n","              \n","                      [[  3606.7317]],\n","              \n","                      [[  4719.2197]],\n","              \n","                      [[  8764.5723]],\n","              \n","                      [[ 32592.5605]],\n","              \n","                      [[ 12912.7529]],\n","              \n","                      [[ 26698.7598]],\n","              \n","                      [[  4873.6382]],\n","              \n","                      [[ 11654.3428]],\n","              \n","                      [[  4061.1497]],\n","              \n","                      [[  6147.6123]],\n","              \n","                      [[  9551.2178]],\n","              \n","                      [[  7023.1284]],\n","              \n","                      [[115090.2188]],\n","              \n","                      [[  9376.0059]],\n","              \n","                      [[ 12658.3340]],\n","              \n","                      [[  9875.4941]],\n","              \n","                      [[  6280.2100]],\n","              \n","                      [[ 16051.9736]],\n","              \n","                      [[ 11521.2832]],\n","              \n","                      [[ 11367.2920]],\n","              \n","                      [[  4280.0215]],\n","              \n","                      [[  8552.9102]],\n","              \n","                      [[  9839.6309]],\n","              \n","                      [[  9172.3418]],\n","              \n","                      [[ 13345.2744]],\n","              \n","                      [[  8217.3896]],\n","              \n","                      [[ 23704.4102]],\n","              \n","                      [[ 33682.0742]],\n","              \n","                      [[  8293.4697]],\n","              \n","                      [[ 36447.0703]],\n","              \n","                      [[ 28988.2109]],\n","              \n","                      [[ 14364.9287]],\n","              \n","                      [[  9528.4668]],\n","              \n","                      [[ 11476.3203]],\n","              \n","                      [[ 10315.4297]],\n","              \n","                      [[  7492.7407]],\n","              \n","                      [[  6654.6245]],\n","              \n","                      [[ 11420.7666]],\n","              \n","                      [[  6701.3369]],\n","              \n","                      [[ 13890.2998]],\n","              \n","                      [[120481.6250]],\n","              \n","                      [[ 20471.1055]],\n","              \n","                      [[ 39545.2969]],\n","              \n","                      [[ 64940.5195]],\n","              \n","                      [[  8723.4639]],\n","              \n","                      [[ 75974.3203]],\n","              \n","                      [[ 11155.2588]],\n","              \n","                      [[ 53826.5078]],\n","              \n","                      [[  9610.1768]],\n","              \n","                      [[ 10761.5518]],\n","              \n","                      [[110103.7031]],\n","              \n","                      [[ 26286.7402]],\n","              \n","                      [[ 38244.1289]],\n","              \n","                      [[  6707.1636]],\n","              \n","                      [[  4133.6265]],\n","              \n","                      [[  6330.9258]],\n","              \n","                      [[ 13928.5977]],\n","              \n","                      [[ 14784.9668]],\n","              \n","                      [[ 11293.3623]],\n","              \n","                      [[  9881.2461]]], device='cuda:0')),\n","             ('module.layer3.8.conv2.is_simulated_quant_weight_shifted',\n","              tensor(False, device='cuda:0')),\n","             ('module.layer3.8.conv2.wrapped_module.weight',\n","              tensor([[[[24., 22., 22.],\n","                        [20., 17., 20.],\n","                        [26., 23., 25.]],\n","              \n","                       [[26., 22., 25.],\n","                        [20., 15., 21.],\n","                        [25., 20., 24.]],\n","              \n","                       [[51., 35., 37.],\n","                        [35., 15., 23.],\n","                        [34., 17., 26.]],\n","              \n","                       ...,\n","              \n","                       [[28., 29., 28.],\n","                        [25., 27., 28.],\n","                        [25., 26., 30.]],\n","              \n","                       [[33., 28., 37.],\n","                        [22., 12., 23.],\n","                        [37., 30., 37.]],\n","              \n","                       [[18., 15., 19.],\n","                        [12.,  7., 13.],\n","                        [20., 14., 17.]]],\n","              \n","              \n","                      [[[39., 34., 37.],\n","                        [36., 31., 36.],\n","                        [45., 40., 41.]],\n","              \n","                       [[41., 39., 44.],\n","                        [36., 36., 44.],\n","                        [38., 37., 43.]],\n","              \n","                       [[19., 13., 24.],\n","                        [ 8.,  0.,  9.],\n","                        [21., 16., 22.]],\n","              \n","                       ...,\n","              \n","                       [[37., 36., 34.],\n","                        [41., 41., 37.],\n","                        [49., 47., 38.]],\n","              \n","                       [[44., 35., 44.],\n","                        [33., 20., 29.],\n","                        [30., 16., 24.]],\n","              \n","                       [[34., 34., 43.],\n","                        [31., 28., 37.],\n","                        [40., 37., 41.]]],\n","              \n","              \n","                      [[[37., 41., 40.],\n","                        [33., 34., 34.],\n","                        [29., 32., 29.]],\n","              \n","                       [[31., 32., 32.],\n","                        [29., 31., 30.],\n","                        [25., 28., 27.]],\n","              \n","                       [[34., 34., 40.],\n","                        [27., 25., 34.],\n","                        [27., 29., 34.]],\n","              \n","                       ...,\n","              \n","                       [[31., 30., 31.],\n","                        [23., 19., 23.],\n","                        [31., 32., 32.]],\n","              \n","                       [[22., 17., 20.],\n","                        [11., 10., 13.],\n","                        [ 0.,  3.,  7.]],\n","              \n","                       [[28., 34., 34.],\n","                        [27., 36., 35.],\n","                        [24., 31., 30.]]],\n","              \n","              \n","                      ...,\n","              \n","              \n","                      [[[16., 18., 22.],\n","                        [12., 12., 16.],\n","                        [13., 14., 16.]],\n","              \n","                       [[16., 16., 21.],\n","                        [14., 14., 19.],\n","                        [21., 20., 24.]],\n","              \n","                       [[17., 15., 19.],\n","                        [20., 17., 19.],\n","                        [31., 23., 21.]],\n","              \n","                       ...,\n","              \n","                       [[21., 22., 25.],\n","                        [22., 23., 25.],\n","                        [19., 22., 21.]],\n","              \n","                       [[24., 23., 27.],\n","                        [22., 22., 30.],\n","                        [32., 34., 44.]],\n","              \n","                       [[33., 33., 40.],\n","                        [38., 37., 41.],\n","                        [46., 46., 47.]]],\n","              \n","              \n","                      [[[22., 24., 27.],\n","                        [20., 18., 18.],\n","                        [28., 26., 25.]],\n","              \n","                       [[31., 27., 28.],\n","                        [23., 19., 20.],\n","                        [27., 23., 25.]],\n","              \n","                       [[63., 61., 62.],\n","                        [41., 36., 38.],\n","                        [35., 28., 31.]],\n","              \n","                       ...,\n","              \n","                       [[23., 19., 13.],\n","                        [16., 13., 11.],\n","                        [18., 19., 21.]],\n","              \n","                       [[24., 16., 25.],\n","                        [18.,  8., 18.],\n","                        [27., 21., 27.]],\n","              \n","                       [[18., 17., 23.],\n","                        [10.,  7., 12.],\n","                        [17., 10., 14.]]],\n","              \n","              \n","                      [[[32., 30., 33.],\n","                        [27., 24., 28.],\n","                        [32., 26., 29.]],\n","              \n","                       [[32., 28., 31.],\n","                        [28., 23., 25.],\n","                        [28., 23., 25.]],\n","              \n","                       [[31., 22., 22.],\n","                        [23., 10., 17.],\n","                        [26., 13., 25.]],\n","              \n","                       ...,\n","              \n","                       [[35., 29., 31.],\n","                        [32., 26., 28.],\n","                        [24., 20., 24.]],\n","              \n","                       [[33., 31., 43.],\n","                        [28., 25., 37.],\n","                        [43., 42., 56.]],\n","              \n","                       [[19., 16., 20.],\n","                        [19., 20., 23.],\n","                        [12., 11., 13.]]]], device='cuda:0')),\n","             ('module.layer3.8.conv2.wrapped_module.bias',\n","              tensor([ 4.4630e+03,  5.1280e+03, -2.0890e+03,  3.6340e+03,  1.6220e+03,\n","                       3.1810e+03,  5.2840e+03,  4.2000e+02,  5.6460e+03, -4.0000e+00,\n","                      -6.4000e+02,  9.6200e+02,  2.5200e+02,  1.5650e+03,  4.8600e+03,\n","                       2.7470e+03, -1.8234e+04, -1.3550e+03,  5.2100e+02,  3.6780e+03,\n","                       1.5300e+02,  5.6200e+02, -8.8700e+02,  1.8830e+03,  3.6970e+03,\n","                       3.5030e+03,  2.3180e+03,  2.7460e+03,  1.3610e+03,  5.8800e+02,\n","                      -2.6900e+02, -1.7710e+03,  1.4810e+03, -2.3890e+03, -4.9650e+03,\n","                       7.0500e+02,  4.2000e+03,  9.5400e+02,  1.4700e+02,  2.4060e+03,\n","                       1.6810e+03, -3.0600e+02,  2.2090e+03,  3.1210e+03,  1.8680e+03,\n","                      -1.6760e+03,  5.8000e+03, -8.2050e+03,  7.3400e+02,  2.3630e+03,\n","                       1.8670e+03, -1.8420e+03,  2.1300e+02,  4.7790e+03, -7.0160e+03,\n","                      -2.5130e+03, -3.8050e+03,  2.4080e+03,  1.9570e+03, -2.9300e+02,\n","                      -2.2570e+03, -4.3000e+02,  1.5660e+03, -6.0400e+02], device='cuda:0')),\n","             ('module.layer3.8.relu2.num_forwards',\n","              tensor([40], device='cuda:0')),\n","             ('module.layer3.8.relu2.force_readjust',\n","              tensor(False, device='cuda:0')),\n","             ('module.layer3.8.relu2.output_scale',\n","              tensor([2.8575], device='cuda:0')),\n","             ('module.layer3.8.relu2.output_zero_point',\n","              tensor([0.], device='cuda:0')),\n","             ('module.layer3.8.residual_eltwiseadd.num_forwards',\n","              tensor([40], device='cuda:0')),\n","             ('module.layer3.8.residual_eltwiseadd.force_readjust',\n","              tensor(False, device='cuda:0')),\n","             ('module.layer3.8.residual_eltwiseadd.output_scale',\n","              tensor([2.8575], device='cuda:0')),\n","             ('module.layer3.8.residual_eltwiseadd.output_zero_point',\n","              tensor([0.], device='cuda:0')),\n","             ('module.avgpool.num_forwards', tensor([40], device='cuda:0')),\n","             ('module.avgpool.force_readjust', tensor(False, device='cuda:0')),\n","             ('module.avgpool.output_scale',\n","              tensor([15.9084], device='cuda:0')),\n","             ('module.avgpool.output_zero_point',\n","              tensor([0.], device='cuda:0')),\n","             ('module.fc.num_forwards', tensor([40], device='cuda:0')),\n","             ('module.fc.force_readjust', tensor(False, device='cuda:0')),\n","             ('module.fc.output_scale', tensor([2.3891], device='cuda:0')),\n","             ('module.fc.output_zero_point', tensor([-18.], device='cuda:0')),\n","             ('module.fc.w_scale', tensor([[26.4416],\n","                      [25.3521],\n","                      [24.4871],\n","                      [30.5889],\n","                      [25.0718],\n","                      [22.3038],\n","                      [26.4640],\n","                      [26.5147],\n","                      [23.1657],\n","                      [22.9864]], device='cuda:0')),\n","             ('module.fc.w_zero_point', tensor([[-26.],\n","                      [-19.],\n","                      [-29.],\n","                      [-21.],\n","                      [-20.],\n","                      [-17.],\n","                      [-21.],\n","                      [-20.],\n","                      [-22.],\n","                      [-15.]], device='cuda:0')),\n","             ('module.fc.fp_bias',\n","              tensor([ 0.0103, -0.4491,  0.2737,  0.4109,  0.1017, -0.1730,  0.1324, -0.0055,\n","                      -0.2107, -0.0913], device='cuda:0')),\n","             ('module.fc.accum_scale',\n","              tensor([420.6423, 403.3112, 389.5495, 486.6202, 398.8517, 354.8169, 421.0000,\n","                      421.8055, 368.5280, 365.6759], device='cuda:0')),\n","             ('module.fc.is_simulated_quant_weight_shifted',\n","              tensor(False, device='cuda:0')),\n","             ('module.fc.wrapped_module.weight',\n","              tensor([[ 4., 15., 25.,  1., 46., 49., 28., 29., 19., 23., 35., 26., 39., 18.,\n","                       17., 38., 22., 38., 18., 29., 12., 18., 19., 45., 49.,  9., 33., 18.,\n","                       19., 24., 21., 18., 39., 27., 25., 23., 52., 18.,  6., 48., 35., 36.,\n","                       18.,  2., 25., 27., 27., 27., 15., 27., 63., 20.,  0., 28., 27., 21.,\n","                       27., 24., 20., 43., 19., 31., 34., 15.],\n","                      [ 8., 13., 63.,  7., 16., 31., 11., 18., 11., 14., 56., 18., 26., 19.,\n","                       16.,  4., 12., 31., 21.,  5., 25., 21., 33., 24.,  0., 13., 10., 25.,\n","                       15., 10., 34., 15., 28., 20.,  9., 31., 17., 16., 58.,  7., 24., 21.,\n","                       17.,  5., 20., 19., 23., 16., 23., 20.,  5., 18.,  5.,  8., 17., 32.,\n","                       18., 14., 13., 28., 21.,  9.,  7., 14.],\n","                      [17., 22., 13., 49., 42., 16., 19., 31., 19., 23., 23., 23.,  0., 11.,\n","                       46.,  9., 17., 28., 46., 16., 13., 27., 28., 19., 33., 39., 23., 30.,\n","                       46., 41., 15., 46., 37., 26., 33., 32., 12., 19., 34., 28., 37., 46.,\n","                       23., 44., 27., 28., 24., 63., 28., 28., 60., 32., 40., 26., 27., 39.,\n","                       25., 34., 37., 38., 26., 42., 37., 50.],\n","                      [10.,  1.,  7., 31., 11., 11., 27., 26., 27., 22.,  1., 54., 39., 16.,\n","                        0., 55., 25., 32., 25., 25., 26., 35.,  7., 11.,  0., 13., 28., 29.,\n","                       16., 33.,  8.,  6., 18., 30., 21., 15.,  2., 41., 18., 30.,  8., 23.,\n","                        1., 31., 22., 29., 10., 10., 29., 21.,  4., 29., 63.,  2., 22., 45.,\n","                       31., 22., 27., 36., 56., 34., 28.,  4.],\n","                      [57.,  7.,  3., 46., 48., 16., 38., 18.,  5., 18., 22., 22., 13., 63.,\n","                       24.,  9., 16., 13.,  9., 36.,  4., 12., 19., 19., 11., 36., 17., 23.,\n","                       18.,  6., 16., 22.,  0., 18., 20., 11., 22., 13.,  9., 38., 16., 22.,\n","                       13., 34., 19., 23., 19., 13., 12., 20.,  4., 16., 26., 34., 17., 16.,\n","                       23., 26.,  9.,  6., 22., 22., 34.,  7.],\n","                      [32.,  0.,  4., 20., 10.,  6., 20., 17.,  8., 24., 14.,  4., 32., 17.,\n","                       28., 34., 48., 19., 40., 17., 19., 24., 21., 10.,  3., 15., 23., 15.,\n","                       15., 32., 15., 25., 17., 26., 21.,  8., 12., 18.,  8.,  3.,  2., 10.,\n","                       63.,  8., 14., 10., 25., 12., 27., 17.,  8., 12., 27., 10., 20.,  5.,\n","                       18., 10., 18.,  7., 19.,  7., 36., 29.],\n","                      [13., 63.,  8.,  0., 11.,  5., 50., 25., 28., 26., 10., 20., 24., 12.,\n","                       17., 12., 15., 12., 29., 20., 11.,  2., 16., 26.,  7., 37., 31., 36.,\n","                       29., 17., 57., 18., 16., 13., 19., 31., 17.,  1., 27., 26.,  5., 17.,\n","                       16., 33., 20., 18., 26., 15., 36., 21., 31., 21., 31., 20., 22., 18.,\n","                       22., 12., 51., 14., 15., 28.,  1., 15.],\n","                      [63., 19.,  3., 19.,  5., 15.,  0., 15., 59., 14.,  3., 17., 23., 18.,\n","                       35., 31., 14., 16.,  3., 16., 24., 37., 17., 11., 17., 18.,  6.,  7.,\n","                       16., 29., 12., 19., 10., 21., 17.,  5., 56., 19., 35., 10., 31., 15.,\n","                        9., 17., 15., 23., 21., 17., 10., 19., 13., 11., 15., 21., 22., 13.,\n","                       18., 40., 20., 14.,  5.,  5., 16., 43.],\n","                      [ 5., 33., 15., 21., 14., 40., 16., 21., 20., 20., 37., 19.,  0., 19.,\n","                       19.,  3., 29., 15., 12., 26., 63., 14., 21., 37., 43., 10., 37., 17.,\n","                       22., 16., 19., 23., 32., 22., 17., 48., 14., 38., 14., 14., 27., 16.,\n","                       20., 17., 31., 27., 19., 22., 14., 23.,  7., 21., 10., 46., 21., 21.,\n","                       19., 25., 15., 20., 13., 27.,  9.,  8.],\n","                      [ 0., 35., 63., 15.,  7., 20.,  5., 11., 19., 25.,  5., 15., 19., 15.,\n","                        4., 21.,  8.,  8.,  6., 19., 11., 21., 24.,  8., 42., 19.,  1., 11.,\n","                       13.,  3., 12., 13., 11.,  9., 28.,  4.,  8., 27.,  3., 11., 23.,  6.,\n","                       19., 21., 16.,  9., 14., 14., 15., 13., 14., 30.,  0., 11., 15.,  7.,\n","                       11.,  4.,  4.,  8., 19.,  8.,  6., 20.]], device='cuda:0')),\n","             ('module.fc.wrapped_module.bias',\n","              tensor([   4., -181.,  107.,  200.,   41.,  -61.,   56.,   -2.,  -78.,  -33.],\n","                     device='cuda:0'))])"]},"metadata":{"tags":[]},"execution_count":9}]},{"cell_type":"code","metadata":{"id":"lzUQbCZpr556"},"source":["testentry = removeModule(torch.load(pather))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"MPaXVDQABgeV"},"source":["# https://github.com/IntelLabs/distiller/blob/master/distiller/quantization/quantizer.py"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"udegmCdr0jr2"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":130},"id":"tuwrHBLb_IdP","executionInfo":{"elapsed":579,"status":"error","timestamp":1607469544653,"user":{"displayName":"Jeremy Wang","photoUrl":"","userId":"16277065741529505083"},"user_tz":300},"outputId":"5d7aaf6e-74b3-4403-f287-b851b243266b"},"source":["## Post-Train Quantize with Distiller\n","model = distiller.models.create_model(False, \"cifar10\", \"resnet56_cifar\", True, None)\n","# entry = removeModule(torch.load(pather))\n","# entry = torch.load(pather)\n","# Load the file\n","\n","quant_mode = {'activations': 'ASYMMETRIC_UNSIGNED', 'weights': 'SYMMETRIC'}\n","stats_file = \"/content/drive/MyDrive/CS6787 - Final Project/Google Colab Scripts/Quantization Models/Resnet56 Quantization Stats/resnet56_quant_stats.yaml\"\n","dummy_input = distiller.get_dummy_input(input_shape=model.input_shape)\n","\n","quantizer = quant.PostTrainLinearQuantizer(\n","    deepcopy(model), bits_activations=8, bits_parameters=8, mode=quant_mode,\n","    model_activation_stats=stats_file, overrides=None\n","\n","quantizer.prepare_model(dummy_input)"],"execution_count":null,"outputs":[{"output_type":"error","ename":"SyntaxError","evalue":"ignored","traceback":["\u001b[0;36m  File \u001b[0;32m\"<ipython-input-18-0a0ef4159894>\"\u001b[0;36m, line \u001b[0;32m15\u001b[0m\n\u001b[0;31m    quantizer.prepare_model(dummy_input)\u001b[0m\n\u001b[0m            ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"]}]},{"cell_type":"markdown","metadata":{"id":"5ZnIC038o5hG"},"source":["# \"Prepare_Model"]},{"cell_type":"code","metadata":{"id":"QIReOwwN8Q7a"},"source":["pather = \"/content/drive/MyDrive/CS6787 - Final Project/Google Colab Scripts/Quantization Models/Resnet56_cifar10_post_train_2_16bit/quantized_checkpoint.pth.tar\""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"n6lCj7Avo_o0"},"source":["model = distiller.models.create_model(False, \"cifar10\", \"resnet56_cifar\", True, None)\n","quant_mode = {'activations': 'ASYMMETRIC_UNSIGNED', 'weights': 'ASYMMETRIC_UNSIGNED'}\n","stats_file = \"/content/drive/MyDrive/CS6787 - Final Project/Google Colab Scripts/Quantization Models/Resnet56 Quantization Stats/resnet56_quant_stats.yaml\"\n","dummy_input = distiller.get_dummy_input(input_shape=model.input_shape)\n","\n","quantizer = quant.PostTrainLinearQuantizer(\n","    deepcopy(model), bits_activations=16, bits_parameters=16, mode=quant_mode,\n","    model_activation_stats=stats_file, overrides=None\n",")\n","quantizer.prepare_model(dummy_input)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/"},"id":"qhNg990C8tE-","executionInfo":{"elapsed":581,"status":"ok","timestamp":1607492377207,"user":{"displayName":"Jeremy Wang","photoUrl":"","userId":"16277065741529505083"},"user_tz":300},"outputId":"e283473f-6c20-46ba-88e2-dfe7e96a83f2"},"source":["print(type(quantizer.model))\n","quantizer.model"],"execution_count":null,"outputs":[{"output_type":"stream","text":["<class 'torch.nn.parallel.data_parallel.DataParallel'>\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"2uy9nqvN9Zq-","executionInfo":{"elapsed":3765,"status":"ok","timestamp":1607492442195,"user":{"displayName":"Jeremy Wang","photoUrl":"","userId":"16277065741529505083"},"user_tz":300},"outputId":"8c34df17-326e-4b23-ff39-7d15a7a1770c"},"source":["type(model)\n","Checkpoint = torch.load(pather)\n","Checkpoint"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["{'arch': 'resnet56_cifar',\n"," 'compression_sched': {'masks_dict': {'module.bn1.bias': None,\n","   'module.bn1.weight': None,\n","   'module.conv1.weight': None,\n","   'module.fc.bias': None,\n","   'module.fc.weight': None,\n","   'module.layer1.0.bn1.bias': None,\n","   'module.layer1.0.bn1.weight': None,\n","   'module.layer1.0.bn2.bias': None,\n","   'module.layer1.0.bn2.weight': None,\n","   'module.layer1.0.conv1.weight': None,\n","   'module.layer1.0.conv2.weight': None,\n","   'module.layer1.1.bn1.bias': None,\n","   'module.layer1.1.bn1.weight': None,\n","   'module.layer1.1.bn2.bias': None,\n","   'module.layer1.1.bn2.weight': None,\n","   'module.layer1.1.conv1.weight': None,\n","   'module.layer1.1.conv2.weight': None,\n","   'module.layer1.2.bn1.bias': None,\n","   'module.layer1.2.bn1.weight': None,\n","   'module.layer1.2.bn2.bias': None,\n","   'module.layer1.2.bn2.weight': None,\n","   'module.layer1.2.conv1.weight': None,\n","   'module.layer1.2.conv2.weight': None,\n","   'module.layer1.3.bn1.bias': None,\n","   'module.layer1.3.bn1.weight': None,\n","   'module.layer1.3.bn2.bias': None,\n","   'module.layer1.3.bn2.weight': None,\n","   'module.layer1.3.conv1.weight': None,\n","   'module.layer1.3.conv2.weight': None,\n","   'module.layer1.4.bn1.bias': None,\n","   'module.layer1.4.bn1.weight': None,\n","   'module.layer1.4.bn2.bias': None,\n","   'module.layer1.4.bn2.weight': None,\n","   'module.layer1.4.conv1.weight': None,\n","   'module.layer1.4.conv2.weight': None,\n","   'module.layer1.5.bn1.bias': None,\n","   'module.layer1.5.bn1.weight': None,\n","   'module.layer1.5.bn2.bias': None,\n","   'module.layer1.5.bn2.weight': None,\n","   'module.layer1.5.conv1.weight': None,\n","   'module.layer1.5.conv2.weight': None,\n","   'module.layer1.6.bn1.bias': None,\n","   'module.layer1.6.bn1.weight': None,\n","   'module.layer1.6.bn2.bias': None,\n","   'module.layer1.6.bn2.weight': None,\n","   'module.layer1.6.conv1.weight': None,\n","   'module.layer1.6.conv2.weight': None,\n","   'module.layer1.7.bn1.bias': None,\n","   'module.layer1.7.bn1.weight': None,\n","   'module.layer1.7.bn2.bias': None,\n","   'module.layer1.7.bn2.weight': None,\n","   'module.layer1.7.conv1.weight': None,\n","   'module.layer1.7.conv2.weight': None,\n","   'module.layer1.8.bn1.bias': None,\n","   'module.layer1.8.bn1.weight': None,\n","   'module.layer1.8.bn2.bias': None,\n","   'module.layer1.8.bn2.weight': None,\n","   'module.layer1.8.conv1.weight': None,\n","   'module.layer1.8.conv2.weight': None,\n","   'module.layer2.0.bn1.bias': None,\n","   'module.layer2.0.bn1.weight': None,\n","   'module.layer2.0.bn2.bias': None,\n","   'module.layer2.0.bn2.weight': None,\n","   'module.layer2.0.conv1.weight': None,\n","   'module.layer2.0.conv2.weight': None,\n","   'module.layer2.0.downsample.0.weight': None,\n","   'module.layer2.0.downsample.1.bias': None,\n","   'module.layer2.0.downsample.1.weight': None,\n","   'module.layer2.1.bn1.bias': None,\n","   'module.layer2.1.bn1.weight': None,\n","   'module.layer2.1.bn2.bias': None,\n","   'module.layer2.1.bn2.weight': None,\n","   'module.layer2.1.conv1.weight': None,\n","   'module.layer2.1.conv2.weight': None,\n","   'module.layer2.2.bn1.bias': None,\n","   'module.layer2.2.bn1.weight': None,\n","   'module.layer2.2.bn2.bias': None,\n","   'module.layer2.2.bn2.weight': None,\n","   'module.layer2.2.conv1.weight': None,\n","   'module.layer2.2.conv2.weight': None,\n","   'module.layer2.3.bn1.bias': None,\n","   'module.layer2.3.bn1.weight': None,\n","   'module.layer2.3.bn2.bias': None,\n","   'module.layer2.3.bn2.weight': None,\n","   'module.layer2.3.conv1.weight': None,\n","   'module.layer2.3.conv2.weight': None,\n","   'module.layer2.4.bn1.bias': None,\n","   'module.layer2.4.bn1.weight': None,\n","   'module.layer2.4.bn2.bias': None,\n","   'module.layer2.4.bn2.weight': None,\n","   'module.layer2.4.conv1.weight': None,\n","   'module.layer2.4.conv2.weight': None,\n","   'module.layer2.5.bn1.bias': None,\n","   'module.layer2.5.bn1.weight': None,\n","   'module.layer2.5.bn2.bias': None,\n","   'module.layer2.5.bn2.weight': None,\n","   'module.layer2.5.conv1.weight': None,\n","   'module.layer2.5.conv2.weight': None,\n","   'module.layer2.6.bn1.bias': None,\n","   'module.layer2.6.bn1.weight': None,\n","   'module.layer2.6.bn2.bias': None,\n","   'module.layer2.6.bn2.weight': None,\n","   'module.layer2.6.conv1.weight': None,\n","   'module.layer2.6.conv2.weight': None,\n","   'module.layer2.7.bn1.bias': None,\n","   'module.layer2.7.bn1.weight': None,\n","   'module.layer2.7.bn2.bias': None,\n","   'module.layer2.7.bn2.weight': None,\n","   'module.layer2.7.conv1.weight': None,\n","   'module.layer2.7.conv2.weight': None,\n","   'module.layer2.8.bn1.bias': None,\n","   'module.layer2.8.bn1.weight': None,\n","   'module.layer2.8.bn2.bias': None,\n","   'module.layer2.8.bn2.weight': None,\n","   'module.layer2.8.conv1.weight': None,\n","   'module.layer2.8.conv2.weight': None,\n","   'module.layer3.0.bn1.bias': None,\n","   'module.layer3.0.bn1.weight': None,\n","   'module.layer3.0.bn2.bias': None,\n","   'module.layer3.0.bn2.weight': None,\n","   'module.layer3.0.conv1.weight': None,\n","   'module.layer3.0.conv2.weight': None,\n","   'module.layer3.0.downsample.0.weight': None,\n","   'module.layer3.0.downsample.1.bias': None,\n","   'module.layer3.0.downsample.1.weight': None,\n","   'module.layer3.1.bn1.bias': None,\n","   'module.layer3.1.bn1.weight': None,\n","   'module.layer3.1.bn2.bias': None,\n","   'module.layer3.1.bn2.weight': None,\n","   'module.layer3.1.conv1.weight': None,\n","   'module.layer3.1.conv2.weight': None,\n","   'module.layer3.2.bn1.bias': None,\n","   'module.layer3.2.bn1.weight': None,\n","   'module.layer3.2.bn2.bias': None,\n","   'module.layer3.2.bn2.weight': None,\n","   'module.layer3.2.conv1.weight': None,\n","   'module.layer3.2.conv2.weight': None,\n","   'module.layer3.3.bn1.bias': None,\n","   'module.layer3.3.bn1.weight': None,\n","   'module.layer3.3.bn2.bias': None,\n","   'module.layer3.3.bn2.weight': None,\n","   'module.layer3.3.conv1.weight': None,\n","   'module.layer3.3.conv2.weight': None,\n","   'module.layer3.4.bn1.bias': None,\n","   'module.layer3.4.bn1.weight': None,\n","   'module.layer3.4.bn2.bias': None,\n","   'module.layer3.4.bn2.weight': None,\n","   'module.layer3.4.conv1.weight': None,\n","   'module.layer3.4.conv2.weight': None,\n","   'module.layer3.5.bn1.bias': None,\n","   'module.layer3.5.bn1.weight': None,\n","   'module.layer3.5.bn2.bias': None,\n","   'module.layer3.5.bn2.weight': None,\n","   'module.layer3.5.conv1.weight': None,\n","   'module.layer3.5.conv2.weight': None,\n","   'module.layer3.6.bn1.bias': None,\n","   'module.layer3.6.bn1.weight': None,\n","   'module.layer3.6.bn2.bias': None,\n","   'module.layer3.6.bn2.weight': None,\n","   'module.layer3.6.conv1.weight': None,\n","   'module.layer3.6.conv2.weight': None,\n","   'module.layer3.7.bn1.bias': None,\n","   'module.layer3.7.bn1.weight': None,\n","   'module.layer3.7.bn2.bias': None,\n","   'module.layer3.7.bn2.weight': None,\n","   'module.layer3.7.conv1.weight': None,\n","   'module.layer3.7.conv2.weight': None,\n","   'module.layer3.8.bn1.bias': None,\n","   'module.layer3.8.bn1.weight': None,\n","   'module.layer3.8.bn2.bias': None,\n","   'module.layer3.8.bn2.weight': None,\n","   'module.layer3.8.conv1.weight': None,\n","   'module.layer3.8.conv2.weight': None}},\n"," 'dataset': 'cifar10',\n"," 'epoch': 0,\n"," 'extras': {'quantized_top1': 31.130000000000003},\n"," 'is_parallel': True,\n"," 'quantizer_metadata': {'dummy_input': tensor([[[[-1.1258, -1.1524, -0.2506,  ...,  1.5863,  0.9463, -0.8437],\n","            [-0.6136,  0.0316, -0.4927,  ..., -1.2341,  1.8197, -0.5515],\n","            [-0.5692,  0.9200,  1.1108,  ..., -0.9565,  0.0335,  0.7101],\n","            ...,\n","            [ 1.0166,  1.2868,  2.0820,  ...,  0.8161, -0.5711, -0.1195],\n","            [-0.4274,  0.8143, -1.4121,  ..., -0.1394, -0.3677, -0.4574],\n","            [-1.2945,  0.7012, -1.9098,  ...,  0.5374,  1.0826, -1.7105]],\n","  \n","           [[-1.0841, -0.1287, -0.6811,  ..., -0.9825,  0.7184,  0.4402],\n","            [-0.5619,  0.6640, -2.1033,  ..., -0.7821, -2.1407,  0.3337],\n","            [-1.1230,  0.6210, -0.8764,  ...,  0.9159,  0.2990,  0.1771],\n","            ...,\n","            [ 2.2746, -0.9119,  0.5105,  ...,  0.4876, -0.9265, -0.5748],\n","            [ 0.7300, -0.9287,  0.1743,  ..., -0.7073, -0.8813, -0.5895],\n","            [-0.8363, -1.8354,  0.4765,  ..., -0.3812, -1.6687,  1.0869]],\n","  \n","           [[ 0.6657,  0.8847,  0.4671,  ...,  0.7709, -0.8416,  1.7962],\n","            [ 0.1924, -0.1777,  0.3214,  ..., -1.1616, -0.5921,  0.7457],\n","            [-1.1870, -0.8221,  0.6051,  ..., -0.1906,  0.2511,  1.3542],\n","            ...,\n","            [ 1.9324, -0.5826, -1.3121,  ...,  0.2871,  0.2620, -0.3582],\n","            [ 2.8424, -0.6401, -0.5874,  ...,  0.4994, -1.5602,  1.1315],\n","            [-0.0504,  0.5482, -1.2351,  ..., -0.6380, -1.1714, -0.8415]]]]),\n","  'params': {'bits_accum': 32,\n","   'bits_activations': 16,\n","   'bits_parameters': 16,\n","   'clip_acts': 'AVG',\n","   'clip_half_range': False,\n","   'clip_n_stds': None,\n","   'fpq_module': None,\n","   'inputs_quant_auto_fallback': True,\n","   'mode': {'activations': 'ASYMMETRIC_UNSIGNED',\n","    'weights': 'ASYMMETRIC_UNSIGNED'},\n","   'model_activation_stats': OrderedDict([('conv1',\n","                 OrderedDict([('inputs',\n","                               OrderedDict([(0,\n","                                             OrderedDict([('min',\n","                                                           -2.429065704345703),\n","                                                          ('max',\n","                                                           2.7537312507629395),\n","                                                          ('avg_min',\n","                                                           -2.1499393680356342),\n","                                                          ('avg_max',\n","                                                           2.345301193845234),\n","                                                          ('mean',\n","                                                           0.05572440083821614),\n","                                                          ('std',\n","                                                           1.2528250303376864),\n","                                                          ('b',\n","                                                           1.042791483561198),\n","                                                          ('shape',\n","                                                           '(128, 3, 32, 32)'),\n","                                                          ('total_numel',\n","                                                           1536000)]))])),\n","                              ('output',\n","                               OrderedDict([('min', 0.0),\n","                                            ('max', 9.178403854370117),\n","                                            ('avg_min', 0.0),\n","                                            ('avg_max', 5.7127441558664005),\n","                                            ('mean', 0.5234575347900391),\n","                                            ('std', 0.9850459875225013),\n","                                            ('b', 0.7439887542724609),\n","                                            ('shape', '(128, 16, 32, 32)'),\n","                                            ('total_numel', 8192000)]))])),\n","                ('relu',\n","                 OrderedDict([('inputs',\n","                               OrderedDict([(0,\n","                                             OrderedDict([('min', 0.0),\n","                                                          ('max',\n","                                                           9.178403854370117),\n","                                                          ('avg_min', 0.0),\n","                                                          ('avg_max',\n","                                                           5.7127441558664005),\n","                                                          ('mean',\n","                                                           0.5234575347900391),\n","                                                          ('std',\n","                                                           0.9850459875225013),\n","                                                          ('b',\n","                                                           0.7439887542724609),\n","                                                          ('shape',\n","                                                           '(128, 16, 32, 32)'),\n","                                                          ('total_numel',\n","                                                           8192000)]))])),\n","                              ('output',\n","                               OrderedDict([('min', 0.0),\n","                                            ('max', 9.178403854370117),\n","                                            ('avg_min', 0.0),\n","                                            ('avg_max', 5.7127441558664005),\n","                                            ('mean', 0.5926739044189453),\n","                                            ('std', 0.8964987488635259),\n","                                            ('b', 0.6949969482421875),\n","                                            ('shape', '(128, 16, 32, 32)'),\n","                                            ('total_numel', 8192000)]))])),\n","                ('layer1.0.conv1',\n","                 OrderedDict([('inputs',\n","                               OrderedDict([(0,\n","                                             OrderedDict([('min', 0.0),\n","                                                          ('max',\n","                                                           9.178403854370117),\n","                                                          ('avg_min', 0.0),\n","                                                          ('avg_max',\n","                                                           5.7127441558664005),\n","                                                          ('mean',\n","                                                           0.5926739044189453),\n","                                                          ('std',\n","                                                           0.8964987488635259),\n","                                                          ('b',\n","                                                           0.6949969482421875),\n","                                                          ('shape',\n","                                                           '(128, 16, 32, 32)'),\n","                                                          ('total_numel',\n","                                                           8192000)]))])),\n","                              ('output',\n","                               OrderedDict([('min', 0.0),\n","                                            ('max', 4.388464450836182),\n","                                            ('avg_min', 0.0),\n","                                            ('avg_max', 1.5130452030799466),\n","                                            ('mean', -0.054349534034729),\n","                                            ('std', 0.48831761973924587),\n","                                            ('b', 0.3468094024658203),\n","                                            ('shape', '(128, 16, 32, 32)'),\n","                                            ('total_numel', 8192000)]))])),\n","                ('layer1.0.relu1',\n","                 OrderedDict([('inputs',\n","                               OrderedDict([(0,\n","                                             OrderedDict([('min', 0.0),\n","                                                          ('max',\n","                                                           4.388464450836182),\n","                                                          ('avg_min', 0.0),\n","                                                          ('avg_max',\n","                                                           1.5130452030799466),\n","                                                          ('mean',\n","                                                           -0.054349534034729),\n","                                                          ('std',\n","                                                           0.48831761973924587),\n","                                                          ('b',\n","                                                           0.3468094024658203),\n","                                                          ('shape',\n","                                                           '(128, 16, 32, 32)'),\n","                                                          ('total_numel',\n","                                                           8192000)]))])),\n","                              ('output',\n","                               OrderedDict([('min', 0.0),\n","                                            ('max', 4.388464450836182),\n","                                            ('avg_min', 0.0),\n","                                            ('avg_max', 1.5130452030799466),\n","                                            ('mean', 0.1406961555480957),\n","                                            ('std', 0.24311054373079644),\n","                                            ('b', 0.17877099227905274),\n","                                            ('shape', '(128, 16, 32, 32)'),\n","                                            ('total_numel', 8192000)]))])),\n","                ('layer1.0.conv2',\n","                 OrderedDict([('inputs',\n","                               OrderedDict([(0,\n","                                             OrderedDict([('min', 0.0),\n","                                                          ('max',\n","                                                           4.388464450836182),\n","                                                          ('avg_min', 0.0),\n","                                                          ('avg_max',\n","                                                           1.5130452030799466),\n","                                                          ('mean',\n","                                                           0.1406961555480957),\n","                                                          ('std',\n","                                                           0.24311054373079644),\n","                                                          ('b',\n","                                                           0.17877099227905274),\n","                                                          ('shape',\n","                                                           '(128, 16, 32, 32)'),\n","                                                          ('total_numel',\n","                                                           8192000)]))])),\n","                              ('output',\n","                               OrderedDict([('min', -4.469544410705566),\n","                                            ('max', 4.414111137390137),\n","                                            ('avg_min', -1.2167726695774779),\n","                                            ('avg_max', 1.6593308779467322),\n","                                            ('mean', 0.0756761074066162),\n","                                            ('std', 0.3172251741932972),\n","                                            ('b', 0.20862440490722656),\n","                                            ('shape', '(128, 16, 32, 32)'),\n","                                            ('total_numel', 8192000)]))])),\n","                ('layer1.0.relu2',\n","                 OrderedDict([('inputs',\n","                               OrderedDict([(0,\n","                                             OrderedDict([('min', 0.0),\n","                                                          ('max',\n","                                                           10.118114471435547),\n","                                                          ('avg_min', 0.0),\n","                                                          ('avg_max',\n","                                                           6.065974079032025),\n","                                                          ('mean',\n","                                                           0.6683500213623047),\n","                                                          ('std',\n","                                                           0.9374112425432524),\n","                                                          ('b',\n","                                                           0.7084393310546875),\n","                                                          ('shape',\n","                                                           '(128, 16, 32, 32)'),\n","                                                          ('total_numel',\n","                                                           8192000)]))])),\n","                              ('output',\n","                               OrderedDict([('min', 0.0),\n","                                            ('max', 10.118114471435547),\n","                                            ('avg_min', 0.0),\n","                                            ('avg_max', 6.065974079032025),\n","                                            ('mean', 0.7011815795898437),\n","                                            ('std', 0.904465469232618),\n","                                            ('b', 0.6843060302734375),\n","                                            ('shape', '(128, 16, 32, 32)'),\n","                                            ('total_numel', 8192000)]))])),\n","                ('layer1.0.residual_eltwiseadd',\n","                 OrderedDict([('inputs',\n","                               OrderedDict([(0,\n","                                             OrderedDict([('min', 0.0),\n","                                                          ('max',\n","                                                           9.178403854370117),\n","                                                          ('avg_min', 0.0),\n","                                                          ('avg_max',\n","                                                           5.7127441558664005),\n","                                                          ('mean',\n","                                                           0.5926739044189453),\n","                                                          ('std',\n","                                                           0.8964987488635259),\n","                                                          ('b',\n","                                                           0.6949969482421875),\n","                                                          ('shape',\n","                                                           '(128, 16, 32, 32)'),\n","                                                          ('total_numel',\n","                                                           8192000)])),\n","                                            (1,\n","                                             OrderedDict([('min',\n","                                                           -4.469544410705566),\n","                                                          ('max',\n","                                                           4.414111137390137),\n","                                                          ('avg_min',\n","                                                           -1.2167726695774779),\n","                                                          ('avg_max',\n","                                                           1.6593308779467322),\n","                                                          ('mean',\n","                                                           0.0756761074066162),\n","                                                          ('std',\n","                                                           0.3172251741932972),\n","                                                          ('b',\n","                                                           0.20862440490722656),\n","                                                          ('shape',\n","                                                           '(128, 16, 32, 32)'),\n","                                                          ('total_numel',\n","                                                           8192000)]))])),\n","                              ('output',\n","                               OrderedDict([('min', 0.0),\n","                                            ('max', 10.118114471435547),\n","                                            ('avg_min', 0.0),\n","                                            ('avg_max', 6.065974079032025),\n","                                            ('mean', 0.6683500213623047),\n","                                            ('std', 0.9374112425432524),\n","                                            ('b', 0.7084393310546875),\n","                                            ('shape', '(128, 16, 32, 32)'),\n","                                            ('total_numel', 8192000)]))])),\n","                ('layer1.1.conv1',\n","                 OrderedDict([('inputs',\n","                               OrderedDict([(0,\n","                                             OrderedDict([('min', 0.0),\n","                                                          ('max',\n","                                                           10.118114471435547),\n","                                                          ('avg_min', 0.0),\n","                                                          ('avg_max',\n","                                                           6.065974079032025),\n","                                                          ('mean',\n","                                                           0.7011815795898437),\n","                                                          ('std',\n","                                                           0.904465469232618),\n","                                                          ('b',\n","                                                           0.6843060302734375),\n","                                                          ('shape',\n","                                                           '(128, 16, 32, 32)'),\n","                                                          ('total_numel',\n","                                                           8192000)]))])),\n","                              ('output',\n","                               OrderedDict([('min', 0.0),\n","                                            ('max', 5.364534378051758),\n","                                            ('avg_min', 0.0),\n","                                            ('avg_max', 3.263419783734336),\n","                                            ('mean', 0.21356946563720702),\n","                                            ('std', 0.5524188656159191),\n","                                            ('b', 0.41735400390625),\n","                                            ('shape', '(128, 16, 32, 32)'),\n","                                            ('total_numel', 8192000)]))])),\n","                ('layer1.1.relu1',\n","                 OrderedDict([('inputs',\n","                               OrderedDict([(0,\n","                                             OrderedDict([('min', 0.0),\n","                                                          ('max',\n","                                                           5.364534378051758),\n","                                                          ('avg_min', 0.0),\n","                                                          ('avg_max',\n","                                                           3.263419783734336),\n","                                                          ('mean',\n","                                                           0.21356946563720702),\n","                                                          ('std',\n","                                                           0.5524188656159191),\n","                                                          ('b',\n","                                                           0.41735400390625),\n","                                                          ('shape',\n","                                                           '(128, 16, 32, 32)'),\n","                                                          ('total_numel',\n","                                                           8192000)]))])),\n","                              ('output',\n","                               OrderedDict([('min', 0.0),\n","                                            ('max', 5.364534378051758),\n","                                            ('avg_min', 0.0),\n","                                            ('avg_max', 3.263419783734336),\n","                                            ('mean', 0.3203838806152344),\n","                                            ('std', 0.41604692883984895),\n","                                            ('b', 0.3289120941162109),\n","                                            ('shape', '(128, 16, 32, 32)'),\n","                                            ('total_numel', 8192000)]))])),\n","                ('layer1.1.conv2',\n","                 OrderedDict([('inputs',\n","                               OrderedDict([(0,\n","                                             OrderedDict([('min', 0.0),\n","                                                          ('max',\n","                                                           5.364534378051758),\n","                                                          ('avg_min', 0.0),\n","                                                          ('avg_max',\n","                                                           3.263419783734336),\n","                                                          ('mean',\n","                                                           0.3203838806152344),\n","                                                          ('std',\n","                                                           0.41604692883984895),\n","                                                          ('b',\n","                                                           0.3289120941162109),\n","                                                          ('shape',\n","                                                           '(128, 16, 32, 32)'),\n","                                                          ('total_numel',\n","                                                           8192000)]))])),\n","                              ('output',\n","                               OrderedDict([('min', -8.348672866821289),\n","                                            ('max', 6.429137706756592),\n","                                            ('avg_min', -4.702761710144826),\n","                                            ('avg_max', 4.144659233072849),\n","                                            ('mean', 0.03326963949203491),\n","                                            ('std', 0.5523889987653912),\n","                                            ('b', 0.36565818786621096),\n","                                            ('shape', '(128, 16, 32, 32)'),\n","                                            ('total_numel', 8192000)]))])),\n","                ('layer1.1.relu2',\n","                 OrderedDict([('inputs',\n","                               OrderedDict([(0,\n","                                             OrderedDict([('min', 0.0),\n","                                                          ('max',\n","                                                           15.045554161071777),\n","                                                          ('avg_min', 0.0),\n","                                                          ('avg_max',\n","                                                           8.767028777579993),\n","                                                          ('mean',\n","                                                           0.7344512176513672),\n","                                                          ('std',\n","                                                           1.2114181379809768),\n","                                                          ('b',\n","                                                           0.8987533721923828),\n","                                                          ('shape',\n","                                                           '(128, 16, 32, 32)'),\n","                                                          ('total_numel',\n","                                                           8192000)]))])),\n","                              ('output',\n","                               OrderedDict([('min', 0.0),\n","                                            ('max', 15.045554161071777),\n","                                            ('avg_min', 0.0),\n","                                            ('avg_max', 8.767028777579993),\n","                                            ('mean', 0.8139702301025391),\n","                                            ('std', 1.1308279086727577),\n","                                            ('b', 0.8402274169921875),\n","                                            ('shape', '(128, 16, 32, 32)'),\n","                                            ('total_numel', 8192000)]))])),\n","                ('layer1.1.residual_eltwiseadd',\n","                 OrderedDict([('inputs',\n","                               OrderedDict([(0,\n","                                             OrderedDict([('min', 0.0),\n","                                                          ('max',\n","                                                           10.118114471435547),\n","                                                          ('avg_min', 0.0),\n","                                                          ('avg_max',\n","                                                           6.065974079032025),\n","                                                          ('mean',\n","                                                           0.7011815795898437),\n","                                                          ('std',\n","                                                           0.904465469232618),\n","                                                          ('b',\n","                                                           0.6843060302734375),\n","                                                          ('shape',\n","                                                           '(128, 16, 32, 32)'),\n","                                                          ('total_numel',\n","                                                           8192000)])),\n","                                            (1,\n","                                             OrderedDict([('min',\n","                                                           -8.348672866821289),\n","                                                          ('max',\n","                                                           6.429137706756592),\n","                                                          ('avg_min',\n","                                                           -4.702761710144826),\n","                                                          ('avg_max',\n","                                                           4.144659233072849),\n","                                                          ('mean',\n","                                                           0.03326963949203491),\n","                                                          ('std',\n","                                                           0.5523889987653912),\n","                                                          ('b',\n","                                                           0.36565818786621096),\n","                                                          ('shape',\n","                                                           '(128, 16, 32, 32)'),\n","                                                          ('total_numel',\n","                                                           8192000)]))])),\n","                              ('output',\n","                               OrderedDict([('min', 0.0),\n","                                            ('max', 15.045554161071777),\n","                                            ('avg_min', 0.0),\n","                                            ('avg_max', 8.767028777579993),\n","                                            ('mean', 0.7344512176513672),\n","                                            ('std', 1.2114181379809768),\n","                                            ('b', 0.8987533721923828),\n","                                            ('shape', '(128, 16, 32, 32)'),\n","                                            ('total_numel', 8192000)]))])),\n","                ('layer1.2.conv1',\n","                 OrderedDict([('inputs',\n","                               OrderedDict([(0,\n","                                             OrderedDict([('min', 0.0),\n","                                                          ('max',\n","                                                           15.045554161071777),\n","                                                          ('avg_min', 0.0),\n","                                                          ('avg_max',\n","                                                           8.767028777579993),\n","                                                          ('mean',\n","                                                           0.8139702301025391),\n","                                                          ('std',\n","                                                           1.1308279086727577),\n","                                                          ('b',\n","                                                           0.8402274169921875),\n","                                                          ('shape',\n","                                                           '(128, 16, 32, 32)'),\n","                                                          ('total_numel',\n","                                                           8192000)]))])),\n","                              ('output',\n","                               OrderedDict([('min', 0.0),\n","                                            ('max', 4.246656894683838),\n","                                            ('avg_min', 0.0),\n","                                            ('avg_max', 2.2381935419572727),\n","                                            ('mean', -0.18785368728637694),\n","                                            ('std', 0.4280728006213849),\n","                                            ('b', 0.31988773345947263),\n","                                            ('shape', '(128, 16, 32, 32)'),\n","                                            ('total_numel', 8192000)]))])),\n","                ('layer1.2.relu1',\n","                 OrderedDict([('inputs',\n","                               OrderedDict([(0,\n","                                             OrderedDict([('min', 0.0),\n","                                                          ('max',\n","                                                           4.246656894683838),\n","                                                          ('avg_min', 0.0),\n","                                                          ('avg_max',\n","                                                           2.2381935419572727),\n","                                                          ('mean',\n","                                                           -0.18785368728637694),\n","                                                          ('std',\n","                                                           0.4280728006213849),\n","                                                          ('b',\n","                                                           0.31988773345947263),\n","                                                          ('shape',\n","                                                           '(128, 16, 32, 32)'),\n","                                                          ('total_numel',\n","                                                           8192000)]))])),\n","                              ('output',\n","                               OrderedDict([('min', 0.0),\n","                                            ('max', 4.246656894683838),\n","                                            ('avg_min', 0.0),\n","                                            ('avg_max', 2.2381935419572727),\n","                                            ('mean', 0.056560070037841796),\n","                                            ('std', 0.15729415066338692),\n","                                            ('b', 0.08739840126037597),\n","                                            ('shape', '(128, 16, 32, 32)'),\n","                                            ('total_numel', 8192000)]))])),\n","                ('layer1.2.conv2',\n","                 OrderedDict([('inputs',\n","                               OrderedDict([(0,\n","                                             OrderedDict([('min', 0.0),\n","                                                          ('max',\n","                                                           4.246656894683838),\n","                                                          ('avg_min', 0.0),\n","                                                          ('avg_max',\n","                                                           2.2381935419572727),\n","                                                          ('mean',\n","                                                           0.056560070037841796),\n","                                                          ('std',\n","                                                           0.15729415066338692),\n","                                                          ('b',\n","                                                           0.08739840126037597),\n","                                                          ('shape',\n","                                                           '(128, 16, 32, 32)'),\n","                                                          ('total_numel',\n","                                                           8192000)]))])),\n","                              ('output',\n","                               OrderedDict([('min', -6.089637279510498),\n","                                            ('max', 3.1322929859161377),\n","                                            ('avg_min', -2.9296466503409726),\n","                                            ('avg_max', 2.17678893550263),\n","                                            ('mean', 0.056571070671081546),\n","                                            ('std', 0.4294431744998536),\n","                                            ('b', 0.2985485534667969),\n","                                            ('shape', '(128, 16, 32, 32)'),\n","                                            ('total_numel', 8192000)]))])),\n","                ('layer1.2.relu2',\n","                 OrderedDict([('inputs',\n","                               OrderedDict([(0,\n","                                             OrderedDict([('min', 0.0),\n","                                                          ('max',\n","                                                           15.097047805786133),\n","                                                          ('avg_min', 0.0),\n","                                                          ('avg_max',\n","                                                           8.838496635733737),\n","                                                          ('mean',\n","                                                           0.8705413055419922),\n","                                                          ('std',\n","                                                           1.211174359395633),\n","                                                          ('b',\n","                                                           0.9096901092529297),\n","                                                          ('shape',\n","                                                           '(128, 16, 32, 32)'),\n","                                                          ('total_numel',\n","                                                           8192000)]))])),\n","                              ('output',\n","                               OrderedDict([('min', 0.0),\n","                                            ('max', 15.097047805786133),\n","                                            ('avg_min', 0.0),\n","                                            ('avg_max', 8.838496635733737),\n","                                            ('mean', 0.9450883483886718),\n","                                            ('std', 1.1330231754528597),\n","                                            ('b', 0.851558364868164),\n","                                            ('shape', '(128, 16, 32, 32)'),\n","                                            ('total_numel', 8192000)]))])),\n","                ('layer1.2.residual_eltwiseadd',\n","                 OrderedDict([('inputs',\n","                               OrderedDict([(0,\n","                                             OrderedDict([('min', 0.0),\n","                                                          ('max',\n","                                                           15.045554161071777),\n","                                                          ('avg_min', 0.0),\n","                                                          ('avg_max',\n","                                                           8.767028777579993),\n","                                                          ('mean',\n","                                                           0.8139702301025391),\n","                                                          ('std',\n","                                                           1.1308279086727577),\n","                                                          ('b',\n","                                                           0.8402274169921875),\n","                                                          ('shape',\n","                                                           '(128, 16, 32, 32)'),\n","                                                          ('total_numel',\n","                                                           8192000)])),\n","                                            (1,\n","                                             OrderedDict([('min',\n","                                                           -6.089637279510498),\n","                                                          ('max',\n","                                                           3.1322929859161377),\n","                                                          ('avg_min',\n","                                                           -2.9296466503409726),\n","                                                          ('avg_max',\n","                                                           2.17678893550263),\n","                                                          ('mean',\n","                                                           0.056571070671081546),\n","                                                          ('std',\n","                                                           0.4294431744998536),\n","                                                          ('b',\n","                                                           0.2985485534667969),\n","                                                          ('shape',\n","                                                           '(128, 16, 32, 32)'),\n","                                                          ('total_numel',\n","                                                           8192000)]))])),\n","                              ('output',\n","                               OrderedDict([('min', 0.0),\n","                                            ('max', 15.097047805786133),\n","                                            ('avg_min', 0.0),\n","                                            ('avg_max', 8.838496635733737),\n","                                            ('mean', 0.8705413055419922),\n","                                            ('std', 1.211174359395633),\n","                                            ('b', 0.9096901092529297),\n","                                            ('shape', '(128, 16, 32, 32)'),\n","                                            ('total_numel', 8192000)]))])),\n","                ('layer1.3.conv1',\n","                 OrderedDict([('inputs',\n","                               OrderedDict([(0,\n","                                             OrderedDict([('min', 0.0),\n","                                                          ('max',\n","                                                           15.097047805786133),\n","                                                          ('avg_min', 0.0),\n","                                                          ('avg_max',\n","                                                           8.838496635733737),\n","                                                          ('mean',\n","                                                           0.9450883483886718),\n","                                                          ('std',\n","                                                           1.1330231754528597),\n","                                                          ('b',\n","                                                           0.851558364868164),\n","                                                          ('shape',\n","                                                           '(128, 16, 32, 32)'),\n","                                                          ('total_numel',\n","                                                           8192000)]))])),\n","                              ('output',\n","                               OrderedDict([('min', 0.0),\n","                                            ('max', 3.1953351497650146),\n","                                            ('avg_min', 0.0),\n","                                            ('avg_max', 1.4293199275483957),\n","                                            ('mean', -0.030617967128753663),\n","                                            ('std', 0.283555347375119),\n","                                            ('b', 0.17355757904052735),\n","                                            ('shape', '(128, 16, 32, 32)'),\n","                                            ('total_numel', 8192000)]))])),\n","                ('layer1.3.relu1',\n","                 OrderedDict([('inputs',\n","                               OrderedDict([(0,\n","                                             OrderedDict([('min', 0.0),\n","                                                          ('max',\n","                                                           3.1953351497650146),\n","                                                          ('avg_min', 0.0),\n","                                                          ('avg_max',\n","                                                           1.4293199275483957),\n","                                                          ('mean',\n","                                                           -0.030617967128753663),\n","                                                          ('std',\n","                                                           0.283555347375119),\n","                                                          ('b',\n","                                                           0.17355757904052735),\n","                                                          ('shape',\n","                                                           '(128, 16, 32, 32)'),\n","                                                          ('total_numel',\n","                                                           8192000)]))])),\n","                              ('output',\n","                               OrderedDict([('min', 0.0),\n","                                            ('max', 3.1953351497650146),\n","                                            ('avg_min', 0.0),\n","                                            ('avg_max', 1.4293199275483957),\n","                                            ('mean', 0.06611821937561035),\n","                                            ('std', 0.1457127021321497),\n","                                            ('b', 0.09546630096435547),\n","                                            ('shape', '(128, 16, 32, 32)'),\n","                                            ('total_numel', 8192000)]))])),\n","                ('layer1.3.conv2',\n","                 OrderedDict([('inputs',\n","                               OrderedDict([(0,\n","                                             OrderedDict([('min', 0.0),\n","                                                          ('max',\n","                                                           3.1953351497650146),\n","                                                          ('avg_min', 0.0),\n","                                                          ('avg_max',\n","                                                           1.4293199275483957),\n","                                                          ('mean',\n","                                                           0.06611821937561035),\n","                                                          ('std',\n","                                                           0.1457127021321497),\n","                                                          ('b',\n","                                                           0.09546630096435547),\n","                                                          ('shape',\n","                                                           '(128, 16, 32, 32)'),\n","                                                          ('total_numel',\n","                                                           8192000)]))])),\n","                              ('output',\n","                               OrderedDict([('min', -5.881913185119629),\n","                                            ('max', 2.6750829219818115),\n","                                            ('avg_min', -2.046247837127757),\n","                                            ('avg_max', 1.5917225343045023),\n","                                            ('mean', 0.0351709041595459),\n","                                            ('std', 0.2574817917691489),\n","                                            ('b', 0.18438605880737305),\n","                                            ('shape', '(128, 16, 32, 32)'),\n","                                            ('total_numel', 8192000)]))])),\n","                ('layer1.3.relu2',\n","                 OrderedDict([('inputs',\n","                               OrderedDict([(0,\n","                                             OrderedDict([('min', 0.0),\n","                                                          ('max',\n","                                                           15.472352027893066),\n","                                                          ('avg_min', 0.0),\n","                                                          ('avg_max',\n","                                                           8.95355361898459),\n","                                                          ('mean',\n","                                                           0.98025927734375),\n","                                                          ('std',\n","                                                           1.221244867288664),\n","                                                          ('b',\n","                                                           0.9281375274658203),\n","                                                          ('shape',\n","                                                           '(128, 16, 32, 32)'),\n","                                                          ('total_numel',\n","                                                           8192000)]))])),\n","                              ('output',\n","                               OrderedDict([('min', 0.0),\n","                                            ('max', 15.472352027893066),\n","                                            ('avg_min', 0.0),\n","                                            ('avg_max', 8.95355361898459),\n","                                            ('mean', 1.0311958618164063),\n","                                            ('std', 1.1689697972842972),\n","                                            ('b', 0.8878563690185547),\n","                                            ('shape', '(128, 16, 32, 32)'),\n","                                            ('total_numel', 8192000)]))])),\n","                ('layer1.3.residual_eltwiseadd',\n","                 OrderedDict([('inputs',\n","                               OrderedDict([(0,\n","                                             OrderedDict([('min', 0.0),\n","                                                          ('max',\n","                                                           15.097047805786133),\n","                                                          ('avg_min', 0.0),\n","                                                          ('avg_max',\n","                                                           8.838496635733737),\n","                                                          ('mean',\n","                                                           0.9450883483886718),\n","                                                          ('std',\n","                                                           1.1330231754528597),\n","                                                          ('b',\n","                                                           0.851558364868164),\n","                                                          ('shape',\n","                                                           '(128, 16, 32, 32)'),\n","                                                          ('total_numel',\n","                                                           8192000)])),\n","                                            (1,\n","                                             OrderedDict([('min',\n","                                                           -5.881913185119629),\n","                                                          ('max',\n","                                                           2.6750829219818115),\n","                                                          ('avg_min',\n","                                                           -2.046247837127757),\n","                                                          ('avg_max',\n","                                                           1.5917225343045023),\n","                                                          ('mean',\n","                                                           0.0351709041595459),\n","                                                          ('std',\n","                                                           0.2574817917691489),\n","                                                          ('b',\n","                                                           0.18438605880737305),\n","                                                          ('shape',\n","                                                           '(128, 16, 32, 32)'),\n","                                                          ('total_numel',\n","                                                           8192000)]))])),\n","                              ('output',\n","                               OrderedDict([('min', 0.0),\n","                                            ('max', 15.472352027893066),\n","                                            ('avg_min', 0.0),\n","                                            ('avg_max', 8.95355361898459),\n","                                            ('mean', 0.98025927734375),\n","                                            ('std', 1.221244867288664),\n","                                            ('b', 0.9281375274658203),\n","                                            ('shape', '(128, 16, 32, 32)'),\n","                                            ('total_numel', 8192000)]))])),\n","                ('layer1.4.conv1',\n","                 OrderedDict([('inputs',\n","                               OrderedDict([(0,\n","                                             OrderedDict([('min', 0.0),\n","                                                          ('max',\n","                                                           15.472352027893066),\n","                                                          ('avg_min', 0.0),\n","                                                          ('avg_max',\n","                                                           8.95355361898459),\n","                                                          ('mean',\n","                                                           1.0311958618164063),\n","                                                          ('std',\n","                                                           1.1689697972842972),\n","                                                          ('b',\n","                                                           0.8878563690185547),\n","                                                          ('shape',\n","                                                           '(128, 16, 32, 32)'),\n","                                                          ('total_numel',\n","                                                           8192000)]))])),\n","                              ('output',\n","                               OrderedDict([('min', 0.0),\n","                                            ('max', 1.7749849557876587),\n","                                            ('avg_min', 0.0),\n","                                            ('avg_max', 1.0059707518698682),\n","                                            ('mean', -0.19345236206054686),\n","                                            ('std', 0.3694703491868091),\n","                                            ('b', 0.27766545104980467),\n","                                            ('shape', '(128, 16, 32, 32)'),\n","                                            ('total_numel', 8192000)]))])),\n","                ('layer1.4.relu1',\n","                 OrderedDict([('inputs',\n","                               OrderedDict([(0,\n","                                             OrderedDict([('min', 0.0),\n","                                                          ('max',\n","                                                           1.7749849557876587),\n","                                                          ('avg_min', 0.0),\n","                                                          ('avg_max',\n","                                                           1.0059707518698682),\n","                                                          ('mean',\n","                                                           -0.19345236206054686),\n","                                                          ('std',\n","                                                           0.3694703491868091),\n","                                                          ('b',\n","                                                           0.27766545104980467),\n","                                                          ('shape',\n","                                                           '(128, 16, 32, 32)'),\n","                                                          ('total_numel',\n","                                                           8192000)]))])),\n","                              ('output',\n","                               OrderedDict([('min', 0.0),\n","                                            ('max', 1.7749849557876587),\n","                                            ('avg_min', 0.0),\n","                                            ('avg_max', 1.0059707518698682),\n","                                            ('mean', 0.040775038719177245),\n","                                            ('std', 0.10490456353798713),\n","                                            ('b', 0.06462263202667236),\n","                                            ('shape', '(128, 16, 32, 32)'),\n","                                            ('total_numel', 8192000)]))])),\n","                ('layer1.4.conv2',\n","                 OrderedDict([('inputs',\n","                               OrderedDict([(0,\n","                                             OrderedDict([('min', 0.0),\n","                                                          ('max',\n","                                                           1.7749849557876587),\n","                                                          ('avg_min', 0.0),\n","                                                          ('avg_max',\n","                                                           1.0059707518698682),\n","                                                          ('mean',\n","                                                           0.040775038719177245),\n","                                                          ('std',\n","                                                           0.10490456353798713),\n","                                                          ('b',\n","                                                           0.06462263202667236),\n","                                                          ('shape',\n","                                                           '(128, 16, 32, 32)'),\n","                                                          ('total_numel',\n","                                                           8192000)]))])),\n","                              ('output',\n","                               OrderedDict([('min', -2.1464974880218506),\n","                                            ('max', 1.6707055568695068),\n","                                            ('avg_min', -0.7220973796483185),\n","                                            ('avg_max', 0.8383174320392568),\n","                                            ('mean', 0.07678975296020508),\n","                                            ('std', 0.20557908493412824),\n","                                            ('b', 0.16977800750732422),\n","                                            ('shape', '(128, 16, 32, 32)'),\n","                                            ('total_numel', 8192000)]))])),\n","                ('layer1.4.relu2',\n","                 OrderedDict([('inputs',\n","                               OrderedDict([(0,\n","                                             OrderedDict([('min', 0.0),\n","                                                          ('max',\n","                                                           15.401484489440918),\n","                                                          ('avg_min', 0.0),\n","                                                          ('avg_max',\n","                                                           9.231053738626324),\n","                                                          ('mean',\n","                                                           1.107985595703125),\n","                                                          ('std',\n","                                                           1.2274488114446145),\n","                                                          ('b',\n","                                                           0.9427761688232422),\n","                                                          ('shape',\n","                                                           '(128, 16, 32, 32)'),\n","                                                          ('total_numel',\n","                                                           8192000)]))])),\n","                              ('output',\n","                               OrderedDict([('min', 0.0),\n","                                            ('max', 15.401484489440918),\n","                                            ('avg_min', 0.0),\n","                                            ('avg_max', 9.231053738626324),\n","                                            ('mean', 1.142388427734375),\n","                                            ('std', 1.1921386324765122),\n","                                            ('b', 0.914347671508789),\n","                                            ('shape', '(128, 16, 32, 32)'),\n","                                            ('total_numel', 8192000)]))])),\n","                ('layer1.4.residual_eltwiseadd',\n","                 OrderedDict([('inputs',\n","                               OrderedDict([(0,\n","                                             OrderedDict([('min', 0.0),\n","                                                          ('max',\n","                                                           15.472352027893066),\n","                                                          ('avg_min', 0.0),\n","                                                          ('avg_max',\n","                                                           8.95355361898459),\n","                                                          ('mean',\n","                                                           1.0311958618164063),\n","                                                          ('std',\n","                                                           1.1689697972842972),\n","                                                          ('b',\n","                                                           0.8878563690185547),\n","                                                          ('shape',\n","                                                           '(128, 16, 32, 32)'),\n","                                                          ('total_numel',\n","                                                           8192000)])),\n","                                            (1,\n","                                             OrderedDict([('min',\n","                                                           -2.1464974880218506),\n","                                                          ('max',\n","                                                           1.6707055568695068),\n","                                                          ('avg_min',\n","                                                           -0.7220973796483185),\n","                                                          ('avg_max',\n","                                                           0.8383174320392568),\n","                                                          ('mean',\n","                                                           0.07678975296020508),\n","                                                          ('std',\n","                                                           0.20557908493412824),\n","                                                          ('b',\n","                                                           0.16977800750732422),\n","                                                          ('shape',\n","                                                           '(128, 16, 32, 32)'),\n","                                                          ('total_numel',\n","                                                           8192000)]))])),\n","                              ('output',\n","                               OrderedDict([('min', 0.0),\n","                                            ('max', 15.401484489440918),\n","                                            ('avg_min', 0.0),\n","                                            ('avg_max', 9.231053738626324),\n","                                            ('mean', 1.107985595703125),\n","                                            ('std', 1.2274488114446145),\n","                                            ('b', 0.9427761688232422),\n","                                            ('shape', '(128, 16, 32, 32)'),\n","                                            ('total_numel', 8192000)]))])),\n","                ('layer1.5.conv1',\n","                 OrderedDict([('inputs',\n","                               OrderedDict([(0,\n","                                             OrderedDict([('min', 0.0),\n","                                                          ('max',\n","                                                           15.401484489440918),\n","                                                          ('avg_min', 0.0),\n","                                                          ('avg_max',\n","                                                           9.231053738626324),\n","                                                          ('mean',\n","                                                           1.142388427734375),\n","                                                          ('std',\n","                                                           1.1921386324765122),\n","                                                          ('b',\n","                                                           0.914347671508789),\n","                                                          ('shape',\n","                                                           '(128, 16, 32, 32)'),\n","                                                          ('total_numel',\n","                                                           8192000)]))])),\n","                              ('output',\n","                               OrderedDict([('min', 0.0),\n","                                            ('max', 2.980760097503662),\n","                                            ('avg_min', 0.0),\n","                                            ('avg_max', 1.9017339650534018),\n","                                            ('mean', -0.10943135452270508),\n","                                            ('std', 0.3927157913160909),\n","                                            ('b', 0.28187429809570314),\n","                                            ('shape', '(128, 16, 32, 32)'),\n","                                            ('total_numel', 8192000)]))])),\n","                ('layer1.5.relu1',\n","                 OrderedDict([('inputs',\n","                               OrderedDict([(0,\n","                                             OrderedDict([('min', 0.0),\n","                                                          ('max',\n","                                                           2.980760097503662),\n","                                                          ('avg_min', 0.0),\n","                                                          ('avg_max',\n","                                                           1.9017339650534018),\n","                                                          ('mean',\n","                                                           -0.10943135452270508),\n","                                                          ('std',\n","                                                           0.3927157913160909),\n","                                                          ('b',\n","                                                           0.28187429809570314),\n","                                                          ('shape',\n","                                                           '(128, 16, 32, 32)'),\n","                                                          ('total_numel',\n","                                                           8192000)]))])),\n","                              ('output',\n","                               OrderedDict([('min', 0.0),\n","                                            ('max', 2.980760097503662),\n","                                            ('avg_min', 0.0),\n","                                            ('avg_max', 1.9017339650534018),\n","                                            ('mean', 0.08092065238952637),\n","                                            ('std', 0.18273791495258518),\n","                                            ('b', 0.11770611953735352),\n","                                            ('shape', '(128, 16, 32, 32)'),\n","                                            ('total_numel', 8192000)]))])),\n","                ('layer1.5.conv2',\n","                 OrderedDict([('inputs',\n","                               OrderedDict([(0,\n","                                             OrderedDict([('min', 0.0),\n","                                                          ('max',\n","                                                           2.980760097503662),\n","                                                          ('avg_min', 0.0),\n","                                                          ('avg_max',\n","                                                           1.9017339650534018),\n","                                                          ('mean',\n","                                                           0.08092065238952637),\n","                                                          ('std',\n","                                                           0.18273791495258518),\n","                                                          ('b',\n","                                                           0.11770611953735352),\n","                                                          ('shape',\n","                                                           '(128, 16, 32, 32)'),\n","                                                          ('total_numel',\n","                                                           8192000)]))])),\n","                              ('output',\n","                               OrderedDict([('min', -4.889275550842285),\n","                                            ('max', 2.9606282711029053),\n","                                            ('avg_min', -2.5572096303740106),\n","                                            ('avg_max', 1.8588118577060748),\n","                                            ('mean', 0.06570400428771973),\n","                                            ('std', 0.3139410864116143),\n","                                            ('b', 0.20427747344970704),\n","                                            ('shape', '(128, 16, 32, 32)'),\n","                                            ('total_numel', 8192000)]))])),\n","                ('layer1.5.relu2',\n","                 OrderedDict([('inputs',\n","                               OrderedDict([(0,\n","                                             OrderedDict([('min', 0.0),\n","                                                          ('max',\n","                                                           15.35622787475586),\n","                                                          ('avg_min', 0.0),\n","                                                          ('avg_max',\n","                                                           9.868333288932188),\n","                                                          ('mean',\n","                                                           1.2080924682617187),\n","                                                          ('std',\n","                                                           1.257321745294897),\n","                                                          ('b',\n","                                                           0.9625741577148438),\n","                                                          ('shape',\n","                                                           '(128, 16, 32, 32)'),\n","                                                          ('total_numel',\n","                                                           8192000)]))])),\n","                              ('output',\n","                               OrderedDict([('min', 0.0),\n","                                            ('max', 15.35622787475586),\n","                                            ('avg_min', 0.0),\n","                                            ('avg_max', 9.868333288932188),\n","                                            ('mean', 1.2368460693359375),\n","                                            ('std', 1.2220854423358216),\n","                                            ('b', 0.938531265258789),\n","                                            ('shape', '(128, 16, 32, 32)'),\n","                                            ('total_numel', 8192000)]))])),\n","                ('layer1.5.residual_eltwiseadd',\n","                 OrderedDict([('inputs',\n","                               OrderedDict([(0,\n","                                             OrderedDict([('min', 0.0),\n","                                                          ('max',\n","                                                           15.401484489440918),\n","                                                          ('avg_min', 0.0),\n","                                                          ('avg_max',\n","                                                           9.231053738626324),\n","                                                          ('mean',\n","                                                           1.142388427734375),\n","                                                          ('std',\n","                                                           1.1921386324765122),\n","                                                          ('b',\n","                                                           0.914347671508789),\n","                                                          ('shape',\n","                                                           '(128, 16, 32, 32)'),\n","                                                          ('total_numel',\n","                                                           8192000)])),\n","                                            (1,\n","                                             OrderedDict([('min',\n","                                                           -4.889275550842285),\n","                                                          ('max',\n","                                                           2.9606282711029053),\n","                                                          ('avg_min',\n","                                                           -2.5572096303740106),\n","                                                          ('avg_max',\n","                                                           1.8588118577060748),\n","                                                          ('mean',\n","                                                           0.06570400428771973),\n","                                                          ('std',\n","                                                           0.3139410864116143),\n","                                                          ('b',\n","                                                           0.20427747344970704),\n","                                                          ('shape',\n","                                                           '(128, 16, 32, 32)'),\n","                                                          ('total_numel',\n","                                                           8192000)]))])),\n","                              ('output',\n","                               OrderedDict([('min', 0.0),\n","                                            ('max', 15.35622787475586),\n","                                            ('avg_min', 0.0),\n","                                            ('avg_max', 9.868333288932188),\n","                                            ('mean', 1.2080924682617187),\n","                                            ('std', 1.257321745294897),\n","                                            ('b', 0.9625741577148438),\n","                                            ('shape', '(128, 16, 32, 32)'),\n","                                            ('total_numel', 8192000)]))])),\n","                ('layer1.6.conv1',\n","                 OrderedDict([('inputs',\n","                               OrderedDict([(0,\n","                                             OrderedDict([('min', 0.0),\n","                                                          ('max',\n","                                                           15.35622787475586),\n","                                                          ('avg_min', 0.0),\n","                                                          ('avg_max',\n","                                                           9.868333288932188),\n","                                                          ('mean',\n","                                                           1.2368460693359375),\n","                                                          ('std',\n","                                                           1.2220854423358216),\n","                                                          ('b',\n","                                                           0.938531265258789),\n","                                                          ('shape',\n","                                                           '(128, 16, 32, 32)'),\n","                                                          ('total_numel',\n","                                                           8192000)]))])),\n","                              ('output',\n","                               OrderedDict([('min', 0.0),\n","                                            ('max', 4.47563362121582),\n","                                            ('avg_min', 0.0),\n","                                            ('avg_max', 2.2373243186135934),\n","                                            ('mean', -0.18059627151489258),\n","                                            ('std', 0.5551505343451373),\n","                                            ('b', 0.4181755142211914),\n","                                            ('shape', '(128, 16, 32, 32)'),\n","                                            ('total_numel', 8192000)]))])),\n","                ('layer1.6.relu1',\n","                 OrderedDict([('inputs',\n","                               OrderedDict([(0,\n","                                             OrderedDict([('min', 0.0),\n","                                                          ('max',\n","                                                           4.47563362121582),\n","                                                          ('avg_min', 0.0),\n","                                                          ('avg_max',\n","                                                           2.2373243186135934),\n","                                                          ('mean',\n","                                                           -0.18059627151489258),\n","                                                          ('std',\n","                                                           0.5551505343451373),\n","                                                          ('b',\n","                                                           0.4181755142211914),\n","                                                          ('shape',\n","                                                           '(128, 16, 32, 32)'),\n","                                                          ('total_numel',\n","                                                           8192000)]))])),\n","                              ('output',\n","                               OrderedDict([('min', 0.0),\n","                                            ('max', 4.47563362121582),\n","                                            ('avg_min', 0.0),\n","                                            ('avg_max', 2.2373243186135934),\n","                                            ('mean', 0.11618092727661133),\n","                                            ('std', 0.23125240427777813),\n","                                            ('b', 0.162153263092041),\n","                                            ('shape', '(128, 16, 32, 32)'),\n","                                            ('total_numel', 8192000)]))])),\n","                ('layer1.6.conv2',\n","                 OrderedDict([('inputs',\n","                               OrderedDict([(0,\n","                                             OrderedDict([('min', 0.0),\n","                                                          ('max',\n","                                                           4.47563362121582),\n","                                                          ('avg_min', 0.0),\n","                                                          ('avg_max',\n","                                                           2.2373243186135934),\n","                                                          ('mean',\n","                                                           0.11618092727661133),\n","                                                          ('std',\n","                                                           0.23125240427777813),\n","                                                          ('b',\n","                                                           0.162153263092041),\n","                                                          ('shape',\n","                                                           '(128, 16, 32, 32)'),\n","                                                          ('total_numel',\n","                                                           8192000)]))])),\n","                              ('output',\n","                               OrderedDict([('min', -3.626922130584717),\n","                                            ('max', 6.0221123695373535),\n","                                            ('avg_min', -2.589784186962228),\n","                                            ('avg_max', 2.8416534890316343),\n","                                            ('mean', 0.03875417423248291),\n","                                            ('std', 0.42112717646203124),\n","                                            ('b', 0.28857421875),\n","                                            ('shape', '(128, 16, 32, 32)'),\n","                                            ('total_numel', 8192000)]))])),\n","                ('layer1.6.relu2',\n","                 OrderedDict([('inputs',\n","                               OrderedDict([(0,\n","                                             OrderedDict([('min', 0.0),\n","                                                          ('max',\n","                                                           16.708539962768555),\n","                                                          ('avg_min', 0.0),\n","                                                          ('avg_max',\n","                                                           11.227175306285801),\n","                                                          ('mean',\n","                                                           1.2756002502441406),\n","                                                          ('std',\n","                                                           1.3667114126432174),\n","                                                          ('b',\n","                                                           1.0401083984375),\n","                                                          ('shape',\n","                                                           '(128, 16, 32, 32)'),\n","                                                          ('total_numel',\n","                                                           8192000)]))])),\n","                              ('output',\n","                               OrderedDict([('min', 0.0),\n","                                            ('max', 16.708539962768555),\n","                                            ('avg_min', 0.0),\n","                                            ('avg_max', 11.227175306285801),\n","                                            ('mean', 1.327176513671875),\n","                                            ('std', 1.301522217638951),\n","                                            ('b', 0.9967764434814453),\n","                                            ('shape', '(128, 16, 32, 32)'),\n","                                            ('total_numel', 8192000)]))])),\n","                ('layer1.6.residual_eltwiseadd',\n","                 OrderedDict([('inputs',\n","                               OrderedDict([(0,\n","                                             OrderedDict([('min', 0.0),\n","                                                          ('max',\n","                                                           15.35622787475586),\n","                                                          ('avg_min', 0.0),\n","                                                          ('avg_max',\n","                                                           9.868333288932188),\n","                                                          ('mean',\n","                                                           1.2368460693359375),\n","                                                          ('std',\n","                                                           1.2220854423358216),\n","                                                          ('b',\n","                                                           0.938531265258789),\n","                                                          ('shape',\n","                                                           '(128, 16, 32, 32)'),\n","                                                          ('total_numel',\n","                                                           8192000)])),\n","                                            (1,\n","                                             OrderedDict([('min',\n","                                                           -3.626922130584717),\n","                                                          ('max',\n","                                                           6.0221123695373535),\n","                                                          ('avg_min',\n","                                                           -2.589784186962228),\n","                                                          ('avg_max',\n","                                                           2.8416534890316343),\n","                                                          ('mean',\n","                                                           0.03875417423248291),\n","                                                          ('std',\n","                                                           0.42112717646203124),\n","                                                          ('b', 0.28857421875),\n","                                                          ('shape',\n","                                                           '(128, 16, 32, 32)'),\n","                                                          ('total_numel',\n","                                                           8192000)]))])),\n","                              ('output',\n","                               OrderedDict([('min', 0.0),\n","                                            ('max', 16.708539962768555),\n","                                            ('avg_min', 0.0),\n","                                            ('avg_max', 11.227175306285801),\n","                                            ('mean', 1.2756002502441406),\n","                                            ('std', 1.3667114126432174),\n","                                            ('b', 1.0401083984375),\n","                                            ('shape', '(128, 16, 32, 32)'),\n","                                            ('total_numel', 8192000)]))])),\n","                ('layer1.7.conv1',\n","                 OrderedDict([('inputs',\n","                               OrderedDict([(0,\n","                                             OrderedDict([('min', 0.0),\n","                                                          ('max',\n","                                                           16.708539962768555),\n","                                                          ('avg_min', 0.0),\n","                                                          ('avg_max',\n","                                                           11.227175306285801),\n","                                                          ('mean',\n","                                                           1.327176513671875),\n","                                                          ('std',\n","                                                           1.301522217638951),\n","                                                          ('b',\n","                                                           0.9967764434814453),\n","                                                          ('shape',\n","                                                           '(128, 16, 32, 32)'),\n","                                                          ('total_numel',\n","                                                           8192000)]))])),\n","                              ('output',\n","                               OrderedDict([('min', 0.0),\n","                                            ('max', 4.353071212768555),\n","                                            ('avg_min', 0.0),\n","                                            ('avg_max', 2.4613453207648774),\n","                                            ('mean', -0.19637778854370116),\n","                                            ('std', 0.5667153386175586),\n","                                            ('b', 0.42094895935058596),\n","                                            ('shape', '(128, 16, 32, 32)'),\n","                                            ('total_numel', 8192000)]))])),\n","                ('layer1.7.relu1',\n","                 OrderedDict([('inputs',\n","                               OrderedDict([(0,\n","                                             OrderedDict([('min', 0.0),\n","                                                          ('max',\n","                                                           4.353071212768555),\n","                                                          ('avg_min', 0.0),\n","                                                          ('avg_max',\n","                                                           2.4613453207648774),\n","                                                          ('mean',\n","                                                           -0.19637778854370116),\n","                                                          ('std',\n","                                                           0.5667153386175586),\n","                                                          ('b',\n","                                                           0.42094895935058596),\n","                                                          ('shape',\n","                                                           '(128, 16, 32, 32)'),\n","                                                          ('total_numel',\n","                                                           8192000)]))])),\n","                              ('output',\n","                               OrderedDict([('min', 0.0),\n","                                            ('max', 4.353071212768555),\n","                                            ('avg_min', 0.0),\n","                                            ('avg_max', 2.4613453207648774),\n","                                            ('mean', 0.1158264446258545),\n","                                            ('std', 0.2384333150953857),\n","                                            ('b', 0.16217910385131837),\n","                                            ('shape', '(128, 16, 32, 32)'),\n","                                            ('total_numel', 8192000)]))])),\n","                ('layer1.7.conv2',\n","                 OrderedDict([('inputs',\n","                               OrderedDict([(0,\n","                                             OrderedDict([('min', 0.0),\n","                                                          ('max',\n","                                                           4.353071212768555),\n","                                                          ('avg_min', 0.0),\n","                                                          ('avg_max',\n","                                                           2.4613453207648774),\n","                                                          ('mean',\n","                                                           0.1158264446258545),\n","                                                          ('std',\n","                                                           0.2384333150953857),\n","                                                          ('b',\n","                                                           0.16217910385131837),\n","                                                          ('shape',\n","                                                           '(128, 16, 32, 32)'),\n","                                                          ('total_numel',\n","                                                           8192000)]))])),\n","                              ('output',\n","                               OrderedDict([('min', -5.91280460357666),\n","                                            ('max', 6.223575592041016),\n","                                            ('avg_min', -3.1766530078571398),\n","                                            ('avg_max', 3.7199429150581875),\n","                                            ('mean', 0.14149718475341796),\n","                                            ('std', 0.4554498465068415),\n","                                            ('b', 0.308756233215332),\n","                                            ('shape', '(128, 16, 32, 32)'),\n","                                            ('total_numel', 8192000)]))])),\n","                ('layer1.7.relu2',\n","                 OrderedDict([('inputs',\n","                               OrderedDict([(0,\n","                                             OrderedDict([('min', 0.0),\n","                                                          ('max',\n","                                                           17.23421287536621),\n","                                                          ('avg_min', 0.0),\n","                                                          ('avg_max',\n","                                                           11.574507115269478),\n","                                                          ('mean',\n","                                                           1.4686736450195312),\n","                                                          ('std',\n","                                                           1.3377200621204757),\n","                                                          ('b',\n","                                                           1.0109161071777344),\n","                                                          ('shape',\n","                                                           '(128, 16, 32, 32)'),\n","                                                          ('total_numel',\n","                                                           8192000)]))])),\n","                              ('output',\n","                               OrderedDict([('min', 0.0),\n","                                            ('max', 17.23421287536621),\n","                                            ('avg_min', 0.0),\n","                                            ('avg_max', 11.574507115269478),\n","                                            ('mean', 1.5039100952148436),\n","                                            ('std', 1.2872445869798732),\n","                                            ('b', 0.9804259643554688),\n","                                            ('shape', '(128, 16, 32, 32)'),\n","                                            ('total_numel', 8192000)]))])),\n","                ('layer1.7.residual_eltwiseadd',\n","                 OrderedDict([('inputs',\n","                               OrderedDict([(0,\n","                                             OrderedDict([('min', 0.0),\n","                                                          ('max',\n","                                                           16.708539962768555),\n","                                                          ('avg_min', 0.0),\n","                                                          ('avg_max',\n","                                                           11.227175306285801),\n","                                                          ('mean',\n","                                                           1.327176513671875),\n","                                                          ('std',\n","                                                           1.301522217638951),\n","                                                          ('b',\n","                                                           0.9967764434814453),\n","                                                          ('shape',\n","                                                           '(128, 16, 32, 32)'),\n","                                                          ('total_numel',\n","                                                           8192000)])),\n","                                            (1,\n","                                             OrderedDict([('min',\n","                                                           -5.91280460357666),\n","                                                          ('max',\n","                                                           6.223575592041016),\n","                                                          ('avg_min',\n","                                                           -3.1766530078571398),\n","                                                          ('avg_max',\n","                                                           3.7199429150581875),\n","                                                          ('mean',\n","                                                           0.14149718475341796),\n","                                                          ('std',\n","                                                           0.4554498465068415),\n","                                                          ('b',\n","                                                           0.308756233215332),\n","                                                          ('shape',\n","                                                           '(128, 16, 32, 32)'),\n","                                                          ('total_numel',\n","                                                           8192000)]))])),\n","                              ('output',\n","                               OrderedDict([('min', 0.0),\n","                                            ('max', 17.23421287536621),\n","                                            ('avg_min', 0.0),\n","                                            ('avg_max', 11.574507115269478),\n","                                            ('mean', 1.4686736450195312),\n","                                            ('std', 1.3377200621204757),\n","                                            ('b', 1.0109161071777344),\n","                                            ('shape', '(128, 16, 32, 32)'),\n","                                            ('total_numel', 8192000)]))])),\n","                ('layer1.8.conv1',\n","                 OrderedDict([('inputs',\n","                               OrderedDict([(0,\n","                                             OrderedDict([('min', 0.0),\n","                                                          ('max',\n","                                                           17.23421287536621),\n","                                                          ('avg_min', 0.0),\n","                                                          ('avg_max',\n","                                                           11.574507115269478),\n","                                                          ('mean',\n","                                                           1.5039100952148436),\n","                                                          ('std',\n","                                                           1.2872445869798732),\n","                                                          ('b',\n","                                                           0.9804259643554688),\n","                                                          ('shape',\n","                                                           '(128, 16, 32, 32)'),\n","                                                          ('total_numel',\n","                                                           8192000)]))])),\n","                              ('output',\n","                               OrderedDict([('min', 0.0),\n","                                            ('max', 5.165977478027344),\n","                                            ('avg_min', 0.0),\n","                                            ('avg_max', 3.1311166241159043),\n","                                            ('mean', -0.20852856826782226),\n","                                            ('std', 0.6316255868455677),\n","                                            ('b', 0.44245022583007815),\n","                                            ('shape', '(128, 16, 32, 32)'),\n","                                            ('total_numel', 8192000)]))])),\n","                ('layer1.8.relu1',\n","                 OrderedDict([('inputs',\n","                               OrderedDict([(0,\n","                                             OrderedDict([('min', 0.0),\n","                                                          ('max',\n","                                                           5.165977478027344),\n","                                                          ('avg_min', 0.0),\n","                                                          ('avg_max',\n","                                                           3.1311166241159043),\n","                                                          ('mean',\n","                                                           -0.20852856826782226),\n","                                                          ('std',\n","                                                           0.6316255868455677),\n","                                                          ('b',\n","                                                           0.44245022583007815),\n","                                                          ('shape',\n","                                                           '(128, 16, 32, 32)'),\n","                                                          ('total_numel',\n","                                                           8192000)]))])),\n","                              ('output',\n","                               OrderedDict([('min', 0.0),\n","                                            ('max', 5.165977478027344),\n","                                            ('avg_min', 0.0),\n","                                            ('avg_max', 3.1311166241159043),\n","                                            ('mean', 0.11280957794189453),\n","                                            ('std', 0.2884957922722851),\n","                                            ('b', 0.17311647415161133),\n","                                            ('shape', '(128, 16, 32, 32)'),\n","                                            ('total_numel', 8192000)]))])),\n","                ('layer1.8.conv2',\n","                 OrderedDict([('inputs',\n","                               OrderedDict([(0,\n","                                             OrderedDict([('min', 0.0),\n","                                                          ('max',\n","                                                           5.165977478027344),\n","                                                          ('avg_min', 0.0),\n","                                                          ('avg_max',\n","                                                           3.1311166241159043),\n","                                                          ('mean',\n","                                                           0.11280957794189453),\n","                                                          ('std',\n","                                                           0.2884957922722851),\n","                                                          ('b',\n","                                                           0.17311647415161133),\n","                                                          ('shape',\n","                                                           '(128, 16, 32, 32)'),\n","                                                          ('total_numel',\n","                                                           8192000)]))])),\n","                              ('output',\n","                               OrderedDict([('min', -6.937506675720215),\n","                                            ('max', 10.464912414550781),\n","                                            ('avg_min', -4.591777397694659),\n","                                            ('avg_max', 5.995261781719864),\n","                                            ('mean', 0.04073733711242676),\n","                                            ('std', 0.6516179240047631),\n","                                            ('b', 0.43062669372558593),\n","                                            ('shape', '(128, 16, 32, 32)'),\n","                                            ('total_numel', 8192000)]))])),\n","                ('layer1.8.relu2',\n","                 OrderedDict([('inputs',\n","                               OrderedDict([(0,\n","                                             OrderedDict([('min', 0.0),\n","                                                          ('max',\n","                                                           15.506997108459473),\n","                                                          ('avg_min', 0.0),\n","                                                          ('avg_max',\n","                                                           8.748587685029795),\n","                                                          ('mean',\n","                                                           1.5446474304199218),\n","                                                          ('std',\n","                                                           1.2914187390692227),\n","                                                          ('b',\n","                                                           1.0250932312011718),\n","                                                          ('shape',\n","                                                           '(128, 16, 32, 32)'),\n","                                                          ('total_numel',\n","                                                           8192000)]))])),\n","                              ('output',\n","                               OrderedDict([('min', 0.0),\n","                                            ('max', 15.506997108459473),\n","                                            ('avg_min', 0.0),\n","                                            ('avg_max', 8.748587685029795),\n","                                            ('mean', 1.5882258605957031),\n","                                            ('std', 1.2205909323442863),\n","                                            ('b', 0.9849984436035156),\n","                                            ('shape', '(128, 16, 32, 32)'),\n","                                            ('total_numel', 8192000)]))])),\n","                ('layer1.8.residual_eltwiseadd',\n","                 OrderedDict([('inputs',\n","                               OrderedDict([(0,\n","                                             OrderedDict([('min', 0.0),\n","                                                          ('max',\n","                                                           17.23421287536621),\n","                                                          ('avg_min', 0.0),\n","                                                          ('avg_max',\n","                                                           11.574507115269478),\n","                                                          ('mean',\n","                                                           1.5039100952148436),\n","                                                          ('std',\n","                                                           1.2872445869798732),\n","                                                          ('b',\n","                                                           0.9804259643554688),\n","                                                          ('shape',\n","                                                           '(128, 16, 32, 32)'),\n","                                                          ('total_numel',\n","                                                           8192000)])),\n","                                            (1,\n","                                             OrderedDict([('min',\n","                                                           -6.937506675720215),\n","                                                          ('max',\n","                                                           10.464912414550781),\n","                                                          ('avg_min',\n","                                                           -4.591777397694659),\n","                                                          ('avg_max',\n","                                                           5.995261781719864),\n","                                                          ('mean',\n","                                                           0.04073733711242676),\n","                                                          ('std',\n","                                                           0.6516179240047631),\n","                                                          ('b',\n","                                                           0.43062669372558593),\n","                                                          ('shape',\n","                                                           '(128, 16, 32, 32)'),\n","                                                          ('total_numel',\n","                                                           8192000)]))])),\n","                              ('output',\n","                               OrderedDict([('min', 0.0),\n","                                            ('max', 15.506997108459473),\n","                                            ('avg_min', 0.0),\n","                                            ('avg_max', 8.748587685029795),\n","                                            ('mean', 1.5446474304199218),\n","                                            ('std', 1.2914187390692227),\n","                                            ('b', 1.0250932312011718),\n","                                            ('shape', '(128, 16, 32, 32)'),\n","                                            ('total_numel', 8192000)]))])),\n","                ('layer2.0.conv1',\n","                 OrderedDict([('inputs',\n","                               OrderedDict([(0,\n","                                             OrderedDict([('min', 0.0),\n","                                                          ('max',\n","                                                           15.506997108459473),\n","                                                          ('avg_min', 0.0),\n","                                                          ('avg_max',\n","                                                           8.748587685029795),\n","                                                          ('mean',\n","                                                           1.5882258605957031),\n","                                                          ('std',\n","                                                           1.2205909323442863),\n","                                                          ('b',\n","                                                           0.9849984436035156),\n","                                                          ('shape',\n","                                                           '(128, 16, 32, 32)'),\n","                                                          ('total_numel',\n","                                                           8192000)]))])),\n","                              ('output',\n","                               OrderedDict([('min', 0.0),\n","                                            ('max', 4.371332168579102),\n","                                            ('avg_min', 0.0),\n","                                            ('avg_max', 2.8005495143885595),\n","                                            ('mean', 0.047050246238708494),\n","                                            ('std', 0.6208776709919803),\n","                                            ('b', 0.4825814895629883),\n","                                            ('shape', '(128, 32, 16, 16)'),\n","                                            ('total_numel', 4096000)]))])),\n","                ('layer2.0.relu1',\n","                 OrderedDict([('inputs',\n","                               OrderedDict([(0,\n","                                             OrderedDict([('min', 0.0),\n","                                                          ('max',\n","                                                           4.371332168579102),\n","                                                          ('avg_min', 0.0),\n","                                                          ('avg_max',\n","                                                           2.8005495143885595),\n","                                                          ('mean',\n","                                                           0.047050246238708494),\n","                                                          ('std',\n","                                                           0.6208776709919803),\n","                                                          ('b',\n","                                                           0.4825814895629883),\n","                                                          ('shape',\n","                                                           '(128, 32, 16, 16)'),\n","                                                          ('total_numel',\n","                                                           4096000)]))])),\n","                              ('output',\n","                               OrderedDict([('min', 0.0),\n","                                            ('max', 4.371332168579102),\n","                                            ('avg_min', 0.0),\n","                                            ('avg_max', 2.8005495143885595),\n","                                            ('mean', 0.2654504585266113),\n","                                            ('std', 0.3816168649045661),\n","                                            ('b', 0.29798584747314455),\n","                                            ('shape', '(128, 32, 16, 16)'),\n","                                            ('total_numel', 4096000)]))])),\n","                ('layer2.0.conv2',\n","                 OrderedDict([('inputs',\n","                               OrderedDict([(0,\n","                                             OrderedDict([('min', 0.0),\n","                                                          ('max',\n","                                                           4.371332168579102),\n","                                                          ('avg_min', 0.0),\n","                                                          ('avg_max',\n","                                                           2.8005495143885595),\n","                                                          ('mean',\n","                                                           0.2654504585266113),\n","                                                          ('std',\n","                                                           0.3816168649045661),\n","                                                          ('b',\n","                                                           0.29798584747314455),\n","                                                          ('shape',\n","                                                           '(128, 32, 16, 16)'),\n","                                                          ('total_numel',\n","                                                           4096000)]))])),\n","                              ('output',\n","                               OrderedDict([('min', -5.951764106750488),\n","                                            ('max', 7.920443058013916),\n","                                            ('avg_min', -3.689236552532436),\n","                                            ('avg_max', 4.899532397413342),\n","                                            ('mean', 0.23071518325805665),\n","                                            ('std', 0.8333546272100388),\n","                                            ('b', 0.6330778198242187),\n","                                            ('shape', '(128, 32, 16, 16)'),\n","                                            ('total_numel', 4096000)]))])),\n","                ('layer2.0.relu2',\n","                 OrderedDict([('inputs',\n","                               OrderedDict([(0,\n","                                             OrderedDict([('min', 0.0),\n","                                                          ('max',\n","                                                           14.358081817626953),\n","                                                          ('avg_min', 0.0),\n","                                                          ('avg_max',\n","                                                           7.222792256563577),\n","                                                          ('mean',\n","                                                           0.4458362274169922),\n","                                                          ('std',\n","                                                           1.2635467239031282),\n","                                                          ('b',\n","                                                           0.9703824310302734),\n","                                                          ('shape',\n","                                                           '(128, 32, 16, 16)'),\n","                                                          ('total_numel',\n","                                                           4096000)]))])),\n","                              ('output',\n","                               OrderedDict([('min', 0.0),\n","                                            ('max', 14.358081817626953),\n","                                            ('avg_min', 0.0),\n","                                            ('avg_max', 7.222792256563577),\n","                                            ('mean', 0.7227191314697266),\n","                                            ('std', 0.9514382086699021),\n","                                            ('b', 0.7420203552246094),\n","                                            ('shape', '(128, 32, 16, 16)'),\n","                                            ('total_numel', 4096000)]))])),\n","                ('layer2.0.downsample.0',\n","                 OrderedDict([('inputs',\n","                               OrderedDict([(0,\n","                                             OrderedDict([('min', 0.0),\n","                                                          ('max',\n","                                                           15.506997108459473),\n","                                                          ('avg_min', 0.0),\n","                                                          ('avg_max',\n","                                                           8.748587685029795),\n","                                                          ('mean',\n","                                                           1.5882258605957031),\n","                                                          ('std',\n","                                                           1.2205909323442863),\n","                                                          ('b',\n","                                                           0.9849984436035156),\n","                                                          ('shape',\n","                                                           '(128, 16, 32, 32)'),\n","                                                          ('total_numel',\n","                                                           8192000)]))])),\n","                              ('output',\n","                               OrderedDict([('min', -3.515953779220581),\n","                                            ('max', 11.313068389892578),\n","                                            ('avg_min', -2.2478450579922757),\n","                                            ('avg_max', 4.652270128981009),\n","                                            ('mean', 0.21512105560302736),\n","                                            ('std', 0.6285924828706468),\n","                                            ('b', 0.45446802520751955),\n","                                            ('shape', '(128, 32, 16, 16)'),\n","                                            ('total_numel', 4096000)]))])),\n","                ('layer2.0.residual_eltwiseadd',\n","                 OrderedDict([('inputs',\n","                               OrderedDict([(0,\n","                                             OrderedDict([('min',\n","                                                           -3.515953779220581),\n","                                                          ('max',\n","                                                           11.313068389892578),\n","                                                          ('avg_min',\n","                                                           -2.2478450579922757),\n","                                                          ('avg_max',\n","                                                           4.652270128981009),\n","                                                          ('mean',\n","                                                           0.21512105560302736),\n","                                                          ('std',\n","                                                           0.6285924828706468),\n","                                                          ('b',\n","                                                           0.45446802520751955),\n","                                                          ('shape',\n","                                                           '(128, 32, 16, 16)'),\n","                                                          ('total_numel',\n","                                                           4096000)])),\n","                                            (1,\n","                                             OrderedDict([('min',\n","                                                           -5.951764106750488),\n","                                                          ('max',\n","                                                           7.920443058013916),\n","                                                          ('avg_min',\n","                                                           -3.689236552532436),\n","                                                          ('avg_max',\n","                                                           4.899532397413342),\n","                                                          ('mean',\n","                                                           0.23071518325805665),\n","                                                          ('std',\n","                                                           0.8333546272100388),\n","                                                          ('b',\n","                                                           0.6330778198242187),\n","                                                          ('shape',\n","                                                           '(128, 32, 16, 16)'),\n","                                                          ('total_numel',\n","                                                           4096000)]))])),\n","                              ('output',\n","                               OrderedDict([('min', 0.0),\n","                                            ('max', 14.358081817626953),\n","                                            ('avg_min', 0.0),\n","                                            ('avg_max', 7.222792256563577),\n","                                            ('mean', 0.4458362274169922),\n","                                            ('std', 1.2635467239031282),\n","                                            ('b', 0.9703824310302734),\n","                                            ('shape', '(128, 32, 16, 16)'),\n","                                            ('total_numel', 4096000)]))])),\n","                ('layer2.1.conv1',\n","                 OrderedDict([('inputs',\n","                               OrderedDict([(0,\n","                                             OrderedDict([('min', 0.0),\n","                                                          ('max',\n","                                                           14.358081817626953),\n","                                                          ('avg_min', 0.0),\n","                                                          ('avg_max',\n","                                                           7.222792256563577),\n","                                                          ('mean',\n","                                                           0.7227191314697266),\n","                                                          ('std',\n","                                                           0.9514382086699021),\n","                                                          ('b',\n","                                                           0.7420203552246094),\n","                                                          ('shape',\n","                                                           '(128, 32, 16, 16)'),\n","                                                          ('total_numel',\n","                                                           4096000)]))])),\n","                              ('output',\n","                               OrderedDict([('min', 0.0),\n","                                            ('max', 3.722210168838501),\n","                                            ('avg_min', 0.0),\n","                                            ('avg_max', 1.732802057914114),\n","                                            ('mean', -0.33160980224609377),\n","                                            ('std', 0.4896323494689504),\n","                                            ('b', 0.3867603149414062),\n","                                            ('shape', '(128, 32, 16, 16)'),\n","                                            ('total_numel', 4096000)]))])),\n","                ('layer2.1.relu1',\n","                 OrderedDict([('inputs',\n","                               OrderedDict([(0,\n","                                             OrderedDict([('min', 0.0),\n","                                                          ('max',\n","                                                           3.722210168838501),\n","                                                          ('avg_min', 0.0),\n","                                                          ('avg_max',\n","                                                           1.732802057914114),\n","                                                          ('mean',\n","                                                           -0.33160980224609377),\n","                                                          ('std',\n","                                                           0.4896323494689504),\n","                                                          ('b',\n","                                                           0.3867603149414062),\n","                                                          ('shape',\n","                                                           '(128, 32, 16, 16)'),\n","                                                          ('total_numel',\n","                                                           4096000)]))])),\n","                              ('output',\n","                               OrderedDict([('min', 0.0),\n","                                            ('max', 3.722210168838501),\n","                                            ('avg_min', 0.0),\n","                                            ('avg_max', 1.732802057914114),\n","                                            ('mean', 0.05998429012298584),\n","                                            ('std', 0.15779740214125224),\n","                                            ('b', 0.09322673606872559),\n","                                            ('shape', '(128, 32, 16, 16)'),\n","                                            ('total_numel', 4096000)]))])),\n","                ('layer2.1.conv2',\n","                 OrderedDict([('inputs',\n","                               OrderedDict([(0,\n","                                             OrderedDict([('min', 0.0),\n","                                                          ('max',\n","                                                           3.722210168838501),\n","                                                          ('avg_min', 0.0),\n","                                                          ('avg_max',\n","                                                           1.732802057914114),\n","                                                          ('mean',\n","                                                           0.05998429012298584),\n","                                                          ('std',\n","                                                           0.15779740214125224),\n","                                                          ('b',\n","                                                           0.09322673606872559),\n","                                                          ('shape',\n","                                                           '(128, 32, 16, 16)'),\n","                                                          ('total_numel',\n","                                                           4096000)]))])),\n","                              ('output',\n","                               OrderedDict([('min', -4.961212635040283),\n","                                            ('max', 9.029803276062012),\n","                                            ('avg_min', -2.2036586008277417),\n","                                            ('avg_max', 3.1221718469224937),\n","                                            ('mean', 0.005400043487548828),\n","                                            ('std', 0.3882058194305517),\n","                                            ('b', 0.27153285217285156),\n","                                            ('shape', '(128, 32, 16, 16)'),\n","                                            ('total_numel', 4096000)]))])),\n","                ('layer2.1.relu2',\n","                 OrderedDict([('inputs',\n","                               OrderedDict([(0,\n","                                             OrderedDict([('min', 0.0),\n","                                                          ('max',\n","                                                           14.465282440185547),\n","                                                          ('avg_min', 0.0),\n","                                                          ('avg_max',\n","                                                           7.529512794779261),\n","                                                          ('mean',\n","                                                           0.7281191711425781),\n","                                                          ('std',\n","                                                           1.0770047962078384),\n","                                                          ('b',\n","                                                           0.8359590759277343),\n","                                                          ('shape',\n","                                                           '(128, 32, 16, 16)'),\n","                                                          ('total_numel',\n","                                                           4096000)]))])),\n","                              ('output',\n","                               OrderedDict([('min', 0.0),\n","                                            ('max', 14.465282440185547),\n","                                            ('avg_min', 0.0),\n","                                            ('avg_max', 7.529512794779261),\n","                                            ('mean', 0.8145196990966797),\n","                                            ('std', 0.986633407272772),\n","                                            ('b', 0.7694193420410156),\n","                                            ('shape', '(128, 32, 16, 16)'),\n","                                            ('total_numel', 4096000)]))])),\n","                ('layer2.1.residual_eltwiseadd',\n","                 OrderedDict([('inputs',\n","                               OrderedDict([(0,\n","                                             OrderedDict([('min', 0.0),\n","                                                          ('max',\n","                                                           14.358081817626953),\n","                                                          ('avg_min', 0.0),\n","                                                          ('avg_max',\n","                                                           7.222792256563577),\n","                                                          ('mean',\n","                                                           0.7227191314697266),\n","                                                          ('std',\n","                                                           0.9514382086699021),\n","                                                          ('b',\n","                                                           0.7420203552246094),\n","                                                          ('shape',\n","                                                           '(128, 32, 16, 16)'),\n","                                                          ('total_numel',\n","                                                           4096000)])),\n","                                            (1,\n","                                             OrderedDict([('min',\n","                                                           -4.961212635040283),\n","                                                          ('max',\n","                                                           9.029803276062012),\n","                                                          ('avg_min',\n","                                                           -2.2036586008277417),\n","                                                          ('avg_max',\n","                                                           3.1221718469224937),\n","                                                          ('mean',\n","                                                           0.005400043487548828),\n","                                                          ('std',\n","                                                           0.3882058194305517),\n","                                                          ('b',\n","                                                           0.27153285217285156),\n","                                                          ('shape',\n","                                                           '(128, 32, 16, 16)'),\n","                                                          ('total_numel',\n","                                                           4096000)]))])),\n","                              ('output',\n","                               OrderedDict([('min', 0.0),\n","                                            ('max', 14.465282440185547),\n","                                            ('avg_min', 0.0),\n","                                            ('avg_max', 7.529512794779261),\n","                                            ('mean', 0.7281191711425781),\n","                                            ('std', 1.0770047962078384),\n","                                            ('b', 0.8359590759277343),\n","                                            ('shape', '(128, 32, 16, 16)'),\n","                                            ('total_numel', 4096000)]))])),\n","                ('layer2.2.conv1',\n","                 OrderedDict([('inputs',\n","                               OrderedDict([(0,\n","                                             OrderedDict([('min', 0.0),\n","                                                          ('max',\n","                                                           14.465282440185547),\n","                                                          ('avg_min', 0.0),\n","                                                          ('avg_max',\n","                                                           7.529512794779261),\n","                                                          ('mean',\n","                                                           0.8145196990966797),\n","                                                          ('std',\n","                                                           0.986633407272772),\n","                                                          ('b',\n","                                                           0.7694193420410156),\n","                                                          ('shape',\n","                                                           '(128, 32, 16, 16)'),\n","                                                          ('total_numel',\n","                                                           4096000)]))])),\n","                              ('output',\n","                               OrderedDict([('min', 0.0),\n","                                            ('max', 3.9087934494018555),\n","                                            ('avg_min', 0.0),\n","                                            ('avg_max', 1.7088585085342838),\n","                                            ('mean', -0.37761759948730467),\n","                                            ('std', 0.49251484185331995),\n","                                            ('b', 0.38675496673583987),\n","                                            ('shape', '(128, 32, 16, 16)'),\n","                                            ('total_numel', 4096000)]))])),\n","                ('layer2.2.relu1',\n","                 OrderedDict([('inputs',\n","                               OrderedDict([(0,\n","                                             OrderedDict([('min', 0.0),\n","                                                          ('max',\n","                                                           3.9087934494018555),\n","                                                          ('avg_min', 0.0),\n","                                                          ('avg_max',\n","                                                           1.7088585085342838),\n","                                                          ('mean',\n","                                                           -0.37761759948730467),\n","                                                          ('std',\n","                                                           0.49251484185331995),\n","                                                          ('b',\n","                                                           0.38675496673583987),\n","                                                          ('shape',\n","                                                           '(128, 32, 16, 16)'),\n","                                                          ('total_numel',\n","                                                           4096000)]))])),\n","                              ('output',\n","                               OrderedDict([('min', 0.0),\n","                                            ('max', 3.9087934494018555),\n","                                            ('avg_min', 0.0),\n","                                            ('avg_max', 1.7088585085342838),\n","                                            ('mean', 0.053349095344543455),\n","                                            ('std', 0.1508533301542526),\n","                                            ('b', 0.08698281860351563),\n","                                            ('shape', '(128, 32, 16, 16)'),\n","                                            ('total_numel', 4096000)]))])),\n","                ('layer2.2.conv2',\n","                 OrderedDict([('inputs',\n","                               OrderedDict([(0,\n","                                             OrderedDict([('min', 0.0),\n","                                                          ('max',\n","                                                           3.9087934494018555),\n","                                                          ('avg_min', 0.0),\n","                                                          ('avg_max',\n","                                                           1.7088585085342838),\n","                                                          ('mean',\n","                                                           0.053349095344543455),\n","                                                          ('std',\n","                                                           0.1508533301542526),\n","                                                          ('b',\n","                                                           0.08698281860351563),\n","                                                          ('shape',\n","                                                           '(128, 32, 16, 16)'),\n","                                                          ('total_numel',\n","                                                           4096000)]))])),\n","                              ('output',\n","                               OrderedDict([('min', -3.9039316177368164),\n","                                            ('max', 8.945950508117676),\n","                                            ('avg_min', -2.1766586633300915),\n","                                            ('avg_max', 3.200339563796649),\n","                                            ('mean', -0.006419229745864868),\n","                                            ('std', 0.3951856471447673),\n","                                            ('b', 0.2756646270751953),\n","                                            ('shape', '(128, 32, 16, 16)'),\n","                                            ('total_numel', 4096000)]))])),\n","                ('layer2.2.relu2',\n","                 OrderedDict([('inputs',\n","                               OrderedDict([(0,\n","                                             OrderedDict([('min', 0.0),\n","                                                          ('max',\n","                                                           16.72279930114746),\n","                                                          ('avg_min', 0.0),\n","                                                          ('avg_max',\n","                                                           7.929282020219035),\n","                                                          ('mean',\n","                                                           0.8081004638671875),\n","                                                          ('std',\n","                                                           1.1141258309488655),\n","                                                          ('b',\n","                                                           0.8606470947265625),\n","                                                          ('shape',\n","                                                           '(128, 32, 16, 16)'),\n","                                                          ('total_numel',\n","                                                           4096000)]))])),\n","                              ('output',\n","                               OrderedDict([('min', 0.0),\n","                                            ('max', 16.72279930114746),\n","                                            ('avg_min', 0.0),\n","                                            ('avg_max', 7.929282020219035),\n","                                            ('mean', 0.8853829498291016),\n","                                            ('std', 1.0312088651833888),\n","                                            ('b', 0.8012216796875),\n","                                            ('shape', '(128, 32, 16, 16)'),\n","                                            ('total_numel', 4096000)]))])),\n","                ('layer2.2.residual_eltwiseadd',\n","                 OrderedDict([('inputs',\n","                               OrderedDict([(0,\n","                                             OrderedDict([('min', 0.0),\n","                                                          ('max',\n","                                                           14.465282440185547),\n","                                                          ('avg_min', 0.0),\n","                                                          ('avg_max',\n","                                                           7.529512794779261),\n","                                                          ('mean',\n","                                                           0.8145196990966797),\n","                                                          ('std',\n","                                                           0.986633407272772),\n","                                                          ('b',\n","                                                           0.7694193420410156),\n","                                                          ('shape',\n","                                                           '(128, 32, 16, 16)'),\n","                                                          ('total_numel',\n","                                                           4096000)])),\n","                                            (1,\n","                                             OrderedDict([('min',\n","                                                           -3.9039316177368164),\n","                                                          ('max',\n","                                                           8.945950508117676),\n","                                                          ('avg_min',\n","                                                           -2.1766586633300915),\n","                                                          ('avg_max',\n","                                                           3.200339563796649),\n","                                                          ('mean',\n","                                                           -0.006419229745864868),\n","                                                          ('std',\n","                                                           0.3951856471447673),\n","                                                          ('b',\n","                                                           0.2756646270751953),\n","                                                          ('shape',\n","                                                           '(128, 32, 16, 16)'),\n","                                                          ('total_numel',\n","                                                           4096000)]))])),\n","                              ('output',\n","                               OrderedDict([('min', 0.0),\n","                                            ('max', 16.72279930114746),\n","                                            ('avg_min', 0.0),\n","                                            ('avg_max', 7.929282020219035),\n","                                            ('mean', 0.8081004638671875),\n","                                            ('std', 1.1141258309488655),\n","                                            ('b', 0.8606470947265625),\n","                                            ('shape', '(128, 32, 16, 16)'),\n","                                            ('total_numel', 4096000)]))])),\n","                ('layer2.3.conv1',\n","                 OrderedDict([('inputs',\n","                               OrderedDict([(0,\n","                                             OrderedDict([('min', 0.0),\n","                                                          ('max',\n","                                                           16.72279930114746),\n","                                                          ('avg_min', 0.0),\n","                                                          ('avg_max',\n","                                                           7.929282020219035),\n","                                                          ('mean',\n","                                                           0.8853829498291016),\n","                                                          ('std',\n","                                                           1.0312088651833888),\n","                                                          ('b',\n","                                                           0.8012216796875),\n","                                                          ('shape',\n","                                                           '(128, 32, 16, 16)'),\n","                                                          ('total_numel',\n","                                                           4096000)]))])),\n","                              ('output',\n","                               OrderedDict([('min', 0.0),\n","                                            ('max', 2.842329502105713),\n","                                            ('avg_min', 0.0),\n","                                            ('avg_max', 1.6570619651982854),\n","                                            ('mean', -0.3927452545166016),\n","                                            ('std', 0.4863933777446177),\n","                                            ('b', 0.3772766265869141),\n","                                            ('shape', '(128, 32, 16, 16)'),\n","                                            ('total_numel', 4096000)]))])),\n","                ('layer2.3.relu1',\n","                 OrderedDict([('inputs',\n","                               OrderedDict([(0,\n","                                             OrderedDict([('min', 0.0),\n","                                                          ('max',\n","                                                           2.842329502105713),\n","                                                          ('avg_min', 0.0),\n","                                                          ('avg_max',\n","                                                           1.6570619651982854),\n","                                                          ('mean',\n","                                                           -0.3927452545166016),\n","                                                          ('std',\n","                                                           0.4863933777446177),\n","                                                          ('b',\n","                                                           0.3772766265869141),\n","                                                          ('shape',\n","                                                           '(128, 32, 16, 16)'),\n","                                                          ('total_numel',\n","                                                           4096000)]))])),\n","                              ('output',\n","                               OrderedDict([('min', 0.0),\n","                                            ('max', 2.842329502105713),\n","                                            ('avg_min', 0.0),\n","                                            ('avg_max', 1.6570619651982854),\n","                                            ('mean', 0.050973328590393066),\n","                                            ('std', 0.1453353831003745),\n","                                            ('b', 0.08329609870910644),\n","                                            ('shape', '(128, 32, 16, 16)'),\n","                                            ('total_numel', 4096000)]))])),\n","                ('layer2.3.conv2',\n","                 OrderedDict([('inputs',\n","                               OrderedDict([(0,\n","                                             OrderedDict([('min', 0.0),\n","                                                          ('max',\n","                                                           2.842329502105713),\n","                                                          ('avg_min', 0.0),\n","                                                          ('avg_max',\n","                                                           1.6570619651982854),\n","                                                          ('mean',\n","                                                           0.050973328590393066),\n","                                                          ('std',\n","                                                           0.1453353831003745),\n","                                                          ('b',\n","                                                           0.08329609870910644),\n","                                                          ('shape',\n","                                                           '(128, 32, 16, 16)'),\n","                                                          ('total_numel',\n","                                                           4096000)]))])),\n","                              ('output',\n","                               OrderedDict([('min', -4.430220127105713),\n","                                            ('max', 5.544358730316162),\n","                                            ('avg_min', -2.2822635889093976),\n","                                            ('avg_max', 2.574026055235532),\n","                                            ('mean', -0.004290765166282654),\n","                                            ('std', 0.37809296779676194),\n","                                            ('b', 0.2700602798461914),\n","                                            ('shape', '(128, 32, 16, 16)'),\n","                                            ('total_numel', 4096000)]))])),\n","                ('layer2.3.relu2',\n","                 OrderedDict([('inputs',\n","                               OrderedDict([(0,\n","                                             OrderedDict([('min', 0.0),\n","                                                          ('max',\n","                                                           17.53993034362793),\n","                                                          ('avg_min', 0.0),\n","                                                          ('avg_max',\n","                                                           8.222635958264679),\n","                                                          ('mean',\n","                                                           0.8810921936035156),\n","                                                          ('std',\n","                                                           1.142432162151078),\n","                                                          ('b',\n","                                                           0.8849485015869141),\n","                                                          ('shape',\n","                                                           '(128, 32, 16, 16)'),\n","                                                          ('total_numel',\n","                                                           4096000)]))])),\n","                              ('output',\n","                               OrderedDict([('min', 0.0),\n","                                            ('max', 17.53993034362793),\n","                                            ('avg_min', 0.0),\n","                                            ('avg_max', 8.222635958264679),\n","                                            ('mean', 0.9447227020263672),\n","                                            ('std', 1.074372403783585),\n","                                            ('b', 0.8358065490722656),\n","                                            ('shape', '(128, 32, 16, 16)'),\n","                                            ('total_numel', 4096000)]))])),\n","                ('layer2.3.residual_eltwiseadd',\n","                 OrderedDict([('inputs',\n","                               OrderedDict([(0,\n","                                             OrderedDict([('min', 0.0),\n","                                                          ('max',\n","                                                           16.72279930114746),\n","                                                          ('avg_min', 0.0),\n","                                                          ('avg_max',\n","                                                           7.929282020219035),\n","                                                          ('mean',\n","                                                           0.8853829498291016),\n","                                                          ('std',\n","                                                           1.0312088651833888),\n","                                                          ('b',\n","                                                           0.8012216796875),\n","                                                          ('shape',\n","                                                           '(128, 32, 16, 16)'),\n","                                                          ('total_numel',\n","                                                           4096000)])),\n","                                            (1,\n","                                             OrderedDict([('min',\n","                                                           -4.430220127105713),\n","                                                          ('max',\n","                                                           5.544358730316162),\n","                                                          ('avg_min',\n","                                                           -2.2822635889093976),\n","                                                          ('avg_max',\n","                                                           2.574026055235532),\n","                                                          ('mean',\n","                                                           -0.004290765166282654),\n","                                                          ('std',\n","                                                           0.37809296779676194),\n","                                                          ('b',\n","                                                           0.2700602798461914),\n","                                                          ('shape',\n","                                                           '(128, 32, 16, 16)'),\n","                                                          ('total_numel',\n","                                                           4096000)]))])),\n","                              ('output',\n","                               OrderedDict([('min', 0.0),\n","                                            ('max', 17.53993034362793),\n","                                            ('avg_min', 0.0),\n","                                            ('avg_max', 8.222635958264679),\n","                                            ('mean', 0.8810921936035156),\n","                                            ('std', 1.142432162151078),\n","                                            ('b', 0.8849485015869141),\n","                                            ('shape', '(128, 32, 16, 16)'),\n","                                            ('total_numel', 4096000)]))])),\n","                ('layer2.4.conv1',\n","                 OrderedDict([('inputs',\n","                               OrderedDict([(0,\n","                                             OrderedDict([('min', 0.0),\n","                                                          ('max',\n","                                                           17.53993034362793),\n","                                                          ('avg_min', 0.0),\n","                                                          ('avg_max',\n","                                                           8.222635958264679),\n","                                                          ('mean',\n","                                                           0.9447227020263672),\n","                                                          ('std',\n","                                                           1.074372403783585),\n","                                                          ('b',\n","                                                           0.8358065490722656),\n","                                                          ('shape',\n","                                                           '(128, 32, 16, 16)'),\n","                                                          ('total_numel',\n","                                                           4096000)]))])),\n","                              ('output',\n","                               OrderedDict([('min', 0.0),\n","                                            ('max', 3.7095980644226074),\n","                                            ('avg_min', 0.0),\n","                                            ('avg_max', 1.5292837369303824),\n","                                            ('mean', -0.35577352905273435),\n","                                            ('std', 0.4271795640165036),\n","                                            ('b', 0.3297741470336914),\n","                                            ('shape', '(128, 32, 16, 16)'),\n","                                            ('total_numel', 4096000)]))])),\n","                ('layer2.4.relu1',\n","                 OrderedDict([('inputs',\n","                               OrderedDict([(0,\n","                                             OrderedDict([('min', 0.0),\n","                                                          ('max',\n","                                                           3.7095980644226074),\n","                                                          ('avg_min', 0.0),\n","                                                          ('avg_max',\n","                                                           1.5292837369303824),\n","                                                          ('mean',\n","                                                           -0.35577352905273435),\n","                                                          ('std',\n","                                                           0.4271795640165036),\n","                                                          ('b',\n","                                                           0.3297741470336914),\n","                                                          ('shape',\n","                                                           '(128, 32, 16, 16)'),\n","                                                          ('total_numel',\n","                                                           4096000)]))])),\n","                              ('output',\n","                               OrderedDict([('min', 0.0),\n","                                            ('max', 3.7095980644226074),\n","                                            ('avg_min', 0.0),\n","                                            ('avg_max', 1.5292837369303824),\n","                                            ('mean', 0.039566059112548825),\n","                                            ('std', 0.12007736116462946),\n","                                            ('b', 0.06558895492553711),\n","                                            ('shape', '(128, 32, 16, 16)'),\n","                                            ('total_numel', 4096000)]))])),\n","                ('layer2.4.conv2',\n","                 OrderedDict([('inputs',\n","                               OrderedDict([(0,\n","                                             OrderedDict([('min', 0.0),\n","                                                          ('max',\n","                                                           3.7095980644226074),\n","                                                          ('avg_min', 0.0),\n","                                                          ('avg_max',\n","                                                           1.5292837369303824),\n","                                                          ('mean',\n","                                                           0.039566059112548825),\n","                                                          ('std',\n","                                                           0.12007736116462946),\n","                                                          ('b',\n","                                                           0.06558895492553711),\n","                                                          ('shape',\n","                                                           '(128, 32, 16, 16)'),\n","                                                          ('total_numel',\n","                                                           4096000)]))])),\n","                              ('output',\n","                               OrderedDict([('min', -5.326929569244385),\n","                                            ('max', 4.811362266540527),\n","                                            ('avg_min', -2.095546034161209),\n","                                            ('avg_max', 2.4082570101220897),\n","                                            ('mean', -0.0441944055557251),\n","                                            ('std', 0.33560140572982117),\n","                                            ('b', 0.23495698165893555),\n","                                            ('shape', '(128, 32, 16, 16)'),\n","                                            ('total_numel', 4096000)]))])),\n","                ('layer2.4.relu2',\n","                 OrderedDict([('inputs',\n","                               OrderedDict([(0,\n","                                             OrderedDict([('min', 0.0),\n","                                                          ('max',\n","                                                           17.741519927978516),\n","                                                          ('avg_min', 0.0),\n","                                                          ('avg_max',\n","                                                           8.522572115969227),\n","                                                          ('mean',\n","                                                           0.9005282897949218),\n","                                                          ('std',\n","                                                           1.1653949745804397),\n","                                                          ('b',\n","                                                           0.9059012451171875),\n","                                                          ('shape',\n","                                                           '(128, 32, 16, 16)'),\n","                                                          ('total_numel',\n","                                                           4096000)]))])),\n","                              ('output',\n","                               OrderedDict([('min', 0.0),\n","                                            ('max', 17.741519927978516),\n","                                            ('avg_min', 0.0),\n","                                            ('avg_max', 8.522572115969227),\n","                                            ('mean', 0.9642572784423828),\n","                                            ('std', 1.0977759470990867),\n","                                            ('b', 0.8563427124023437),\n","                                            ('shape', '(128, 32, 16, 16)'),\n","                                            ('total_numel', 4096000)]))])),\n","                ('layer2.4.residual_eltwiseadd',\n","                 OrderedDict([('inputs',\n","                               OrderedDict([(0,\n","                                             OrderedDict([('min', 0.0),\n","                                                          ('max',\n","                                                           17.53993034362793),\n","                                                          ('avg_min', 0.0),\n","                                                          ('avg_max',\n","                                                           8.222635958264679),\n","                                                          ('mean',\n","                                                           0.9447227020263672),\n","                                                          ('std',\n","                                                           1.074372403783585),\n","                                                          ('b',\n","                                                           0.8358065490722656),\n","                                                          ('shape',\n","                                                           '(128, 32, 16, 16)'),\n","                                                          ('total_numel',\n","                                                           4096000)])),\n","                                            (1,\n","                                             OrderedDict([('min',\n","                                                           -5.326929569244385),\n","                                                          ('max',\n","                                                           4.811362266540527),\n","                                                          ('avg_min',\n","                                                           -2.095546034161209),\n","                                                          ('avg_max',\n","                                                           2.4082570101220897),\n","                                                          ('mean',\n","                                                           -0.0441944055557251),\n","                                                          ('std',\n","                                                           0.33560140572982117),\n","                                                          ('b',\n","                                                           0.23495698165893555),\n","                                                          ('shape',\n","                                                           '(128, 32, 16, 16)'),\n","                                                          ('total_numel',\n","                                                           4096000)]))])),\n","                              ('output',\n","                               OrderedDict([('min', 0.0),\n","                                            ('max', 17.741519927978516),\n","                                            ('avg_min', 0.0),\n","                                            ('avg_max', 8.522572115969227),\n","                                            ('mean', 0.9005282897949218),\n","                                            ('std', 1.1653949745804397),\n","                                            ('b', 0.9059012451171875),\n","                                            ('shape', '(128, 32, 16, 16)'),\n","                                            ('total_numel', 4096000)]))])),\n","                ('layer2.5.conv1',\n","                 OrderedDict([('inputs',\n","                               OrderedDict([(0,\n","                                             OrderedDict([('min', 0.0),\n","                                                          ('max',\n","                                                           17.741519927978516),\n","                                                          ('avg_min', 0.0),\n","                                                          ('avg_max',\n","                                                           8.522572115969227),\n","                                                          ('mean',\n","                                                           0.9642572784423828),\n","                                                          ('std',\n","                                                           1.0977759470990867),\n","                                                          ('b',\n","                                                           0.8563427124023437),\n","                                                          ('shape',\n","                                                           '(128, 32, 16, 16)'),\n","                                                          ('total_numel',\n","                                                           4096000)]))])),\n","                              ('output',\n","                               OrderedDict([('min', 0.0),\n","                                            ('max', 2.860159397125244),\n","                                            ('avg_min', 0.0),\n","                                            ('avg_max', 1.5307479592869226),\n","                                            ('mean', -0.38140894317626955),\n","                                            ('std', 0.45343158741730094),\n","                                            ('b', 0.35484073638916014),\n","                                            ('shape', '(128, 32, 16, 16)'),\n","                                            ('total_numel', 4096000)]))])),\n","                ('layer2.5.relu1',\n","                 OrderedDict([('inputs',\n","                               OrderedDict([(0,\n","                                             OrderedDict([('min', 0.0),\n","                                                          ('max',\n","                                                           2.860159397125244),\n","                                                          ('avg_min', 0.0),\n","                                                          ('avg_max',\n","                                                           1.5307479592869226),\n","                                                          ('mean',\n","                                                           -0.38140894317626955),\n","                                                          ('std',\n","                                                           0.45343158741730094),\n","                                                          ('b',\n","                                                           0.35484073638916014),\n","                                                          ('shape',\n","                                                           '(128, 32, 16, 16)'),\n","                                                          ('total_numel',\n","                                                           4096000)]))])),\n","                              ('output',\n","                               OrderedDict([('min', 0.0),\n","                                            ('max', 2.860159397125244),\n","                                            ('avg_min', 0.0),\n","                                            ('avg_max', 1.5307479592869226),\n","                                            ('mean', 0.0416651029586792),\n","                                            ('std', 0.12067678318417162),\n","                                            ('b', 0.06849159240722656),\n","                                            ('shape', '(128, 32, 16, 16)'),\n","                                            ('total_numel', 4096000)]))])),\n","                ('layer2.5.conv2',\n","                 OrderedDict([('inputs',\n","                               OrderedDict([(0,\n","                                             OrderedDict([('min', 0.0),\n","                                                          ('max',\n","                                                           2.860159397125244),\n","                                                          ('avg_min', 0.0),\n","                                                          ('avg_max',\n","                                                           1.5307479592869226),\n","                                                          ('mean',\n","                                                           0.0416651029586792),\n","                                                          ('std',\n","                                                           0.12067678318417162),\n","                                                          ('b',\n","                                                           0.06849159240722656),\n","                                                          ('shape',\n","                                                           '(128, 32, 16, 16)'),\n","                                                          ('total_numel',\n","                                                           4096000)]))])),\n","                              ('output',\n","                               OrderedDict([('min', -3.63093638420105),\n","                                            ('max', 3.491438150405884),\n","                                            ('avg_min', -1.8045934618954957),\n","                                            ('avg_max', 1.93667802199738),\n","                                            ('mean', -0.03446662712097168),\n","                                            ('std', 0.3151897095302675),\n","                                            ('b', 0.2283224754333496),\n","                                            ('shape', '(128, 32, 16, 16)'),\n","                                            ('total_numel', 4096000)]))])),\n","                ('layer2.5.relu2',\n","                 OrderedDict([('inputs',\n","                               OrderedDict([(0,\n","                                             OrderedDict([('min', 0.0),\n","                                                          ('max',\n","                                                           17.90947914123535),\n","                                                          ('avg_min', 0.0),\n","                                                          ('avg_max',\n","                                                           8.651630766785427),\n","                                                          ('mean',\n","                                                           0.9297906494140625),\n","                                                          ('std',\n","                                                           1.18697314330187),\n","                                                          ('b',\n","                                                           0.9272167663574219),\n","                                                          ('shape',\n","                                                           '(128, 32, 16, 16)'),\n","                                                          ('total_numel',\n","                                                           4096000)]))])),\n","                              ('output',\n","                               OrderedDict([('min', 0.0),\n","                                            ('max', 17.90947914123535),\n","                                            ('avg_min', 0.0),\n","                                            ('avg_max', 8.651630766785427),\n","                                            ('mean', 0.9896835174560547),\n","                                            ('std', 1.124615846955153),\n","                                            ('b', 0.8804254455566406),\n","                                            ('shape', '(128, 32, 16, 16)'),\n","                                            ('total_numel', 4096000)]))])),\n","                ('layer2.5.residual_eltwiseadd',\n","                 OrderedDict([('inputs',\n","                               OrderedDict([(0,\n","                                             OrderedDict([('min', 0.0),\n","                                                          ('max',\n","                                                           17.741519927978516),\n","                                                          ('avg_min', 0.0),\n","                                                          ('avg_max',\n","                                                           8.522572115969227),\n","                                                          ('mean',\n","                                                           0.9642572784423828),\n","                                                          ('std',\n","                                                           1.0977759470990867),\n","                                                          ('b',\n","                                                           0.8563427124023437),\n","                                                          ('shape',\n","                                                           '(128, 32, 16, 16)'),\n","                                                          ('total_numel',\n","                                                           4096000)])),\n","                                            (1,\n","                                             OrderedDict([('min',\n","                                                           -3.63093638420105),\n","                                                          ('max',\n","                                                           3.491438150405884),\n","                                                          ('avg_min',\n","                                                           -1.8045934618954957),\n","                                                          ('avg_max',\n","                                                           1.93667802199738),\n","                                                          ('mean',\n","                                                           -0.03446662712097168),\n","                                                          ('std',\n","                                                           0.3151897095302675),\n","                                                          ('b',\n","                                                           0.2283224754333496),\n","                                                          ('shape',\n","                                                           '(128, 32, 16, 16)'),\n","                                                          ('total_numel',\n","                                                           4096000)]))])),\n","                              ('output',\n","                               OrderedDict([('min', 0.0),\n","                                            ('max', 17.90947914123535),\n","                                            ('avg_min', 0.0),\n","                                            ('avg_max', 8.651630766785427),\n","                                            ('mean', 0.9297906494140625),\n","                                            ('std', 1.18697314330187),\n","                                            ('b', 0.9272167663574219),\n","                                            ('shape', '(128, 32, 16, 16)'),\n","                                            ('total_numel', 4096000)]))])),\n","                ('layer2.6.conv1',\n","                 OrderedDict([('inputs',\n","                               OrderedDict([(0,\n","                                             OrderedDict([('min', 0.0),\n","                                                          ('max',\n","                                                           17.90947914123535),\n","                                                          ('avg_min', 0.0),\n","                                                          ('avg_max',\n","                                                           8.651630766785427),\n","                                                          ('mean',\n","                                                           0.9896835174560547),\n","                                                          ('std',\n","                                                           1.124615846955153),\n","                                                          ('b',\n","                                                           0.8804254455566406),\n","                                                          ('shape',\n","                                                           '(128, 32, 16, 16)'),\n","                                                          ('total_numel',\n","                                                           4096000)]))])),\n","                              ('output',\n","                               OrderedDict([('min', 0.0),\n","                                            ('max', 3.0475142002105713),\n","                                            ('avg_min', 0.0),\n","                                            ('avg_max', 1.3361971983437735),\n","                                            ('mean', -0.45325987243652344),\n","                                            ('std', 0.42418460940400066),\n","                                            ('b', 0.3298612976074219),\n","                                            ('shape', '(128, 32, 16, 16)'),\n","                                            ('total_numel', 4096000)]))])),\n","                ('layer2.6.relu1',\n","                 OrderedDict([('inputs',\n","                               OrderedDict([(0,\n","                                             OrderedDict([('min', 0.0),\n","                                                          ('max',\n","                                                           3.0475142002105713),\n","                                                          ('avg_min', 0.0),\n","                                                          ('avg_max',\n","                                                           1.3361971983437735),\n","                                                          ('mean',\n","                                                           -0.45325987243652344),\n","                                                          ('std',\n","                                                           0.42418460940400066),\n","                                                          ('b',\n","                                                           0.3298612976074219),\n","                                                          ('shape',\n","                                                           '(128, 32, 16, 16)'),\n","                                                          ('total_numel',\n","                                                           4096000)]))])),\n","                              ('output',\n","                               OrderedDict([('min', 0.0),\n","                                            ('max', 3.0475142002105713),\n","                                            ('avg_min', 0.0),\n","                                            ('avg_max', 1.3361971983437735),\n","                                            ('mean', 0.025003472805023193),\n","                                            ('std', 0.09391721309197143),\n","                                            ('b', 0.044091920852661136),\n","                                            ('shape', '(128, 32, 16, 16)'),\n","                                            ('total_numel', 4096000)]))])),\n","                ('layer2.6.conv2',\n","                 OrderedDict([('inputs',\n","                               OrderedDict([(0,\n","                                             OrderedDict([('min', 0.0),\n","                                                          ('max',\n","                                                           3.0475142002105713),\n","                                                          ('avg_min', 0.0),\n","                                                          ('avg_max',\n","                                                           1.3361971983437735),\n","                                                          ('mean',\n","                                                           0.025003472805023193),\n","                                                          ('std',\n","                                                           0.09391721309197143),\n","                                                          ('b',\n","                                                           0.044091920852661136),\n","                                                          ('shape',\n","                                                           '(128, 32, 16, 16)'),\n","                                                          ('total_numel',\n","                                                           4096000)]))])),\n","                              ('output',\n","                               OrderedDict([('min', -4.742549896240234),\n","                                            ('max', 6.551323890686035),\n","                                            ('avg_min', -1.8776231284844729),\n","                                            ('avg_max', 2.4092028150450657),\n","                                            ('mean', -0.02005104970932007),\n","                                            ('std', 0.3008239145116529),\n","                                            ('b', 0.2100850830078125),\n","                                            ('shape', '(128, 32, 16, 16)'),\n","                                            ('total_numel', 4096000)]))])),\n","                ('layer2.6.relu2',\n","                 OrderedDict([('inputs',\n","                               OrderedDict([(0,\n","                                             OrderedDict([('min', 0.0),\n","                                                          ('max',\n","                                                           21.038938522338867),\n","                                                          ('avg_min', 0.0),\n","                                                          ('avg_max',\n","                                                           9.043843783762151),\n","                                                          ('mean',\n","                                                           0.9696324615478515),\n","                                                          ('std',\n","                                                           1.2043654066415408),\n","                                                          ('b',\n","                                                           0.9408681030273438),\n","                                                          ('shape',\n","                                                           '(128, 32, 16, 16)'),\n","                                                          ('total_numel',\n","                                                           4096000)]))])),\n","                              ('output',\n","                               OrderedDict([('min', 0.0),\n","                                            ('max', 21.038938522338867),\n","                                            ('avg_min', 0.0),\n","                                            ('avg_max', 9.043843783762151),\n","                                            ('mean', 1.0211082763671875),\n","                                            ('std', 1.1508385561512173),\n","                                            ('b', 0.9007834625244141),\n","                                            ('shape', '(128, 32, 16, 16)'),\n","                                            ('total_numel', 4096000)]))])),\n","                ('layer2.6.residual_eltwiseadd',\n","                 OrderedDict([('inputs',\n","                               OrderedDict([(0,\n","                                             OrderedDict([('min', 0.0),\n","                                                          ('max',\n","                                                           17.90947914123535),\n","                                                          ('avg_min', 0.0),\n","                                                          ('avg_max',\n","                                                           8.651630766785427),\n","                                                          ('mean',\n","                                                           0.9896835174560547),\n","                                                          ('std',\n","                                                           1.124615846955153),\n","                                                          ('b',\n","                                                           0.8804254455566406),\n","                                                          ('shape',\n","                                                           '(128, 32, 16, 16)'),\n","                                                          ('total_numel',\n","                                                           4096000)])),\n","                                            (1,\n","                                             OrderedDict([('min',\n","                                                           -4.742549896240234),\n","                                                          ('max',\n","                                                           6.551323890686035),\n","                                                          ('avg_min',\n","                                                           -1.8776231284844729),\n","                                                          ('avg_max',\n","                                                           2.4092028150450657),\n","                                                          ('mean',\n","                                                           -0.02005104970932007),\n","                                                          ('std',\n","                                                           0.3008239145116529),\n","                                                          ('b',\n","                                                           0.2100850830078125),\n","                                                          ('shape',\n","                                                           '(128, 32, 16, 16)'),\n","                                                          ('total_numel',\n","                                                           4096000)]))])),\n","                              ('output',\n","                               OrderedDict([('min', 0.0),\n","                                            ('max', 21.038938522338867),\n","                                            ('avg_min', 0.0),\n","                                            ('avg_max', 9.043843783762151),\n","                                            ('mean', 0.9696324615478515),\n","                                            ('std', 1.2043654066415408),\n","                                            ('b', 0.9408681030273438),\n","                                            ('shape', '(128, 32, 16, 16)'),\n","                                            ('total_numel', 4096000)]))])),\n","                ('layer2.7.conv1',\n","                 OrderedDict([('inputs',\n","                               OrderedDict([(0,\n","                                             OrderedDict([('min', 0.0),\n","                                                          ('max',\n","                                                           21.038938522338867),\n","                                                          ('avg_min', 0.0),\n","                                                          ('avg_max',\n","                                                           9.043843783762151),\n","                                                          ('mean',\n","                                                           1.0211082763671875),\n","                                                          ('std',\n","                                                           1.1508385561512173),\n","                                                          ('b',\n","                                                           0.9007834625244141),\n","                                                          ('shape',\n","                                                           '(128, 32, 16, 16)'),\n","                                                          ('total_numel',\n","                                                           4096000)]))])),\n","                              ('output',\n","                               OrderedDict([('min', 0.0),\n","                                            ('max', 2.691556215286255),\n","                                            ('avg_min', 0.0),\n","                                            ('avg_max', 1.2107010773926592),\n","                                            ('mean', -0.37589942169189455),\n","                                            ('std', 0.3763241747363127),\n","                                            ('b', 0.29255635833740234),\n","                                            ('shape', '(128, 32, 16, 16)'),\n","                                            ('total_numel', 4096000)]))])),\n","                ('layer2.7.relu1',\n","                 OrderedDict([('inputs',\n","                               OrderedDict([(0,\n","                                             OrderedDict([('min', 0.0),\n","                                                          ('max',\n","                                                           2.691556215286255),\n","                                                          ('avg_min', 0.0),\n","                                                          ('avg_max',\n","                                                           1.2107010773926592),\n","                                                          ('mean',\n","                                                           -0.37589942169189455),\n","                                                          ('std',\n","                                                           0.3763241747363127),\n","                                                          ('b',\n","                                                           0.29255635833740234),\n","                                                          ('shape',\n","                                                           '(128, 32, 16, 16)'),\n","                                                          ('total_numel',\n","                                                           4096000)]))])),\n","                              ('output',\n","                               OrderedDict([('min', 0.0),\n","                                            ('max', 2.691556215286255),\n","                                            ('avg_min', 0.0),\n","                                            ('avg_max', 1.2107010773926592),\n","                                            ('mean', 0.023559682846069335),\n","                                            ('std', 0.08461349759048455),\n","                                            ('b', 0.04092980861663818),\n","                                            ('shape', '(128, 32, 16, 16)'),\n","                                            ('total_numel', 4096000)]))])),\n","                ('layer2.7.conv2',\n","                 OrderedDict([('inputs',\n","                               OrderedDict([(0,\n","                                             OrderedDict([('min', 0.0),\n","                                                          ('max',\n","                                                           2.691556215286255),\n","                                                          ('avg_min', 0.0),\n","                                                          ('avg_max',\n","                                                           1.2107010773926592),\n","                                                          ('mean',\n","                                                           0.023559682846069335),\n","                                                          ('std',\n","                                                           0.08461349759048455),\n","                                                          ('b',\n","                                                           0.04092980861663818),\n","                                                          ('shape',\n","                                                           '(128, 32, 16, 16)'),\n","                                                          ('total_numel',\n","                                                           4096000)]))])),\n","                              ('output',\n","                               OrderedDict([('min', -3.8545455932617188),\n","                                            ('max', 8.511265754699707),\n","                                            ('avg_min', -1.6620864242716935),\n","                                            ('avg_max', 2.0810392440287404),\n","                                            ('mean', -0.005008552551269531),\n","                                            ('std', 0.26421849084409416),\n","                                            ('b', 0.18171722030639648),\n","                                            ('shape', '(128, 32, 16, 16)'),\n","                                            ('total_numel', 4096000)]))])),\n","                ('layer2.7.relu2',\n","                 OrderedDict([('inputs',\n","                               OrderedDict([(0,\n","                                             OrderedDict([('min', 0.0),\n","                                                          ('max',\n","                                                           22.57757568359375),\n","                                                          ('avg_min', 0.0),\n","                                                          ('avg_max',\n","                                                           9.365338555244728),\n","                                                          ('mean',\n","                                                           1.0160997314453124),\n","                                                          ('std',\n","                                                           1.2097189685667313),\n","                                                          ('b',\n","                                                           0.9450925750732422),\n","                                                          ('shape',\n","                                                           '(128, 32, 16, 16)'),\n","                                                          ('total_numel',\n","                                                           4096000)]))])),\n","                              ('output',\n","                               OrderedDict([('min', 0.0),\n","                                            ('max', 22.57757568359375),\n","                                            ('avg_min', 0.0),\n","                                            ('avg_max', 9.365338555244728),\n","                                            ('mean', 1.0540851593017577),\n","                                            ('std', 1.1699037717714555),\n","                                            ('b', 0.9155070953369141),\n","                                            ('shape', '(128, 32, 16, 16)'),\n","                                            ('total_numel', 4096000)]))])),\n","                ('layer2.7.residual_eltwiseadd',\n","                 OrderedDict([('inputs',\n","                               OrderedDict([(0,\n","                                             OrderedDict([('min', 0.0),\n","                                                          ('max',\n","                                                           21.038938522338867),\n","                                                          ('avg_min', 0.0),\n","                                                          ('avg_max',\n","                                                           9.043843783762151),\n","                                                          ('mean',\n","                                                           1.0211082763671875),\n","                                                          ('std',\n","                                                           1.1508385561512173),\n","                                                          ('b',\n","                                                           0.9007834625244141),\n","                                                          ('shape',\n","                                                           '(128, 32, 16, 16)'),\n","                                                          ('total_numel',\n","                                                           4096000)])),\n","                                            (1,\n","                                             OrderedDict([('min',\n","                                                           -3.8545455932617188),\n","                                                          ('max',\n","                                                           8.511265754699707),\n","                                                          ('avg_min',\n","                                                           -1.6620864242716935),\n","                                                          ('avg_max',\n","                                                           2.0810392440287404),\n","                                                          ('mean',\n","                                                           -0.005008552551269531),\n","                                                          ('std',\n","                                                           0.26421849084409416),\n","                                                          ('b',\n","                                                           0.18171722030639648),\n","                                                          ('shape',\n","                                                           '(128, 32, 16, 16)'),\n","                                                          ('total_numel',\n","                                                           4096000)]))])),\n","                              ('output',\n","                               OrderedDict([('min', 0.0),\n","                                            ('max', 22.57757568359375),\n","                                            ('avg_min', 0.0),\n","                                            ('avg_max', 9.365338555244728),\n","                                            ('mean', 1.0160997314453124),\n","                                            ('std', 1.2097189685667313),\n","                                            ('b', 0.9450925750732422),\n","                                            ('shape', '(128, 32, 16, 16)'),\n","                                            ('total_numel', 4096000)]))])),\n","                ('layer2.8.conv1',\n","                 OrderedDict([('inputs',\n","                               OrderedDict([(0,\n","                                             OrderedDict([('min', 0.0),\n","                                                          ('max',\n","                                                           22.57757568359375),\n","                                                          ('avg_min', 0.0),\n","                                                          ('avg_max',\n","                                                           9.365338555244728),\n","                                                          ('mean',\n","                                                           1.0540851593017577),\n","                                                          ('std',\n","                                                           1.1699037717714555),\n","                                                          ('b',\n","                                                           0.9155070953369141),\n","                                                          ('shape',\n","                                                           '(128, 32, 16, 16)'),\n","                                                          ('total_numel',\n","                                                           4096000)]))])),\n","                              ('output',\n","                               OrderedDict([('min', 0.0),\n","                                            ('max', 2.326397180557251),\n","                                            ('avg_min', 0.0),\n","                                            ('avg_max', 1.2259771152269434),\n","                                            ('mean', -0.3519814682006836),\n","                                            ('std', 0.3711620208581949),\n","                                            ('b', 0.29627001953125),\n","                                            ('shape', '(128, 32, 16, 16)'),\n","                                            ('total_numel', 4096000)]))])),\n","                ('layer2.8.relu1',\n","                 OrderedDict([('inputs',\n","                               OrderedDict([(0,\n","                                             OrderedDict([('min', 0.0),\n","                                                          ('max',\n","                                                           2.326397180557251),\n","                                                          ('avg_min', 0.0),\n","                                                          ('avg_max',\n","                                                           1.2259771152269434),\n","                                                          ('mean',\n","                                                           -0.3519814682006836),\n","                                                          ('std',\n","                                                           0.3711620208581949),\n","                                                          ('b',\n","                                                           0.29627001953125),\n","                                                          ('shape',\n","                                                           '(128, 32, 16, 16)'),\n","                                                          ('total_numel',\n","                                                           4096000)]))])),\n","                              ('output',\n","                               OrderedDict([('min', 0.0),\n","                                            ('max', 2.326397180557251),\n","                                            ('avg_min', 0.0),\n","                                            ('avg_max', 1.2259771152269434),\n","                                            ('mean', 0.02305075693130493),\n","                                            ('std', 0.085411583508845),\n","                                            ('b', 0.040562756538391115),\n","                                            ('shape', '(128, 32, 16, 16)'),\n","                                            ('total_numel', 4096000)]))])),\n","                ('layer2.8.conv2',\n","                 OrderedDict([('inputs',\n","                               OrderedDict([(0,\n","                                             OrderedDict([('min', 0.0),\n","                                                          ('max',\n","                                                           2.326397180557251),\n","                                                          ('avg_min', 0.0),\n","                                                          ('avg_max',\n","                                                           1.2259771152269434),\n","                                                          ('mean',\n","                                                           0.02305075693130493),\n","                                                          ('std',\n","                                                           0.085411583508845),\n","                                                          ('b',\n","                                                           0.040562756538391115),\n","                                                          ('shape',\n","                                                           '(128, 32, 16, 16)'),\n","                                                          ('total_numel',\n","                                                           4096000)]))])),\n","                              ('output',\n","                               OrderedDict([('min', -3.4414641857147217),\n","                                            ('max', 5.7318806648254395),\n","                                            ('avg_min', -1.5343473049421983),\n","                                            ('avg_max', 2.088723470508249),\n","                                            ('mean', 0.010238233089447022),\n","                                            ('std', 0.26520647893848154),\n","                                            ('b', 0.1784181251525879),\n","                                            ('shape', '(128, 32, 16, 16)'),\n","                                            ('total_numel', 4096000)]))])),\n","                ('layer2.8.relu2',\n","                 OrderedDict([('inputs',\n","                               OrderedDict([(0,\n","                                             OrderedDict([('min', 0.0),\n","                                                          ('max',\n","                                                           23.050748825073242),\n","                                                          ('avg_min', 0.0),\n","                                                          ('avg_max',\n","                                                           9.55260952890111),\n","                                                          ('mean',\n","                                                           1.064323486328125),\n","                                                          ('std',\n","                                                           1.2147998635561719),\n","                                                          ('b',\n","                                                           0.9461611022949219),\n","                                                          ('shape',\n","                                                           '(128, 32, 16, 16)'),\n","                                                          ('total_numel',\n","                                                           4096000)]))])),\n","                              ('output',\n","                               OrderedDict([('min', 0.0),\n","                                            ('max', 23.050748825073242),\n","                                            ('avg_min', 0.0),\n","                                            ('avg_max', 9.55260952890111),\n","                                            ('mean', 1.0944281921386718),\n","                                            ('std', 1.1823780627619835),\n","                                            ('b', 0.9226607208251953),\n","                                            ('shape', '(128, 32, 16, 16)'),\n","                                            ('total_numel', 4096000)]))])),\n","                ('layer2.8.residual_eltwiseadd',\n","                 OrderedDict([('inputs',\n","                               OrderedDict([(0,\n","                                             OrderedDict([('min', 0.0),\n","                                                          ('max',\n","                                                           22.57757568359375),\n","                                                          ('avg_min', 0.0),\n","                                                          ('avg_max',\n","                                                           9.365338555244728),\n","                                                          ('mean',\n","                                                           1.0540851593017577),\n","                                                          ('std',\n","                                                           1.1699037717714555),\n","                                                          ('b',\n","                                                           0.9155070953369141),\n","                                                          ('shape',\n","                                                           '(128, 32, 16, 16)'),\n","                                                          ('total_numel',\n","                                                           4096000)])),\n","                                            (1,\n","                                             OrderedDict([('min',\n","                                                           -3.4414641857147217),\n","                                                          ('max',\n","                                                           5.7318806648254395),\n","                                                          ('avg_min',\n","                                                           -1.5343473049421983),\n","                                                          ('avg_max',\n","                                                           2.088723470508249),\n","                                                          ('mean',\n","                                                           0.010238233089447022),\n","                                                          ('std',\n","                                                           0.26520647893848154),\n","                                                          ('b',\n","                                                           0.1784181251525879),\n","                                                          ('shape',\n","                                                           '(128, 32, 16, 16)'),\n","                                                          ('total_numel',\n","                                                           4096000)]))])),\n","                              ('output',\n","                               OrderedDict([('min', 0.0),\n","                                            ('max', 23.050748825073242),\n","                                            ('avg_min', 0.0),\n","                                            ('avg_max', 9.55260952890111),\n","                                            ('mean', 1.064323486328125),\n","                                            ('std', 1.2147998635561719),\n","                                            ('b', 0.9461611022949219),\n","                                            ('shape', '(128, 32, 16, 16)'),\n","                                            ('total_numel', 4096000)]))])),\n","                ('layer3.0.conv1',\n","                 OrderedDict([('inputs',\n","                               OrderedDict([(0,\n","                                             OrderedDict([('min', 0.0),\n","                                                          ('max',\n","                                                           23.050748825073242),\n","                                                          ('avg_min', 0.0),\n","                                                          ('avg_max',\n","                                                           9.55260952890111),\n","                                                          ('mean',\n","                                                           1.0944281921386718),\n","                                                          ('std',\n","                                                           1.1823780627619835),\n","                                                          ('b',\n","                                                           0.9226607208251953),\n","                                                          ('shape',\n","                                                           '(128, 32, 16, 16)'),\n","                                                          ('total_numel',\n","                                                           4096000)]))])),\n","                              ('output',\n","                               OrderedDict([('min', 0.0),\n","                                            ('max', 5.928091526031494),\n","                                            ('avg_min', 0.0),\n","                                            ('avg_max', 2.694959983203275),\n","                                            ('mean', -0.10242862129211426),\n","                                            ('std', 0.5815309366539708),\n","                                            ('b', 0.45482650756835935),\n","                                            ('shape', '(128, 64, 8, 8)'),\n","                                            ('total_numel', 2048000)]))])),\n","                ('layer3.0.relu1',\n","                 OrderedDict([('inputs',\n","                               OrderedDict([(0,\n","                                             OrderedDict([('min', 0.0),\n","                                                          ('max',\n","                                                           5.928091526031494),\n","                                                          ('avg_min', 0.0),\n","                                                          ('avg_max',\n","                                                           2.694959983203275),\n","                                                          ('mean',\n","                                                           -0.10242862129211426),\n","                                                          ('std',\n","                                                           0.5815309366539708),\n","                                                          ('b',\n","                                                           0.45482650756835935),\n","                                                          ('shape',\n","                                                           '(128, 64, 8, 8)'),\n","                                                          ('total_numel',\n","                                                           2048000)]))])),\n","                              ('output',\n","                               OrderedDict([('min', 0.0),\n","                                            ('max', 5.928091526031494),\n","                                            ('avg_min', 0.0),\n","                                            ('avg_max', 2.694959983203275),\n","                                            ('mean', 0.18174277877807618),\n","                                            ('std', 0.3247772920929487),\n","                                            ('b', 0.23612217712402345),\n","                                            ('shape', '(128, 64, 8, 8)'),\n","                                            ('total_numel', 2048000)]))])),\n","                ('layer3.0.conv2',\n","                 OrderedDict([('inputs',\n","                               OrderedDict([(0,\n","                                             OrderedDict([('min', 0.0),\n","                                                          ('max',\n","                                                           5.928091526031494),\n","                                                          ('avg_min', 0.0),\n","                                                          ('avg_max',\n","                                                           2.694959983203275),\n","                                                          ('mean',\n","                                                           0.18174277877807618),\n","                                                          ('std',\n","                                                           0.3247772920929487),\n","                                                          ('b',\n","                                                           0.23612217712402345),\n","                                                          ('shape',\n","                                                           '(128, 64, 8, 8)'),\n","                                                          ('total_numel',\n","                                                           2048000)]))])),\n","                              ('output',\n","                               OrderedDict([('min', -6.2018208503723145),\n","                                            ('max', 11.787038803100586),\n","                                            ('avg_min', -3.4687120649906267),\n","                                            ('avg_max', 5.188910490111849),\n","                                            ('mean', 0.10037873649597168),\n","                                            ('std', 0.890034172173585),\n","                                            ('b', 0.6416780242919922),\n","                                            ('shape', '(128, 64, 8, 8)'),\n","                                            ('total_numel', 2048000)]))])),\n","                ('layer3.0.relu2',\n","                 OrderedDict([('inputs',\n","                               OrderedDict([(0,\n","                                             OrderedDict([('min', 0.0),\n","                                                          ('max',\n","                                                           14.916658401489258),\n","                                                          ('avg_min', 0.0),\n","                                                          ('avg_max',\n","                                                           6.778487668138527),\n","                                                          ('mean',\n","                                                           0.131059326171875),\n","                                                          ('std',\n","                                                           1.176604803978844),\n","                                                          ('b',\n","                                                           0.8547882537841797),\n","                                                          ('shape',\n","                                                           '(128, 64, 8, 8)'),\n","                                                          ('total_numel',\n","                                                           2048000)]))])),\n","                              ('output',\n","                               OrderedDict([('min', 0.0),\n","                                            ('max', 14.916658401489258),\n","                                            ('avg_min', 0.0),\n","                                            ('avg_max', 6.778487668138527),\n","                                            ('mean', 0.4827768859863281),\n","                                            ('std', 0.8296447581975598),\n","                                            ('b', 0.6072489776611328),\n","                                            ('shape', '(128, 64, 8, 8)'),\n","                                            ('total_numel', 2048000)]))])),\n","                ('layer3.0.downsample.0',\n","                 OrderedDict([('inputs',\n","                               OrderedDict([(0,\n","                                             OrderedDict([('min', 0.0),\n","                                                          ('max',\n","                                                           23.050748825073242),\n","                                                          ('avg_min', 0.0),\n","                                                          ('avg_max',\n","                                                           9.55260952890111),\n","                                                          ('mean',\n","                                                           1.0944281921386718),\n","                                                          ('std',\n","                                                           1.1823780627619835),\n","                                                          ('b',\n","                                                           0.9226607208251953),\n","                                                          ('shape',\n","                                                           '(128, 32, 16, 16)'),\n","                                                          ('total_numel',\n","                                                           4096000)]))])),\n","                              ('output',\n","                               OrderedDict([('min', -4.699625015258789),\n","                                            ('max', 6.177471160888672),\n","                                            ('avg_min', -1.916971394506927),\n","                                            ('avg_max', 3.2439447377596773),\n","                                            ('mean', 0.030680596351623537),\n","                                            ('std', 0.4811153154040189),\n","                                            ('b', 0.33399266815185547),\n","                                            ('shape', '(128, 64, 8, 8)'),\n","                                            ('total_numel', 2048000)]))])),\n","                ('layer3.0.residual_eltwiseadd',\n","                 OrderedDict([('inputs',\n","                               OrderedDict([(0,\n","                                             OrderedDict([('min',\n","                                                           -4.699625015258789),\n","                                                          ('max',\n","                                                           6.177471160888672),\n","                                                          ('avg_min',\n","                                                           -1.916971394506927),\n","                                                          ('avg_max',\n","                                                           3.2439447377596773),\n","                                                          ('mean',\n","                                                           0.030680596351623537),\n","                                                          ('std',\n","                                                           0.4811153154040189),\n","                                                          ('b',\n","                                                           0.33399266815185547),\n","                                                          ('shape',\n","                                                           '(128, 64, 8, 8)'),\n","                                                          ('total_numel',\n","                                                           2048000)])),\n","                                            (1,\n","                                             OrderedDict([('min',\n","                                                           -6.2018208503723145),\n","                                                          ('max',\n","                                                           11.787038803100586),\n","                                                          ('avg_min',\n","                                                           -3.4687120649906267),\n","                                                          ('avg_max',\n","                                                           5.188910490111849),\n","                                                          ('mean',\n","                                                           0.10037873649597168),\n","                                                          ('std',\n","                                                           0.890034172173585),\n","                                                          ('b',\n","                                                           0.6416780242919922),\n","                                                          ('shape',\n","                                                           '(128, 64, 8, 8)'),\n","                                                          ('total_numel',\n","                                                           2048000)]))])),\n","                              ('output',\n","                               OrderedDict([('min', 0.0),\n","                                            ('max', 14.916658401489258),\n","                                            ('avg_min', 0.0),\n","                                            ('avg_max', 6.778487668138527),\n","                                            ('mean', 0.131059326171875),\n","                                            ('std', 1.176604803978844),\n","                                            ('b', 0.8547882537841797),\n","                                            ('shape', '(128, 64, 8, 8)'),\n","                                            ('total_numel', 2048000)]))])),\n","                ('layer3.1.conv1',\n","                 OrderedDict([('inputs',\n","                               OrderedDict([(0,\n","                                             OrderedDict([('min', 0.0),\n","                                                          ('max',\n","                                                           14.916658401489258),\n","                                                          ('avg_min', 0.0),\n","                                                          ('avg_max',\n","                                                           6.778487668138527),\n","                                                          ('mean',\n","                                                           0.4827768859863281),\n","                                                          ('std',\n","                                                           0.8296447581975598),\n","                                                          ('b',\n","                                                           0.6072489776611328),\n","                                                          ('shape',\n","                                                           '(128, 64, 8, 8)'),\n","                                                          ('total_numel',\n","                                                           2048000)]))])),\n","                              ('output',\n","                               OrderedDict([('min', 0.0),\n","                                            ('max', 3.1925389766693115),\n","                                            ('avg_min', 0.0),\n","                                            ('avg_max', 1.5244309419971473),\n","                                            ('mean', -0.3393576126098633),\n","                                            ('std', 0.4545012018336824),\n","                                            ('b', 0.35456957244873044),\n","                                            ('shape', '(128, 64, 8, 8)'),\n","                                            ('total_numel', 2048000)]))])),\n","                ('layer3.1.relu1',\n","                 OrderedDict([('inputs',\n","                               OrderedDict([(0,\n","                                             OrderedDict([('min', 0.0),\n","                                                          ('max',\n","                                                           3.1925389766693115),\n","                                                          ('avg_min', 0.0),\n","                                                          ('avg_max',\n","                                                           1.5244309419971473),\n","                                                          ('mean',\n","                                                           -0.3393576126098633),\n","                                                          ('std',\n","                                                           0.4545012018336824),\n","                                                          ('b',\n","                                                           0.35456957244873044),\n","                                                          ('shape',\n","                                                           '(128, 64, 8, 8)'),\n","                                                          ('total_numel',\n","                                                           2048000)]))])),\n","                              ('output',\n","                               OrderedDict([('min', 0.0),\n","                                            ('max', 3.1925389766693115),\n","                                            ('avg_min', 0.0),\n","                                            ('avg_max', 1.5244309419971473),\n","                                            ('mean', 0.053858756065368656),\n","                                            ('std', 0.14568146981909236),\n","                                            ('b', 0.08626000595092774),\n","                                            ('shape', '(128, 64, 8, 8)'),\n","                                            ('total_numel', 2048000)]))])),\n","                ('layer3.1.conv2',\n","                 OrderedDict([('inputs',\n","                               OrderedDict([(0,\n","                                             OrderedDict([('min', 0.0),\n","                                                          ('max',\n","                                                           3.1925389766693115),\n","                                                          ('avg_min', 0.0),\n","                                                          ('avg_max',\n","                                                           1.5244309419971473),\n","                                                          ('mean',\n","                                                           0.053858756065368656),\n","                                                          ('std',\n","                                                           0.14568146981909236),\n","                                                          ('b',\n","                                                           0.08626000595092774),\n","                                                          ('shape',\n","                                                           '(128, 64, 8, 8)'),\n","                                                          ('total_numel',\n","                                                           2048000)]))])),\n","                              ('output',\n","                               OrderedDict([('min', -4.983215808868408),\n","                                            ('max', 9.632580757141113),\n","                                            ('avg_min', -2.5714176718187454),\n","                                            ('avg_max', 2.911819152019224),\n","                                            ('mean', -0.1461656837463379),\n","                                            ('std', 0.48828580466625715),\n","                                            ('b', 0.35475289916992186),\n","                                            ('shape', '(128, 64, 8, 8)'),\n","                                            ('total_numel', 2048000)]))])),\n","                ('layer3.1.relu2',\n","                 OrderedDict([('inputs',\n","                               OrderedDict([(0,\n","                                             OrderedDict([('min', 0.0),\n","                                                          ('max',\n","                                                           15.260210037231445),\n","                                                          ('avg_min', 0.0),\n","                                                          ('avg_max',\n","                                                           7.417616809173027),\n","                                                          ('mean',\n","                                                           0.3366112060546875),\n","                                                          ('std',\n","                                                           0.9985926910762458),\n","                                                          ('b',\n","                                                           0.7257076721191407),\n","                                                          ('shape',\n","                                                           '(128, 64, 8, 8)'),\n","                                                          ('total_numel',\n","                                                           2048000)]))])),\n","                              ('output',\n","                               OrderedDict([('min', 0.0),\n","                                            ('max', 15.260210037231445),\n","                                            ('avg_min', 0.0),\n","                                            ('avg_max', 7.417616809173027),\n","                                            ('mean', 0.5154522552490234),\n","                                            ('std', 0.8456940494605415),\n","                                            ('b', 0.6057228240966797),\n","                                            ('shape', '(128, 64, 8, 8)'),\n","                                            ('total_numel', 2048000)]))])),\n","                ('layer3.1.residual_eltwiseadd',\n","                 OrderedDict([('inputs',\n","                               OrderedDict([(0,\n","                                             OrderedDict([('min', 0.0),\n","                                                          ('max',\n","                                                           14.916658401489258),\n","                                                          ('avg_min', 0.0),\n","                                                          ('avg_max',\n","                                                           6.778487668138527),\n","                                                          ('mean',\n","                                                           0.4827768859863281),\n","                                                          ('std',\n","                                                           0.8296447581975598),\n","                                                          ('b',\n","                                                           0.6072489776611328),\n","                                                          ('shape',\n","                                                           '(128, 64, 8, 8)'),\n","                                                          ('total_numel',\n","                                                           2048000)])),\n","                                            (1,\n","                                             OrderedDict([('min',\n","                                                           -4.983215808868408),\n","                                                          ('max',\n","                                                           9.632580757141113),\n","                                                          ('avg_min',\n","                                                           -2.5714176718187454),\n","                                                          ('avg_max',\n","                                                           2.911819152019224),\n","                                                          ('mean',\n","                                                           -0.1461656837463379),\n","                                                          ('std',\n","                                                           0.48828580466625715),\n","                                                          ('b',\n","                                                           0.35475289916992186),\n","                                                          ('shape',\n","                                                           '(128, 64, 8, 8)'),\n","                                                          ('total_numel',\n","                                                           2048000)]))])),\n","                              ('output',\n","                               OrderedDict([('min', 0.0),\n","                                            ('max', 15.260210037231445),\n","                                            ('avg_min', 0.0),\n","                                            ('avg_max', 7.417616809173027),\n","                                            ('mean', 0.3366112060546875),\n","                                            ('std', 0.9985926910762458),\n","                                            ('b', 0.7257076721191407),\n","                                            ('shape', '(128, 64, 8, 8)'),\n","                                            ('total_numel', 2048000)]))])),\n","                ('layer3.2.conv1',\n","                 OrderedDict([('inputs',\n","                               OrderedDict([(0,\n","                                             OrderedDict([('min', 0.0),\n","                                                          ('max',\n","                                                           15.260210037231445),\n","                                                          ('avg_min', 0.0),\n","                                                          ('avg_max',\n","                                                           7.417616809173027),\n","                                                          ('mean',\n","                                                           0.5154522552490234),\n","                                                          ('std',\n","                                                           0.8456940494605415),\n","                                                          ('b',\n","                                                           0.6057228240966797),\n","                                                          ('shape',\n","                                                           '(128, 64, 8, 8)'),\n","                                                          ('total_numel',\n","                                                           2048000)]))])),\n","                              ('output',\n","                               OrderedDict([('min', 0.0),\n","                                            ('max', 2.814661741256714),\n","                                            ('avg_min', 0.0),\n","                                            ('avg_max', 1.2185429923144537),\n","                                            ('mean', -0.3287262115478516),\n","                                            ('std', 0.36827198144759254),\n","                                            ('b', 0.2841187973022461),\n","                                            ('shape', '(128, 64, 8, 8)'),\n","                                            ('total_numel', 2048000)]))])),\n","                ('layer3.2.relu1',\n","                 OrderedDict([('inputs',\n","                               OrderedDict([(0,\n","                                             OrderedDict([('min', 0.0),\n","                                                          ('max',\n","                                                           2.814661741256714),\n","                                                          ('avg_min', 0.0),\n","                                                          ('avg_max',\n","                                                           1.2185429923144537),\n","                                                          ('mean',\n","                                                           -0.3287262115478516),\n","                                                          ('std',\n","                                                           0.36827198144759254),\n","                                                          ('b',\n","                                                           0.2841187973022461),\n","                                                          ('shape',\n","                                                           '(128, 64, 8, 8)'),\n","                                                          ('total_numel',\n","                                                           2048000)]))])),\n","                              ('output',\n","                               OrderedDict([('min', 0.0),\n","                                            ('max', 2.814661741256714),\n","                                            ('avg_min', 0.0),\n","                                            ('avg_max', 1.2185429923144537),\n","                                            ('mean', 0.031223477840423584),\n","                                            ('std', 0.09986180531757576),\n","                                            ('b', 0.052706332206726075),\n","                                            ('shape', '(128, 64, 8, 8)'),\n","                                            ('total_numel', 2048000)]))])),\n","                ('layer3.2.conv2',\n","                 OrderedDict([('inputs',\n","                               OrderedDict([(0,\n","                                             OrderedDict([('min', 0.0),\n","                                                          ('max',\n","                                                           2.814661741256714),\n","                                                          ('avg_min', 0.0),\n","                                                          ('avg_max',\n","                                                           1.2185429923144537),\n","                                                          ('mean',\n","                                                           0.031223477840423584),\n","                                                          ('std',\n","                                                           0.09986180531757576),\n","                                                          ('b',\n","                                                           0.052706332206726075),\n","                                                          ('shape',\n","                                                           '(128, 64, 8, 8)'),\n","                                                          ('total_numel',\n","                                                           2048000)]))])),\n","                              ('output',\n","                               OrderedDict([('min', -5.308638572692871),\n","                                            ('max', 6.281679630279541),\n","                                            ('avg_min', -2.3598061861618986),\n","                                            ('avg_max', 2.2862196279068554),\n","                                            ('mean', -0.18199658203125),\n","                                            ('std', 0.39849897561127107),\n","                                            ('b', 0.2837679748535156),\n","                                            ('shape', '(128, 64, 8, 8)'),\n","                                            ('total_numel', 2048000)]))])),\n","                ('layer3.2.relu2',\n","                 OrderedDict([('inputs',\n","                               OrderedDict([(0,\n","                                             OrderedDict([('min', 0.0),\n","                                                          ('max',\n","                                                           16.18870735168457),\n","                                                          ('avg_min', 0.0),\n","                                                          ('avg_max',\n","                                                           7.871765061554286),\n","                                                          ('mean',\n","                                                           0.3334556884765625),\n","                                                          ('std',\n","                                                           0.9792386145164805),\n","                                                          ('b',\n","                                                           0.6987550506591796),\n","                                                          ('shape',\n","                                                           '(128, 64, 8, 8)'),\n","                                                          ('total_numel',\n","                                                           2048000)]))])),\n","                              ('output',\n","                               OrderedDict([('min', 0.0),\n","                                            ('max', 16.18870735168457),\n","                                            ('avg_min', 0.0),\n","                                            ('avg_max', 7.871765061554286),\n","                                            ('mean', 0.4938083267211914),\n","                                            ('std', 0.8503957388167325),\n","                                            ('b', 0.5956240997314454),\n","                                            ('shape', '(128, 64, 8, 8)'),\n","                                            ('total_numel', 2048000)]))])),\n","                ('layer3.2.residual_eltwiseadd',\n","                 OrderedDict([('inputs',\n","                               OrderedDict([(0,\n","                                             OrderedDict([('min', 0.0),\n","                                                          ('max',\n","                                                           15.260210037231445),\n","                                                          ('avg_min', 0.0),\n","                                                          ('avg_max',\n","                                                           7.417616809173027),\n","                                                          ('mean',\n","                                                           0.5154522552490234),\n","                                                          ('std',\n","                                                           0.8456940494605415),\n","                                                          ('b',\n","                                                           0.6057228240966797),\n","                                                          ('shape',\n","                                                           '(128, 64, 8, 8)'),\n","                                                          ('total_numel',\n","                                                           2048000)])),\n","                                            (1,\n","                                             OrderedDict([('min',\n","                                                           -5.308638572692871),\n","                                                          ('max',\n","                                                           6.281679630279541),\n","                                                          ('avg_min',\n","                                                           -2.3598061861618986),\n","                                                          ('avg_max',\n","                                                           2.2862196279068554),\n","                                                          ('mean',\n","                                                           -0.18199658203125),\n","                                                          ('std',\n","                                                           0.39849897561127107),\n","                                                          ('b',\n","                                                           0.2837679748535156),\n","                                                          ('shape',\n","                                                           '(128, 64, 8, 8)'),\n","                                                          ('total_numel',\n","                                                           2048000)]))])),\n","                              ('output',\n","                               OrderedDict([('min', 0.0),\n","                                            ('max', 16.18870735168457),\n","                                            ('avg_min', 0.0),\n","                                            ('avg_max', 7.871765061554286),\n","                                            ('mean', 0.3334556884765625),\n","                                            ('std', 0.9792386145164805),\n","                                            ('b', 0.6987550506591796),\n","                                            ('shape', '(128, 64, 8, 8)'),\n","                                            ('total_numel', 2048000)]))])),\n","                ('layer3.3.conv1',\n","                 OrderedDict([('inputs',\n","                               OrderedDict([(0,\n","                                             OrderedDict([('min', 0.0),\n","                                                          ('max',\n","                                                           16.18870735168457),\n","                                                          ('avg_min', 0.0),\n","                                                          ('avg_max',\n","                                                           7.871765061554286),\n","                                                          ('mean',\n","                                                           0.4938083267211914),\n","                                                          ('std',\n","                                                           0.8503957388167325),\n","                                                          ('b',\n","                                                           0.5956240997314454),\n","                                                          ('shape',\n","                                                           '(128, 64, 8, 8)'),\n","                                                          ('total_numel',\n","                                                           2048000)]))])),\n","                              ('output',\n","                               OrderedDict([('min', 0.0),\n","                                            ('max', 2.492131233215332),\n","                                            ('avg_min', 0.0),\n","                                            ('avg_max', 1.1422941664898427),\n","                                            ('mean', -0.3452389373779297),\n","                                            ('std', 0.34309224401439337),\n","                                            ('b', 0.26466763305664065),\n","                                            ('shape', '(128, 64, 8, 8)'),\n","                                            ('total_numel', 2048000)]))])),\n","                ('layer3.3.relu1',\n","                 OrderedDict([('inputs',\n","                               OrderedDict([(0,\n","                                             OrderedDict([('min', 0.0),\n","                                                          ('max',\n","                                                           2.492131233215332),\n","                                                          ('avg_min', 0.0),\n","                                                          ('avg_max',\n","                                                           1.1422941664898427),\n","                                                          ('mean',\n","                                                           -0.3452389373779297),\n","                                                          ('std',\n","                                                           0.34309224401439337),\n","                                                          ('b',\n","                                                           0.26466763305664065),\n","                                                          ('shape',\n","                                                           '(128, 64, 8, 8)'),\n","                                                          ('total_numel',\n","                                                           2048000)]))])),\n","                              ('output',\n","                               OrderedDict([('min', 0.0),\n","                                            ('max', 2.492131233215332),\n","                                            ('avg_min', 0.0),\n","                                            ('avg_max', 1.1422941664898427),\n","                                            ('mean', 0.024775771617889405),\n","                                            ('std', 0.08919356623698763),\n","                                            ('b', 0.04315297508239746),\n","                                            ('shape', '(128, 64, 8, 8)'),\n","                                            ('total_numel', 2048000)]))])),\n","                ('layer3.3.conv2',\n","                 OrderedDict([('inputs',\n","                               OrderedDict([(0,\n","                                             OrderedDict([('min', 0.0),\n","                                                          ('max',\n","                                                           2.492131233215332),\n","                                                          ('avg_min', 0.0),\n","                                                          ('avg_max',\n","                                                           1.1422941664898427),\n","                                                          ('mean',\n","                                                           0.024775771617889405),\n","                                                          ('std',\n","                                                           0.08919356623698763),\n","                                                          ('b',\n","                                                           0.04315297508239746),\n","                                                          ('shape',\n","                                                           '(128, 64, 8, 8)'),\n","                                                          ('total_numel',\n","                                                           2048000)]))])),\n","                              ('output',\n","                               OrderedDict([('min', -8.03017520904541),\n","                                            ('max', 8.042428016662598),\n","                                            ('avg_min', -2.918304804677765),\n","                                            ('avg_max', 2.4558103599111774),\n","                                            ('mean', -0.20530621337890625),\n","                                            ('std', 0.4057145754239374),\n","                                            ('b', 0.27549238204956056),\n","                                            ('shape', '(128, 64, 8, 8)'),\n","                                            ('total_numel', 2048000)]))])),\n","                ('layer3.3.relu2',\n","                 OrderedDict([('inputs',\n","                               OrderedDict([(0,\n","                                             OrderedDict([('min', 0.0),\n","                                                          ('max',\n","                                                           18.947933197021484),\n","                                                          ('avg_min', 0.0),\n","                                                          ('avg_max',\n","                                                           8.596502174182096),\n","                                                          ('mean',\n","                                                           0.28850210571289064),\n","                                                          ('std',\n","                                                           0.9782524986166939),\n","                                                          ('b',\n","                                                           0.6754125823974609),\n","                                                          ('shape',\n","                                                           '(128, 64, 8, 8)'),\n","                                                          ('total_numel',\n","                                                           2048000)]))])),\n","                              ('output',\n","                               OrderedDict([('min', 0.0),\n","                                            ('max', 18.947933197021484),\n","                                            ('avg_min', 0.0),\n","                                            ('avg_max', 8.596502174182096),\n","                                            ('mean', 0.4577082824707031),\n","                                            ('std', 0.841256714747301),\n","                                            ('b', 0.57109130859375),\n","                                            ('shape', '(128, 64, 8, 8)'),\n","                                            ('total_numel', 2048000)]))])),\n","                ('layer3.3.residual_eltwiseadd',\n","                 OrderedDict([('inputs',\n","                               OrderedDict([(0,\n","                                             OrderedDict([('min', 0.0),\n","                                                          ('max',\n","                                                           16.18870735168457),\n","                                                          ('avg_min', 0.0),\n","                                                          ('avg_max',\n","                                                           7.871765061554286),\n","                                                          ('mean',\n","                                                           0.4938083267211914),\n","                                                          ('std',\n","                                                           0.8503957388167325),\n","                                                          ('b',\n","                                                           0.5956240997314454),\n","                                                          ('shape',\n","                                                           '(128, 64, 8, 8)'),\n","                                                          ('total_numel',\n","                                                           2048000)])),\n","                                            (1,\n","                                             OrderedDict([('min',\n","                                                           -8.03017520904541),\n","                                                          ('max',\n","                                                           8.042428016662598),\n","                                                          ('avg_min',\n","                                                           -2.918304804677765),\n","                                                          ('avg_max',\n","                                                           2.4558103599111774),\n","                                                          ('mean',\n","                                                           -0.20530621337890625),\n","                                                          ('std',\n","                                                           0.4057145754239374),\n","                                                          ('b',\n","                                                           0.27549238204956056),\n","                                                          ('shape',\n","                                                           '(128, 64, 8, 8)'),\n","                                                          ('total_numel',\n","                                                           2048000)]))])),\n","                              ('output',\n","                               OrderedDict([('min', 0.0),\n","                                            ('max', 18.947933197021484),\n","                                            ('avg_min', 0.0),\n","                                            ('avg_max', 8.596502174182096),\n","                                            ('mean', 0.28850210571289064),\n","                                            ('std', 0.9782524986166939),\n","                                            ('b', 0.6754125823974609),\n","                                            ('shape', '(128, 64, 8, 8)'),\n","                                            ('total_numel', 2048000)]))])),\n","                ('layer3.4.conv1',\n","                 OrderedDict([('inputs',\n","                               OrderedDict([(0,\n","                                             OrderedDict([('min', 0.0),\n","                                                          ('max',\n","                                                           18.947933197021484),\n","                                                          ('avg_min', 0.0),\n","                                                          ('avg_max',\n","                                                           8.596502174182096),\n","                                                          ('mean',\n","                                                           0.4577082824707031),\n","                                                          ('std',\n","                                                           0.841256714747301),\n","                                                          ('b',\n","                                                           0.57109130859375),\n","                                                          ('shape',\n","                                                           '(128, 64, 8, 8)'),\n","                                                          ('total_numel',\n","                                                           2048000)]))])),\n","                              ('output',\n","                               OrderedDict([('min', 0.0),\n","                                            ('max', 2.6231045722961426),\n","                                            ('avg_min', 0.0),\n","                                            ('avg_max', 1.1373994348371521),\n","                                            ('mean', -0.31154684448242187),\n","                                            ('std', 0.3387041326909861),\n","                                            ('b', 0.2586338119506836),\n","                                            ('shape', '(128, 64, 8, 8)'),\n","                                            ('total_numel', 2048000)]))])),\n","                ('layer3.4.relu1',\n","                 OrderedDict([('inputs',\n","                               OrderedDict([(0,\n","                                             OrderedDict([('min', 0.0),\n","                                                          ('max',\n","                                                           2.6231045722961426),\n","                                                          ('avg_min', 0.0),\n","                                                          ('avg_max',\n","                                                           1.1373994348371521),\n","                                                          ('mean',\n","                                                           -0.31154684448242187),\n","                                                          ('std',\n","                                                           0.3387041326909861),\n","                                                          ('b',\n","                                                           0.2586338119506836),\n","                                                          ('shape',\n","                                                           '(128, 64, 8, 8)'),\n","                                                          ('total_numel',\n","                                                           2048000)]))])),\n","                              ('output',\n","                               OrderedDict([('min', 0.0),\n","                                            ('max', 2.6231045722961426),\n","                                            ('avg_min', 0.0),\n","                                            ('avg_max', 1.1373994348371521),\n","                                            ('mean', 0.02661249017715454),\n","                                            ('std', 0.09060901961344887),\n","                                            ('b', 0.04551980113983154),\n","                                            ('shape', '(128, 64, 8, 8)'),\n","                                            ('total_numel', 2048000)]))])),\n","                ('layer3.4.conv2',\n","                 OrderedDict([('inputs',\n","                               OrderedDict([(0,\n","                                             OrderedDict([('min', 0.0),\n","                                                          ('max',\n","                                                           2.6231045722961426),\n","                                                          ('avg_min', 0.0),\n","                                                          ('avg_max',\n","                                                           1.1373994348371521),\n","                                                          ('mean',\n","                                                           0.02661249017715454),\n","                                                          ('std',\n","                                                           0.09060901961344887),\n","                                                          ('b',\n","                                                           0.04551980113983154),\n","                                                          ('shape',\n","                                                           '(128, 64, 8, 8)'),\n","                                                          ('total_numel',\n","                                                           2048000)]))])),\n","                              ('output',\n","                               OrderedDict([('min', -9.337818145751953),\n","                                            ('max', 9.944296836853027),\n","                                            ('avg_min', -3.814363761043839),\n","                                            ('avg_max', 2.986646022011393),\n","                                            ('mean', -0.21773394393920897),\n","                                            ('std', 0.39360438000482717),\n","                                            ('b', 0.25468707275390623),\n","                                            ('shape', '(128, 64, 8, 8)'),\n","                                            ('total_numel', 2048000)]))])),\n","                ('layer3.4.relu2',\n","                 OrderedDict([('inputs',\n","                               OrderedDict([(0,\n","                                             OrderedDict([('min', 0.0),\n","                                                          ('max',\n","                                                           18.86583137512207),\n","                                                          ('avg_min', 0.0),\n","                                                          ('avg_max',\n","                                                           8.9730771056246),\n","                                                          ('mean',\n","                                                           0.23997433853149414),\n","                                                          ('std',\n","                                                           0.9732823740887914),\n","                                                          ('b',\n","                                                           0.655755111694336),\n","                                                          ('shape',\n","                                                           '(128, 64, 8, 8)'),\n","                                                          ('total_numel',\n","                                                           2048000)]))])),\n","                              ('output',\n","                               OrderedDict([('min', 0.0),\n","                                            ('max', 18.86583137512207),\n","                                            ('avg_min', 0.0),\n","                                            ('avg_max', 8.9730771056246),\n","                                            ('mean', 0.42112385559082033),\n","                                            ('std', 0.8377891291966016),\n","                                            ('b', 0.5493365325927735),\n","                                            ('shape', '(128, 64, 8, 8)'),\n","                                            ('total_numel', 2048000)]))])),\n","                ('layer3.4.residual_eltwiseadd',\n","                 OrderedDict([('inputs',\n","                               OrderedDict([(0,\n","                                             OrderedDict([('min', 0.0),\n","                                                          ('max',\n","                                                           18.947933197021484),\n","                                                          ('avg_min', 0.0),\n","                                                          ('avg_max',\n","                                                           8.596502174182096),\n","                                                          ('mean',\n","                                                           0.4577082824707031),\n","                                                          ('std',\n","                                                           0.841256714747301),\n","                                                          ('b',\n","                                                           0.57109130859375),\n","                                                          ('shape',\n","                                                           '(128, 64, 8, 8)'),\n","                                                          ('total_numel',\n","                                                           2048000)])),\n","                                            (1,\n","                                             OrderedDict([('min',\n","                                                           -9.337818145751953),\n","                                                          ('max',\n","                                                           9.944296836853027),\n","                                                          ('avg_min',\n","                                                           -3.814363761043839),\n","                                                          ('avg_max',\n","                                                           2.986646022011393),\n","                                                          ('mean',\n","                                                           -0.21773394393920897),\n","                                                          ('std',\n","                                                           0.39360438000482717),\n","                                                          ('b',\n","                                                           0.25468707275390623),\n","                                                          ('shape',\n","                                                           '(128, 64, 8, 8)'),\n","                                                          ('total_numel',\n","                                                           2048000)]))])),\n","                              ('output',\n","                               OrderedDict([('min', 0.0),\n","                                            ('max', 18.86583137512207),\n","                                            ('avg_min', 0.0),\n","                                            ('avg_max', 8.9730771056246),\n","                                            ('mean', 0.23997433853149414),\n","                                            ('std', 0.9732823740887914),\n","                                            ('b', 0.655755111694336),\n","                                            ('shape', '(128, 64, 8, 8)'),\n","                                            ('total_numel', 2048000)]))])),\n","                ('layer3.5.conv1',\n","                 OrderedDict([('inputs',\n","                               OrderedDict([(0,\n","                                             OrderedDict([('min', 0.0),\n","                                                          ('max',\n","                                                           18.86583137512207),\n","                                                          ('avg_min', 0.0),\n","                                                          ('avg_max',\n","                                                           8.9730771056246),\n","                                                          ('mean',\n","                                                           0.42112385559082033),\n","                                                          ('std',\n","                                                           0.8377891291966016),\n","                                                          ('b',\n","                                                           0.5493365325927735),\n","                                                          ('shape',\n","                                                           '(128, 64, 8, 8)'),\n","                                                          ('total_numel',\n","                                                           2048000)]))])),\n","                              ('output',\n","                               OrderedDict([('min', 0.0),\n","                                            ('max', 2.651230812072754),\n","                                            ('avg_min', 0.0),\n","                                            ('avg_max', 1.1575954056738518),\n","                                            ('mean', -0.290103759765625),\n","                                            ('std', 0.326262276371002),\n","                                            ('b', 0.24917665100097655),\n","                                            ('shape', '(128, 64, 8, 8)'),\n","                                            ('total_numel', 2048000)]))])),\n","                ('layer3.5.relu1',\n","                 OrderedDict([('inputs',\n","                               OrderedDict([(0,\n","                                             OrderedDict([('min', 0.0),\n","                                                          ('max',\n","                                                           2.651230812072754),\n","                                                          ('avg_min', 0.0),\n","                                                          ('avg_max',\n","                                                           1.1575954056738518),\n","                                                          ('mean',\n","                                                           -0.290103759765625),\n","                                                          ('std',\n","                                                           0.326262276371002),\n","                                                          ('b',\n","                                                           0.24917665100097655),\n","                                                          ('shape',\n","                                                           '(128, 64, 8, 8)'),\n","                                                          ('total_numel',\n","                                                           2048000)]))])),\n","                              ('output',\n","                               OrderedDict([('min', 0.0),\n","                                            ('max', 2.651230812072754),\n","                                            ('avg_min', 0.0),\n","                                            ('avg_max', 1.1575954056738518),\n","                                            ('mean', 0.02626177978515625),\n","                                            ('std', 0.08926458754588484),\n","                                            ('b', 0.04487940216064453),\n","                                            ('shape', '(128, 64, 8, 8)'),\n","                                            ('total_numel', 2048000)]))])),\n","                ('layer3.5.conv2',\n","                 OrderedDict([('inputs',\n","                               OrderedDict([(0,\n","                                             OrderedDict([('min', 0.0),\n","                                                          ('max',\n","                                                           2.651230812072754),\n","                                                          ('avg_min', 0.0),\n","                                                          ('avg_max',\n","                                                           1.1575954056738518),\n","                                                          ('mean',\n","                                                           0.02626177978515625),\n","                                                          ('std',\n","                                                           0.08926458754588484),\n","                                                          ('b',\n","                                                           0.04487940216064453),\n","                                                          ('shape',\n","                                                           '(128, 64, 8, 8)'),\n","                                                          ('total_numel',\n","                                                           2048000)]))])),\n","                              ('output',\n","                               OrderedDict([('min', -5.854752540588379),\n","                                            ('max', 16.497774124145508),\n","                                            ('avg_min', -2.7310241882038766),\n","                                            ('avg_max', 4.305344312636263),\n","                                            ('mean', -0.20688906860351564),\n","                                            ('std', 0.44858509147044867),\n","                                            ('b', 0.2841084594726562),\n","                                            ('shape', '(128, 64, 8, 8)'),\n","                                            ('total_numel', 2048000)]))])),\n","                ('layer3.5.relu2',\n","                 OrderedDict([('inputs',\n","                               OrderedDict([(0,\n","                                             OrderedDict([('min', 0.0),\n","                                                          ('max',\n","                                                           21.005830764770508),\n","                                                          ('avg_min', 0.0),\n","                                                          ('avg_max',\n","                                                           9.819647954839029),\n","                                                          ('mean',\n","                                                           0.21423479080200195),\n","                                                          ('std',\n","                                                           0.9959767011498805),\n","                                                          ('b',\n","                                                           0.6566763000488282),\n","                                                          ('shape',\n","                                                           '(128, 64, 8, 8)'),\n","                                                          ('total_numel',\n","                                                           2048000)]))])),\n","                              ('output',\n","                               OrderedDict([('min', 0.0),\n","                                            ('max', 21.005830764770508),\n","                                            ('avg_min', 0.0),\n","                                            ('avg_max', 9.819647954839029),\n","                                            ('mean', 0.41092259979248047),\n","                                            ('std', 0.8570253745810454),\n","                                            ('b', 0.5428783187866211),\n","                                            ('shape', '(128, 64, 8, 8)'),\n","                                            ('total_numel', 2048000)]))])),\n","                ('layer3.5.residual_eltwiseadd',\n","                 OrderedDict([('inputs',\n","                               OrderedDict([(0,\n","                                             OrderedDict([('min', 0.0),\n","                                                          ('max',\n","                                                           18.86583137512207),\n","                                                          ('avg_min', 0.0),\n","                                                          ('avg_max',\n","                                                           8.9730771056246),\n","                                                          ('mean',\n","                                                           0.42112385559082033),\n","                                                          ('std',\n","                                                           0.8377891291966016),\n","                                                          ('b',\n","                                                           0.5493365325927735),\n","                                                          ('shape',\n","                                                           '(128, 64, 8, 8)'),\n","                                                          ('total_numel',\n","                                                           2048000)])),\n","                                            (1,\n","                                             OrderedDict([('min',\n","                                                           -5.854752540588379),\n","                                                          ('max',\n","                                                           16.497774124145508),\n","                                                          ('avg_min',\n","                                                           -2.7310241882038766),\n","                                                          ('avg_max',\n","                                                           4.305344312636263),\n","                                                          ('mean',\n","                                                           -0.20688906860351564),\n","                                                          ('std',\n","                                                           0.44858509147044867),\n","                                                          ('b',\n","                                                           0.2841084594726562),\n","                                                          ('shape',\n","                                                           '(128, 64, 8, 8)'),\n","                                                          ('total_numel',\n","                                                           2048000)]))])),\n","                              ('output',\n","                               OrderedDict([('min', 0.0),\n","                                            ('max', 21.005830764770508),\n","                                            ('avg_min', 0.0),\n","                                            ('avg_max', 9.819647954839029),\n","                                            ('mean', 0.21423479080200195),\n","                                            ('std', 0.9959767011498805),\n","                                            ('b', 0.6566763000488282),\n","                                            ('shape', '(128, 64, 8, 8)'),\n","                                            ('total_numel', 2048000)]))])),\n","                ('layer3.6.conv1',\n","                 OrderedDict([('inputs',\n","                               OrderedDict([(0,\n","                                             OrderedDict([('min', 0.0),\n","                                                          ('max',\n","                                                           21.005830764770508),\n","                                                          ('avg_min', 0.0),\n","                                                          ('avg_max',\n","                                                           9.819647954839029),\n","                                                          ('mean',\n","                                                           0.41092259979248047),\n","                                                          ('std',\n","                                                           0.8570253745810454),\n","                                                          ('b',\n","                                                           0.5428783187866211),\n","                                                          ('shape',\n","                                                           '(128, 64, 8, 8)'),\n","                                                          ('total_numel',\n","                                                           2048000)]))])),\n","                              ('output',\n","                               OrderedDict([('min', 0.0),\n","                                            ('max', 3.5055131912231445),\n","                                            ('avg_min', 0.0),\n","                                            ('avg_max', 1.7136339790778428),\n","                                            ('mean', -0.3061948471069336),\n","                                            ('std', 0.4052580381110451),\n","                                            ('b', 0.30543255615234377),\n","                                            ('shape', '(128, 64, 8, 8)'),\n","                                            ('total_numel', 2048000)]))])),\n","                ('layer3.6.relu1',\n","                 OrderedDict([('inputs',\n","                               OrderedDict([(0,\n","                                             OrderedDict([('min', 0.0),\n","                                                          ('max',\n","                                                           3.5055131912231445),\n","                                                          ('avg_min', 0.0),\n","                                                          ('avg_max',\n","                                                           1.7136339790778428),\n","                                                          ('mean',\n","                                                           -0.3061948471069336),\n","                                                          ('std',\n","                                                           0.4052580381110451),\n","                                                          ('b',\n","                                                           0.30543255615234377),\n","                                                          ('shape',\n","                                                           '(128, 64, 8, 8)'),\n","                                                          ('total_numel',\n","                                                           2048000)]))])),\n","                              ('output',\n","                               OrderedDict([('min', 0.0),\n","                                            ('max', 3.5055131912231445),\n","                                            ('avg_min', 0.0),\n","                                            ('avg_max', 1.7136339790778428),\n","                                            ('mean', 0.04402978801727295),\n","                                            ('std', 0.1342221921539343),\n","                                            ('b', 0.07216107749938964),\n","                                            ('shape', '(128, 64, 8, 8)'),\n","                                            ('total_numel', 2048000)]))])),\n","                ('layer3.6.conv2',\n","                 OrderedDict([('inputs',\n","                               OrderedDict([(0,\n","                                             OrderedDict([('min', 0.0),\n","                                                          ('max',\n","                                                           3.5055131912231445),\n","                                                          ('avg_min', 0.0),\n","                                                          ('avg_max',\n","                                                           1.7136339790778428),\n","                                                          ('mean',\n","                                                           0.04402978801727295),\n","                                                          ('std',\n","                                                           0.1342221921539343),\n","                                                          ('b',\n","                                                           0.07216107749938964),\n","                                                          ('shape',\n","                                                           '(128, 64, 8, 8)'),\n","                                                          ('total_numel',\n","                                                           2048000)]))])),\n","                              ('output',\n","                               OrderedDict([('min', -8.548360824584961),\n","                                            ('max', 18.159011840820312),\n","                                            ('avg_min', -3.933704377850074),\n","                                            ('avg_max', 7.549812193545245),\n","                                            ('mean', -0.14327786636352538),\n","                                            ('std', 0.794561016834237),\n","                                            ('b', 0.4890469512939453),\n","                                            ('shape', '(128, 64, 8, 8)'),\n","                                            ('total_numel', 2048000)]))])),\n","                ('layer3.6.relu2',\n","                 OrderedDict([('inputs',\n","                               OrderedDict([(0,\n","                                             OrderedDict([('min', 0.0),\n","                                                          ('max',\n","                                                           34.393211364746094),\n","                                                          ('avg_min', 0.0),\n","                                                          ('avg_max',\n","                                                           15.300551496840047),\n","                                                          ('mean',\n","                                                           0.26764473342895506),\n","                                                          ('std',\n","                                                           1.3387205569095393),\n","                                                          ('b',\n","                                                           0.8389351959228516),\n","                                                          ('shape',\n","                                                           '(128, 64, 8, 8)'),\n","                                                          ('total_numel',\n","                                                           2048000)]))])),\n","                              ('output',\n","                               OrderedDict([('min', 0.0),\n","                                            ('max', 34.393211364746094),\n","                                            ('avg_min', 0.0),\n","                                            ('avg_max', 15.300551496840047),\n","                                            ('mean', 0.5272121353149414),\n","                                            ('std', 1.1547743169747633),\n","                                            ('b', 0.6866435699462891),\n","                                            ('shape', '(128, 64, 8, 8)'),\n","                                            ('total_numel', 2048000)]))])),\n","                ('layer3.6.residual_eltwiseadd',\n","                 OrderedDict([('inputs',\n","                               OrderedDict([(0,\n","                                             OrderedDict([('min', 0.0),\n","                                                          ('max',\n","                                                           21.005830764770508),\n","                                                          ('avg_min', 0.0),\n","                                                          ('avg_max',\n","                                                           9.819647954839029),\n","                                                          ('mean',\n","                                                           0.41092259979248047),\n","                                                          ('std',\n","                                                           0.8570253745810454),\n","                                                          ('b',\n","                                                           0.5428783187866211),\n","                                                          ('shape',\n","                                                           '(128, 64, 8, 8)'),\n","                                                          ('total_numel',\n","                                                           2048000)])),\n","                                            (1,\n","                                             OrderedDict([('min',\n","                                                           -8.548360824584961),\n","                                                          ('max',\n","                                                           18.159011840820312),\n","                                                          ('avg_min',\n","                                                           -3.933704377850074),\n","                                                          ('avg_max',\n","                                                           7.549812193545245),\n","                                                          ('mean',\n","                                                           -0.14327786636352538),\n","                                                          ('std',\n","                                                           0.794561016834237),\n","                                                          ('b',\n","                                                           0.4890469512939453),\n","                                                          ('shape',\n","                                                           '(128, 64, 8, 8)'),\n","                                                          ('total_numel',\n","                                                           2048000)]))])),\n","                              ('output',\n","                               OrderedDict([('min', 0.0),\n","                                            ('max', 34.393211364746094),\n","                                            ('avg_min', 0.0),\n","                                            ('avg_max', 15.300551496840047),\n","                                            ('mean', 0.26764473342895506),\n","                                            ('std', 1.3387205569095393),\n","                                            ('b', 0.8389351959228516),\n","                                            ('shape', '(128, 64, 8, 8)'),\n","                                            ('total_numel', 2048000)]))])),\n","                ('layer3.7.conv1',\n","                 OrderedDict([('inputs',\n","                               OrderedDict([(0,\n","                                             OrderedDict([('min', 0.0),\n","                                                          ('max',\n","                                                           34.393211364746094),\n","                                                          ('avg_min', 0.0),\n","                                                          ('avg_max',\n","                                                           15.300551496840047),\n","                                                          ('mean',\n","                                                           0.5272121353149414),\n","                                                          ('std',\n","                                                           1.1547743169747633),\n","                                                          ('b',\n","                                                           0.6866435699462891),\n","                                                          ('shape',\n","                                                           '(128, 64, 8, 8)'),\n","                                                          ('total_numel',\n","                                                           2048000)]))])),\n","                              ('output',\n","                               OrderedDict([('min', 0.0),\n","                                            ('max', 3.0296130180358887),\n","                                            ('avg_min', 0.0),\n","                                            ('avg_max', 1.3018484799284298),\n","                                            ('mean', -0.12925942611694335),\n","                                            ('std', 0.2719628729164978),\n","                                            ('b', 0.19748550033569337),\n","                                            ('shape', '(128, 64, 8, 8)'),\n","                                            ('total_numel', 2048000)]))])),\n","                ('layer3.7.relu1',\n","                 OrderedDict([('inputs',\n","                               OrderedDict([(0,\n","                                             OrderedDict([('min', 0.0),\n","                                                          ('max',\n","                                                           3.0296130180358887),\n","                                                          ('avg_min', 0.0),\n","                                                          ('avg_max',\n","                                                           1.3018484799284298),\n","                                                          ('mean',\n","                                                           -0.12925942611694335),\n","                                                          ('std',\n","                                                           0.2719628729164978),\n","                                                          ('b',\n","                                                           0.19748550033569337),\n","                                                          ('shape',\n","                                                           '(128, 64, 8, 8)'),\n","                                                          ('total_numel',\n","                                                           2048000)]))])),\n","                              ('output',\n","                               OrderedDict([('min', 0.0),\n","                                            ('max', 3.0296130180358887),\n","                                            ('avg_min', 0.0),\n","                                            ('avg_max', 1.3018484799284298),\n","                                            ('mean', 0.04511661434173584),\n","                                            ('std', 0.11233332791219938),\n","                                            ('b', 0.06770285415649414),\n","                                            ('shape', '(128, 64, 8, 8)'),\n","                                            ('total_numel', 2048000)]))])),\n","                ('layer3.7.conv2',\n","                 OrderedDict([('inputs',\n","                               OrderedDict([(0,\n","                                             OrderedDict([('min', 0.0),\n","                                                          ('max',\n","                                                           3.0296130180358887),\n","                                                          ('avg_min', 0.0),\n","                                                          ('avg_max',\n","                                                           1.3018484799284298),\n","                                                          ('mean',\n","                                                           0.04511661434173584),\n","                                                          ('std',\n","                                                           0.11233332791219938),\n","                                                          ('b',\n","                                                           0.06770285415649414),\n","                                                          ('shape',\n","                                                           '(128, 64, 8, 8)'),\n","                                                          ('total_numel',\n","                                                           2048000)]))])),\n","                              ('output',\n","                               OrderedDict([('min', -6.455540657043457),\n","                                            ('max', 20.839441299438477),\n","                                            ('avg_min', -2.6459398133828245),\n","                                            ('avg_max', 5.475611021906046),\n","                                            ('mean', -0.09245600509643555),\n","                                            ('std', 0.5916923897036391),\n","                                            ('b', 0.36234928131103517),\n","                                            ('shape', '(128, 64, 8, 8)'),\n","                                            ('total_numel', 2048000)]))])),\n","                ('layer3.7.relu2',\n","                 OrderedDict([('inputs',\n","                               OrderedDict([(0,\n","                                             OrderedDict([('min', 0.0),\n","                                                          ('max',\n","                                                           40.56829833984375),\n","                                                          ('avg_min', 0.0),\n","                                                          ('avg_max',\n","                                                           18.80425892763652),\n","                                                          ('mean',\n","                                                           0.4347561416625977),\n","                                                          ('std',\n","                                                           1.5170098980434237),\n","                                                          ('b',\n","                                                           0.9125549926757812),\n","                                                          ('shape',\n","                                                           '(128, 64, 8, 8)'),\n","                                                          ('total_numel',\n","                                                           2048000)]))])),\n","                              ('output',\n","                               OrderedDict([('min', 0.0),\n","                                            ('max', 40.56829833984375),\n","                                            ('avg_min', 0.0),\n","                                            ('avg_max', 18.80425892763652),\n","                                            ('mean', 0.6197190551757813),\n","                                            ('std', 1.4069308898480386),\n","                                            ('b', 0.8129118804931641),\n","                                            ('shape', '(128, 64, 8, 8)'),\n","                                            ('total_numel', 2048000)]))])),\n","                ('layer3.7.residual_eltwiseadd',\n","                 OrderedDict([('inputs',\n","                               OrderedDict([(0,\n","                                             OrderedDict([('min', 0.0),\n","                                                          ('max',\n","                                                           34.393211364746094),\n","                                                          ('avg_min', 0.0),\n","                                                          ('avg_max',\n","                                                           15.300551496840047),\n","                                                          ('mean',\n","                                                           0.5272121353149414),\n","                                                          ('std',\n","                                                           1.1547743169747633),\n","                                                          ('b',\n","                                                           0.6866435699462891),\n","                                                          ('shape',\n","                                                           '(128, 64, 8, 8)'),\n","                                                          ('total_numel',\n","                                                           2048000)])),\n","                                            (1,\n","                                             OrderedDict([('min',\n","                                                           -6.455540657043457),\n","                                                          ('max',\n","                                                           20.839441299438477),\n","                                                          ('avg_min',\n","                                                           -2.6459398133828245),\n","                                                          ('avg_max',\n","                                                           5.475611021906046),\n","                                                          ('mean',\n","                                                           -0.09245600509643555),\n","                                                          ('std',\n","                                                           0.5916923897036391),\n","                                                          ('b',\n","                                                           0.36234928131103517),\n","                                                          ('shape',\n","                                                           '(128, 64, 8, 8)'),\n","                                                          ('total_numel',\n","                                                           2048000)]))])),\n","                              ('output',\n","                               OrderedDict([('min', 0.0),\n","                                            ('max', 40.56829833984375),\n","                                            ('avg_min', 0.0),\n","                                            ('avg_max', 18.80425892763652),\n","                                            ('mean', 0.4347561416625977),\n","                                            ('std', 1.5170098980434237),\n","                                            ('b', 0.9125549926757812),\n","                                            ('shape', '(128, 64, 8, 8)'),\n","                                            ('total_numel', 2048000)]))])),\n","                ('layer3.8.conv1',\n","                 OrderedDict([('inputs',\n","                               OrderedDict([(0,\n","                                             OrderedDict([('min', 0.0),\n","                                                          ('max',\n","                                                           40.56829833984375),\n","                                                          ('avg_min', 0.0),\n","                                                          ('avg_max',\n","                                                           18.80425892763652),\n","                                                          ('mean',\n","                                                           0.6197190551757813),\n","                                                          ('std',\n","                                                           1.4069308898480386),\n","                                                          ('b',\n","                                                           0.8129118804931641),\n","                                                          ('shape',\n","                                                           '(128, 64, 8, 8)'),\n","                                                          ('total_numel',\n","                                                           2048000)]))])),\n","                              ('output',\n","                               OrderedDict([('min', 0.0),\n","                                            ('max', 2.1022541522979736),\n","                                            ('avg_min', 0.0),\n","                                            ('avg_max', 1.0261945500288443),\n","                                            ('mean', -0.04789583492279053),\n","                                            ('std', 0.22034621609736188),\n","                                            ('b', 0.1608121910095215),\n","                                            ('shape', '(128, 64, 8, 8)'),\n","                                            ('total_numel', 2048000)]))])),\n","                ('layer3.8.relu1',\n","                 OrderedDict([('inputs',\n","                               OrderedDict([(0,\n","                                             OrderedDict([('min', 0.0),\n","                                                          ('max',\n","                                                           2.1022541522979736),\n","                                                          ('avg_min', 0.0),\n","                                                          ('avg_max',\n","                                                           1.0261945500288443),\n","                                                          ('mean',\n","                                                           -0.04789583492279053),\n","                                                          ('std',\n","                                                           0.22034621609736188),\n","                                                          ('b',\n","                                                           0.1608121910095215),\n","                                                          ('shape',\n","                                                           '(128, 64, 8, 8)'),\n","                                                          ('total_numel',\n","                                                           2048000)]))])),\n","                              ('output',\n","                               OrderedDict([('min', 0.0),\n","                                            ('max', 2.1022541522979736),\n","                                            ('avg_min', 0.0),\n","                                            ('avg_max', 1.0261945500288443),\n","                                            ('mean', 0.058204874038696286),\n","                                            ('std', 0.1090985362681128),\n","                                            ('b', 0.07608969116210937),\n","                                            ('shape', '(128, 64, 8, 8)'),\n","                                            ('total_numel', 2048000)]))])),\n","                ('layer3.8.conv2',\n","                 OrderedDict([('inputs',\n","                               OrderedDict([(0,\n","                                             OrderedDict([('min', 0.0),\n","                                                          ('max',\n","                                                           2.1022541522979736),\n","                                                          ('avg_min', 0.0),\n","                                                          ('avg_max',\n","                                                           1.0261945500288443),\n","                                                          ('mean',\n","                                                           0.058204874038696286),\n","                                                          ('std',\n","                                                           0.1090985362681128),\n","                                                          ('b',\n","                                                           0.07608969116210937),\n","                                                          ('shape',\n","                                                           '(128, 64, 8, 8)'),\n","                                                          ('total_numel',\n","                                                           2048000)]))])),\n","                              ('output',\n","                               OrderedDict([('min', -5.082885265350342),\n","                                            ('max', 14.583540916442871),\n","                                            ('avg_min', -2.471313698602165),\n","                                            ('avg_max', 5.212500712788765),\n","                                            ('mean', -0.09875971221923828),\n","                                            ('std', 0.5525806019534828),\n","                                            ('b', 0.32574913787841797),\n","                                            ('shape', '(128, 64, 8, 8)'),\n","                                            ('total_numel', 2048000)]))])),\n","                ('layer3.8.relu2',\n","                 OrderedDict([('inputs',\n","                               OrderedDict([(0,\n","                                             OrderedDict([('min', 0.0),\n","                                                          ('max',\n","                                                           44.03279113769531),\n","                                                          ('avg_min', 0.0),\n","                                                          ('avg_max',\n","                                                           22.047299853038663),\n","                                                          ('mean',\n","                                                           0.5209593276977539),\n","                                                          ('std',\n","                                                           1.7581459405969402),\n","                                                          ('b',\n","                                                           1.0365723571777343),\n","                                                          ('shape',\n","                                                           '(128, 64, 8, 8)'),\n","                                                          ('total_numel',\n","                                                           2048000)]))])),\n","                              ('output',\n","                               OrderedDict([('min', 0.0),\n","                                            ('max', 44.03279113769531),\n","                                            ('avg_min', 0.0),\n","                                            ('avg_max', 22.047299853038663),\n","                                            ('mean', 0.7026326599121093),\n","                                            ('std', 1.65818760114936),\n","                                            ('b', 0.9425569000244141),\n","                                            ('shape', '(128, 64, 8, 8)'),\n","                                            ('total_numel', 2048000)]))])),\n","                ('layer3.8.residual_eltwiseadd',\n","                 OrderedDict([('inputs',\n","                               OrderedDict([(0,\n","                                             OrderedDict([('min', 0.0),\n","                                                          ('max',\n","                                                           40.56829833984375),\n","                                                          ('avg_min', 0.0),\n","                                                          ('avg_max',\n","                                                           18.80425892763652),\n","                                                          ('mean',\n","                                                           0.6197190551757813),\n","                                                          ('std',\n","                                                           1.4069308898480386),\n","                                                          ('b',\n","                                                           0.8129118804931641),\n","                                                          ('shape',\n","                                                           '(128, 64, 8, 8)'),\n","                                                          ('total_numel',\n","                                                           2048000)])),\n","                                            (1,\n","                                             OrderedDict([('min',\n","                                                           -5.082885265350342),\n","                                                          ('max',\n","                                                           14.583540916442871),\n","                                                          ('avg_min',\n","                                                           -2.471313698602165),\n","                                                          ('avg_max',\n","                                                           5.212500712788765),\n","                                                          ('mean',\n","                                                           -0.09875971221923828),\n","                                                          ('std',\n","                                                           0.5525806019534828),\n","                                                          ('b',\n","                                                           0.32574913787841797),\n","                                                          ('shape',\n","                                                           '(128, 64, 8, 8)'),\n","                                                          ('total_numel',\n","                                                           2048000)]))])),\n","                              ('output',\n","                               OrderedDict([('min', 0.0),\n","                                            ('max', 44.03279113769531),\n","                                            ('avg_min', 0.0),\n","                                            ('avg_max', 22.047299853038663),\n","                                            ('mean', 0.5209593276977539),\n","                                            ('std', 1.7581459405969402),\n","                                            ('b', 1.0365723571777343),\n","                                            ('shape', '(128, 64, 8, 8)'),\n","                                            ('total_numel', 2048000)]))])),\n","                ('avgpool',\n","                 OrderedDict([('inputs',\n","                               OrderedDict([(0,\n","                                             OrderedDict([('min', 0.0),\n","                                                          ('max',\n","                                                           44.03279113769531),\n","                                                          ('avg_min', 0.0),\n","                                                          ('avg_max',\n","                                                           22.047299853038663),\n","                                                          ('mean',\n","                                                           0.7026326599121093),\n","                                                          ('std',\n","                                                           1.65818760114936),\n","                                                          ('b',\n","                                                           0.9425569000244141),\n","                                                          ('shape',\n","                                                           '(128, 64, 8, 8)'),\n","                                                          ('total_numel',\n","                                                           2048000)]))])),\n","                              ('output',\n","                               OrderedDict([('min', 0.0),\n","                                            ('max', 8.449792861938477),\n","                                            ('avg_min', 0.00912673898272754),\n","                                            ('avg_max', 3.9601773089487082),\n","                                            ('mean', 0.7026326599121093),\n","                                            ('std', 0.8109255045626542),\n","                                            ('b', 0.5805507354736328),\n","                                            ('shape', '(128, 64, 1, 1)'),\n","                                            ('total_numel', 32000)]))])),\n","                ('fc',\n","                 OrderedDict([('inputs',\n","                               OrderedDict([(0,\n","                                             OrderedDict([('min', 0.0),\n","                                                          ('max',\n","                                                           8.449792861938477),\n","                                                          ('avg_min',\n","                                                           0.00912673898272754),\n","                                                          ('avg_max',\n","                                                           3.9601773089487082),\n","                                                          ('mean',\n","                                                           0.7026326599121093),\n","                                                          ('std',\n","                                                           0.8109255045626542),\n","                                                          ('b',\n","                                                           0.5805507354736328),\n","                                                          ('shape',\n","                                                           '(128, 64)'),\n","                                                          ('total_numel',\n","                                                           32000)]))])),\n","                              ('output',\n","                               OrderedDict([('min', -13.131094932556152),\n","                                            ('max', 36.608516693115234),\n","                                            ('avg_min', -7.470999614534291),\n","                                            ('avg_max', 18.898433523052994),\n","                                            ('mean', -0.000564019775390625),\n","                                            ('std', 7.463488994347751),\n","                                            ('b', 5.23724560546875),\n","                                            ('shape', '(128, 10)'),\n","                                            ('total_numel', 5000)]))]))]),\n","   'overrides': None,\n","   'per_channel_wts': True,\n","   'scale_approx_mult_bits': None},\n","  'type': distiller.quantization.range_linear.PostTrainLinearQuantizer},\n"," 'state_dict': OrderedDict([('module.conv1.num_forwards',\n","               tensor([40], device='cuda:0')),\n","              ('module.conv1.force_readjust', tensor(False, device='cuda:0')),\n","              ('module.conv1.output_scale',\n","               tensor([11471.7197], device='cuda:0')),\n","              ('module.conv1.output_zero_point',\n","               tensor([0.], device='cuda:0')),\n","              ('module.conv1.w_scale', tensor([[[[1.0455e+05]]],\n","               \n","               \n","                       [[[2.2628e+09]]],\n","               \n","               \n","                       [[[7.2255e+08]]],\n","               \n","               \n","                       [[[1.1931e+05]]],\n","               \n","               \n","                       [[[8.8057e+04]]],\n","               \n","               \n","                       [[[6.2112e+08]]],\n","               \n","               \n","                       [[[4.3012e+04]]],\n","               \n","               \n","                       [[[1.3069e+09]]],\n","               \n","               \n","                       [[[6.9139e+04]]],\n","               \n","               \n","                       [[[4.0806e+04]]],\n","               \n","               \n","                       [[[9.7206e+06]]],\n","               \n","               \n","                       [[[9.5019e+04]]],\n","               \n","               \n","                       [[[8.4237e+04]]],\n","               \n","               \n","                       [[[1.5586e+10]]],\n","               \n","               \n","                       [[[3.8874e+05]]],\n","               \n","               \n","                       [[[1.8380e+09]]]], device='cuda:0')),\n","              ('module.conv1.w_zero_point', tensor([[[[-29996.]]],\n","               \n","               \n","                       [[[-49094.]]],\n","               \n","               \n","                       [[[-22021.]]],\n","               \n","               \n","                       [[[-28723.]]],\n","               \n","               \n","                       [[[-30997.]]],\n","               \n","               \n","                       [[[-61062.]]],\n","               \n","               \n","                       [[[-20822.]]],\n","               \n","               \n","                       [[[-52674.]]],\n","               \n","               \n","                       [[[-21410.]]],\n","               \n","               \n","                       [[[-13754.]]],\n","               \n","               \n","                       [[[-10212.]]],\n","               \n","               \n","                       [[[-29466.]]],\n","               \n","               \n","                       [[[-54637.]]],\n","               \n","               \n","                       [[[ -4351.]]],\n","               \n","               \n","                       [[[-17822.]]],\n","               \n","               \n","                       [[[-65535.]]]], device='cuda:0')),\n","              ('module.conv1.fp_bias',\n","               tensor([ 6.7084e-01, -1.1652e-03, -3.5343e-03,  6.3502e-01,  7.3546e-01,\n","                       -2.7732e-03,  2.4089e+00, -1.0072e-03,  1.0231e+00,  1.5622e+00,\n","                        1.1219e-03,  1.0911e+00,  3.4948e-02, -2.4342e-03,  1.5152e-01,\n","                       -1.9359e-03], device='cuda:0')),\n","              ('module.conv1.accum_scale', tensor([[[1.5242e+09]],\n","               \n","                       [[3.2988e+13]],\n","               \n","                       [[1.0534e+13]],\n","               \n","                       [[1.7393e+09]],\n","               \n","                       [[1.2838e+09]],\n","               \n","                       [[9.0552e+12]],\n","               \n","                       [[6.2706e+08]],\n","               \n","                       [[1.9052e+13]],\n","               \n","                       [[1.0080e+09]],\n","               \n","                       [[5.9490e+08]],\n","               \n","                       [[1.4171e+11]],\n","               \n","                       [[1.3853e+09]],\n","               \n","                       [[1.2281e+09]],\n","               \n","                       [[2.2723e+14]],\n","               \n","                       [[5.6673e+09]],\n","               \n","                       [[2.6795e+13]]], device='cuda:0')),\n","              ('module.conv1.is_simulated_quant_weight_shifted',\n","               tensor(False, device='cuda:0')),\n","              ('module.conv1.wrapped_module.weight',\n","               tensor([[[[44131., 56203., 38979.],\n","                         [31547., 39694., 25675.],\n","                         [14699., 20210., 20150.]],\n","               \n","                        [[59738., 65535., 33931.],\n","                         [38648., 42721., 17397.],\n","                         [34127., 34775., 19210.]],\n","               \n","                        [[22027., 12570., 21223.],\n","                         [ 4678.,     0., 20036.],\n","                         [22948., 22679., 38893.]]],\n","               \n","               \n","                       [[[49642., 29738., 32774.],\n","                         [54107., 44295., 47323.],\n","                         [65535., 48559., 53822.]],\n","               \n","                        [[28371.,  7574.,  6157.],\n","                         [28436., 13678., 24060.],\n","                         [37179., 28970., 33197.]],\n","               \n","                        [[16712.,     0.,  2717.],\n","                         [21453., 11684., 15297.],\n","                         [32331., 19036., 23377.]]],\n","               \n","               \n","                       [[[36397., 24414., 38675.],\n","                         [41406., 33706., 46931.],\n","                         [49686., 43409., 65535.]],\n","               \n","                        [[21504., 18571., 31951.],\n","                         [35593., 30678., 40360.],\n","                         [50434., 44573., 62424.]],\n","               \n","                        [[14248.,     0., 21087.],\n","                         [25633., 18716., 44208.],\n","                         [44470., 43613., 56578.]]],\n","               \n","               \n","                       [[[23108., 13660., 18283.],\n","                         [24117., 32920., 23307.],\n","                         [20832., 29173., 32109.]],\n","               \n","                        [[43924., 45786., 24912.],\n","                         [52006., 65535., 30102.],\n","                         [31443., 37789., 26055.]],\n","               \n","                        [[45216., 28267., 14442.],\n","                         [44357., 31143.,     0.],\n","                         [31411., 16271.,  2138.]]],\n","               \n","               \n","                       [[[31401.,  9246., 25079.],\n","                         [20066.,     0., 12345.],\n","                         [22753., 13302., 24539.]],\n","               \n","                        [[32477., 27278., 35730.],\n","                         [36255., 34261., 33611.],\n","                         [34904., 31959., 33062.]],\n","               \n","                        [[35156., 45451., 39742.],\n","                         [48125., 65535., 50393.],\n","                         [33269., 42540., 33688.]]],\n","               \n","               \n","                       [[[17426., 25583., 46414.],\n","                         [24838., 21915., 20451.],\n","                         [14740.,     0., 20893.]],\n","               \n","                        [[27325., 41268., 58308.],\n","                         [46112., 47034., 45323.],\n","                         [28991., 29247., 64027.]],\n","               \n","                        [[33862., 49370., 65535.],\n","                         [51212., 56395., 46205.],\n","                         [31342., 31863., 61360.]]],\n","               \n","               \n","                       [[[13191., 37526., 11261.],\n","                         [27893.,     0., 15367.],\n","                         [27682., 26395., 26269.]],\n","               \n","                        [[ 9272., 65535., 19321.],\n","                         [13263.,  1121., 10475.],\n","                         [22982., 12768., 20371.]],\n","               \n","                        [[13900., 54770., 24262.],\n","                         [18147., 27273., 26753.],\n","                         [14105., 19873., 16879.]]],\n","               \n","               \n","                       [[[45776., 54454., 63219.],\n","                         [26167., 38569., 40144.],\n","                         [ 8636., 27850., 25546.]],\n","               \n","                        [[28941., 34390., 58654.],\n","                         [15583., 42163., 39377.],\n","                         [    0., 27368., 30736.]],\n","               \n","                        [[41168., 45951., 65535.],\n","                         [27432., 38241., 44081.],\n","                         [13372., 28958., 30883.]]],\n","               \n","               \n","                       [[[ 5429.,     0., 12545.],\n","                         [12561., 16845., 16838.],\n","                         [17144., 22438., 23725.]],\n","               \n","                        [[37382., 46194., 32861.],\n","                         [47736., 65535., 38644.],\n","                         [32945., 42699., 23341.]],\n","               \n","                        [[15977.,  5474., 19974.],\n","                         [ 6252.,  1298., 12888.],\n","                         [17283.,  7297., 14836.]]],\n","               \n","               \n","                       [[[ 3348., 25032.,  9627.],\n","                         [ 8563., 65535., 40339.],\n","                         [ 6151., 28338., 12988.]],\n","               \n","                        [[11573.,  2312.,  6212.],\n","                         [  243.,  3222.,  8243.],\n","                         [10004.,  1381., 14622.]],\n","               \n","                        [[23558., 14515., 18655.],\n","                         [20888.,  6753.,     0.],\n","                         [23870., 10957.,  9468.]]],\n","               \n","               \n","                       [[[65535., 52042., 47210.],\n","                         [45190., 28681., 23469.],\n","                         [29598., 18663., 17474.]],\n","               \n","                        [[39749., 29410., 30130.],\n","                         [40525., 24311., 14027.],\n","                         [29861., 15121.,  4909.]],\n","               \n","                        [[42251., 32143., 30247.],\n","                         [39069., 22498., 14076.],\n","                         [28300., 13251.,     0.]]],\n","               \n","               \n","                       [[[30901., 33663., 24122.],\n","                         [42663., 54389., 20889.],\n","                         [36176., 40014., 28996.]],\n","               \n","                        [[27108., 32374.,  8830.],\n","                         [34719., 41046.,     0.],\n","                         [25164., 20260., 11285.]],\n","               \n","                        [[28191., 40847., 20777.],\n","                         [47480., 65535., 28260.],\n","                         [26956., 36428., 25470.]]],\n","               \n","               \n","                       [[[64045., 61613., 58384.],\n","                         [62433., 23661., 51189.],\n","                         [65535., 57644., 54713.]],\n","               \n","                        [[50446., 31665., 56388.],\n","                         [45787.,     0., 49335.],\n","                         [61319., 48043., 60239.]],\n","               \n","                        [[62127., 59086., 58712.],\n","                         [60367., 29810., 54958.],\n","                         [57375., 54301., 53802.]]],\n","               \n","               \n","                       [[[35816., 42340., 20093.],\n","                         [41638., 42291., 24643.],\n","                         [10959., 29541., 23366.]],\n","               \n","                        [[33799., 35180., 13459.],\n","                         [31286., 14911., 46957.],\n","                         [    0., 22428., 12567.]],\n","               \n","                        [[43824., 39883., 56672.],\n","                         [64867., 65535., 61138.],\n","                         [20261., 20702., 47265.]]],\n","               \n","               \n","                       [[[23075., 30117., 27737.],\n","                         [21687., 43041., 20184.],\n","                         [    0., 21093., 23482.]],\n","               \n","                        [[18954., 39812., 34125.],\n","                         [31735., 65535., 32141.],\n","                         [11596., 37813., 32835.]],\n","               \n","                        [[13294., 16430., 13083.],\n","                         [25806., 34853., 10752.],\n","                         [15999., 20580., 20162.]]],\n","               \n","               \n","                       [[[43341., 19110., 21075.],\n","                         [18884., 19843., 15683.],\n","                         [14325., 24358., 25474.]],\n","               \n","                        [[24286., 11236.,  6911.],\n","                         [ 6853.,  5073.,  3953.],\n","                         [   71., 11503., 18306.]],\n","               \n","                        [[22104.,  8777.,  6752.],\n","                         [ 9697., 14022.,  6370.],\n","                         [    0., 15980., 15751.]]]], device='cuda:0')),\n","              ('module.conv1.wrapped_module.bias',\n","               tensor([ 1.0225e+09, -2.1475e+09, -2.1475e+09,  1.1045e+09,  9.4416e+08,\n","                       -2.1475e+09,  1.5105e+09, -2.1475e+09,  1.0312e+09,  9.2933e+08,\n","                        1.5899e+08,  1.5115e+09,  4.2919e+07, -2.1475e+09,  8.5870e+08,\n","                       -2.1475e+09], device='cuda:0')),\n","              ('module.layer1.0.conv1.num_forwards',\n","               tensor([40], device='cuda:0')),\n","              ('module.layer1.0.conv1.force_readjust',\n","               tensor(False, device='cuda:0')),\n","              ('module.layer1.0.conv1.output_scale',\n","               tensor([43313.3125], device='cuda:0')),\n","              ('module.layer1.0.conv1.output_zero_point',\n","               tensor([0.], device='cuda:0')),\n","              ('module.layer1.0.conv1.w_scale', tensor([[[[1.8782e+08]]],\n","               \n","               \n","                       [[[2.9786e+05]]],\n","               \n","               \n","                       [[[9.8702e+05]]],\n","               \n","               \n","                       [[[2.9171e+05]]],\n","               \n","               \n","                       [[[2.5775e+05]]],\n","               \n","               \n","                       [[[3.6661e+05]]],\n","               \n","               \n","                       [[[4.6710e+05]]],\n","               \n","               \n","                       [[[6.2243e+05]]],\n","               \n","               \n","                       [[[3.9893e+05]]],\n","               \n","               \n","                       [[[5.2050e+05]]],\n","               \n","               \n","                       [[[1.0234e+06]]],\n","               \n","               \n","                       [[[3.5579e+05]]],\n","               \n","               \n","                       [[[2.5805e+09]]],\n","               \n","               \n","                       [[[3.7323e+05]]],\n","               \n","               \n","                       [[[1.1882e+08]]],\n","               \n","               \n","                       [[[4.6231e+05]]]], device='cuda:0')),\n","              ('module.layer1.0.conv1.w_zero_point', tensor([[[[-35198.]]],\n","               \n","               \n","                       [[[-18053.]]],\n","               \n","               \n","                       [[[-26140.]]],\n","               \n","               \n","                       [[[-37744.]]],\n","               \n","               \n","                       [[[-29421.]]],\n","               \n","               \n","                       [[[-36772.]]],\n","               \n","               \n","                       [[[-25708.]]],\n","               \n","               \n","                       [[[-43357.]]],\n","               \n","               \n","                       [[[-20958.]]],\n","               \n","               \n","                       [[[-31020.]]],\n","               \n","               \n","                       [[[-30920.]]],\n","               \n","               \n","                       [[[-24658.]]],\n","               \n","               \n","                       [[[-24804.]]],\n","               \n","               \n","                       [[[-31796.]]],\n","               \n","               \n","                       [[[-31419.]]],\n","               \n","               \n","                       [[[-29481.]]]], device='cuda:0')),\n","              ('module.layer1.0.conv1.fp_bias',\n","               tensor([ 3.9175e-04, -1.2039e+00, -2.6362e-01,  8.5549e-01,  8.8966e-01,\n","                       -4.0299e-01, -1.8411e+00,  4.7812e-01, -1.0780e+00, -5.6041e-02,\n","                       -1.6244e-01, -1.0612e-01, -3.8254e-03,  1.2814e+00, -4.4502e-03,\n","                        3.1543e-01], device='cuda:0')),\n","              ('module.layer1.0.conv1.accum_scale', tensor([[[2.1547e+12]],\n","               \n","                       [[3.4170e+09]],\n","               \n","                       [[1.1323e+10]],\n","               \n","                       [[3.3464e+09]],\n","               \n","                       [[2.9569e+09]],\n","               \n","                       [[4.2057e+09]],\n","               \n","                       [[5.3584e+09]],\n","               \n","                       [[7.1403e+09]],\n","               \n","                       [[4.5764e+09]],\n","               \n","                       [[5.9710e+09]],\n","               \n","                       [[1.1740e+10]],\n","               \n","                       [[4.0815e+09]],\n","               \n","                       [[2.9603e+13]],\n","               \n","                       [[4.2816e+09]],\n","               \n","                       [[1.3630e+12]],\n","               \n","                       [[5.3035e+09]]], device='cuda:0')),\n","              ('module.layer1.0.conv1.is_simulated_quant_weight_shifted',\n","               tensor(False, device='cuda:0')),\n","              ('module.layer1.0.conv1.wrapped_module.weight',\n","               tensor([[[[ 2577., 10769.,  9144.],\n","                         [ 2799., 17952., 16886.],\n","                         [    0., 14323., 18818.]],\n","               \n","                        [[23860., 28268., 11305.],\n","                         [21934., 23685., 14556.],\n","                         [22583., 33657., 20501.]],\n","               \n","                        [[17575.,  8992., 12169.],\n","                         [18119., 14451., 18686.],\n","                         [27826., 26759., 27697.]],\n","               \n","                        ...,\n","               \n","                        [[41537., 42974., 37355.],\n","                         [42511., 46222., 45550.],\n","                         [38904., 41917., 39909.]],\n","               \n","                        [[ 6412., 20380., 13286.],\n","                         [ 8066., 12555., 16276.],\n","                         [19268., 30039., 31433.]],\n","               \n","                        [[ 5273., 10707.,   420.],\n","                         [11773., 14623.,  7788.],\n","                         [20063., 18302., 24655.]]],\n","               \n","               \n","                       [[[ 5947., 11037., 10451.],\n","                         [ 1566.,  9218.,  5876.],\n","                         [ 7823., 15570.,  9158.]],\n","               \n","                        [[18023., 18053., 18052.],\n","                         [18058., 17912., 17966.],\n","                         [18054., 18002., 18137.]],\n","               \n","                        [[18010., 18005., 17986.],\n","                         [18121., 18125., 18180.],\n","                         [18124., 18153., 18089.]],\n","               \n","                        ...,\n","               \n","                        [[18253., 18223., 18161.],\n","                         [18137., 18101., 18162.],\n","                         [17893., 18050., 18013.]],\n","               \n","                        [[11384.,  8254.,  9463.],\n","                         [12657.,  9345., 11667.],\n","                         [17227., 15427., 15764.]],\n","               \n","                        [[17999., 18001., 17976.],\n","                         [18040., 18163., 18063.],\n","                         [17897., 18132., 18042.]]],\n","               \n","               \n","                       [[[39487., 39857., 29893.],\n","                         [20410., 30259., 26953.],\n","                         [19126., 34106., 36254.]],\n","               \n","                        [[27465., 27245., 26667.],\n","                         [27705., 27487., 27437.],\n","                         [27539., 27411., 27255.]],\n","               \n","                        [[27816., 27624., 27310.],\n","                         [27748., 27878., 27295.],\n","                         [27834., 27765., 27492.]],\n","               \n","                        ...,\n","               \n","                        [[26037., 26219., 26145.],\n","                         [25400., 25721., 25575.],\n","                         [25563., 25653., 25667.]],\n","               \n","                        [[55879., 61271., 60831.],\n","                         [47060., 52110., 52239.],\n","                         [37054., 37755., 35552.]],\n","               \n","                        [[28002., 27713., 27071.],\n","                         [27821., 27993., 27189.],\n","                         [28086., 27774., 27243.]]],\n","               \n","               \n","                       ...,\n","               \n","               \n","                       [[[39326., 40702., 32688.],\n","                         [36201., 32480., 28536.],\n","                         [22141., 16090., 27918.]],\n","               \n","                        [[31722., 31762., 31764.],\n","                         [31678., 31643., 31665.],\n","                         [31848., 31683., 31771.]],\n","               \n","                        [[31877., 31931., 32001.],\n","                         [31816., 31798., 31827.],\n","                         [31919., 31854., 31912.]],\n","               \n","                        ...,\n","               \n","                        [[31821., 31840., 31825.],\n","                         [31892., 31790., 31809.],\n","                         [31787., 31775., 31893.]],\n","               \n","                        [[24110., 21698., 27419.],\n","                         [21568., 22461., 26786.],\n","                         [24880., 25401., 26886.]],\n","               \n","                        [[31652., 31721., 31697.],\n","                         [31733., 31730., 31732.],\n","                         [31888., 31714., 31856.]]],\n","               \n","               \n","                       [[[61354., 62550., 46470.],\n","                         [49959., 48512., 35690.],\n","                         [45311., 45963., 31989.]],\n","               \n","                        [[44024., 41469., 45783.],\n","                         [41740., 33235., 29080.],\n","                         [22790., 11361., 18526.]],\n","               \n","                        [[44003., 31382., 37581.],\n","                         [44465., 26044., 32877.],\n","                         [61398., 42644., 41584.]],\n","               \n","                        ...,\n","               \n","                        [[17832.,  6548., 10315.],\n","                         [15337.,  6764.,  8078.],\n","                         [29507., 13855., 15676.]],\n","               \n","                        [[55446., 45276., 30550.],\n","                         [50232., 48088., 35716.],\n","                         [64705., 53257., 39242.]],\n","               \n","                        [[54890., 43662., 44649.],\n","                         [50328., 38108., 29902.],\n","                         [52344., 36152., 27658.]]],\n","               \n","               \n","                       [[[53656., 46463., 32786.],\n","                         [37124., 25965., 17324.],\n","                         [34016., 22047., 19740.]],\n","               \n","                        [[29651., 29399., 29297.],\n","                         [29684., 29439., 29254.],\n","                         [29799., 29348., 29607.]],\n","               \n","                        [[29583., 29155., 29291.],\n","                         [29579., 29294., 29358.],\n","                         [29697., 29484., 29552.]],\n","               \n","                        ...,\n","               \n","                        [[29360., 29423., 29415.],\n","                         [29315., 29376., 29362.],\n","                         [29473., 29329., 29343.]],\n","               \n","                        [[30615., 25496., 30432.],\n","                         [28318., 24361., 26862.],\n","                         [28839., 23626., 24549.]],\n","               \n","                        [[29806., 29440., 29600.],\n","                         [29715., 29603., 29635.],\n","                         [29883., 29717., 29831.]]]], device='cuda:0')),\n","              ('module.layer1.0.conv1.wrapped_module.bias',\n","               tensor([ 8.4408e+08, -2.1475e+09, -2.1475e+09,  2.1475e+09,  2.1475e+09,\n","                       -1.6948e+09, -2.1475e+09,  2.1475e+09, -2.1475e+09, -3.3462e+08,\n","                       -1.9070e+09, -4.3314e+08, -2.1475e+09,  2.1475e+09, -2.1475e+09,\n","                        1.6729e+09], device='cuda:0')),\n","              ('module.layer1.0.conv2.num_forwards',\n","               tensor([40], device='cuda:0')),\n","              ('module.layer1.0.conv2.force_readjust',\n","               tensor(False, device='cuda:0')),\n","              ('module.layer1.0.conv2.output_scale',\n","               tensor([22786.0371], device='cuda:0')),\n","              ('module.layer1.0.conv2.output_zero_point',\n","               tensor([-27725.], device='cuda:0')),\n","              ('module.layer1.0.conv2.w_scale', tensor([[[[3.8044e+05]]],\n","               \n","               \n","                       [[[2.6784e+05]]],\n","               \n","               \n","                       [[[7.9256e+04]]],\n","               \n","               \n","                       [[[1.1884e+07]]],\n","               \n","               \n","                       [[[2.8639e+05]]],\n","               \n","               \n","                       [[[1.7229e+05]]],\n","               \n","               \n","                       [[[3.1369e+05]]],\n","               \n","               \n","                       [[[3.0566e+08]]],\n","               \n","               \n","                       [[[1.2513e+05]]],\n","               \n","               \n","                       [[[1.8544e+05]]],\n","               \n","               \n","                       [[[4.1808e+06]]],\n","               \n","               \n","                       [[[1.0755e+06]]],\n","               \n","               \n","                       [[[5.6422e+05]]],\n","               \n","               \n","                       [[[3.5438e+08]]],\n","               \n","               \n","                       [[[4.9393e+05]]],\n","               \n","               \n","                       [[[2.1785e+05]]]], device='cuda:0')),\n","              ('module.layer1.0.conv2.w_zero_point', tensor([[[[-34339.]]],\n","               \n","               \n","                       [[[-24753.]]],\n","               \n","               \n","                       [[[-26252.]]],\n","               \n","               \n","                       [[[-28910.]]],\n","               \n","               \n","                       [[[-25743.]]],\n","               \n","               \n","                       [[[-28992.]]],\n","               \n","               \n","                       [[[-26687.]]],\n","               \n","               \n","                       [[[-37927.]]],\n","               \n","               \n","                       [[[-37584.]]],\n","               \n","               \n","                       [[[-23953.]]],\n","               \n","               \n","                       [[[-33454.]]],\n","               \n","               \n","                       [[[-37089.]]],\n","               \n","               \n","                       [[[-23683.]]],\n","               \n","               \n","                       [[[-27744.]]],\n","               \n","               \n","                       [[[-32664.]]],\n","               \n","               \n","                       [[[-39497.]]]], device='cuda:0')),\n","              ('module.layer1.0.conv2.fp_bias',\n","               tensor([ 0.0511, -0.3457, -0.1257,  0.0648, -0.1589,  0.2921,  0.3049, -0.0050,\n","                       -0.2575, -0.2578, -0.0308,  0.0748,  0.0125, -0.0022,  0.1688,  0.6248],\n","                      device='cuda:0')),\n","              ('module.layer1.0.conv2.accum_scale', tensor([[[1.6478e+10]],\n","               \n","                       [[1.1601e+10]],\n","               \n","                       [[3.4328e+09]],\n","               \n","                       [[5.1475e+11]],\n","               \n","                       [[1.2404e+10]],\n","               \n","                       [[7.4626e+09]],\n","               \n","                       [[1.3587e+10]],\n","               \n","                       [[1.3239e+13]],\n","               \n","                       [[5.4199e+09]],\n","               \n","                       [[8.0321e+09]],\n","               \n","                       [[1.8108e+11]],\n","               \n","                       [[4.6582e+10]],\n","               \n","                       [[2.4438e+10]],\n","               \n","                       [[1.5349e+13]],\n","               \n","                       [[2.1394e+10]],\n","               \n","                       [[9.4358e+09]]], device='cuda:0')),\n","              ('module.layer1.0.conv2.is_simulated_quant_weight_shifted',\n","               tensor(False, device='cuda:0')),\n","              ('module.layer1.0.conv2.wrapped_module.weight',\n","               tensor([[[[34132., 33969., 34017.],\n","                         [34303., 34196., 34340.],\n","                         [34245., 34168., 34269.]],\n","               \n","                        [[42397., 40623., 39422.],\n","                         [38341., 40185., 38412.],\n","                         [42442., 37476., 44221.]],\n","               \n","                        [[52406., 49162., 47219.],\n","                         [49048., 44963., 41040.],\n","                         [47801., 49065., 45406.]],\n","               \n","                        ...,\n","               \n","                        [[48367., 45762., 48199.],\n","                         [41870., 37161., 33837.],\n","                         [42689., 29663., 29205.]],\n","               \n","                        [[34161., 34305., 34523.],\n","                         [34338., 34296., 34348.],\n","                         [34122., 34027., 34328.]],\n","               \n","                        [[35781., 42968., 55111.],\n","                         [27499., 39127., 44720.],\n","                         [34630., 49004., 47115.]]],\n","               \n","               \n","                       [[[24545., 24593., 24459.],\n","                         [24892., 24811., 24938.],\n","                         [25049., 24842., 24729.]],\n","               \n","                        [[22033., 20624., 20900.],\n","                         [20101., 20843., 17271.],\n","                         [26796., 27269., 26096.]],\n","               \n","                        [[14829., 23474., 30667.],\n","                         [10204., 21942., 29338.],\n","                         [ 4729., 13899., 22390.]],\n","               \n","                        ...,\n","               \n","                        [[32804., 36330., 43502.],\n","                         [30115., 31736., 31806.],\n","                         [25168., 16231., 20111.]],\n","               \n","                        [[25196., 25072., 25088.],\n","                         [24962., 25238., 25445.],\n","                         [24853., 25110., 24924.]],\n","               \n","                        [[28087., 26978., 26288.],\n","                         [28980., 29139., 19705.],\n","                         [27630., 23073., 13850.]]],\n","               \n","               \n","                       [[[26395., 26255., 26426.],\n","                         [26421., 26450., 26317.],\n","                         [26343., 26253., 26172.]],\n","               \n","                        [[30119., 25909., 24125.],\n","                         [28182., 22975., 16716.],\n","                         [22567., 19688., 13233.]],\n","               \n","                        [[24152., 27080., 29006.],\n","                         [22868., 25949., 28024.],\n","                         [20735., 23642., 24490.]],\n","               \n","                        ...,\n","               \n","                        [[37297., 38056., 42609.],\n","                         [26768., 26328., 26971.],\n","                         [27096., 26658., 28042.]],\n","               \n","                        [[26184., 26103., 26136.],\n","                         [26381., 26434., 26388.],\n","                         [26407., 26556., 26462.]],\n","               \n","                        [[17067., 19313., 28429.],\n","                         [17082., 20204., 26446.],\n","                         [25468., 26039., 27014.]]],\n","               \n","               \n","                       ...,\n","               \n","               \n","                       [[[19271., 13578.,  8730.],\n","                         [41388., 16943., 34985.],\n","                         [25153., 37401., 42467.]],\n","               \n","                        [[20490., 35282., 33993.],\n","                         [21377., 30369., 32981.],\n","                         [ 4403., 30012., 27895.]],\n","               \n","                        [[20436., 20292., 31220.],\n","                         [ 3893., 29326., 30171.],\n","                         [    0., 18845., 26781.]],\n","               \n","                        ...,\n","               \n","                        [[21019., 22146., 27670.],\n","                         [20722., 30520., 38120.],\n","                         [18351., 23031., 28734.]],\n","               \n","                        [[26397., 37566., 18985.],\n","                         [13153., 26689., 33563.],\n","                         [ 9036., 32350., 11655.]],\n","               \n","                        [[ 4463., 17063., 12141.],\n","                         [19647., 29606.,  9834.],\n","                         [33196., 36550., 13103.]]],\n","               \n","               \n","                       [[[32852., 32695., 32711.],\n","                         [32803., 32834., 32726.],\n","                         [32786., 32835., 32960.]],\n","               \n","                        [[48606., 35984., 35483.],\n","                         [32815., 26711., 25801.],\n","                         [29343., 21224., 21392.]],\n","               \n","                        [[20288., 18339., 28057.],\n","                         [25189., 23814., 30915.],\n","                         [30450., 35291., 38037.]],\n","               \n","                        ...,\n","               \n","                        [[42293., 38670., 50793.],\n","                         [35658., 39163., 58363.],\n","                         [32384., 34544., 47721.]],\n","               \n","                        [[32676., 32574., 32763.],\n","                         [32710., 32444., 32607.],\n","                         [32461., 32506., 32617.]],\n","               \n","                        [[32426., 30069., 39605.],\n","                         [27070., 25655., 39363.],\n","                         [26821., 27015., 46019.]]],\n","               \n","               \n","                       [[[39236., 39360., 39374.],\n","                         [39562., 39504., 39532.],\n","                         [39510., 39479., 39453.]],\n","               \n","                        [[33515., 26010., 22588.],\n","                         [32227., 24999., 21158.],\n","                         [40358., 34922., 31019.]],\n","               \n","                        [[44432., 50767., 45917.],\n","                         [53990., 59230., 54480.],\n","                         [51152., 49232., 45180.]],\n","               \n","                        ...,\n","               \n","                        [[43468., 37877., 20759.],\n","                         [58765., 48561., 16264.],\n","                         [57191., 45980., 10891.]],\n","               \n","                        [[39275., 39589., 39478.],\n","                         [39466., 39574., 39364.],\n","                         [39463., 39492., 39708.]],\n","               \n","                        [[38611., 47101., 40020.],\n","                         [38521., 42609., 32070.],\n","                         [42082., 41787., 28833.]]]], device='cuda:0')),\n","              ('module.layer1.0.conv2.wrapped_module.bias',\n","               tensor([ 8.4127e+08, -2.1475e+09, -4.3164e+08,  2.1475e+09, -1.9715e+09,\n","                        2.1475e+09,  2.1475e+09, -2.1475e+09, -1.3958e+09, -2.0705e+09,\n","                       -2.1475e+09,  2.1475e+09,  3.0641e+08, -2.1475e+09,  2.1475e+09,\n","                        2.1475e+09], device='cuda:0')),\n","              ('module.layer1.0.relu2.num_forwards',\n","               tensor([40], device='cuda:0')),\n","              ('module.layer1.0.relu2.force_readjust',\n","               tensor(False, device='cuda:0')),\n","              ('module.layer1.0.relu2.output_scale',\n","               tensor([10803.7051], device='cuda:0')),\n","              ('module.layer1.0.relu2.output_zero_point',\n","               tensor([0.], device='cuda:0')),\n","              ('module.layer1.0.residual_eltwiseadd.num_forwards',\n","               tensor([40], device='cuda:0')),\n","              ('module.layer1.0.residual_eltwiseadd.force_readjust',\n","               tensor(False, device='cuda:0')),\n","              ('module.layer1.0.residual_eltwiseadd.output_scale',\n","               tensor([10803.7051], device='cuda:0')),\n","              ('module.layer1.0.residual_eltwiseadd.output_zero_point',\n","               tensor([0.], device='cuda:0')),\n","              ('module.layer1.1.conv1.num_forwards',\n","               tensor([40], device='cuda:0')),\n","              ('module.layer1.1.conv1.force_readjust',\n","               tensor(False, device='cuda:0')),\n","              ('module.layer1.1.conv1.output_scale',\n","               tensor([20081.6934], device='cuda:0')),\n","              ('module.layer1.1.conv1.output_zero_point',\n","               tensor([0.], device='cuda:0')),\n","              ('module.layer1.1.conv1.w_scale', tensor([[[[2.1977e+05]]],\n","               \n","               \n","                       [[[2.3034e+05]]],\n","               \n","               \n","                       [[[3.1967e+05]]],\n","               \n","               \n","                       [[[1.1433e+06]]],\n","               \n","               \n","                       [[[1.9858e+05]]],\n","               \n","               \n","                       [[[4.4027e+05]]],\n","               \n","               \n","                       [[[2.6525e+05]]],\n","               \n","               \n","                       [[[2.2384e+05]]],\n","               \n","               \n","                       [[[1.6794e+05]]],\n","               \n","               \n","                       [[[7.9411e+04]]],\n","               \n","               \n","                       [[[3.1690e+05]]],\n","               \n","               \n","                       [[[3.7573e+09]]],\n","               \n","               \n","                       [[[1.2026e+06]]],\n","               \n","               \n","                       [[[1.3556e+09]]],\n","               \n","               \n","                       [[[1.3085e+05]]],\n","               \n","               \n","                       [[[3.5441e+05]]]], device='cuda:0')),\n","              ('module.layer1.1.conv1.w_zero_point', tensor([[[[-34501.]]],\n","               \n","               \n","                       [[[-23155.]]],\n","               \n","               \n","                       [[[-23083.]]],\n","               \n","               \n","                       [[[-29398.]]],\n","               \n","               \n","                       [[[-29020.]]],\n","               \n","               \n","                       [[[-28328.]]],\n","               \n","               \n","                       [[[-29043.]]],\n","               \n","               \n","                       [[[-27761.]]],\n","               \n","               \n","                       [[[-32403.]]],\n","               \n","               \n","                       [[[-43514.]]],\n","               \n","               \n","                       [[[-23857.]]],\n","               \n","               \n","                       [[[-27496.]]],\n","               \n","               \n","                       [[[-41374.]]],\n","               \n","               \n","                       [[[-35448.]]],\n","               \n","               \n","                       [[[-20156.]]],\n","               \n","               \n","                       [[[-40222.]]]], device='cuda:0')),\n","              ('module.layer1.1.conv1.fp_bias',\n","               tensor([ 1.2476e+00, -4.3928e-01, -1.5150e+00, -4.3638e-01,  3.9016e-01,\n","                       -4.0804e-01,  3.5084e-02, -7.0724e-01,  4.2889e-01,  1.6761e+00,\n","                       -4.9018e-01, -7.7723e-04,  6.2775e-01, -8.6198e-04,  1.0671e+00,\n","                        7.8780e-01], device='cuda:0')),\n","              ('module.layer1.1.conv1.accum_scale', tensor([[[2.3744e+09]],\n","               \n","                       [[2.4885e+09]],\n","               \n","                       [[3.4536e+09]],\n","               \n","                       [[1.2352e+10]],\n","               \n","                       [[2.1454e+09]],\n","               \n","                       [[4.7566e+09]],\n","               \n","                       [[2.8657e+09]],\n","               \n","                       [[2.4183e+09]],\n","               \n","                       [[1.8144e+09]],\n","               \n","                       [[8.5793e+08]],\n","               \n","                       [[3.4237e+09]],\n","               \n","                       [[4.0592e+13]],\n","               \n","                       [[1.2992e+10]],\n","               \n","                       [[1.4646e+13]],\n","               \n","                       [[1.4136e+09]],\n","               \n","                       [[3.8290e+09]]], device='cuda:0')),\n","              ('module.layer1.1.conv1.is_simulated_quant_weight_shifted',\n","               tensor(False, device='cuda:0')),\n","              ('module.layer1.1.conv1.wrapped_module.weight',\n","               tensor([[[[35649., 29326., 19133.],\n","                         [48970., 30083.,  6697.],\n","                         [40223., 23150.,  6671.]],\n","               \n","                        [[31579., 32901., 33089.],\n","                         [28427., 30545., 32582.],\n","                         [27302., 29030., 31126.]],\n","               \n","                        [[35561., 38977., 39454.],\n","                         [39453., 37176., 35972.],\n","                         [33091., 25517., 27345.]],\n","               \n","                        ...,\n","               \n","                        [[34516., 34513., 34522.],\n","                         [34525., 34498., 34364.],\n","                         [34532., 34480., 34427.]],\n","               \n","                        [[31336., 28216., 27039.],\n","                         [34917., 29772., 26654.],\n","                         [41026., 37794., 34202.]],\n","               \n","                        [[33150., 30955., 32817.],\n","                         [31929., 31341., 33985.],\n","                         [35038., 33229., 34456.]]],\n","               \n","               \n","                       [[[ 2808., 22327., 39018.],\n","                         [13273., 47674., 65535.],\n","                         [10290., 41254., 48600.]],\n","               \n","                        [[30106., 23724., 20553.],\n","                         [32138., 25414., 22276.],\n","                         [30856., 24961., 22240.]],\n","               \n","                        [[30509., 22375., 12072.],\n","                         [36307., 32592., 21712.],\n","                         [43368., 45667., 34813.]],\n","               \n","                        ...,\n","               \n","                        [[23075., 23096., 23158.],\n","                         [23046., 23172., 23111.],\n","                         [23164., 23145., 23049.]],\n","               \n","                        [[36017., 37916., 35313.],\n","                         [34615., 36287., 34659.],\n","                         [32308., 33432., 33525.]],\n","               \n","                        [[22656., 23708., 24858.],\n","                         [19722., 20019., 22417.],\n","                         [22995., 21825., 24100.]]],\n","               \n","               \n","                       [[[51674., 56416., 60292.],\n","                         [36793., 46691., 56883.],\n","                         [19456., 31025., 44270.]],\n","               \n","                        [[23574., 24043., 21312.],\n","                         [25818., 26704., 24571.],\n","                         [26899., 27156., 25028.]],\n","               \n","                        [[15554., 13512.,  8019.],\n","                         [22801., 23467., 20948.],\n","                         [29499., 32073., 29921.]],\n","               \n","                        ...,\n","               \n","                        [[23154., 23132., 23123.],\n","                         [23232., 23133., 23210.],\n","                         [23236., 23082., 23239.]],\n","               \n","                        [[41219., 40385., 34676.],\n","                         [30954., 33094., 27585.],\n","                         [20567., 21145., 14632.]],\n","               \n","                        [[27814., 24937., 25062.],\n","                         [28375., 26820., 28631.],\n","                         [26971., 25613., 24525.]]],\n","               \n","               \n","                       ...,\n","               \n","               \n","                       [[[30010., 11282., 13762.],\n","                         [27291., 15454., 15646.],\n","                         [32655., 20506., 11296.]],\n","               \n","                        [[17336.,  1335., 11604.],\n","                         [29899., 14463., 13492.],\n","                         [28060.,  9693., 26229.]],\n","               \n","                        [[29142., 37118., 14488.],\n","                         [28132., 20999., 11105.],\n","                         [36424., 25688., 13847.]],\n","               \n","                        ...,\n","               \n","                        [[64724., 65535., 59448.],\n","                         [43503., 40863., 49651.],\n","                         [34014., 51171., 38696.]],\n","               \n","                        [[36319., 30935., 18935.],\n","                         [14482., 14595., 23294.],\n","                         [20119., 18396., 25267.]],\n","               \n","                        [[32719., 26641., 41317.],\n","                         [46119., 28017., 31385.],\n","                         [24551., 23181., 30773.]]],\n","               \n","               \n","                       [[[25820., 23046., 25000.],\n","                         [11352., 12134., 17279.],\n","                         [ 9206., 19348., 22894.]],\n","               \n","                        [[19593., 21002., 18787.],\n","                         [20325., 21978., 20504.],\n","                         [19017., 21647., 20238.]],\n","               \n","                        [[20983., 19026., 15515.],\n","                         [23290., 21497., 17654.],\n","                         [17886., 18880., 17990.]],\n","               \n","                        ...,\n","               \n","                        [[20210., 20170., 20206.],\n","                         [20199., 20177., 20165.],\n","                         [20172., 20149., 20166.]],\n","               \n","                        [[20966., 24833., 23574.],\n","                         [22746., 28223., 28372.],\n","                         [22873., 26663., 26933.]],\n","               \n","                        [[21474., 21969., 23494.],\n","                         [20660., 21288., 23336.],\n","                         [23188., 22410., 21910.]]],\n","               \n","               \n","                       [[[47037., 34039., 30463.],\n","                         [41521., 27570., 30739.],\n","                         [21165., 21295., 35760.]],\n","               \n","                        [[42184., 43669., 40994.],\n","                         [40984., 41730., 38905.],\n","                         [39894., 41382., 39192.]],\n","               \n","                        [[45062., 41879., 36393.],\n","                         [51862., 46132., 37568.],\n","                         [48789., 41218., 32816.]],\n","               \n","                        ...,\n","               \n","                        [[40197., 40113., 40259.],\n","                         [40286., 40267., 40262.],\n","                         [40256., 40299., 40201.]],\n","               \n","                        [[35170., 40182., 45190.],\n","                         [41986., 47437., 52320.],\n","                         [46153., 51430., 54299.]],\n","               \n","                        [[35356., 38206., 40345.],\n","                         [38961., 37419., 39285.],\n","                         [40548., 37538., 38528.]]]], device='cuda:0')),\n","              ('module.layer1.1.conv1.wrapped_module.bias',\n","               tensor([ 2.1475e+09, -1.0932e+09, -2.1475e+09, -2.1475e+09,  8.3705e+08,\n","                       -1.9409e+09,  1.0054e+08, -1.7103e+09,  7.7818e+08,  1.4380e+09,\n","                       -1.6782e+09, -2.1475e+09,  2.1475e+09, -2.1475e+09,  1.5085e+09,\n","                        2.1475e+09], device='cuda:0')),\n","              ('module.layer1.1.conv2.num_forwards',\n","               tensor([40], device='cuda:0')),\n","              ('module.layer1.1.conv2.force_readjust',\n","               tensor(False, device='cuda:0')),\n","              ('module.layer1.1.conv2.output_scale',\n","               tensor([7407.2437], device='cuda:0')),\n","              ('module.layer1.1.conv2.output_zero_point',\n","               tensor([-34834.], device='cuda:0')),\n","              ('module.layer1.1.conv2.w_scale', tensor([[[[1.1191e+05]]],\n","               \n","               \n","                       [[[1.7965e+06]]],\n","               \n","               \n","                       [[[3.2483e+05]]],\n","               \n","               \n","                       [[[1.9032e+05]]],\n","               \n","               \n","                       [[[2.3616e+05]]],\n","               \n","               \n","                       [[[1.7766e+05]]],\n","               \n","               \n","                       [[[5.4156e+04]]],\n","               \n","               \n","                       [[[4.2194e+08]]],\n","               \n","               \n","                       [[[1.5406e+05]]],\n","               \n","               \n","                       [[[9.4377e+04]]],\n","               \n","               \n","                       [[[1.1473e+07]]],\n","               \n","               \n","                       [[[3.0154e+05]]],\n","               \n","               \n","                       [[[2.0657e+05]]],\n","               \n","               \n","                       [[[7.0774e+08]]],\n","               \n","               \n","                       [[[5.5742e+04]]],\n","               \n","               \n","                       [[[1.9584e+05]]]], device='cuda:0')),\n","              ('module.layer1.1.conv2.w_zero_point', tensor([[[[-26734.]]],\n","               \n","               \n","                       [[[-26598.]]],\n","               \n","               \n","                       [[[-33722.]]],\n","               \n","               \n","                       [[[-49700.]]],\n","               \n","               \n","                       [[[-24641.]]],\n","               \n","               \n","                       [[[-34544.]]],\n","               \n","               \n","                       [[[-32981.]]],\n","               \n","               \n","                       [[[-21583.]]],\n","               \n","               \n","                       [[[-27838.]]],\n","               \n","               \n","                       [[[-40894.]]],\n","               \n","               \n","                       [[[-31194.]]],\n","               \n","               \n","                       [[[-37903.]]],\n","               \n","               \n","                       [[[-25970.]]],\n","               \n","               \n","                       [[[-30819.]]],\n","               \n","               \n","                       [[[-36398.]]],\n","               \n","               \n","                       [[[-37521.]]]], device='cuda:0')),\n","              ('module.layer1.1.conv2.fp_bias',\n","               tensor([-0.5288, -0.2127, -0.1348,  0.5942, -0.4085,  0.1393,  0.8161, -0.0033,\n","                        0.4911,  0.8536, -0.0766,  0.4875, -0.1539, -0.0015,  1.0717,  0.8257],\n","                      device='cuda:0')),\n","              ('module.layer1.1.conv2.accum_scale', tensor([[[2.2473e+09]],\n","               \n","                       [[3.6077e+10]],\n","               \n","                       [[6.5231e+09]],\n","               \n","                       [[3.8220e+09]],\n","               \n","                       [[4.7426e+09]],\n","               \n","                       [[3.5677e+09]],\n","               \n","                       [[1.0875e+09]],\n","               \n","                       [[8.4732e+12]],\n","               \n","                       [[3.0937e+09]],\n","               \n","                       [[1.8952e+09]],\n","               \n","                       [[2.3040e+11]],\n","               \n","                       [[6.0554e+09]],\n","               \n","                       [[4.1483e+09]],\n","               \n","                       [[1.4213e+13]],\n","               \n","                       [[1.1194e+09]],\n","               \n","                       [[3.9328e+09]]], device='cuda:0')),\n","              ('module.layer1.1.conv2.is_simulated_quant_weight_shifted',\n","               tensor(False, device='cuda:0')),\n","              ('module.layer1.1.conv2.wrapped_module.weight',\n","               tensor([[[[11682., 39132., 44573.],\n","                         [25966., 65535., 58277.],\n","                         [34638., 59383., 41893.]],\n","               \n","                        [[41058., 29775., 16461.],\n","                         [44267., 13254.,     0.],\n","                         [31055.,  3788.,  2488.]],\n","               \n","                        [[35714., 19854., 17155.],\n","                         [33587., 20366., 14666.],\n","                         [28476., 21809., 16571.]],\n","               \n","                        ...,\n","               \n","                        [[26781., 26739., 26794.],\n","                         [26793., 26781., 26703.],\n","                         [26763., 26775., 26672.]],\n","               \n","                        [[31139., 24624., 29835.],\n","                         [36043., 17560., 34560.],\n","                         [37442., 21309., 15134.]],\n","               \n","                        [[30431., 24119., 28394.],\n","                         [25953., 21604., 27714.],\n","                         [27754., 26086., 25243.]]],\n","               \n","               \n","                       [[[30644., 36923., 18834.],\n","                         [20314., 25410., 10909.],\n","                         [23103., 22475., 10789.]],\n","               \n","                        [[33699., 23190., 23125.],\n","                         [24018., 16044., 19267.],\n","                         [38296., 31142., 36555.]],\n","               \n","                        [[27580., 30663., 37862.],\n","                         [28852., 33826., 41213.],\n","                         [28432., 34960., 44080.]],\n","               \n","                        ...,\n","               \n","                        [[25535., 25930., 26315.],\n","                         [26519., 26497., 26264.],\n","                         [25942., 26370., 25981.]],\n","               \n","                        [[18550., 35512., 28758.],\n","                         [27611., 43980., 34676.],\n","                         [45775., 57811., 65535.]],\n","               \n","                        [[39003., 25576., 19232.],\n","                         [42004., 28484., 17810.],\n","                         [36642., 36244., 28290.]]],\n","               \n","               \n","                       [[[43602., 47060., 39060.],\n","                         [27080., 31519., 28858.],\n","                         [37057., 33740., 29381.]],\n","               \n","                        [[54217., 63990., 65535.],\n","                         [41858., 51280., 49665.],\n","                         [33271., 35291., 36158.]],\n","               \n","                        [[30366., 27460., 27759.],\n","                         [32927., 28558., 30405.],\n","                         [31303., 29419., 31648.]],\n","               \n","                        ...,\n","               \n","                        [[33704., 33966., 33942.],\n","                         [33833., 33972., 33840.],\n","                         [33930., 34003., 33832.]],\n","               \n","                        [[55964., 46310., 50843.],\n","                         [42233., 32239., 11269.],\n","                         [38374., 41093., 28438.]],\n","               \n","                        [[20991., 28332., 32980.],\n","                         [24458., 24279., 23619.],\n","                         [28815., 34304., 26383.]]],\n","               \n","               \n","                       ...,\n","               \n","               \n","                       [[[15220., 21063., 24988.],\n","                         [20694., 17500., 21084.],\n","                         [24480., 21420., 20192.]],\n","               \n","                        [[32709., 30506., 22566.],\n","                         [25942., 25992., 24832.],\n","                         [24063., 23289., 19280.]],\n","               \n","                        [[58802., 57439., 62295.],\n","                         [58076., 65134., 65535.],\n","                         [51929., 56391., 60578.]],\n","               \n","                        ...,\n","               \n","                        [[28672., 28121., 22922.],\n","                         [16474., 15781., 19557.],\n","                         [17973., 15542., 10849.]],\n","               \n","                        [[41795., 51051., 34576.],\n","                         [51694., 55644., 49095.],\n","                         [53110., 63661., 51002.]],\n","               \n","                        [[46455., 38488., 21268.],\n","                         [44469., 48361., 38364.],\n","                         [45125., 43656., 38172.]]],\n","               \n","               \n","                       [[[35175., 35832., 37990.],\n","                         [40084., 41929., 43594.],\n","                         [41106., 38244., 39819.]],\n","               \n","                        [[31599., 35886., 41628.],\n","                         [33607., 34012., 36633.],\n","                         [39388., 36755., 34077.]],\n","               \n","                        [[33415., 31396., 30182.],\n","                         [33592., 37451., 34784.],\n","                         [27922., 33388., 32899.]],\n","               \n","                        ...,\n","               \n","                        [[36386., 36368., 36339.],\n","                         [36425., 36368., 36394.],\n","                         [36421., 36361., 36388.]],\n","               \n","                        [[43008., 56392., 20155.],\n","                         [40714., 47472.,     0.],\n","                         [35558., 31238., 26952.]],\n","               \n","                        [[43436., 34091., 30489.],\n","                         [43168., 26500., 21047.],\n","                         [38122., 33588., 27332.]]],\n","               \n","               \n","                       [[[38120., 37660., 26529.],\n","                         [46034., 44760., 21453.],\n","                         [55412., 53124., 22030.]],\n","               \n","                        [[47772., 40710., 34968.],\n","                         [31437., 21921., 28271.],\n","                         [31032., 23628., 29607.]],\n","               \n","                        [[41467., 32755., 22004.],\n","                         [42827., 32302., 20944.],\n","                         [44645., 32336., 22750.]],\n","               \n","                        ...,\n","               \n","                        [[37633., 37536., 37480.],\n","                         [37596., 37531., 37559.],\n","                         [37376., 37429., 37525.]],\n","               \n","                        [[42473., 50603., 61098.],\n","                         [43900., 47836., 65535.],\n","                         [27968., 25837., 46782.]],\n","               \n","                        [[42589., 47336., 32857.],\n","                         [43207., 58880., 52898.],\n","                         [34802., 50415., 45160.]]]], device='cuda:0')),\n","              ('module.layer1.1.conv2.wrapped_module.bias',\n","               tensor([-1.1885e+09, -2.1475e+09, -8.7963e+08,  2.1475e+09, -1.9373e+09,\n","                        4.9713e+08,  8.8755e+08, -2.1475e+09,  1.5193e+09,  1.6178e+09,\n","                       -2.1475e+09,  2.1475e+09, -6.3862e+08, -2.1475e+09,  1.1996e+09,\n","                        2.1475e+09], device='cuda:0')),\n","              ('module.layer1.1.relu2.num_forwards',\n","               tensor([40], device='cuda:0')),\n","              ('module.layer1.1.relu2.force_readjust',\n","               tensor(False, device='cuda:0')),\n","              ('module.layer1.1.relu2.output_scale',\n","               tensor([7475.1665], device='cuda:0')),\n","              ('module.layer1.1.relu2.output_zero_point',\n","               tensor([0.], device='cuda:0')),\n","              ('module.layer1.1.residual_eltwiseadd.num_forwards',\n","               tensor([40], device='cuda:0')),\n","              ('module.layer1.1.residual_eltwiseadd.force_readjust',\n","               tensor(False, device='cuda:0')),\n","              ('module.layer1.1.residual_eltwiseadd.output_scale',\n","               tensor([7475.1665], device='cuda:0')),\n","              ('module.layer1.1.residual_eltwiseadd.output_zero_point',\n","               tensor([0.], device='cuda:0')),\n","              ('module.layer1.2.conv1.num_forwards',\n","               tensor([40], device='cuda:0')),\n","              ('module.layer1.2.conv1.force_readjust',\n","               tensor(False, device='cuda:0')),\n","              ('module.layer1.2.conv1.output_scale',\n","               tensor([29280.3105], device='cuda:0')),\n","              ('module.layer1.2.conv1.output_zero_point',\n","               tensor([0.], device='cuda:0')),\n","              ('module.layer1.2.conv1.w_scale', tensor([[[[2.6812e+05]]],\n","               \n","               \n","                       [[[6.0550e+05]]],\n","               \n","               \n","                       [[[5.0254e+05]]],\n","               \n","               \n","                       [[[9.5027e+08]]],\n","               \n","               \n","                       [[[1.4348e+06]]],\n","               \n","               \n","                       [[[7.4181e+08]]],\n","               \n","               \n","                       [[[3.0352e+06]]],\n","               \n","               \n","                       [[[3.5499e+08]]],\n","               \n","               \n","                       [[[2.2559e+05]]],\n","               \n","               \n","                       [[[5.0829e+05]]],\n","               \n","               \n","                       [[[3.8233e+05]]],\n","               \n","               \n","                       [[[4.5155e+05]]],\n","               \n","               \n","                       [[[7.3839e+05]]],\n","               \n","               \n","                       [[[4.1617e+05]]],\n","               \n","               \n","                       [[[2.0265e+05]]],\n","               \n","               \n","                       [[[4.2129e+05]]]], device='cuda:0')),\n","              ('module.layer1.2.conv1.w_zero_point', tensor([[[[-37260.]]],\n","               \n","               \n","                       [[[-42743.]]],\n","               \n","               \n","                       [[[-21765.]]],\n","               \n","               \n","                       [[[-20737.]]],\n","               \n","               \n","                       [[[-37908.]]],\n","               \n","               \n","                       [[[-32155.]]],\n","               \n","               \n","                       [[[-33785.]]],\n","               \n","               \n","                       [[[-35378.]]],\n","               \n","               \n","                       [[[-30132.]]],\n","               \n","               \n","                       [[[-31499.]]],\n","               \n","               \n","                       [[[-28398.]]],\n","               \n","               \n","                       [[[-36063.]]],\n","               \n","               \n","                       [[[-35539.]]],\n","               \n","               \n","                       [[[-30899.]]],\n","               \n","               \n","                       [[[-23195.]]],\n","               \n","               \n","                       [[[-32774.]]]], device='cuda:0')),\n","              ('module.layer1.2.conv1.fp_bias',\n","               tensor([ 1.5662e-01,  9.0454e-01, -1.0476e-01, -3.4575e-03,  1.1974e-01,\n","                       -5.8092e-04,  5.7970e-02, -1.0339e-03,  4.8168e-01,  8.6120e-02,\n","                       -2.1244e-01,  1.7261e-01, -2.3331e-01, -2.6251e-01, -1.5355e-01,\n","                        6.2831e-02], device='cuda:0')),\n","              ('module.layer1.2.conv1.accum_scale', tensor([[[2.0043e+09]],\n","               \n","                       [[4.5262e+09]],\n","               \n","                       [[3.7565e+09]],\n","               \n","                       [[7.1034e+12]],\n","               \n","                       [[1.0726e+10]],\n","               \n","                       [[5.5451e+12]],\n","               \n","                       [[2.2688e+10]],\n","               \n","                       [[2.6536e+12]],\n","               \n","                       [[1.6864e+09]],\n","               \n","                       [[3.7996e+09]],\n","               \n","                       [[2.8580e+09]],\n","               \n","                       [[3.3754e+09]],\n","               \n","                       [[5.5196e+09]],\n","               \n","                       [[3.1109e+09]],\n","               \n","                       [[1.5149e+09]],\n","               \n","                       [[3.1492e+09]]], device='cuda:0')),\n","              ('module.layer1.2.conv1.is_simulated_quant_weight_shifted',\n","               tensor(False, device='cuda:0')),\n","              ('module.layer1.2.conv1.wrapped_module.weight',\n","               tensor([[[[43868., 38021., 33390.],\n","                         [41525., 35083., 29945.],\n","                         [40008., 36565., 29782.]],\n","               \n","                        [[34772., 36077., 36148.],\n","                         [35430., 36584., 36707.],\n","                         [35861., 36699., 36341.]],\n","               \n","                        [[35959., 35983., 37401.],\n","                         [34848., 35718., 37743.],\n","                         [36625., 37720., 38843.]],\n","               \n","                        ...,\n","               \n","                        [[37269., 37267., 37281.],\n","                         [37226., 37252., 37241.],\n","                         [37208., 37236., 37207.]],\n","               \n","                        [[38100., 23025., 38322.],\n","                         [45658., 21817., 45065.],\n","                         [36696., 31257., 41793.]],\n","               \n","                        [[34092., 40794., 38148.],\n","                         [29735., 42622., 34575.],\n","                         [32491., 39725., 34666.]]],\n","               \n","               \n","                       [[[46982., 47756., 38818.],\n","                         [42818., 52808., 43122.],\n","                         [25774., 49646., 46269.]],\n","               \n","                        [[39874., 39214., 40614.],\n","                         [39331., 39637., 42005.],\n","                         [40574., 41711., 43172.]],\n","               \n","                        [[32546., 35807., 41395.],\n","                         [37865., 35789., 36095.],\n","                         [39443., 35650., 33494.]],\n","               \n","                        ...,\n","               \n","                        [[42514., 42549., 42618.],\n","                         [42556., 42520., 42702.],\n","                         [42635., 42616., 42668.]],\n","               \n","                        [[14327., 29371., 20897.],\n","                         [21159., 21009., 23560.],\n","                         [14238., 18478., 33041.]],\n","               \n","                        [[37176., 38216., 40984.],\n","                         [39740., 47221., 53085.],\n","                         [43571., 51266., 57850.]]],\n","               \n","               \n","                       [[[ 8614.,  1195.,     0.],\n","                         [10346.,  7874.,  7748.],\n","                         [11437., 14361.,  5014.]],\n","               \n","                        [[20950., 21584., 22461.],\n","                         [20991., 21449., 22204.],\n","                         [21392., 21681., 21866.]],\n","               \n","                        [[20369., 22182., 23470.],\n","                         [13082., 13763., 13433.],\n","                         [13274., 12506., 11621.]],\n","               \n","                        ...,\n","               \n","                        [[21725., 21723., 21719.],\n","                         [21707., 21692., 21734.],\n","                         [21853., 21842., 21816.]],\n","               \n","                        [[34261., 16264., 25847.],\n","                         [27615.,  7218., 29704.],\n","                         [ 8086., 19561., 22733.]],\n","               \n","                        [[ 8470., 20429.,  9179.],\n","                         [10508., 23649., 11617.],\n","                         [14916., 24316., 27471.]]],\n","               \n","               \n","                       ...,\n","               \n","               \n","                       [[[36075., 39854., 54723.],\n","                         [40274., 28337., 33147.],\n","                         [16455., 12391., 24830.]],\n","               \n","                        [[30397., 31740., 31932.],\n","                         [30910., 31880., 32345.],\n","                         [32381., 33761., 33940.]],\n","               \n","                        [[33434., 33956., 32360.],\n","                         [25165., 28212., 29299.],\n","                         [22526., 28541., 30042.]],\n","               \n","                        ...,\n","               \n","                        [[30868., 30842., 30928.],\n","                         [30962., 30869., 30874.],\n","                         [30952., 30919., 30989.]],\n","               \n","                        [[38297., 36346., 36402.],\n","                         [42005., 38363., 36196.],\n","                         [44846., 43966., 41161.]],\n","               \n","                        [[30176., 39146., 37088.],\n","                         [37380., 42954., 40290.],\n","                         [24414., 22229., 18292.]]],\n","               \n","               \n","                       [[[19316., 26043., 24979.],\n","                         [19546., 22946., 22002.],\n","                         [17578., 22901., 21923.]],\n","               \n","                        [[22371., 22085., 22168.],\n","                         [22380., 22210., 22043.],\n","                         [23153., 22930., 22435.]],\n","               \n","                        [[19718., 22830., 25113.],\n","                         [20291., 21356., 20854.],\n","                         [20157., 20877., 18829.]],\n","               \n","                        ...,\n","               \n","                        [[23215., 23167., 23208.],\n","                         [23201., 23222., 23245.],\n","                         [23191., 23169., 23225.]],\n","               \n","                        [[20208., 25884., 27770.],\n","                         [31024., 24386., 23175.],\n","                         [20383., 16167., 25195.]],\n","               \n","                        [[18096., 26881., 24279.],\n","                         [21298., 28099., 27232.],\n","                         [25504., 27081., 28389.]]],\n","               \n","               \n","                       [[[34375., 40522., 36408.],\n","                         [41549., 31415., 25518.],\n","                         [33724., 23821., 25942.]],\n","               \n","                        [[32695., 33575., 34013.],\n","                         [33601., 34302., 34455.],\n","                         [33330., 33556., 32994.]],\n","               \n","                        [[31666., 35175., 36177.],\n","                         [32875., 36008., 37950.],\n","                         [33737., 35467., 37755.]],\n","               \n","                        ...,\n","               \n","                        [[32730., 32712., 32762.],\n","                         [32737., 32730., 32726.],\n","                         [32696., 32658., 32733.]],\n","               \n","                        [[34244., 37081., 27105.],\n","                         [39721., 17221., 18462.],\n","                         [28779.,  9127., 36101.]],\n","               \n","                        [[31654., 37341., 38830.],\n","                         [27956., 34576., 32444.],\n","                         [30093., 37602., 33576.]]]], device='cuda:0')),\n","              ('module.layer1.2.conv1.wrapped_module.bias',\n","               tensor([ 3.1390e+08,  2.1475e+09, -3.9354e+08, -2.1475e+09,  1.2843e+09,\n","                       -2.1475e+09,  1.3152e+09, -2.1475e+09,  8.1228e+08,  3.2722e+08,\n","                       -6.0715e+08,  5.8262e+08, -1.2878e+09, -8.1666e+08, -2.3260e+08,\n","                        1.9787e+08], device='cuda:0')),\n","              ('module.layer1.2.conv2.num_forwards',\n","               tensor([40], device='cuda:0')),\n","              ('module.layer1.2.conv2.force_readjust',\n","               tensor(False, device='cuda:0')),\n","              ('module.layer1.2.conv2.output_scale',\n","               tensor([12833.8047], device='cuda:0')),\n","              ('module.layer1.2.conv2.output_zero_point',\n","               tensor([-37599.], device='cuda:0')),\n","              ('module.layer1.2.conv2.w_scale', tensor([[[[1.0990e+05]]],\n","               \n","               \n","                       [[[1.6008e+05]]],\n","               \n","               \n","                       [[[8.1437e+04]]],\n","               \n","               \n","                       [[[2.1002e+05]]],\n","               \n","               \n","                       [[[2.0859e+05]]],\n","               \n","               \n","                       [[[2.4019e+05]]],\n","               \n","               \n","                       [[[1.9094e+05]]],\n","               \n","               \n","                       [[[1.1733e+05]]],\n","               \n","               \n","                       [[[1.2640e+05]]],\n","               \n","               \n","                       [[[8.6679e+05]]],\n","               \n","               \n","                       [[[5.5904e+04]]],\n","               \n","               \n","                       [[[1.1413e+05]]],\n","               \n","               \n","                       [[[2.7435e+05]]],\n","               \n","               \n","                       [[[4.4361e+08]]],\n","               \n","               \n","                       [[[8.6254e+04]]],\n","               \n","               \n","                       [[[2.3753e+05]]]], device='cuda:0')),\n","              ('module.layer1.2.conv2.w_zero_point', tensor([[[[-30677.]]],\n","               \n","               \n","                       [[[-26216.]]],\n","               \n","               \n","                       [[[-32687.]]],\n","               \n","               \n","                       [[[-37874.]]],\n","               \n","               \n","                       [[[-21461.]]],\n","               \n","               \n","                       [[[-34979.]]],\n","               \n","               \n","                       [[[-27153.]]],\n","               \n","               \n","                       [[[-38706.]]],\n","               \n","               \n","                       [[[-37573.]]],\n","               \n","               \n","                       [[[-30207.]]],\n","               \n","               \n","                       [[[-43894.]]],\n","               \n","               \n","                       [[[-38801.]]],\n","               \n","               \n","                       [[[-29387.]]],\n","               \n","               \n","                       [[[-23504.]]],\n","               \n","               \n","                       [[[-31260.]]],\n","               \n","               \n","                       [[[-35498.]]]], device='cuda:0')),\n","              ('module.layer1.2.conv2.fp_bias',\n","               tensor([-0.4849, -0.4158, -0.5719,  0.1680, -0.2105,  0.0181, -0.1813,  0.4380,\n","                        0.7847,  0.0946,  1.4698,  0.3243,  0.0639, -0.0031, -0.2415,  0.3647],\n","                      device='cuda:0')),\n","              ('module.layer1.2.conv2.accum_scale', tensor([[[3.2178e+09]],\n","               \n","                       [[4.6873e+09]],\n","               \n","                       [[2.3845e+09]],\n","               \n","                       [[6.1494e+09]],\n","               \n","                       [[6.1077e+09]],\n","               \n","                       [[7.0329e+09]],\n","               \n","                       [[5.5908e+09]],\n","               \n","                       [[3.4355e+09]],\n","               \n","                       [[3.7009e+09]],\n","               \n","                       [[2.5380e+10]],\n","               \n","                       [[1.6369e+09]],\n","               \n","                       [[3.3417e+09]],\n","               \n","                       [[8.0331e+09]],\n","               \n","                       [[1.2989e+13]],\n","               \n","                       [[2.5255e+09]],\n","               \n","                       [[6.9548e+09]]], device='cuda:0')),\n","              ('module.layer1.2.conv2.is_simulated_quant_weight_shifted',\n","               tensor(False, device='cuda:0')),\n","              ('module.layer1.2.conv2.wrapped_module.weight',\n","               tensor([[[[17483., 38749., 17519.],\n","                         [34664., 30235., 32833.],\n","                         [34309., 22185., 42412.]],\n","               \n","                        [[37525., 31161., 26608.],\n","                         [37701., 26090., 24091.],\n","                         [27347., 20497., 19176.]],\n","               \n","                        [[32193., 26342., 23163.],\n","                         [33443., 21010., 25833.],\n","                         [31856., 26013., 40294.]],\n","               \n","                        ...,\n","               \n","                        [[16414., 37264., 65036.],\n","                         [ 5855., 24510., 65535.],\n","                         [    0., 22729., 49648.]],\n","               \n","                        [[42929., 31886., 22603.],\n","                         [40215., 29587., 47313.],\n","                         [24741., 17347., 35790.]],\n","               \n","                        [[15673., 52533., 43563.],\n","                         [17106., 48177., 49749.],\n","                         [ 8942., 42487., 52326.]]],\n","               \n","               \n","                       [[[36187., 50136.,  7383.],\n","                         [32143., 53435.,  8853.],\n","                         [25100., 62135.,  1510.]],\n","               \n","                        [[21588., 26954., 24409.],\n","                         [42428., 39712., 34288.],\n","                         [22394., 27959., 24379.]],\n","               \n","                        [[20489., 46796., 26751.],\n","                         [22899., 42220., 16205.],\n","                         [34034., 38774., 19239.]],\n","               \n","                        ...,\n","               \n","                        [[32076., 29518., 31308.],\n","                         [28310., 32135., 22600.],\n","                         [34319., 33073., 24742.]],\n","               \n","                        [[28231., 42231., 16963.],\n","                         [42270., 65535., 46733.],\n","                         [28659., 55579., 26784.]],\n","               \n","                        [[44262., 37416., 10567.],\n","                         [34359., 35527., 26268.],\n","                         [    0., 33278., 22146.]]],\n","               \n","               \n","                       [[[23905., 43522., 23241.],\n","                         [27742., 27793., 34705.],\n","                         [28659., 22872., 33750.]],\n","               \n","                        [[39512., 42376., 31641.],\n","                         [39139., 36188., 32216.],\n","                         [41856., 36873., 31781.]],\n","               \n","                        [[25567., 35450., 28030.],\n","                         [34117., 38018., 39573.],\n","                         [37099., 36671., 35241.]],\n","               \n","                        ...,\n","               \n","                        [[37568., 40899., 43525.],\n","                         [37664., 37262., 37494.],\n","                         [30180., 32751., 31972.]],\n","               \n","                        [[38697., 51329., 27399.],\n","                         [45057., 58218., 63112.],\n","                         [51728., 58102., 65535.]],\n","               \n","                        [[24945., 31010., 18375.],\n","                         [20902., 26990., 25952.],\n","                         [    0., 25983., 35519.]]],\n","               \n","               \n","                       ...,\n","               \n","               \n","                       [[[19952., 22449., 25460.],\n","                         [14091., 14798., 23974.],\n","                         [18715., 23959., 29681.]],\n","               \n","                        [[19034., 12722., 29947.],\n","                         [ 8122., 14039., 19515.],\n","                         [14183., 13371., 25490.]],\n","               \n","                        [[ 6121.,  6361., 11985.],\n","                         [28535., 22599., 18288.],\n","                         [26313., 25774., 24604.]],\n","               \n","                        ...,\n","               \n","                        [[65218., 61638., 55260.],\n","                         [64796., 65535., 52207.],\n","                         [57128., 60704., 59222.]],\n","               \n","                        [[14243., 24813., 25803.],\n","                         [20082., 19430., 17080.],\n","                         [15389., 16874., 31506.]],\n","               \n","                        [[28752., 27208., 47565.],\n","                         [35199., 34011., 62458.],\n","                         [48514., 55371., 62702.]]],\n","               \n","               \n","                       [[[23883., 34674., 25045.],\n","                         [45624., 49381., 62984.],\n","                         [46972., 38092., 35483.]],\n","               \n","                        [[40026., 42035., 42092.],\n","                         [36817., 32997., 40479.],\n","                         [42911., 38957., 31187.]],\n","               \n","                        [[30008., 42038., 35460.],\n","                         [37579., 27985., 43805.],\n","                         [41277., 37155., 41418.]],\n","               \n","                        ...,\n","               \n","                        [[13450., 18565., 31923.],\n","                         [26091., 17103., 39436.],\n","                         [18560., 29826., 29576.]],\n","               \n","                        [[23249., 27384., 25706.],\n","                         [    0., 14103., 44885.],\n","                         [22311., 26150., 40909.]],\n","               \n","                        [[35707., 36219., 42000.],\n","                         [23398., 50373., 64797.],\n","                         [17425., 65535., 48164.]]],\n","               \n","               \n","                       [[[28269., 25878., 35761.],\n","                         [ 4568., 34396., 36709.],\n","                         [32419., 37502., 44634.]],\n","               \n","                        [[49156., 34357., 22299.],\n","                         [51674., 49191., 27110.],\n","                         [46173., 50328., 34379.]],\n","               \n","                        [[39257., 25193., 13836.],\n","                         [45422., 43775., 32237.],\n","                         [39541., 48344., 33857.]],\n","               \n","                        ...,\n","               \n","                        [[46444., 38811., 24601.],\n","                         [37072., 38369., 31180.],\n","                         [65535., 46008., 38974.]],\n","               \n","                        [[40975.,     0., 15648.],\n","                         [55314., 32454.,  6236.],\n","                         [61545., 39986., 25288.]],\n","               \n","                        [[26638., 33140.,  4916.],\n","                         [12034.,  3810.,  1922.],\n","                         [45724., 17188.,  1527.]]]], device='cuda:0')),\n","              ('module.layer1.2.conv2.wrapped_module.bias',\n","               tensor([-1.5602e+09, -1.9490e+09, -1.3637e+09,  1.0330e+09, -1.2858e+09,\n","                        1.2724e+08, -1.0135e+09,  1.5048e+09,  2.1475e+09,  2.1475e+09,\n","                        2.1475e+09,  1.0837e+09,  5.1310e+08, -2.1475e+09, -6.0983e+08,\n","                        2.1475e+09], device='cuda:0')),\n","              ('module.layer1.2.relu2.num_forwards',\n","               tensor([40], device='cuda:0')),\n","              ('module.layer1.2.relu2.force_readjust',\n","               tensor(False, device='cuda:0')),\n","              ('module.layer1.2.relu2.output_scale',\n","               tensor([7414.7227], device='cuda:0')),\n","              ('module.layer1.2.relu2.output_zero_point',\n","               tensor([0.], device='cuda:0')),\n","              ('module.layer1.2.residual_eltwiseadd.num_forwards',\n","               tensor([40], device='cuda:0')),\n","              ('module.layer1.2.residual_eltwiseadd.force_readjust',\n","               tensor(False, device='cuda:0')),\n","              ('module.layer1.2.residual_eltwiseadd.output_scale',\n","               tensor([7414.7227], device='cuda:0')),\n","              ('module.layer1.2.residual_eltwiseadd.output_zero_point',\n","               tensor([0.], device='cuda:0')),\n","              ('module.layer1.3.conv1.num_forwards',\n","               tensor([40], device='cuda:0')),\n","              ('module.layer1.3.conv1.force_readjust',\n","               tensor(False, device='cuda:0')),\n","              ('module.layer1.3.conv1.output_scale',\n","               tensor([45850.4766], device='cuda:0')),\n","              ('module.layer1.3.conv1.output_zero_point',\n","               tensor([0.], device='cuda:0')),\n","              ('module.layer1.3.conv1.w_scale', tensor([[[[4.9628e+09]]],\n","               \n","               \n","                       [[[8.2632e+08]]],\n","               \n","               \n","                       [[[5.5689e+05]]],\n","               \n","               \n","                       [[[1.3177e+06]]],\n","               \n","               \n","                       [[[1.0727e+09]]],\n","               \n","               \n","                       [[[4.7879e+05]]],\n","               \n","               \n","                       [[[1.9353e+06]]],\n","               \n","               \n","                       [[[1.0472e+06]]],\n","               \n","               \n","                       [[[4.9779e+05]]],\n","               \n","               \n","                       [[[4.9143e+05]]],\n","               \n","               \n","                       [[[5.9264e+08]]],\n","               \n","               \n","                       [[[8.2837e+06]]],\n","               \n","               \n","                       [[[5.7665e+08]]],\n","               \n","               \n","                       [[[4.1972e+05]]],\n","               \n","               \n","                       [[[4.6655e+05]]],\n","               \n","               \n","                       [[[8.9862e+08]]]], device='cuda:0')),\n","              ('module.layer1.3.conv1.w_zero_point', tensor([[[[-42737.]]],\n","               \n","               \n","                       [[[-41731.]]],\n","               \n","               \n","                       [[[-26817.]]],\n","               \n","               \n","                       [[[-23420.]]],\n","               \n","               \n","                       [[[-22933.]]],\n","               \n","               \n","                       [[[-23135.]]],\n","               \n","               \n","                       [[[-41372.]]],\n","               \n","               \n","                       [[[-28087.]]],\n","               \n","               \n","                       [[[-33217.]]],\n","               \n","               \n","                       [[[-33042.]]],\n","               \n","               \n","                       [[[-36991.]]],\n","               \n","               \n","                       [[[-34235.]]],\n","               \n","               \n","                       [[[-42713.]]],\n","               \n","               \n","                       [[[-23475.]]],\n","               \n","               \n","                       [[[-35924.]]],\n","               \n","               \n","                       [[[-23714.]]]], device='cuda:0')),\n","              ('module.layer1.3.conv1.fp_bias',\n","               tensor([-4.5256e-04, -3.4339e-04,  1.0159e-01, -2.6967e-01, -2.1598e-03,\n","                       -1.2630e+00,  1.7931e-01, -2.1908e-01,  3.6326e-01,  6.8814e-01,\n","                       -9.6575e-04,  1.1105e-02, -4.2278e-04, -1.3538e+00,  3.8317e-01,\n","                       -3.3907e-03], device='cuda:0')),\n","              ('module.layer1.3.conv1.accum_scale', tensor([[[3.6798e+13]],\n","               \n","                       [[6.1270e+12]],\n","               \n","                       [[4.1292e+09]],\n","               \n","                       [[9.7704e+09]],\n","               \n","                       [[7.9536e+12]],\n","               \n","                       [[3.5501e+09]],\n","               \n","                       [[1.4350e+10]],\n","               \n","                       [[7.7644e+09]],\n","               \n","                       [[3.6909e+09]],\n","               \n","                       [[3.6438e+09]],\n","               \n","                       [[4.3943e+12]],\n","               \n","                       [[6.1422e+10]],\n","               \n","                       [[4.2757e+12]],\n","               \n","                       [[3.1121e+09]],\n","               \n","                       [[3.4593e+09]],\n","               \n","                       [[6.6630e+12]]], device='cuda:0')),\n","              ('module.layer1.3.conv1.is_simulated_quant_weight_shifted',\n","               tensor(False, device='cuda:0')),\n","              ('module.layer1.3.conv1.wrapped_module.weight',\n","               tensor([[[[45380., 56706., 47372.],\n","                         [46454., 45135., 52375.],\n","                         [44813., 45148., 51309.]],\n","               \n","                        [[35216., 31772., 34233.],\n","                         [29295., 44573., 47006.],\n","                         [27794., 36158., 35390.]],\n","               \n","                        [[51611., 51851., 54259.],\n","                         [50269., 55606., 54496.],\n","                         [65535., 54969., 51359.]],\n","               \n","                        ...,\n","               \n","                        [[18819., 19215., 40619.],\n","                         [27102., 18483., 44300.],\n","                         [26010., 30150., 40632.]],\n","               \n","                        [[45586., 57351., 44838.],\n","                         [56542., 49818., 48838.],\n","                         [43993., 39289., 43996.]],\n","               \n","                        [[20244., 28334., 21076.],\n","                         [12767., 15715., 14168.],\n","                         [12918., 21371., 19836.]]],\n","               \n","               \n","                       [[[40663., 32643., 40405.],\n","                         [39597., 34722., 46001.],\n","                         [35558., 42933., 42294.]],\n","               \n","                        [[31996., 27282., 25252.],\n","                         [39891., 34656., 47408.],\n","                         [59294., 39891., 45035.]],\n","               \n","                        [[31632., 35689., 40940.],\n","                         [32461., 20260., 35130.],\n","                         [49153., 37853., 47830.]],\n","               \n","                        ...,\n","               \n","                        [[46376., 40808., 41268.],\n","                         [22753., 27457., 24376.],\n","                         [22634., 29298., 16044.]],\n","               \n","                        [[49494., 63189., 61276.],\n","                         [39042., 60149., 52238.],\n","                         [22930., 43792., 39337.]],\n","               \n","                        [[17155., 25476., 21867.],\n","                         [16120., 27787.,  8735.],\n","                         [    0., 29949.,  5817.]]],\n","               \n","               \n","                       [[[27686., 36491., 35815.],\n","                         [24462., 30948., 25117.],\n","                         [14677., 19445., 19371.]],\n","               \n","                        [[26551., 27882., 27501.],\n","                         [25801., 28219., 27178.],\n","                         [26832., 29010., 28620.]],\n","               \n","                        [[22447., 21960., 24377.],\n","                         [23219., 23738., 27589.],\n","                         [23840., 25422., 29841.]],\n","               \n","                        ...,\n","               \n","                        [[26810., 26776., 26705.],\n","                         [26819., 26769., 26672.],\n","                         [26747., 26702., 26748.]],\n","               \n","                        [[30157., 15989., 20699.],\n","                         [ 7612., 16977., 24304.],\n","                         [14130., 20203., 21320.]],\n","               \n","                        [[24334., 24153., 21424.],\n","                         [38936., 31898., 26802.],\n","                         [28133., 17989., 13005.]]],\n","               \n","               \n","                       ...,\n","               \n","               \n","                       [[[24135., 29485., 32082.],\n","                         [21855., 25829., 28888.],\n","                         [26675., 31364., 36257.]],\n","               \n","                        [[24257., 28142., 28399.],\n","                         [25036., 28255., 28937.],\n","                         [29660., 32052., 32128.]],\n","               \n","                        [[30646., 34413., 36477.],\n","                         [30993., 33217., 34049.],\n","                         [37440., 38682., 40647.]],\n","               \n","                        ...,\n","               \n","                        [[23610., 23555., 23472.],\n","                         [23513., 23303., 23454.],\n","                         [23513., 23416., 23609.]],\n","               \n","                        [[12605.,  3538.,  7981.],\n","                         [ 9243.,  2345., 11678.],\n","                         [18418., 21227., 27802.]],\n","               \n","                        [[23363., 23897., 28576.],\n","                         [20091., 22107., 24280.],\n","                         [23452., 24781., 24441.]]],\n","               \n","               \n","                       [[[35117., 31436., 35867.],\n","                         [35065., 31450., 33284.],\n","                         [33069., 29321., 40300.]],\n","               \n","                        [[36255., 37319., 34087.],\n","                         [37111., 37772., 33816.],\n","                         [37315., 37575., 36099.]],\n","               \n","                        [[38638., 35906., 37994.],\n","                         [37975., 33029., 33573.],\n","                         [35779., 32975., 32403.]],\n","               \n","                        ...,\n","               \n","                        [[35838., 35885., 35800.],\n","                         [35880., 35818., 35794.],\n","                         [35832., 35888., 35824.]],\n","               \n","                        [[32030., 36390., 41905.],\n","                         [11520., 31991., 39813.],\n","                         [19740., 31368., 30897.]],\n","               \n","                        [[33487., 27712., 32554.],\n","                         [36385., 29158., 38398.],\n","                         [31532., 28652., 41355.]]],\n","               \n","               \n","                       [[[29211., 32317., 31269.],\n","                         [21766., 28279., 30666.],\n","                         [11665., 20951., 18725.]],\n","               \n","                        [[30318., 40753., 54472.],\n","                         [33425., 44537., 49522.],\n","                         [42118., 44908., 53039.]],\n","               \n","                        [[27703., 24752., 20623.],\n","                         [23176., 28991., 16213.],\n","                         [28426., 25910., 16525.]],\n","               \n","                        ...,\n","               \n","                        [[37459., 39227., 35593.],\n","                         [42069., 29503., 34177.],\n","                         [37915., 41956., 28886.]],\n","               \n","                        [[20346., 24739., 20880.],\n","                         [13679., 20318., 24554.],\n","                         [13449., 23255., 23662.]],\n","               \n","                        [[56518., 57458., 49572.],\n","                         [51509., 51920., 36596.],\n","                         [62597., 52670., 36275.]]]], device='cuda:0')),\n","              ('module.layer1.3.conv1.wrapped_module.bias',\n","               tensor([-2.1475e+09, -2.1039e+09,  4.1947e+08, -2.1475e+09, -2.1475e+09,\n","                       -2.1475e+09,  2.1475e+09, -1.7010e+09,  1.3408e+09,  2.1475e+09,\n","                       -2.1475e+09,  6.8211e+08, -1.8077e+09, -2.1475e+09,  1.3255e+09,\n","                       -2.1475e+09], device='cuda:0')),\n","              ('module.layer1.3.conv2.num_forwards',\n","               tensor([40], device='cuda:0')),\n","              ('module.layer1.3.conv2.force_readjust',\n","               tensor(False, device='cuda:0')),\n","              ('module.layer1.3.conv2.output_scale',\n","               tensor([18014.1660], device='cuda:0')),\n","              ('module.layer1.3.conv2.output_zero_point',\n","               tensor([-36861.], device='cuda:0')),\n","              ('module.layer1.3.conv2.w_scale', tensor([[[[ 107952.8281]]],\n","               \n","               \n","                       [[[ 389522.3438]]],\n","               \n","               \n","                       [[[ 429797.2812]]],\n","               \n","               \n","                       [[[ 241943.5938]]],\n","               \n","               \n","                       [[[ 474378.8125]]],\n","               \n","               \n","                       [[[ 501905.2500]]],\n","               \n","               \n","                       [[[ 871562.7500]]],\n","               \n","               \n","                       [[[ 158298.3438]]],\n","               \n","               \n","                       [[[1458308.6250]]],\n","               \n","               \n","                       [[[  99071.0781]]],\n","               \n","               \n","                       [[[ 232080.6875]]],\n","               \n","               \n","                       [[[ 646625.5000]]],\n","               \n","               \n","                       [[[ 348608.9062]]],\n","               \n","               \n","                       [[[  58402.5273]]],\n","               \n","               \n","                       [[[ 352644.3750]]],\n","               \n","               \n","                       [[[ 157108.7656]]]], device='cuda:0')),\n","              ('module.layer1.3.conv2.w_zero_point', tensor([[[[-28181.]]],\n","               \n","               \n","                       [[[-31148.]]],\n","               \n","               \n","                       [[[-22391.]]],\n","               \n","               \n","                       [[[-42831.]]],\n","               \n","               \n","                       [[[-23608.]]],\n","               \n","               \n","                       [[[-31141.]]],\n","               \n","               \n","                       [[[-44306.]]],\n","               \n","               \n","                       [[[-39701.]]],\n","               \n","               \n","                       [[[-42305.]]],\n","               \n","               \n","                       [[[-24831.]]],\n","               \n","               \n","                       [[[-37726.]]],\n","               \n","               \n","                       [[[-34955.]]],\n","               \n","               \n","                       [[[-33634.]]],\n","               \n","               \n","                       [[[-27034.]]],\n","               \n","               \n","                       [[[-42435.]]],\n","               \n","               \n","                       [[[-37571.]]]], device='cuda:0')),\n","              ('module.layer1.3.conv2.fp_bias',\n","               tensor([-0.1534, -0.1410, -0.3128,  0.1994, -0.2188,  0.1751,  0.1624,  0.3793,\n","                        0.0586,  0.2881,  0.0968,  0.1546,  0.0568,  0.7840,  0.1181,  0.2540],\n","                      device='cuda:0')),\n","              ('module.layer1.3.conv2.accum_scale', tensor([[[4.9497e+09]],\n","               \n","                       [[1.7860e+10]],\n","               \n","                       [[1.9706e+10]],\n","               \n","                       [[1.1093e+10]],\n","               \n","                       [[2.1750e+10]],\n","               \n","                       [[2.3013e+10]],\n","               \n","                       [[3.9962e+10]],\n","               \n","                       [[7.2581e+09]],\n","               \n","                       [[6.6864e+10]],\n","               \n","                       [[4.5425e+09]],\n","               \n","                       [[1.0641e+10]],\n","               \n","                       [[2.9648e+10]],\n","               \n","                       [[1.5984e+10]],\n","               \n","                       [[2.6778e+09]],\n","               \n","                       [[1.6169e+10]],\n","               \n","                       [[7.2035e+09]]], device='cuda:0')),\n","              ('module.layer1.3.conv2.is_simulated_quant_weight_shifted',\n","               tensor(False, device='cuda:0')),\n","              ('module.layer1.3.conv2.wrapped_module.weight',\n","               tensor([[[[28091., 28054., 28089.],\n","                         [28108., 28013., 28112.],\n","                         [28164., 28005., 28052.]],\n","               \n","                        [[28447., 28201., 28078.],\n","                         [28136., 28192., 27965.],\n","                         [28150., 28055., 28008.]],\n","               \n","                        [[24996.,  9740.,  9282.],\n","                         [34204.,  4567.,  8279.],\n","                         [48049., 12141., 12410.]],\n","               \n","                        ...,\n","               \n","                        [[ 9942., 17121., 28576.],\n","                         [25643., 22016., 26875.],\n","                         [30222., 27223., 34479.]],\n","               \n","                        [[32602., 34011., 10799.],\n","                         [16664., 20497.,     0.],\n","                         [19035., 27499.,  2358.]],\n","               \n","                        [[28044., 27868., 28021.],\n","                         [28171., 27762., 27923.],\n","                         [27809., 27788., 27768.]]],\n","               \n","               \n","                       [[[31484., 31125., 30956.],\n","                         [31028., 31065., 31192.],\n","                         [30902., 30817., 30618.]],\n","               \n","                        [[30739., 30839., 30686.],\n","                         [30649., 30595., 30689.],\n","                         [30635., 30649., 30430.]],\n","               \n","                        [[27618., 22533., 20440.],\n","                         [30392., 25057., 22523.],\n","                         [34739., 32895., 32152.]],\n","               \n","                        ...,\n","               \n","                        [[32794., 37927., 38958.],\n","                         [12991., 17542., 25936.],\n","                         [34623., 38902., 49178.]],\n","               \n","                        [[    0., 27111., 30561.],\n","                         [19596., 38709., 34725.],\n","                         [13618., 41787., 60743.]],\n","               \n","                        [[30873., 30643., 31134.],\n","                         [31108., 30854., 30915.],\n","                         [30970., 30478., 30514.]]],\n","               \n","               \n","                       [[[21660., 22034., 22038.],\n","                         [22001., 21942., 21907.],\n","                         [21957., 22157., 22211.]],\n","               \n","                        [[22006., 21647., 21870.],\n","                         [21916., 22121., 21920.],\n","                         [21925., 21984., 22198.]],\n","               \n","                        [[17745., 18837.,  1683.],\n","                         [24482., 27250.,  5161.],\n","                         [22011., 29718., 15296.]],\n","               \n","                        ...,\n","               \n","                        [[39111., 42897., 44287.],\n","                         [ 9820., 14954., 21374.],\n","                         [10198.,  9621., 21973.]],\n","               \n","                        [[ 3975.,   255., 44184.],\n","                         [35216., 18434.,  2975.],\n","                         [38916., 33883.,  5233.]],\n","               \n","                        [[21838., 22179., 22027.],\n","                         [21971., 21781., 22307.],\n","                         [22406., 21906., 22070.]]],\n","               \n","               \n","                       ...,\n","               \n","               \n","                       [[[26858., 26955., 26997.],\n","                         [27043., 27055., 27059.],\n","                         [27115., 27151., 27041.]],\n","               \n","                        [[26956., 27009., 27039.],\n","                         [27009., 27146., 27094.],\n","                         [27233., 27242., 27206.]],\n","               \n","                        [[27356., 32247., 36407.],\n","                         [15757., 24373., 27101.],\n","                         [12305., 17690., 18871.]],\n","               \n","                        ...,\n","               \n","                        [[21675., 20801., 23524.],\n","                         [19226., 17233., 19583.],\n","                         [26594., 20869., 15912.]],\n","               \n","                        [[    0., 14995., 10884.],\n","                         [13019., 18821., 21101.],\n","                         [30791., 32877., 23968.]],\n","               \n","                        [[26639., 26663., 26704.],\n","                         [26641., 26781., 26756.],\n","                         [26631., 26767., 26768.]]],\n","               \n","               \n","                       [[[42519., 42504., 42479.],\n","                         [42583., 42503., 42473.],\n","                         [42461., 42448., 42428.]],\n","               \n","                        [[42564., 42612., 42644.],\n","                         [42533., 42432., 42460.],\n","                         [42548., 42354., 42439.]],\n","               \n","                        [[48636., 43262., 47083.],\n","                         [55303., 37136., 40066.],\n","                         [41250., 35921., 37987.]],\n","               \n","                        ...,\n","               \n","                        [[43504., 32142., 25717.],\n","                         [49605., 36743., 30414.],\n","                         [51290., 39105., 35849.]],\n","               \n","                        [[47658., 49713., 31968.],\n","                         [55607., 52391.,     0.],\n","                         [53284., 60450., 23401.]],\n","               \n","                        [[42507., 42502., 42399.],\n","                         [42403., 42531., 42359.],\n","                         [42477., 42469., 42449.]]],\n","               \n","               \n","                       [[[38212., 37940., 37773.],\n","                         [38099., 37927., 37857.],\n","                         [38031., 37995., 37906.]],\n","               \n","                        [[38255., 38183., 38177.],\n","                         [38192., 38217., 38153.],\n","                         [38285., 38319., 38219.]],\n","               \n","                        [[43092., 42786., 44843.],\n","                         [36247., 50732., 51412.],\n","                         [38473., 47047., 52173.]],\n","               \n","                        ...,\n","               \n","                        [[31617., 45464., 39730.],\n","                         [42949., 44398., 47172.],\n","                         [38141., 39779., 47278.]],\n","               \n","                        [[55866., 59122., 26007.],\n","                         [44969., 49349., 60706.],\n","                         [36767., 37104., 58360.]],\n","               \n","                        [[37903., 37854., 37810.],\n","                         [37770., 37777., 37740.],\n","                         [37673., 37842., 37743.]]]], device='cuda:0')),\n","              ('module.layer1.3.conv2.wrapped_module.bias',\n","               tensor([-7.5952e+08, -2.1475e+09, -2.1475e+09,  2.1475e+09, -2.1475e+09,\n","                        2.1475e+09,  2.1475e+09,  2.1475e+09,  2.1475e+09,  1.3087e+09,\n","                        1.0303e+09,  2.1475e+09,  9.0799e+08,  2.0994e+09,  1.9102e+09,\n","                        1.8297e+09], device='cuda:0')),\n","              ('module.layer1.3.relu2.num_forwards',\n","               tensor([40], device='cuda:0')),\n","              ('module.layer1.3.relu2.force_readjust',\n","               tensor(False, device='cuda:0')),\n","              ('module.layer1.3.relu2.output_scale',\n","               tensor([7319.4404], device='cuda:0')),\n","              ('module.layer1.3.relu2.output_zero_point',\n","               tensor([0.], device='cuda:0')),\n","              ('module.layer1.3.residual_eltwiseadd.num_forwards',\n","               tensor([40], device='cuda:0')),\n","              ('module.layer1.3.residual_eltwiseadd.force_readjust',\n","               tensor(False, device='cuda:0')),\n","              ('module.layer1.3.residual_eltwiseadd.output_scale',\n","               tensor([7319.4404], device='cuda:0')),\n","              ('module.layer1.3.residual_eltwiseadd.output_zero_point',\n","               tensor([0.], device='cuda:0')),\n","              ('module.layer1.4.conv1.num_forwards',\n","               tensor([40], device='cuda:0')),\n","              ('module.layer1.4.conv1.force_readjust',\n","               tensor(False, device='cuda:0')),\n","              ('module.layer1.4.conv1.output_scale',\n","               tensor([65146.0352], device='cuda:0')),\n","              ('module.layer1.4.conv1.output_zero_point',\n","               tensor([0.], device='cuda:0')),\n","              ('module.layer1.4.conv1.w_scale', tensor([[[[7.7955e+05]]],\n","               \n","               \n","                       [[[8.1357e+05]]],\n","               \n","               \n","                       [[[3.4932e+06]]],\n","               \n","               \n","                       [[[1.3312e+08]]],\n","               \n","               \n","                       [[[6.4943e+05]]],\n","               \n","               \n","                       [[[6.1444e+06]]],\n","               \n","               \n","                       [[[4.8032e+05]]],\n","               \n","               \n","                       [[[9.7500e+05]]],\n","               \n","               \n","                       [[[5.5292e+05]]],\n","               \n","               \n","                       [[[6.3870e+05]]],\n","               \n","               \n","                       [[[1.1762e+06]]],\n","               \n","               \n","                       [[[3.4834e+05]]],\n","               \n","               \n","                       [[[8.8844e+06]]],\n","               \n","               \n","                       [[[4.9106e+05]]],\n","               \n","               \n","                       [[[8.2477e+05]]],\n","               \n","               \n","                       [[[1.6904e+07]]]], device='cuda:0')),\n","              ('module.layer1.4.conv1.w_zero_point', tensor([[[[-25967.]]],\n","               \n","               \n","                       [[[-26805.]]],\n","               \n","               \n","                       [[[-33561.]]],\n","               \n","               \n","                       [[[-19364.]]],\n","               \n","               \n","                       [[[-30688.]]],\n","               \n","               \n","                       [[[-26784.]]],\n","               \n","               \n","                       [[[-34483.]]],\n","               \n","               \n","                       [[[-32541.]]],\n","               \n","               \n","                       [[[-30930.]]],\n","               \n","               \n","                       [[[-39116.]]],\n","               \n","               \n","                       [[[-33856.]]],\n","               \n","               \n","                       [[[-23098.]]],\n","               \n","               \n","                       [[[-40728.]]],\n","               \n","               \n","                       [[[-48289.]]],\n","               \n","               \n","                       [[[-34425.]]],\n","               \n","               \n","                       [[[-35490.]]]], device='cuda:0')),\n","              ('module.layer1.4.conv1.fp_bias',\n","               tensor([-0.7734, -0.2687, -0.1228, -0.0209, -0.7211,  0.0539, -0.6993, -0.6185,\n","                       -0.3982,  0.2551,  0.1397, -1.2107, -0.1246,  0.2174,  0.2743, -0.0374],\n","                      device='cuda:0')),\n","              ('module.layer1.4.conv1.accum_scale', tensor([[[5.7059e+09]],\n","               \n","                       [[5.9549e+09]],\n","               \n","                       [[2.5568e+10]],\n","               \n","                       [[9.7433e+11]],\n","               \n","                       [[4.7535e+09]],\n","               \n","                       [[4.4974e+10]],\n","               \n","                       [[3.5157e+09]],\n","               \n","                       [[7.1364e+09]],\n","               \n","                       [[4.0470e+09]],\n","               \n","                       [[4.6749e+09]],\n","               \n","                       [[8.6090e+09]],\n","               \n","                       [[2.5496e+09]],\n","               \n","                       [[6.5029e+10]],\n","               \n","                       [[3.5943e+09]],\n","               \n","                       [[6.0369e+09]],\n","               \n","                       [[1.2372e+11]]], device='cuda:0')),\n","              ('module.layer1.4.conv1.is_simulated_quant_weight_shifted',\n","               tensor(False, device='cuda:0')),\n","              ('module.layer1.4.conv1.wrapped_module.weight',\n","               tensor([[[[ 9757., 34317., 34479.],\n","                         [25259., 42606., 34431.],\n","                         [27833., 36769., 21374.]],\n","               \n","                        [[24307., 23617., 28262.],\n","                         [27597., 26974., 32538.],\n","                         [26041., 25166., 32435.]],\n","               \n","                        [[22824., 27546., 38880.],\n","                         [22791., 24610., 34226.],\n","                         [26581., 26636., 37332.]],\n","               \n","                        ...,\n","               \n","                        [[20624., 21627., 23144.],\n","                         [23121., 19524., 21326.],\n","                         [18148., 13950., 15852.]],\n","               \n","                        [[17793., 49304., 43713.],\n","                         [13008., 31090., 18517.],\n","                         [ 5191., 28984., 16073.]],\n","               \n","                        [[26503., 28591., 16612.],\n","                         [24252., 32439., 18864.],\n","                         [24635., 31415., 20535.]]],\n","               \n","               \n","                       [[[15112., 15562., 15230.],\n","                         [26747., 22055., 16517.],\n","                         [34387., 32832., 30621.]],\n","               \n","                        [[25713., 23643., 25368.],\n","                         [26445., 24945., 25127.],\n","                         [26358., 27696., 24880.]],\n","               \n","                        [[24816., 19793., 24771.],\n","                         [19548., 20333., 22111.],\n","                         [19183., 21186., 21738.]],\n","               \n","                        ...,\n","               \n","                        [[31571., 32933., 25942.],\n","                         [26420., 29372., 26932.],\n","                         [22059., 21903., 24090.]],\n","               \n","                        [[ 4458.,  6226.,  6769.],\n","                         [22520.,  4456.,  6259.],\n","                         [26324.,     0.,   236.]],\n","               \n","                        [[25634., 19963., 10358.],\n","                         [18934., 31353., 22071.],\n","                         [21242., 35482., 34276.]]],\n","               \n","               \n","                       [[[16073., 24185., 36769.],\n","                         [24068., 30882., 40619.],\n","                         [36405., 40526., 46637.]],\n","               \n","                        [[35043., 31240., 33734.],\n","                         [39056., 35603., 38391.],\n","                         [37222., 31220., 35968.]],\n","               \n","                        [[37443., 32976., 38601.],\n","                         [39011., 35384., 39125.],\n","                         [35825., 30410., 35159.]],\n","               \n","                        ...,\n","               \n","                        [[35742., 37072., 36332.],\n","                         [36059., 39851., 36071.],\n","                         [32551., 40046., 37474.]],\n","               \n","                        [[38050., 24961., 29882.],\n","                         [21399., 17942., 31644.],\n","                         [22544., 17358., 42516.]],\n","               \n","                        [[46088., 45996., 45114.],\n","                         [50115., 52693., 52990.],\n","                         [65535., 64131., 55879.]]],\n","               \n","               \n","                       ...,\n","               \n","               \n","                       [[[50915., 51536., 51711.],\n","                         [46468., 47988., 48732.],\n","                         [44817., 52268., 50191.]],\n","               \n","                        [[45607., 48706., 47369.],\n","                         [47361., 49491., 48602.],\n","                         [47880., 47738., 47282.]],\n","               \n","                        [[49307., 50664., 47510.],\n","                         [47932., 48696., 47550.],\n","                         [49224., 50080., 48046.]],\n","               \n","                        ...,\n","               \n","                        [[49465., 50690., 49983.],\n","                         [49251., 47986., 49173.],\n","                         [48046., 49179., 49305.]],\n","               \n","                        [[54216., 49369., 53332.],\n","                         [54116., 54278., 49942.],\n","                         [50167., 53593., 47387.]],\n","               \n","                        [[55700., 58530., 48248.],\n","                         [49051., 47519., 48342.],\n","                         [55931., 50909., 50682.]]],\n","               \n","               \n","                       [[[33566., 42966., 37121.],\n","                         [35013., 44498., 39141.],\n","                         [31588., 40287., 31428.]],\n","               \n","                        [[31211., 31139., 25823.],\n","                         [32268., 32876., 31938.],\n","                         [28727., 31055., 31464.]],\n","               \n","                        [[29506., 31220., 21007.],\n","                         [26061., 32572., 24174.],\n","                         [30382., 32993., 31777.]],\n","               \n","                        ...,\n","               \n","                        [[35492., 37969., 36001.],\n","                         [40833., 34041., 36138.],\n","                         [39345., 35536., 30910.]],\n","               \n","                        [[27137., 37732., 47244.],\n","                         [28953., 19064., 27134.],\n","                         [14008., 13561., 14844.]],\n","               \n","                        [[26406., 31228., 34970.],\n","                         [32602., 36781., 33200.],\n","                         [32041., 37160., 39398.]]],\n","               \n","               \n","                       [[[36920., 40586., 32567.],\n","                         [35601., 34800., 30618.],\n","                         [40003., 35343., 34219.]],\n","               \n","                        [[36117., 36423., 35975.],\n","                         [36778., 36019., 37861.],\n","                         [33860., 35320., 34972.]],\n","               \n","                        [[36930., 35611., 33790.],\n","                         [40198., 40652., 39532.],\n","                         [36034., 38017., 35778.]],\n","               \n","                        ...,\n","               \n","                        [[31518., 31880., 30356.],\n","                         [30753., 30865., 32058.],\n","                         [31778., 31649., 33903.]],\n","               \n","                        [[23039., 47804., 32531.],\n","                         [36636., 49552., 44468.],\n","                         [44268., 41865., 37757.]],\n","               \n","                        [[31316., 31182., 30231.],\n","                         [32254., 35334., 24378.],\n","                         [30222., 32044., 22801.]]]], device='cuda:0')),\n","              ('module.layer1.4.conv1.wrapped_module.bias',\n","               tensor([-2.1475e+09, -1.6003e+09, -2.1475e+09, -2.1475e+09, -2.1475e+09,\n","                        2.1475e+09, -2.1475e+09, -2.1475e+09, -1.6116e+09,  1.1925e+09,\n","                        1.2031e+09, -2.1475e+09, -2.1475e+09,  7.8146e+08,  1.6559e+09,\n","                       -2.1475e+09], device='cuda:0')),\n","              ('module.layer1.4.conv2.num_forwards',\n","               tensor([40], device='cuda:0')),\n","              ('module.layer1.4.conv2.force_readjust',\n","               tensor(False, device='cuda:0')),\n","              ('module.layer1.4.conv2.output_scale',\n","               tensor([41998.4492], device='cuda:0')),\n","              ('module.layer1.4.conv2.output_zero_point',\n","               tensor([-30327.], device='cuda:0')),\n","              ('module.layer1.4.conv2.w_scale', tensor([[[[177410.5625]]],\n","               \n","               \n","                       [[[210093.9531]]],\n","               \n","               \n","                       [[[221902.8750]]],\n","               \n","               \n","                       [[[134714.0781]]],\n","               \n","               \n","                       [[[401358.4062]]],\n","               \n","               \n","                       [[[773068.1250]]],\n","               \n","               \n","                       [[[ 73651.6641]]],\n","               \n","               \n","                       [[[168618.9062]]],\n","               \n","               \n","                       [[[180688.0000]]],\n","               \n","               \n","                       [[[151383.8125]]],\n","               \n","               \n","                       [[[109042.5469]]],\n","               \n","               \n","                       [[[138915.6094]]],\n","               \n","               \n","                       [[[ 92420.8203]]],\n","               \n","               \n","                       [[[113684.8516]]],\n","               \n","               \n","                       [[[123821.7266]]],\n","               \n","               \n","                       [[[165650.8125]]]], device='cuda:0')),\n","              ('module.layer1.4.conv2.w_zero_point', tensor([[[[-37358.]]],\n","               \n","               \n","                       [[[-18495.]]],\n","               \n","               \n","                       [[[-28402.]]],\n","               \n","               \n","                       [[[-44810.]]],\n","               \n","               \n","                       [[[-43897.]]],\n","               \n","               \n","                       [[[-23638.]]],\n","               \n","               \n","                       [[[-28435.]]],\n","               \n","               \n","                       [[[-36719.]]],\n","               \n","               \n","                       [[[-34729.]]],\n","               \n","               \n","                       [[[-31648.]]],\n","               \n","               \n","                       [[[-38558.]]],\n","               \n","               \n","                       [[[-28654.]]],\n","               \n","               \n","                       [[[-39467.]]],\n","               \n","               \n","                       [[[-30791.]]],\n","               \n","               \n","                       [[[-41539.]]],\n","               \n","               \n","                       [[[-40989.]]]], device='cuda:0')),\n","              ('module.layer1.4.conv2.fp_bias',\n","               tensor([-0.0326, -0.2163, -0.1812,  0.4234, -0.0543,  0.2223, -0.0781,  0.3413,\n","                        0.2444, -0.0318,  0.2379, -0.0833,  0.2922,  0.1616,  0.0247,  0.4540],\n","                      device='cuda:0')),\n","              ('module.layer1.4.conv2.accum_scale', tensor([[[1.1558e+10]],\n","               \n","                       [[1.3687e+10]],\n","               \n","                       [[1.4456e+10]],\n","               \n","                       [[8.7761e+09]],\n","               \n","                       [[2.6147e+10]],\n","               \n","                       [[5.0362e+10]],\n","               \n","                       [[4.7981e+09]],\n","               \n","                       [[1.0985e+10]],\n","               \n","                       [[1.1771e+10]],\n","               \n","                       [[9.8621e+09]],\n","               \n","                       [[7.1037e+09]],\n","               \n","                       [[9.0498e+09]],\n","               \n","                       [[6.0209e+09]],\n","               \n","                       [[7.4061e+09]],\n","               \n","                       [[8.0665e+09]],\n","               \n","                       [[1.0791e+10]]], device='cuda:0')),\n","              ('module.layer1.4.conv2.is_simulated_quant_weight_shifted',\n","               tensor(False, device='cuda:0')),\n","              ('module.layer1.4.conv2.wrapped_module.weight',\n","               tensor([[[[56943., 50126., 41911.],\n","                         [49364., 24356.,  7373.],\n","                         [20199.,     0., 32936.]],\n","               \n","                        [[ 4851., 25817., 59476.],\n","                         [ 7391., 15930., 61518.],\n","                         [15458., 13883., 37214.]],\n","               \n","                        [[40560., 40104., 39550.],\n","                         [41151., 39140., 36251.],\n","                         [38467., 35884., 36666.]],\n","               \n","                        ...,\n","               \n","                        [[ 9160.,  7526., 26736.],\n","                         [47810., 44684., 54275.],\n","                         [30287., 49771., 59485.]],\n","               \n","                        [[18813., 16260., 30201.],\n","                         [23661., 12461., 31148.],\n","                         [ 8019.,  2289., 23174.]],\n","               \n","                        [[36725., 29957., 27458.],\n","                         [39264., 33525., 31851.],\n","                         [36561., 34760., 34097.]]],\n","               \n","               \n","                       [[[27382., 24251., 15362.],\n","                         [21860., 24113., 21175.],\n","                         [ 8241., 14520., 13764.]],\n","               \n","                        [[13928., 14501., 16688.],\n","                         [14510., 15022., 21468.],\n","                         [13410., 16116., 20637.]],\n","               \n","                        [[18448., 17531., 16659.],\n","                         [18951., 18131., 16474.],\n","                         [19329., 18333., 16632.]],\n","               \n","                        ...,\n","               \n","                        [[26641., 24487., 11492.],\n","                         [27849., 21136.,     0.],\n","                         [34911., 16890., 14565.]],\n","               \n","                        [[15855., 29265., 18844.],\n","                         [28412., 42949., 31712.],\n","                         [17788., 24088., 19474.]],\n","               \n","                        [[17216., 18778., 17133.],\n","                         [19859., 20361., 19643.],\n","                         [21259., 20490., 20313.]]],\n","               \n","               \n","                       [[[40920., 27973., 26407.],\n","                         [38282., 29781., 26650.],\n","                         [23715., 12403., 14762.]],\n","               \n","                        [[29171., 28520., 27524.],\n","                         [27199., 25959., 28199.],\n","                         [25017., 24437., 25984.]],\n","               \n","                        [[27752., 28454., 28697.],\n","                         [28438., 28513., 27978.],\n","                         [28277., 28124., 27852.]],\n","               \n","                        ...,\n","               \n","                        [[40688., 29632., 16855.],\n","                         [37943., 44131., 16659.],\n","                         [    0., 14134., 17979.]],\n","               \n","                        [[19083., 23111., 19250.],\n","                         [25193., 26207., 35354.],\n","                         [19050., 19338., 28738.]],\n","               \n","                        [[28565., 27247., 26966.],\n","                         [32729., 30336., 30133.],\n","                         [32094., 29758., 29527.]]],\n","               \n","               \n","                       ...,\n","               \n","               \n","                       [[[31104., 30031., 36960.],\n","                         [22640., 25994., 32826.],\n","                         [21211., 26092., 36946.]],\n","               \n","                        [[33595., 18866., 17199.],\n","                         [40619., 29564., 29767.],\n","                         [39753., 33870., 38404.]],\n","               \n","                        [[29001., 29135., 28925.],\n","                         [29639., 30021., 29296.],\n","                         [31636., 32182., 30732.]],\n","               \n","                        ...,\n","               \n","                        [[26680., 20112., 37581.],\n","                         [23604., 38338., 65535.],\n","                         [24321., 17462., 21143.]],\n","               \n","                        [[ 8057., 22883., 43788.],\n","                         [18355., 24016., 36665.],\n","                         [20007., 23465., 23991.]],\n","               \n","                        [[34787., 33120., 31536.],\n","                         [32480., 32429., 32077.],\n","                         [27829., 29773., 29722.]]],\n","               \n","               \n","                       [[[41989., 34181., 36244.],\n","                         [46849., 26096., 27035.],\n","                         [33182., 15600., 42076.]],\n","               \n","                        [[54502., 35443., 48558.],\n","                         [47113., 32877., 39879.],\n","                         [42478., 36270., 35353.]],\n","               \n","                        [[42505., 39888., 40608.],\n","                         [43802., 38863., 42404.],\n","                         [42427., 38690., 41931.]],\n","               \n","                        ...,\n","               \n","                        [[47554., 42354., 20662.],\n","                         [46090., 30536., 40632.],\n","                         [34878., 42769., 65535.]],\n","               \n","                        [[41405., 40572., 45404.],\n","                         [32841., 33894., 59142.],\n","                         [44905., 41395., 39722.]],\n","               \n","                        [[43020., 39200., 43779.],\n","                         [41142., 37452., 40621.],\n","                         [38308., 35746., 39332.]]],\n","               \n","               \n","                       [[[56466., 46539., 57489.],\n","                         [50186., 46086., 50462.],\n","                         [38601., 44920., 53019.]],\n","               \n","                        [[56150., 47577., 36226.],\n","                         [52726., 48831., 37048.],\n","                         [39183., 41002., 46826.]],\n","               \n","                        [[39073., 42530., 39345.],\n","                         [37903., 40921., 37333.],\n","                         [35162., 39721., 37804.]],\n","               \n","                        ...,\n","               \n","                        [[30971., 19137., 42037.],\n","                         [35271.,   280., 10865.],\n","                         [46154., 34773., 21360.]],\n","               \n","                        [[28248., 14728.,  4361.],\n","                         [40303., 47449., 28647.],\n","                         [50109., 65535., 50762.]],\n","               \n","                        [[38697., 42080., 38903.],\n","                         [41348., 42984., 40921.],\n","                         [44484., 43869., 41681.]]]], device='cuda:0')),\n","              ('module.layer1.4.conv2.wrapped_module.bias',\n","               tensor([-3.7633e+08, -2.1475e+09, -2.1475e+09,  2.1475e+09, -1.4196e+09,\n","                        2.1475e+09, -3.7454e+08,  2.1475e+09,  2.1475e+09, -3.1369e+08,\n","                        1.6900e+09, -7.5349e+08,  1.7592e+09,  1.1966e+09,  1.9908e+08,\n","                        2.1475e+09], device='cuda:0')),\n","              ('module.layer1.4.relu2.num_forwards',\n","               tensor([40], device='cuda:0')),\n","              ('module.layer1.4.relu2.force_readjust',\n","               tensor(False, device='cuda:0')),\n","              ('module.layer1.4.relu2.output_scale',\n","               tensor([7099.4062], device='cuda:0')),\n","              ('module.layer1.4.relu2.output_zero_point',\n","               tensor([0.], device='cuda:0')),\n","              ('module.layer1.4.residual_eltwiseadd.num_forwards',\n","               tensor([40], device='cuda:0')),\n","              ('module.layer1.4.residual_eltwiseadd.force_readjust',\n","               tensor(False, device='cuda:0')),\n","              ('module.layer1.4.residual_eltwiseadd.output_scale',\n","               tensor([7099.4062], device='cuda:0')),\n","              ('module.layer1.4.residual_eltwiseadd.output_zero_point',\n","               tensor([0.], device='cuda:0')),\n","              ('module.layer1.5.conv1.num_forwards',\n","               tensor([40], device='cuda:0')),\n","              ('module.layer1.5.conv1.force_readjust',\n","               tensor(False, device='cuda:0')),\n","              ('module.layer1.5.conv1.output_scale',\n","               tensor([34460.6523], device='cuda:0')),\n","              ('module.layer1.5.conv1.output_zero_point',\n","               tensor([0.], device='cuda:0')),\n","              ('module.layer1.5.conv1.w_scale', tensor([[[[6.0899e+05]]],\n","               \n","               \n","                       [[[3.5260e+05]]],\n","               \n","               \n","                       [[[6.9779e+08]]],\n","               \n","               \n","                       [[[2.6090e+05]]],\n","               \n","               \n","                       [[[3.8685e+05]]],\n","               \n","               \n","                       [[[7.2191e+05]]],\n","               \n","               \n","                       [[[1.0725e+06]]],\n","               \n","               \n","                       [[[5.6695e+05]]],\n","               \n","               \n","                       [[[6.0976e+08]]],\n","               \n","               \n","                       [[[3.9228e+05]]],\n","               \n","               \n","                       [[[3.9521e+05]]],\n","               \n","               \n","                       [[[8.4214e+08]]],\n","               \n","               \n","                       [[[1.3034e+06]]],\n","               \n","               \n","                       [[[3.0914e+05]]],\n","               \n","               \n","                       [[[6.9938e+05]]],\n","               \n","               \n","                       [[[7.5155e+05]]]], device='cuda:0')),\n","              ('module.layer1.5.conv1.w_zero_point', tensor([[[[-28782.]]],\n","               \n","               \n","                       [[[-42582.]]],\n","               \n","               \n","                       [[[-46195.]]],\n","               \n","               \n","                       [[[-22090.]]],\n","               \n","               \n","                       [[[-27356.]]],\n","               \n","               \n","                       [[[-23043.]]],\n","               \n","               \n","                       [[[-27159.]]],\n","               \n","               \n","                       [[[-30810.]]],\n","               \n","               \n","                       [[[-50573.]]],\n","               \n","               \n","                       [[[-35613.]]],\n","               \n","               \n","                       [[[-27910.]]],\n","               \n","               \n","                       [[[-23648.]]],\n","               \n","               \n","                       [[[-42003.]]],\n","               \n","               \n","                       [[[-34351.]]],\n","               \n","               \n","                       [[[-33383.]]],\n","               \n","               \n","                       [[[-34489.]]]], device='cuda:0')),\n","              ('module.layer1.5.conv1.fp_bias',\n","               tensor([-9.7457e-01,  3.7921e-01, -5.0638e-05, -1.1780e-01,  5.5562e-01,\n","                       -5.4378e-01,  1.3785e-01, -3.6645e-01, -5.6000e-06, -9.3494e-02,\n","                       -5.0181e-01, -3.4027e-03,  3.0561e-01, -5.2634e-01,  3.7857e-02,\n","                        1.0125e+00], device='cuda:0')),\n","              ('module.layer1.5.conv1.accum_scale', tensor([[[4.3235e+09]],\n","               \n","                       [[2.5032e+09]],\n","               \n","                       [[4.9539e+12]],\n","               \n","                       [[1.8522e+09]],\n","               \n","                       [[2.7464e+09]],\n","               \n","                       [[5.1251e+09]],\n","               \n","                       [[7.6143e+09]],\n","               \n","                       [[4.0250e+09]],\n","               \n","                       [[4.3289e+12]],\n","               \n","                       [[2.7849e+09]],\n","               \n","                       [[2.8058e+09]],\n","               \n","                       [[5.9787e+12]],\n","               \n","                       [[9.2530e+09]],\n","               \n","                       [[2.1947e+09]],\n","               \n","                       [[4.9652e+09]],\n","               \n","                       [[5.3356e+09]]], device='cuda:0')),\n","              ('module.layer1.5.conv1.is_simulated_quant_weight_shifted',\n","               tensor(False, device='cuda:0')),\n","              ('module.layer1.5.conv1.wrapped_module.weight',\n","               tensor([[[[21436., 24403., 24114.],\n","                         [23519., 23806., 26682.],\n","                         [17382., 20468., 23718.]],\n","               \n","                        [[29714., 34092., 32715.],\n","                         [28204., 33407., 31509.],\n","                         [25658., 31295., 28157.]],\n","               \n","                        [[37815., 40329., 33226.],\n","                         [38509., 38976., 31022.],\n","                         [32962., 33664., 26975.]],\n","               \n","                        ...,\n","               \n","                        [[23876., 32552., 36842.],\n","                         [22139., 28380., 39891.],\n","                         [28283., 31870., 40860.]],\n","               \n","                        [[12804., 29362., 28572.],\n","                         [25141., 28069., 36964.],\n","                         [13977., 21061., 22743.]],\n","               \n","                        [[48744., 40036., 23440.],\n","                         [60937., 48674., 17058.],\n","                         [60650., 50309., 29136.]]],\n","               \n","               \n","                       [[[36227., 37963., 43212.],\n","                         [31831., 34421., 39026.],\n","                         [29206., 32019., 37984.]],\n","               \n","                        [[39277., 38702., 35652.],\n","                         [40633., 40395., 36903.],\n","                         [42079., 41970., 40050.]],\n","               \n","                        [[39597., 40030., 43043.],\n","                         [37681., 38341., 40066.],\n","                         [40246., 40284., 40814.]],\n","               \n","                        ...,\n","               \n","                        [[45131., 41345., 44314.],\n","                         [49978., 48978., 47288.],\n","                         [44401., 46118., 49648.]],\n","               \n","                        [[48145., 37733., 49170.],\n","                         [40581., 38061., 35346.],\n","                         [33463., 31309., 46945.]],\n","               \n","                        [[41649., 47357., 39768.],\n","                         [42767., 42001., 42622.],\n","                         [53966., 45784., 38908.]]],\n","               \n","               \n","                       [[[50297., 39429., 46668.],\n","                         [48955., 55756., 52101.],\n","                         [48665., 47525., 42400.]],\n","               \n","                        [[45902., 54294., 61410.],\n","                         [47960., 57399., 57971.],\n","                         [48079., 56486., 58524.]],\n","               \n","                        [[47166., 53965., 57344.],\n","                         [37199., 53141., 50945.],\n","                         [51569., 58203., 50090.]],\n","               \n","                        ...,\n","               \n","                        [[41434., 46256., 65535.],\n","                         [43582., 48321., 56981.],\n","                         [47622., 52536., 59698.]],\n","               \n","                        [[40138., 19674., 19932.],\n","                         [38966., 28375., 32910.],\n","                         [46501., 48106., 28945.]],\n","               \n","                        [[18590.,  8392.,     0.],\n","                         [38247., 16618.,  6669.],\n","                         [44608., 25535., 16829.]]],\n","               \n","               \n","                       ...,\n","               \n","               \n","                       [[[37709., 35543., 32022.],\n","                         [32661., 30595., 35499.],\n","                         [31392., 35396., 40159.]],\n","               \n","                        [[30175., 30631., 30599.],\n","                         [34953., 34815., 33813.],\n","                         [33072., 29258., 28977.]],\n","               \n","                        [[32447., 33369., 35581.],\n","                         [32523., 33952., 33291.],\n","                         [30201., 32127., 32994.]],\n","               \n","                        ...,\n","               \n","                        [[38432., 37931., 39356.],\n","                         [38790., 34954., 33719.],\n","                         [34889., 33690., 33596.]],\n","               \n","                        [[40154., 36597., 13587.],\n","                         [30392., 35149., 30564.],\n","                         [26953., 31331., 34324.]],\n","               \n","                        [[36295., 33780., 38276.],\n","                         [33116., 26923., 30039.],\n","                         [38169., 37902., 39189.]]],\n","               \n","               \n","                       [[[35258., 30922., 23753.],\n","                         [36320., 33792., 26499.],\n","                         [31163., 27961., 34577.]],\n","               \n","                        [[32083., 32687., 31985.],\n","                         [33075., 34119., 33492.],\n","                         [31184., 35133., 36172.]],\n","               \n","                        [[31867., 31944., 25733.],\n","                         [34052., 35116., 30188.],\n","                         [31106., 35703., 33020.]],\n","               \n","                        ...,\n","               \n","                        [[32320., 30560., 34874.],\n","                         [34416., 35598., 37599.],\n","                         [38361., 40468., 37211.]],\n","               \n","                        [[29108., 28760., 18970.],\n","                         [44050., 43625., 24181.],\n","                         [35391., 47737., 48693.]],\n","               \n","                        [[38962., 44385., 54335.],\n","                         [41751., 36310., 49957.],\n","                         [65535., 42039., 37406.]]],\n","               \n","               \n","                       [[[55025., 40885., 26083.],\n","                         [48353., 39731., 30019.],\n","                         [51709., 45308., 38791.]],\n","               \n","                        [[40147., 42469., 38581.],\n","                         [41232., 38993., 34624.],\n","                         [43298., 40165., 35951.]],\n","               \n","                        [[33045., 33065., 33629.],\n","                         [34242., 35382., 39800.],\n","                         [40754., 38005., 39589.]],\n","               \n","                        ...,\n","               \n","                        [[37765., 36880., 33235.],\n","                         [34279., 35866., 37512.],\n","                         [25035., 27265., 35662.]],\n","               \n","                        [[34915., 36083., 18598.],\n","                         [20406., 49152., 45234.],\n","                         [20034., 41890., 51175.]],\n","               \n","                        [[22380., 19437., 25596.],\n","                         [36235., 26529., 26444.],\n","                         [38242., 37822., 22119.]]]], device='cuda:0')),\n","              ('module.layer1.5.conv1.wrapped_module.bias',\n","               tensor([-2.1475e+09,  9.4924e+08, -2.5086e+08, -2.1820e+08,  1.5260e+09,\n","                       -2.1475e+09,  1.0497e+09, -1.4749e+09, -2.4242e+07, -2.6038e+08,\n","                       -1.4080e+09, -2.1475e+09,  2.1475e+09, -1.1552e+09,  1.8797e+08,\n","                        2.1475e+09], device='cuda:0')),\n","              ('module.layer1.5.conv2.num_forwards',\n","               tensor([40], device='cuda:0')),\n","              ('module.layer1.5.conv2.force_readjust',\n","               tensor(False, device='cuda:0')),\n","              ('module.layer1.5.conv2.output_scale',\n","               tensor([14840.2812], device='cuda:0')),\n","              ('module.layer1.5.conv2.output_zero_point',\n","               tensor([-37950.], device='cuda:0')),\n","              ('module.layer1.5.conv2.w_scale', tensor([[[[  93323.5312]]],\n","               \n","               \n","                       [[[1329835.3750]]],\n","               \n","               \n","                       [[[  95244.3828]]],\n","               \n","               \n","                       [[[  85350.3125]]],\n","               \n","               \n","                       [[[ 685045.0000]]],\n","               \n","               \n","                       [[[ 159212.7656]]],\n","               \n","               \n","                       [[[  86152.1328]]],\n","               \n","               \n","                       [[[ 139306.0000]]],\n","               \n","               \n","                       [[[ 557750.3750]]],\n","               \n","               \n","                       [[[ 874955.8125]]],\n","               \n","               \n","                       [[[ 136862.5781]]],\n","               \n","               \n","                       [[[1520532.2500]]],\n","               \n","               \n","                       [[[ 303204.7812]]],\n","               \n","               \n","                       [[[ 155586.6406]]],\n","               \n","               \n","                       [[[  81279.3203]]],\n","               \n","               \n","                       [[[ 120913.5391]]]], device='cuda:0')),\n","              ('module.layer1.5.conv2.w_zero_point', tensor([[[[-29037.]]],\n","               \n","               \n","                       [[[-24125.]]],\n","               \n","               \n","                       [[[-29112.]]],\n","               \n","               \n","                       [[[-44052.]]],\n","               \n","               \n","                       [[[-34436.]]],\n","               \n","               \n","                       [[[-27239.]]],\n","               \n","               \n","                       [[[-27686.]]],\n","               \n","               \n","                       [[[-30506.]]],\n","               \n","               \n","                       [[[-41786.]]],\n","               \n","               \n","                       [[[-32429.]]],\n","               \n","               \n","                       [[[-36297.]]],\n","               \n","               \n","                       [[[-31858.]]],\n","               \n","               \n","                       [[[-40140.]]],\n","               \n","               \n","                       [[[-28985.]]],\n","               \n","               \n","                       [[[-31925.]]],\n","               \n","               \n","                       [[[-37582.]]]], device='cuda:0')),\n","              ('module.layer1.5.conv2.fp_bias',\n","               tensor([ 0.4020, -0.0762,  0.0583,  1.2242, -0.0382,  0.3693,  0.2824,  0.1326,\n","                        0.0866, -0.0213,  0.3084,  0.0153,  0.1010,  0.2958, -0.1804,  0.4928],\n","                      device='cuda:0')),\n","              ('module.layer1.5.conv2.accum_scale', tensor([[[3.2160e+09]],\n","               \n","                       [[4.5827e+10]],\n","               \n","                       [[3.2822e+09]],\n","               \n","                       [[2.9412e+09]],\n","               \n","                       [[2.3607e+10]],\n","               \n","                       [[5.4866e+09]],\n","               \n","                       [[2.9689e+09]],\n","               \n","                       [[4.8006e+09]],\n","               \n","                       [[1.9220e+10]],\n","               \n","                       [[3.0152e+10]],\n","               \n","                       [[4.7164e+09]],\n","               \n","                       [[5.2399e+10]],\n","               \n","                       [[1.0449e+10]],\n","               \n","                       [[5.3616e+09]],\n","               \n","                       [[2.8009e+09]],\n","               \n","                       [[4.1668e+09]]], device='cuda:0')),\n","              ('module.layer1.5.conv2.is_simulated_quant_weight_shifted',\n","               tensor(False, device='cuda:0')),\n","              ('module.layer1.5.conv2.wrapped_module.weight',\n","               tensor([[[[22958., 14264., 19450.],\n","                         [20237., 20551., 36627.],\n","                         [26638., 31702., 53061.]],\n","               \n","                        [[16359., 30790., 45871.],\n","                         [ 2912., 36503., 65535.],\n","                         [26133., 52160., 61541.]],\n","               \n","                        [[29193., 29177., 29120.],\n","                         [29130., 29062., 29133.],\n","                         [29158., 29103., 29153.]],\n","               \n","                        ...,\n","               \n","                        [[12333., 14926., 48898.],\n","                         [12414., 21168., 42719.],\n","                         [ 2480., 40267., 58059.]],\n","               \n","                        [[26920., 28976., 27787.],\n","                         [25593., 33080., 37311.],\n","                         [29337., 37272., 33938.]],\n","               \n","                        [[18563., 21197., 36081.],\n","                         [28402., 31263., 36399.],\n","                         [30878., 29339., 25741.]]],\n","               \n","               \n","                       [[[12897., 19078., 20080.],\n","                         [ 9918., 20898., 21863.],\n","                         [11119., 21438., 26591.]],\n","               \n","                        [[16632., 28420., 23661.],\n","                         [29775., 35333., 27175.],\n","                         [65535., 63503., 38962.]],\n","               \n","                        [[24039., 23994., 24509.],\n","                         [24560., 24491., 24146.],\n","                         [24146., 24449., 24179.]],\n","               \n","                        ...,\n","               \n","                        [[12195., 20142., 13147.],\n","                         [24909., 30209., 35285.],\n","                         [24569., 28128., 22305.]],\n","               \n","                        [[26592., 26331., 27201.],\n","                         [22698., 25173., 26347.],\n","                         [26008., 25887., 30288.]],\n","               \n","                        [[21029., 20857., 25471.],\n","                         [23072., 24992., 26852.],\n","                         [25451., 26786., 27400.]]],\n","               \n","               \n","                       [[[29698., 24981., 35890.],\n","                         [37923., 27239., 31753.],\n","                         [44194., 42268., 34281.]],\n","               \n","                        [[33473., 17097., 11833.],\n","                         [30611., 46185., 29115.],\n","                         [20055., 27656., 41565.]],\n","               \n","                        [[29075., 28960., 28971.],\n","                         [29042., 29018., 29073.],\n","                         [28973., 29031., 29177.]],\n","               \n","                        ...,\n","               \n","                        [[51435., 26167., 26352.],\n","                         [65535., 30406.,  9126.],\n","                         [12428., 44411., 32274.]],\n","               \n","                        [[38025., 25994., 25217.],\n","                         [31524., 35987., 30362.],\n","                         [32403., 28444., 27086.]],\n","               \n","                        [[29633., 26769., 26981.],\n","                         [31373., 29489., 25332.],\n","                         [27736., 32566., 26396.]]],\n","               \n","               \n","                       ...,\n","               \n","               \n","                       [[[17638., 22059., 20164.],\n","                         [35022., 35096., 26688.],\n","                         [28749., 32081., 30219.]],\n","               \n","                        [[31021., 21530., 39881.],\n","                         [ 7638., 14772., 41006.],\n","                         [18107.,  5998., 20192.]],\n","               \n","                        [[29043., 29110., 29016.],\n","                         [29045., 28987., 28976.],\n","                         [28872., 28932., 28974.]],\n","               \n","                        ...,\n","               \n","                        [[41655., 27899., 13641.],\n","                         [24142., 53189., 57242.],\n","                         [31353., 11172., 28173.]],\n","               \n","                        [[32632., 34642., 30033.],\n","                         [27440., 23674., 24613.],\n","                         [27534., 23684., 21538.]],\n","               \n","                        [[37905., 30214., 18781.],\n","                         [34235., 33038., 29112.],\n","                         [27211., 25347., 27717.]]],\n","               \n","               \n","                       [[[39816., 32219., 23210.],\n","                         [35131., 33992., 16042.],\n","                         [43967., 35935., 12915.]],\n","               \n","                        [[44934., 23163., 27976.],\n","                         [23732., 28322., 33266.],\n","                         [36041., 24429., 40370.]],\n","               \n","                        [[31964., 31889., 31809.],\n","                         [31956., 31868., 31869.],\n","                         [31941., 31948., 31888.]],\n","               \n","                        ...,\n","               \n","                        [[41209., 36448., 32614.],\n","                         [31778., 37300., 30067.],\n","                         [16242., 41949., 36463.]],\n","               \n","                        [[32579., 31432., 24420.],\n","                         [34432., 36325., 22628.],\n","                         [36589., 33198., 22220.]],\n","               \n","                        [[28046., 31238., 28459.],\n","                         [30177., 31138., 32709.],\n","                         [30348., 31120., 33028.]]],\n","               \n","               \n","                       [[[16740., 36528., 32627.],\n","                         [ 7644., 27168., 38165.],\n","                         [14246., 17719., 20064.]],\n","               \n","                        [[10873.,  4712., 12071.],\n","                         [22059., 13651., 14429.],\n","                         [41876., 32632., 26851.]],\n","               \n","                        [[37689., 37663., 37803.],\n","                         [37731., 37686., 37778.],\n","                         [37846., 37842., 37810.]],\n","               \n","                        ...,\n","               \n","                        [[15274., 45626., 53305.],\n","                         [19843.,     0., 36128.],\n","                         [32456., 20508., 36580.]],\n","               \n","                        [[33533., 22629., 27914.],\n","                         [45070., 33755., 27603.],\n","                         [31835., 27267., 22664.]],\n","               \n","                        [[33899., 38308., 37307.],\n","                         [37759., 32649., 35248.],\n","                         [41308., 22815., 27781.]]]], device='cuda:0')),\n","              ('module.layer1.5.conv2.wrapped_module.bias',\n","               tensor([ 1.2927e+09, -2.1475e+09,  1.9142e+08,  2.1475e+09, -9.0172e+08,\n","                        2.0260e+09,  8.3832e+08,  6.3679e+08,  1.6636e+09, -6.4183e+08,\n","                        1.4545e+09,  8.0039e+08,  1.0552e+09,  1.5859e+09, -5.0516e+08,\n","                        2.0536e+09], device='cuda:0')),\n","              ('module.layer1.5.relu2.num_forwards',\n","               tensor([40], device='cuda:0')),\n","              ('module.layer1.5.relu2.force_readjust',\n","               tensor(False, device='cuda:0')),\n","              ('module.layer1.5.relu2.output_scale',\n","               tensor([6640.9390], device='cuda:0')),\n","              ('module.layer1.5.relu2.output_zero_point',\n","               tensor([0.], device='cuda:0')),\n","              ('module.layer1.5.residual_eltwiseadd.num_forwards',\n","               tensor([40], device='cuda:0')),\n","              ('module.layer1.5.residual_eltwiseadd.force_readjust',\n","               tensor(False, device='cuda:0')),\n","              ('module.layer1.5.residual_eltwiseadd.output_scale',\n","               tensor([6640.9390], device='cuda:0')),\n","              ('module.layer1.5.residual_eltwiseadd.output_zero_point',\n","               tensor([0.], device='cuda:0')),\n","              ('module.layer1.6.conv1.num_forwards',\n","               tensor([40], device='cuda:0')),\n","              ('module.layer1.6.conv1.force_readjust',\n","               tensor(False, device='cuda:0')),\n","              ('module.layer1.6.conv1.output_scale',\n","               tensor([29291.6855], device='cuda:0')),\n","              ('module.layer1.6.conv1.output_zero_point',\n","               tensor([0.], device='cuda:0')),\n","              ('module.layer1.6.conv1.w_scale', tensor([[[[3.5171e+05]]],\n","               \n","               \n","                       [[[3.0329e+05]]],\n","               \n","               \n","                       [[[3.1705e+05]]],\n","               \n","               \n","                       [[[5.4395e+05]]],\n","               \n","               \n","                       [[[2.4862e+05]]],\n","               \n","               \n","                       [[[3.9835e+05]]],\n","               \n","               \n","                       [[[2.6315e+05]]],\n","               \n","               \n","                       [[[5.5873e+05]]],\n","               \n","               \n","                       [[[4.2114e+05]]],\n","               \n","               \n","                       [[[6.8909e+08]]],\n","               \n","               \n","                       [[[2.5881e+05]]],\n","               \n","               \n","                       [[[2.9096e+05]]],\n","               \n","               \n","                       [[[4.2968e+05]]],\n","               \n","               \n","                       [[[4.4657e+08]]],\n","               \n","               \n","                       [[[2.3576e+05]]],\n","               \n","               \n","                       [[[3.6727e+05]]]], device='cuda:0')),\n","              ('module.layer1.6.conv1.w_zero_point', tensor([[[[-35780.]]],\n","               \n","               \n","                       [[[-35009.]]],\n","               \n","               \n","                       [[[-36817.]]],\n","               \n","               \n","                       [[[-33585.]]],\n","               \n","               \n","                       [[[-28716.]]],\n","               \n","               \n","                       [[[-38082.]]],\n","               \n","               \n","                       [[[-23797.]]],\n","               \n","               \n","                       [[[-24683.]]],\n","               \n","               \n","                       [[[-41241.]]],\n","               \n","               \n","                       [[[-41549.]]],\n","               \n","               \n","                       [[[-31181.]]],\n","               \n","               \n","                       [[[-40610.]]],\n","               \n","               \n","                       [[[-39644.]]],\n","               \n","               \n","                       [[[-38115.]]],\n","               \n","               \n","                       [[[-30912.]]],\n","               \n","               \n","                       [[[-31457.]]]], device='cuda:0')),\n","              ('module.layer1.6.conv1.fp_bias',\n","               tensor([ 3.0149e-01, -4.8343e-01, -4.0765e-01,  1.2714e-01, -1.7941e-01,\n","                       -9.8203e-02, -1.5358e+00, -6.5454e-01,  8.6668e-02,  3.5398e-04,\n","                       -8.0544e-01,  2.6903e-01,  5.2843e-01,  6.5613e-04, -4.3428e-01,\n","                       -2.1402e-01], device='cuda:0')),\n","              ('module.layer1.6.conv1.accum_scale', tensor([[[2.3357e+09]],\n","               \n","                       [[2.0142e+09]],\n","               \n","                       [[2.1055e+09]],\n","               \n","                       [[3.6124e+09]],\n","               \n","                       [[1.6511e+09]],\n","               \n","                       [[2.6454e+09]],\n","               \n","                       [[1.7476e+09]],\n","               \n","                       [[3.7105e+09]],\n","               \n","                       [[2.7968e+09]],\n","               \n","                       [[4.5762e+12]],\n","               \n","                       [[1.7187e+09]],\n","               \n","                       [[1.9323e+09]],\n","               \n","                       [[2.8535e+09]],\n","               \n","                       [[2.9657e+12]],\n","               \n","                       [[1.5657e+09]],\n","               \n","                       [[2.4390e+09]]], device='cuda:0')),\n","              ('module.layer1.6.conv1.is_simulated_quant_weight_shifted',\n","               tensor(False, device='cuda:0')),\n","              ('module.layer1.6.conv1.wrapped_module.weight',\n","               tensor([[[[28827., 28449., 36828.],\n","                         [31467., 30782., 47957.],\n","                         [24708., 30175., 46668.]],\n","               \n","                        [[38221., 33716., 35425.],\n","                         [36403., 32323., 32767.],\n","                         [39322., 36136., 37845.]],\n","               \n","                        [[38098., 33870., 35272.],\n","                         [28116., 30490., 27565.],\n","                         [31007., 36916., 32002.]],\n","               \n","                        ...,\n","               \n","                        [[34126., 34274., 38955.],\n","                         [31888., 34291., 41499.],\n","                         [32269., 28834., 31673.]],\n","               \n","                        [[22177., 22383., 31930.],\n","                         [27231.,  6525., 35059.],\n","                         [27899., 18290., 30808.]],\n","               \n","                        [[29171., 41434., 23014.],\n","                         [35015., 49075., 33247.],\n","                         [24681., 37674., 47384.]]],\n","               \n","               \n","                       [[[28860., 28957., 28662.],\n","                         [25299., 31619., 26755.],\n","                         [33792., 37342., 34475.]],\n","               \n","                        [[36076., 35119., 34338.],\n","                         [33872., 31387., 29806.],\n","                         [33365., 30573., 29043.]],\n","               \n","                        [[31345., 35574., 42557.],\n","                         [30936., 33341., 37395.],\n","                         [30901., 26498., 32005.]],\n","               \n","                        ...,\n","               \n","                        [[40263., 39765., 31329.],\n","                         [32628., 32798., 31227.],\n","                         [29108., 33943., 29927.]],\n","               \n","                        [[44921., 31204., 27918.],\n","                         [33667., 35500., 33303.],\n","                         [37272., 29918., 36986.]],\n","               \n","                        [[47313., 40354., 48139.],\n","                         [31240., 36365., 36892.],\n","                         [32071., 34809., 37210.]]],\n","               \n","               \n","                       [[[32937., 41543., 35295.],\n","                         [39574., 42198., 39152.],\n","                         [26933., 35773., 38152.]],\n","               \n","                        [[39514., 37434., 36437.],\n","                         [33068., 32433., 31441.],\n","                         [37289., 37045., 36620.]],\n","               \n","                        [[37697., 34027., 37228.],\n","                         [27061., 30825., 32129.],\n","                         [28022., 27878., 33949.]],\n","               \n","                        ...,\n","               \n","                        [[37877., 37991., 29700.],\n","                         [27291., 32133., 34922.],\n","                         [34452., 32166., 29433.]],\n","               \n","                        [[27004., 42692., 43669.],\n","                         [37593., 38821., 32006.],\n","                         [37234., 43660., 29983.]],\n","               \n","                        [[26769., 42076., 41397.],\n","                         [35751., 52356., 40300.],\n","                         [25356., 33696., 40009.]]],\n","               \n","               \n","                       ...,\n","               \n","               \n","                       [[[33836., 33959., 37238.],\n","                         [47580., 37158., 39546.],\n","                         [35216., 43542., 42796.]],\n","               \n","                        [[45382., 31120., 33524.],\n","                         [52943., 34827., 27879.],\n","                         [55258., 52711., 36602.]],\n","               \n","                        [[48030., 45521., 55322.],\n","                         [43142., 51131., 36200.],\n","                         [45978., 37655., 24981.]],\n","               \n","                        ...,\n","               \n","                        [[65535., 37775., 41537.],\n","                         [51376., 44736., 35570.],\n","                         [48226., 44315., 40070.]],\n","               \n","                        [[24152., 11067., 19306.],\n","                         [30612., 25554., 35547.],\n","                         [35075., 35186., 28910.]],\n","               \n","                        [[ 3409.,  1349., 16068.],\n","                         [ 3291.,  2830., 12520.],\n","                         [    0., 11666., 19361.]]],\n","               \n","               \n","                       [[[27093., 30151., 25621.],\n","                         [25343., 28520., 25102.],\n","                         [21897., 24872., 27860.]],\n","               \n","                        [[30513., 29426., 27093.],\n","                         [31401., 29673., 27007.],\n","                         [31488., 29503., 27223.]],\n","               \n","                        [[30311., 31566., 30016.],\n","                         [36962., 33491., 29965.],\n","                         [38774., 35218., 29373.]],\n","               \n","                        ...,\n","               \n","                        [[37689., 35252., 36189.],\n","                         [34383., 34217., 35419.],\n","                         [36290., 33981., 29523.]],\n","               \n","                        [[22758., 29927., 25076.],\n","                         [31949., 32750., 27995.],\n","                         [35059., 32800., 25598.]],\n","               \n","                        [[41023., 33568., 32738.],\n","                         [38143., 25175., 25297.],\n","                         [27411., 19543., 26194.]]],\n","               \n","               \n","                       [[[32046., 29033., 21684.],\n","                         [33597., 24697., 22785.],\n","                         [32135., 25887., 23146.]],\n","               \n","                        [[30315., 28618., 30163.],\n","                         [32844., 28747., 30497.],\n","                         [31808., 28868., 30259.]],\n","               \n","                        [[30879., 26533., 31416.],\n","                         [36606., 40346., 36197.],\n","                         [31795., 40618., 41147.]],\n","               \n","                        ...,\n","               \n","                        [[28761., 29951., 34134.],\n","                         [39625., 37922., 34727.],\n","                         [32376., 34471., 27539.]],\n","               \n","                        [[39005., 37939., 34489.],\n","                         [44213., 24334., 29350.],\n","                         [13536., 30922., 14447.]],\n","               \n","                        [[39673., 43907., 24384.],\n","                         [28593., 37331., 44710.],\n","                         [33396., 25236., 23625.]]]], device='cuda:0')),\n","              ('module.layer1.6.conv1.wrapped_module.bias',\n","               tensor([ 7.0419e+08, -9.7370e+08, -8.5831e+08,  4.5927e+08, -2.9622e+08,\n","                       -2.5979e+08, -2.1475e+09, -2.1475e+09,  2.4239e+08,  1.6199e+09,\n","                       -1.3843e+09,  5.1983e+08,  1.5078e+09,  1.9459e+09, -6.7994e+08,\n","                       -5.2198e+08], device='cuda:0')),\n","              ('module.layer1.6.conv2.num_forwards',\n","               tensor([40], device='cuda:0')),\n","              ('module.layer1.6.conv2.force_readjust',\n","               tensor(False, device='cuda:0')),\n","              ('module.layer1.6.conv2.output_scale',\n","               tensor([12065.8662], device='cuda:0')),\n","              ('module.layer1.6.conv2.output_zero_point',\n","               tensor([-31248.], device='cuda:0')),\n","              ('module.layer1.6.conv2.w_scale', tensor([[[[  96002.8203]]],\n","               \n","               \n","                       [[[ 121484.4453]]],\n","               \n","               \n","                       [[[ 114631.7812]]],\n","               \n","               \n","                       [[[ 134744.2188]]],\n","               \n","               \n","                       [[[ 117625.9062]]],\n","               \n","               \n","                       [[[ 138567.3906]]],\n","               \n","               \n","                       [[[  44947.4453]]],\n","               \n","               \n","                       [[[ 169196.8906]]],\n","               \n","               \n","                       [[[ 256150.1875]]],\n","               \n","               \n","                       [[[ 561986.4375]]],\n","               \n","               \n","                       [[[ 425124.5312]]],\n","               \n","               \n","                       [[[1176897.6250]]],\n","               \n","               \n","                       [[[  87953.7812]]],\n","               \n","               \n","                       [[[ 240536.7812]]],\n","               \n","               \n","                       [[[  74824.9375]]],\n","               \n","               \n","                       [[[ 253381.9844]]]], device='cuda:0')),\n","              ('module.layer1.6.conv2.w_zero_point', tensor([[[[-36191.]]],\n","               \n","               \n","                       [[[-37718.]]],\n","               \n","               \n","                       [[[-32155.]]],\n","               \n","               \n","                       [[[-43614.]]],\n","               \n","               \n","                       [[[-18528.]]],\n","               \n","               \n","                       [[[-39460.]]],\n","               \n","               \n","                       [[[-26708.]]],\n","               \n","               \n","                       [[[-31160.]]],\n","               \n","               \n","                       [[[-36677.]]],\n","               \n","               \n","                       [[[-31915.]]],\n","               \n","               \n","                       [[[-39202.]]],\n","               \n","               \n","                       [[[-30443.]]],\n","               \n","               \n","                       [[[-29341.]]],\n","               \n","               \n","                       [[[-39540.]]],\n","               \n","               \n","                       [[[-35405.]]],\n","               \n","               \n","                       [[[-25161.]]]], device='cuda:0')),\n","              ('module.layer1.6.conv2.fp_bias',\n","               tensor([-0.3155,  0.3414,  0.2406,  0.8222, -0.1610,  0.5049, -0.2586,  0.0120,\n","                        0.1783, -0.0393,  0.1329,  0.0085,  0.1854,  0.3821, -0.4849,  0.1005],\n","                      device='cuda:0')),\n","              ('module.layer1.6.conv2.accum_scale', tensor([[[2.8121e+09]],\n","               \n","                       [[3.5585e+09]],\n","               \n","                       [[3.3578e+09]],\n","               \n","                       [[3.9469e+09]],\n","               \n","                       [[3.4455e+09]],\n","               \n","                       [[4.0589e+09]],\n","               \n","                       [[1.3166e+09]],\n","               \n","                       [[4.9561e+09]],\n","               \n","                       [[7.5031e+09]],\n","               \n","                       [[1.6462e+10]],\n","               \n","                       [[1.2453e+10]],\n","               \n","                       [[3.4473e+10]],\n","               \n","                       [[2.5763e+09]],\n","               \n","                       [[7.0457e+09]],\n","               \n","                       [[2.1917e+09]],\n","               \n","                       [[7.4220e+09]]], device='cuda:0')),\n","              ('module.layer1.6.conv2.is_simulated_quant_weight_shifted',\n","               tensor(False, device='cuda:0')),\n","              ('module.layer1.6.conv2.wrapped_module.weight',\n","               tensor([[[[44030., 44897., 27139.],\n","                         [53577., 32902., 20397.],\n","                         [46751., 39414., 38178.]],\n","               \n","                        [[18489., 33658., 53003.],\n","                         [ 7453., 35995., 56769.],\n","                         [12211., 35834., 55483.]],\n","               \n","                        [[29557., 32423., 42561.],\n","                         [14661., 24530., 45595.],\n","                         [31884., 37581., 35958.]],\n","               \n","                        ...,\n","               \n","                        [[36265., 36222., 36312.],\n","                         [36187., 36225., 36211.],\n","                         [36168., 36219., 36258.]],\n","               \n","                        [[55027., 61392., 40339.],\n","                         [46117., 60432., 60512.],\n","                         [33363., 49086., 51508.]],\n","               \n","                        [[37146., 42330., 44698.],\n","                         [ 9517., 24590., 40639.],\n","                         [24242., 53612., 56290.]]],\n","               \n","               \n","                       [[[25591., 52937., 47963.],\n","                         [15859., 39521., 42619.],\n","                         [21458., 40635., 41674.]],\n","               \n","                        [[18653., 18677., 31318.],\n","                         [26266., 19819., 30494.],\n","                         [19711., 19382., 26247.]],\n","               \n","                        [[36483., 42299., 33814.],\n","                         [50743., 65535., 52499.],\n","                         [36585., 57077., 41443.]],\n","               \n","                        ...,\n","               \n","                        [[37650., 37741., 37744.],\n","                         [37709., 37871., 37797.],\n","                         [37673., 37699., 37741.]],\n","               \n","                        [[37477., 30841., 22876.],\n","                         [45865., 25385., 29301.],\n","                         [36352., 31538., 41800.]],\n","               \n","                        [[29258., 27470., 36683.],\n","                         [32259., 32177., 43666.],\n","                         [34942., 33217., 33592.]]],\n","               \n","               \n","                       [[[32038., 56831., 45504.],\n","                         [23340., 10653., 49649.],\n","                         [42160., 15649., 29397.]],\n","               \n","                        [[33488., 40056., 33200.],\n","                         [35975., 43533., 35787.],\n","                         [32609., 23127., 40253.]],\n","               \n","                        [[46342., 42935.,  5133.],\n","                         [13097., 42548., 56102.],\n","                         [33871., 18364., 46868.]],\n","               \n","                        ...,\n","               \n","                        [[32189., 32259., 32141.],\n","                         [32152., 32099., 32090.],\n","                         [32137., 32242., 32193.]],\n","               \n","                        [[28554.,  8325.,  7665.],\n","                         [17212., 18329., 16054.],\n","                         [20239., 30559., 22815.]],\n","               \n","                        [[22534., 20242., 21066.],\n","                         [31974., 40646., 36834.],\n","                         [28333., 34439., 28727.]]],\n","               \n","               \n","                       ...,\n","               \n","               \n","                       [[[30654., 15116., 41191.],\n","                         [29906., 49683., 34836.],\n","                         [40907., 44228., 52362.]],\n","               \n","                        [[43040., 45185., 40487.],\n","                         [41060., 29179., 34470.],\n","                         [25418., 22110., 43895.]],\n","               \n","                        [[24420., 32911., 56150.],\n","                         [53908., 40659., 32214.],\n","                         [37639., 44380., 55720.]],\n","               \n","                        ...,\n","               \n","                        [[39481., 39503., 39411.],\n","                         [39679., 39592., 39527.],\n","                         [39728., 39573., 39535.]],\n","               \n","                        [[ 7396.,  7688., 29902.],\n","                         [    0., 12342., 19296.],\n","                         [21638., 15353., 16711.]],\n","               \n","                        [[41987., 47871., 54973.],\n","                         [34564., 43245., 51121.],\n","                         [28177., 31370., 45339.]]],\n","               \n","               \n","                       [[[41400., 34746., 16353.],\n","                         [64993.,  4538., 33818.],\n","                         [49455., 22156., 15213.]],\n","               \n","                        [[30928., 28215., 44400.],\n","                         [31979., 26190., 35034.],\n","                         [28262., 34881., 44070.]],\n","               \n","                        [[39087., 27100., 41053.],\n","                         [37921., 19870., 58730.],\n","                         [46223., 29703., 44881.]],\n","               \n","                        ...,\n","               \n","                        [[35404., 35433., 35440.],\n","                         [35459., 35398., 35442.],\n","                         [35424., 35377., 35439.]],\n","               \n","                        [[34587., 51419., 36502.],\n","                         [35246., 41640., 42233.],\n","                         [34504., 39687., 43046.]],\n","               \n","                        [[42799., 35300., 40818.],\n","                         [29823., 27946., 33974.],\n","                         [42822., 38204., 36422.]]],\n","               \n","               \n","                       [[[21255., 46410., 18331.],\n","                         [22584., 65535., 37882.],\n","                         [14736., 41139., 31283.]],\n","               \n","                        [[16320., 28345., 10449.],\n","                         [22407., 18633., 18464.],\n","                         [15710., 19065.,  9276.]],\n","               \n","                        [[30988.,  5780.,  1104.],\n","                         [31120., 43361., 26030.],\n","                         [42042., 39715., 25466.]],\n","               \n","                        ...,\n","               \n","                        [[25088., 25069., 25256.],\n","                         [25115., 25052., 25170.],\n","                         [25144., 25223., 25157.]],\n","               \n","                        [[23479.,  7707.,  1485.],\n","                         [27323., 18767., 21041.],\n","                         [26131., 28764., 34338.]],\n","               \n","                        [[31318., 24689., 22734.],\n","                         [16030., 12194.,  8360.],\n","                         [15846., 11937., 17362.]]]], device='cuda:0')),\n","              ('module.layer1.6.conv2.wrapped_module.bias',\n","               tensor([-8.8726e+08,  1.2149e+09,  8.0795e+08,  2.1475e+09, -5.5472e+08,\n","                        2.0491e+09, -3.4045e+08,  5.9688e+07,  1.3381e+09, -6.4647e+08,\n","                        1.6550e+09,  2.9188e+08,  4.7766e+08,  2.1475e+09, -1.0628e+09,\n","                        7.4598e+08], device='cuda:0')),\n","              ('module.layer1.6.relu2.num_forwards',\n","               tensor([40], device='cuda:0')),\n","              ('module.layer1.6.relu2.force_readjust',\n","               tensor(False, device='cuda:0')),\n","              ('module.layer1.6.relu2.output_scale',\n","               tensor([5837.1763], device='cuda:0')),\n","              ('module.layer1.6.relu2.output_zero_point',\n","               tensor([0.], device='cuda:0')),\n","              ('module.layer1.6.residual_eltwiseadd.num_forwards',\n","               tensor([40], device='cuda:0')),\n","              ('module.layer1.6.residual_eltwiseadd.force_readjust',\n","               tensor(False, device='cuda:0')),\n","              ('module.layer1.6.residual_eltwiseadd.output_scale',\n","               tensor([5837.1763], device='cuda:0')),\n","              ('module.layer1.6.residual_eltwiseadd.output_zero_point',\n","               tensor([0.], device='cuda:0')),\n","              ('module.layer1.7.conv1.num_forwards',\n","               tensor([40], device='cuda:0')),\n","              ('module.layer1.7.conv1.force_readjust',\n","               tensor(False, device='cuda:0')),\n","              ('module.layer1.7.conv1.output_scale',\n","               tensor([26625.6816], device='cuda:0')),\n","              ('module.layer1.7.conv1.output_zero_point',\n","               tensor([0.], device='cuda:0')),\n","              ('module.layer1.7.conv1.w_scale', tensor([[[[5.8384e+05]]],\n","               \n","               \n","                       [[[4.2467e+05]]],\n","               \n","               \n","                       [[[2.9170e+05]]],\n","               \n","               \n","                       [[[5.5932e+05]]],\n","               \n","               \n","                       [[[3.3423e+05]]],\n","               \n","               \n","                       [[[3.4852e+05]]],\n","               \n","               \n","                       [[[2.2687e+05]]],\n","               \n","               \n","                       [[[7.6235e+08]]],\n","               \n","               \n","                       [[[3.8530e+05]]],\n","               \n","               \n","                       [[[4.8637e+05]]],\n","               \n","               \n","                       [[[4.3386e+05]]],\n","               \n","               \n","                       [[[4.9165e+05]]],\n","               \n","               \n","                       [[[4.5652e+05]]],\n","               \n","               \n","                       [[[5.9389e+05]]],\n","               \n","               \n","                       [[[3.3963e+05]]],\n","               \n","               \n","                       [[[1.8564e+05]]]], device='cuda:0')),\n","              ('module.layer1.7.conv1.w_zero_point', tensor([[[[-29111.]]],\n","               \n","               \n","                       [[[-31838.]]],\n","               \n","               \n","                       [[[-30852.]]],\n","               \n","               \n","                       [[[-28274.]]],\n","               \n","               \n","                       [[[-31935.]]],\n","               \n","               \n","                       [[[-37286.]]],\n","               \n","               \n","                       [[[-31286.]]],\n","               \n","               \n","                       [[[-19511.]]],\n","               \n","               \n","                       [[[-32094.]]],\n","               \n","               \n","                       [[[-28997.]]],\n","               \n","               \n","                       [[[-28507.]]],\n","               \n","               \n","                       [[[-34364.]]],\n","               \n","               \n","                       [[[-40346.]]],\n","               \n","               \n","                       [[[-30912.]]],\n","               \n","               \n","                       [[[-31729.]]],\n","               \n","               \n","                       [[[-31537.]]]], device='cuda:0')),\n","              ('module.layer1.7.conv1.fp_bias',\n","               tensor([-0.2850, -0.1314, -0.6494, -0.0181,  0.1499,  0.0593, -0.4293, -0.0031,\n","                       -0.4750,  0.2260,  0.0419, -0.0828,  0.6380,  0.0742, -0.4524,  0.0504],\n","                      device='cuda:0')),\n","              ('module.layer1.7.conv1.accum_scale', tensor([[[3.4080e+09]],\n","               \n","                       [[2.4789e+09]],\n","               \n","                       [[1.7027e+09]],\n","               \n","                       [[3.2649e+09]],\n","               \n","                       [[1.9510e+09]],\n","               \n","                       [[2.0344e+09]],\n","               \n","                       [[1.3243e+09]],\n","               \n","                       [[4.4500e+12]],\n","               \n","                       [[2.2491e+09]],\n","               \n","                       [[2.8390e+09]],\n","               \n","                       [[2.5325e+09]],\n","               \n","                       [[2.8698e+09]],\n","               \n","                       [[2.6648e+09]],\n","               \n","                       [[3.4666e+09]],\n","               \n","                       [[1.9825e+09]],\n","               \n","                       [[1.0836e+09]]], device='cuda:0')),\n","              ('module.layer1.7.conv1.is_simulated_quant_weight_shifted',\n","               tensor(False, device='cuda:0')),\n","              ('module.layer1.7.conv1.wrapped_module.weight',\n","               tensor([[[[28325., 30476., 40938.],\n","                         [24469., 25798., 36344.],\n","                         [25590., 20862., 32495.]],\n","               \n","                        [[27700., 34305., 38442.],\n","                         [25219., 36916., 29666.],\n","                         [28052., 45801., 29235.]],\n","               \n","                        [[33519., 40107., 27880.],\n","                         [31732., 35919., 21132.],\n","                         [43176., 37993., 17808.]],\n","               \n","                        ...,\n","               \n","                        [[27271., 30443., 34150.],\n","                         [20787., 30123., 29620.],\n","                         [23753., 27152., 27168.]],\n","               \n","                        [[26628., 58594., 22909.],\n","                         [53364., 41007., 10301.],\n","                         [65535., 12849., 20037.]],\n","               \n","                        [[35793., 29164., 30884.],\n","                         [18976., 44026., 45704.],\n","                         [ 3250., 41744., 38639.]]],\n","               \n","               \n","                       [[[23855., 28834., 31637.],\n","                         [25358., 26267., 33639.],\n","                         [24060., 26701., 36956.]],\n","               \n","                        [[30610., 33380., 35704.],\n","                         [30654., 33450., 34595.],\n","                         [32964., 33618., 32735.]],\n","               \n","                        [[27996., 32896., 39318.],\n","                         [41518., 28418., 31798.],\n","                         [38266., 41594., 33551.]],\n","               \n","                        ...,\n","               \n","                        [[39946., 36696., 24660.],\n","                         [23990., 29571., 26325.],\n","                         [30122., 26087., 22777.]],\n","               \n","                        [[39021., 44366., 31251.],\n","                         [26877., 35284., 33117.],\n","                         [36406., 24599., 29307.]],\n","               \n","                        [[29658., 20846., 32212.],\n","                         [49340., 40225., 34875.],\n","                         [32887., 48810., 43102.]]],\n","               \n","               \n","                       [[[25955., 26809., 30358.],\n","                         [24772., 32251., 31498.],\n","                         [30944., 27472., 29399.]],\n","               \n","                        [[32293., 33359., 31657.],\n","                         [36808., 37170., 34165.],\n","                         [32483., 31454., 33594.]],\n","               \n","                        [[37013., 34191., 28827.],\n","                         [36239., 39689., 38693.],\n","                         [39624., 37122., 30900.]],\n","               \n","                        ...,\n","               \n","                        [[29423., 28145., 27318.],\n","                         [36768., 33365., 29452.],\n","                         [25514., 29101., 30356.]],\n","               \n","                        [[38567., 23416., 28127.],\n","                         [23585., 31130., 32585.],\n","                         [29592., 31741., 24358.]],\n","               \n","                        [[23881., 33548., 26099.],\n","                         [25905., 26571., 26414.],\n","                         [42959., 45621., 42910.]]],\n","               \n","               \n","                       ...,\n","               \n","               \n","                       [[[26035., 27875., 32913.],\n","                         [24760., 30579., 30180.],\n","                         [28583., 18908., 23774.]],\n","               \n","                        [[31224., 28084., 28955.],\n","                         [35868., 24486., 31135.],\n","                         [41539., 25408., 30702.]],\n","               \n","                        [[29139., 32260., 29835.],\n","                         [30039., 17242., 23597.],\n","                         [24522., 31743., 31501.]],\n","               \n","                        ...,\n","               \n","                        [[20300., 22030., 31506.],\n","                         [32643., 43042., 39143.],\n","                         [33693., 30882., 31877.]],\n","               \n","                        [[25137., 14587., 41316.],\n","                         [16412., 18479., 29129.],\n","                         [21573., 26137., 16669.]],\n","               \n","                        [[37964., 23470., 41740.],\n","                         [30003., 14492., 17772.],\n","                         [35154., 28836., 32306.]]],\n","               \n","               \n","                       [[[19870., 31830., 36806.],\n","                         [20130., 21390., 26169.],\n","                         [26441., 21285., 16601.]],\n","               \n","                        [[32226., 36759., 36268.],\n","                         [31982., 34306., 31430.],\n","                         [32126., 30963., 30783.]],\n","               \n","                        [[28176., 31244., 35350.],\n","                         [30481., 27255., 27670.],\n","                         [25706., 29752., 25514.]],\n","               \n","                        ...,\n","               \n","                        [[32972., 29926., 22629.],\n","                         [36213., 39280., 29897.],\n","                         [25038., 32206., 29050.]],\n","               \n","                        [[29288., 30265., 36449.],\n","                         [29671., 37579., 29345.],\n","                         [22612., 24744., 19656.]],\n","               \n","                        [[19378., 18901., 24090.],\n","                         [30125., 20069., 10076.],\n","                         [41398., 31225., 32997.]]],\n","               \n","               \n","                       [[[22799., 32930., 37773.],\n","                         [28549., 37734., 37613.],\n","                         [29073., 31495., 29216.]],\n","               \n","                        [[30805., 32557., 33819.],\n","                         [29732., 29519., 31183.],\n","                         [29319., 29712., 31739.]],\n","               \n","                        [[32837., 35715., 35827.],\n","                         [34080., 33628., 35513.],\n","                         [35418., 33561., 34071.]],\n","               \n","                        ...,\n","               \n","                        [[30483., 31845., 34195.],\n","                         [31159., 32905., 33149.],\n","                         [31887., 32543., 33193.]],\n","               \n","                        [[36877., 36170., 26261.],\n","                         [35184., 29740., 27774.],\n","                         [32435., 29962., 27679.]],\n","               \n","                        [[26032., 27001., 35113.],\n","                         [29183., 35618., 41335.],\n","                         [35476., 38022., 35295.]]]], device='cuda:0')),\n","              ('module.layer1.7.conv1.wrapped_module.bias',\n","               tensor([-9.7140e+08, -3.2584e+08, -1.1057e+09, -5.9203e+07,  2.9238e+08,\n","                        1.2063e+08, -5.6853e+08, -2.1475e+09, -1.0684e+09,  6.4152e+08,\n","                        1.0620e+08, -2.3761e+08,  1.7003e+09,  2.5727e+08, -8.9683e+08,\n","                        5.4600e+07], device='cuda:0')),\n","              ('module.layer1.7.conv2.num_forwards',\n","               tensor([40], device='cuda:0')),\n","              ('module.layer1.7.conv2.force_readjust',\n","               tensor(False, device='cuda:0')),\n","              ('module.layer1.7.conv2.output_scale',\n","               tensor([9502.5146], device='cuda:0')),\n","              ('module.layer1.7.conv2.output_zero_point',\n","               tensor([-30186.], device='cuda:0')),\n","              ('module.layer1.7.conv2.w_scale', tensor([[[[ 126892.4453]]],\n","               \n","               \n","                       [[[  95047.8594]]],\n","               \n","               \n","                       [[[  67818.3906]]],\n","               \n","               \n","                       [[[ 183389.8281]]],\n","               \n","               \n","                       [[[ 471293.8438]]],\n","               \n","               \n","                       [[[ 184018.7031]]],\n","               \n","               \n","                       [[[  52543.2031]]],\n","               \n","               \n","                       [[[  74650.1797]]],\n","               \n","               \n","                       [[[ 328180.1562]]],\n","               \n","               \n","                       [[[1039592.0000]]],\n","               \n","               \n","                       [[[  91695.1094]]],\n","               \n","               \n","                       [[[ 617526.0625]]],\n","               \n","               \n","                       [[[ 145934.7344]]],\n","               \n","               \n","                       [[[ 103378.8359]]],\n","               \n","               \n","                       [[[  60974.1875]]],\n","               \n","               \n","                       [[[ 155219.8438]]]], device='cuda:0')),\n","              ('module.layer1.7.conv2.w_zero_point', tensor([[[[-30681.]]],\n","               \n","               \n","                       [[[-43023.]]],\n","               \n","               \n","                       [[[-29529.]]],\n","               \n","               \n","                       [[[-37906.]]],\n","               \n","               \n","                       [[[-32106.]]],\n","               \n","               \n","                       [[[-39228.]]],\n","               \n","               \n","                       [[[-29746.]]],\n","               \n","               \n","                       [[[-35052.]]],\n","               \n","               \n","                       [[[-39443.]]],\n","               \n","               \n","                       [[[-30890.]]],\n","               \n","               \n","                       [[[-43577.]]],\n","               \n","               \n","                       [[[-47251.]]],\n","               \n","               \n","                       [[[-32339.]]],\n","               \n","               \n","                       [[[-39732.]]],\n","               \n","               \n","                       [[[-29398.]]],\n","               \n","               \n","                       [[[-32793.]]]], device='cuda:0')),\n","              ('module.layer1.7.conv2.fp_bias',\n","               tensor([-0.2527,  0.9502,  0.1846,  0.4076, -0.0119,  0.2312, -0.4490,  0.8684,\n","                        0.0698,  0.0182,  0.4140,  0.1132, -0.0422,  0.4636,  0.3376,  0.1273],\n","                      device='cuda:0')),\n","              ('module.layer1.7.conv2.accum_scale', tensor([[[3.3786e+09]],\n","               \n","                       [[2.5307e+09]],\n","               \n","                       [[1.8057e+09]],\n","               \n","                       [[4.8829e+09]],\n","               \n","                       [[1.2549e+10]],\n","               \n","                       [[4.8996e+09]],\n","               \n","                       [[1.3990e+09]],\n","               \n","                       [[1.9876e+09]],\n","               \n","                       [[8.7380e+09]],\n","               \n","                       [[2.7680e+10]],\n","               \n","                       [[2.4414e+09]],\n","               \n","                       [[1.6442e+10]],\n","               \n","                       [[3.8856e+09]],\n","               \n","                       [[2.7525e+09]],\n","               \n","                       [[1.6235e+09]],\n","               \n","                       [[4.1328e+09]]], device='cuda:0')),\n","              ('module.layer1.7.conv2.is_simulated_quant_weight_shifted',\n","               tensor(False, device='cuda:0')),\n","              ('module.layer1.7.conv2.wrapped_module.weight',\n","               tensor([[[[25761., 48808., 30141.],\n","                         [41618., 46199., 29835.],\n","                         [43502., 34322., 24880.]],\n","               \n","                        [[31869., 25282., 23248.],\n","                         [28494., 26006., 41670.],\n","                         [30671., 24765., 49448.]],\n","               \n","                        [[17809., 23718., 50506.],\n","                         [    0., 18305., 53241.],\n","                         [ 5879., 30896., 36406.]],\n","               \n","                        ...,\n","               \n","                        [[31325., 30819., 34681.],\n","                         [27854., 29928., 32824.],\n","                         [38871., 29581., 24108.]],\n","               \n","                        [[ 8527., 14503., 46823.],\n","                         [16312., 13784., 59390.],\n","                         [29979., 46445., 42882.]],\n","               \n","                        [[11561., 41447., 40731.],\n","                         [10880., 57720., 60536.],\n","                         [19203., 46730., 34100.]]],\n","               \n","               \n","                       [[[41546., 32382., 34653.],\n","                         [43868., 34292., 37379.],\n","                         [38055., 50098., 51489.]],\n","               \n","                        [[44472., 33309., 22374.],\n","                         [38758., 25678., 32154.],\n","                         [45639., 22631., 22588.]],\n","               \n","                        [[49151., 42744., 46597.],\n","                         [44817., 41996., 34612.],\n","                         [35440., 32658., 34894.]],\n","               \n","                        ...,\n","               \n","                        [[40190., 37964., 50504.],\n","                         [44632., 39511., 47642.],\n","                         [49718., 43732., 42873.]],\n","               \n","                        [[36144., 31571., 50219.],\n","                         [41065., 10551., 19512.],\n","                         [35880., 31187., 36304.]],\n","               \n","                        [[39393., 41591., 42619.],\n","                         [50847., 44213., 38716.],\n","                         [61355., 55411., 47530.]]],\n","               \n","               \n","                       [[[24926., 20470., 26258.],\n","                         [31042.,  8862., 15629.],\n","                         [32229., 11186., 14544.]],\n","               \n","                        [[34407., 31336., 26263.],\n","                         [28755., 32233., 39842.],\n","                         [12839., 40769., 47957.]],\n","               \n","                        [[23841., 31625., 39989.],\n","                         [38211., 34178., 31629.],\n","                         [30909., 20583., 12050.]],\n","               \n","                        ...,\n","               \n","                        [[36446., 34499., 36880.],\n","                         [27850., 21515., 35874.],\n","                         [20862., 40512., 31577.]],\n","               \n","                        [[29283., 37595., 43579.],\n","                         [25506., 41772., 40184.],\n","                         [24600., 31435., 42272.]],\n","               \n","                        [[14070.,  9131., 20502.],\n","                         [25372.,  8948.,  9778.],\n","                         [36090., 21118., 10197.]]],\n","               \n","               \n","                       ...,\n","               \n","               \n","                       [[[25917., 27044., 40451.],\n","                         [22589., 11192., 36086.],\n","                         [23149., 20658., 30526.]],\n","               \n","                        [[35165., 43579., 43179.],\n","                         [39053., 45955., 52021.],\n","                         [40119., 35307., 34423.]],\n","               \n","                        [[48897., 37904., 24643.],\n","                         [40356., 25915., 42035.],\n","                         [39159., 27530., 19413.]],\n","               \n","                        ...,\n","               \n","                        [[35079., 35441., 35614.],\n","                         [55703., 46095., 34806.],\n","                         [44594., 27651., 33735.]],\n","               \n","                        [[55955., 57436., 52799.],\n","                         [47436., 47548., 47907.],\n","                         [35952., 36269., 48790.]],\n","               \n","                        [[13955., 25507., 30097.],\n","                         [32946., 35413., 32010.],\n","                         [43053., 35948., 40207.]]],\n","               \n","               \n","                       [[[30195., 25236., 24995.],\n","                         [33804., 33417., 25137.],\n","                         [33585., 26897., 29165.]],\n","               \n","                        [[21980., 26682., 31983.],\n","                         [28316., 22748., 36871.],\n","                         [30870., 28075., 32352.]],\n","               \n","                        [[35035., 30840., 27406.],\n","                         [35669., 29740., 17176.],\n","                         [26092., 18922., 22403.]],\n","               \n","                        ...,\n","               \n","                        [[27716., 30194., 22931.],\n","                         [36059., 29354., 15470.],\n","                         [32810., 38082., 10297.]],\n","               \n","                        [[32227., 30164., 29693.],\n","                         [36666., 32114., 23084.],\n","                         [39811., 30685., 26961.]],\n","               \n","                        [[36220., 27371., 25732.],\n","                         [29394., 32354., 33715.],\n","                         [21843., 23034., 31591.]]],\n","               \n","               \n","                       [[[27747., 37740., 48935.],\n","                         [27631., 38076., 43590.],\n","                         [21830., 38582., 46309.]],\n","               \n","                        [[32286., 18686., 29825.],\n","                         [33921., 30167., 20808.],\n","                         [28779., 25437., 24883.]],\n","               \n","                        [[    0., 20595., 33575.],\n","                         [ 4867.,  3434., 37091.],\n","                         [19113., 15469., 19150.]],\n","               \n","                        ...,\n","               \n","                        [[41100., 30699., 24894.],\n","                         [26307., 35764., 44041.],\n","                         [26106., 25118., 32058.]],\n","               \n","                        [[19390., 25332., 21010.],\n","                         [21608., 26100., 30066.],\n","                         [23528., 21930., 12826.]],\n","               \n","                        [[23987., 34376., 37418.],\n","                         [38945., 25876., 21746.],\n","                         [31145., 35222., 24141.]]]], device='cuda:0')),\n","              ('module.layer1.7.conv2.wrapped_module.bias',\n","               tensor([-8.5376e+08,  2.1475e+09,  3.3331e+08,  1.9901e+09, -1.4898e+08,\n","                        1.1326e+09, -6.2816e+08,  1.7260e+09,  6.0973e+08,  5.0478e+08,\n","                        1.0108e+09,  1.8619e+09, -1.6379e+08,  1.2762e+09,  5.4803e+08,\n","                        5.2604e+08], device='cuda:0')),\n","              ('module.layer1.7.relu2.num_forwards',\n","               tensor([40], device='cuda:0')),\n","              ('module.layer1.7.relu2.force_readjust',\n","               tensor(False, device='cuda:0')),\n","              ('module.layer1.7.relu2.output_scale',\n","               tensor([5662.0122], device='cuda:0')),\n","              ('module.layer1.7.relu2.output_zero_point',\n","               tensor([0.], device='cuda:0')),\n","              ('module.layer1.7.residual_eltwiseadd.num_forwards',\n","               tensor([40], device='cuda:0')),\n","              ('module.layer1.7.residual_eltwiseadd.force_readjust',\n","               tensor(False, device='cuda:0')),\n","              ('module.layer1.7.residual_eltwiseadd.output_scale',\n","               tensor([5662.0122], device='cuda:0')),\n","              ('module.layer1.7.residual_eltwiseadd.output_zero_point',\n","               tensor([0.], device='cuda:0')),\n","              ('module.layer1.8.conv1.num_forwards',\n","               tensor([40], device='cuda:0')),\n","              ('module.layer1.8.conv1.force_readjust',\n","               tensor(False, device='cuda:0')),\n","              ('module.layer1.8.conv1.output_scale',\n","               tensor([20930.2324], device='cuda:0')),\n","              ('module.layer1.8.conv1.output_zero_point',\n","               tensor([0.], device='cuda:0')),\n","              ('module.layer1.8.conv1.w_scale', tensor([[[[1.2238e+06]]],\n","               \n","               \n","                       [[[9.4096e+05]]],\n","               \n","               \n","                       [[[1.7855e+05]]],\n","               \n","               \n","                       [[[4.1380e+05]]],\n","               \n","               \n","                       [[[3.5415e+05]]],\n","               \n","               \n","                       [[[3.0043e+09]]],\n","               \n","               \n","                       [[[2.2386e+05]]],\n","               \n","               \n","                       [[[2.3546e+05]]],\n","               \n","               \n","                       [[[3.5613e+05]]],\n","               \n","               \n","                       [[[3.0183e+05]]],\n","               \n","               \n","                       [[[3.4312e+05]]],\n","               \n","               \n","                       [[[4.7930e+05]]],\n","               \n","               \n","                       [[[2.8314e+05]]],\n","               \n","               \n","                       [[[3.6719e+05]]],\n","               \n","               \n","                       [[[6.3344e+08]]],\n","               \n","               \n","                       [[[3.4683e+08]]]], device='cuda:0')),\n","              ('module.layer1.8.conv1.w_zero_point', tensor([[[[-35227.]]],\n","               \n","               \n","                       [[[-40412.]]],\n","               \n","               \n","                       [[[-33339.]]],\n","               \n","               \n","                       [[[-31826.]]],\n","               \n","               \n","                       [[[-28888.]]],\n","               \n","               \n","                       [[[ -8620.]]],\n","               \n","               \n","                       [[[-32551.]]],\n","               \n","               \n","                       [[[-39859.]]],\n","               \n","               \n","                       [[[-32784.]]],\n","               \n","               \n","                       [[[-37812.]]],\n","               \n","               \n","                       [[[-32017.]]],\n","               \n","               \n","                       [[[-22568.]]],\n","               \n","               \n","                       [[[-45638.]]],\n","               \n","               \n","                       [[[-30980.]]],\n","               \n","               \n","                       [[[-39133.]]],\n","               \n","               \n","                       [[[-33377.]]]], device='cuda:0')),\n","              ('module.layer1.8.conv1.fp_bias',\n","               tensor([ 4.3502e-01,  9.0834e-01,  1.8020e-01, -2.3086e-01, -7.9125e-02,\n","                       -2.7617e-03, -4.0597e-01,  1.1646e-01, -6.8226e-01,  1.6747e-01,\n","                       -5.9856e-01, -6.8906e-01,  3.1833e-01, -1.1924e+00,  2.8335e-05,\n","                       -1.3006e-03], device='cuda:0')),\n","              ('module.layer1.8.conv1.accum_scale', tensor([[[6.9290e+09]],\n","               \n","                       [[5.3277e+09]],\n","               \n","                       [[1.0109e+09]],\n","               \n","                       [[2.3429e+09]],\n","               \n","                       [[2.0052e+09]],\n","               \n","                       [[1.7010e+13]],\n","               \n","                       [[1.2675e+09]],\n","               \n","                       [[1.3332e+09]],\n","               \n","                       [[2.0164e+09]],\n","               \n","                       [[1.7090e+09]],\n","               \n","                       [[1.9427e+09]],\n","               \n","                       [[2.7138e+09]],\n","               \n","                       [[1.6032e+09]],\n","               \n","                       [[2.0790e+09]],\n","               \n","                       [[3.5865e+12]],\n","               \n","                       [[1.9638e+12]]], device='cuda:0')),\n","              ('module.layer1.8.conv1.is_simulated_quant_weight_shifted',\n","               tensor(False, device='cuda:0')),\n","              ('module.layer1.8.conv1.wrapped_module.weight',\n","               tensor([[[[24375., 28885., 27841.],\n","                         [25382., 23876., 20364.],\n","                         [24850., 18815., 21026.]],\n","               \n","                        [[53333., 58820., 56480.],\n","                         [51975., 57903., 58784.],\n","                         [46551., 58328., 58996.]],\n","               \n","                        [[29663., 33695., 34792.],\n","                         [17098., 19912., 26848.],\n","                         [22432., 29459., 28249.]],\n","               \n","                        ...,\n","               \n","                        [[24728., 31776., 32142.],\n","                         [24798., 34122., 31358.],\n","                         [19675., 30929., 40308.]],\n","               \n","                        [[32390., 41756., 31068.],\n","                         [19415., 18068., 13147.],\n","                         [ 6117.,  3139.,  7381.]],\n","               \n","                        [[37444., 28862., 36869.],\n","                         [42157., 26560., 22626.],\n","                         [49168., 34539., 28277.]]],\n","               \n","               \n","                       [[[25349., 39184., 31323.],\n","                         [27356., 33793., 26898.],\n","                         [36194., 37497., 32184.]],\n","               \n","                        [[52160., 61661., 60313.],\n","                         [52627., 63021., 65535.],\n","                         [47363., 64383., 64726.]],\n","               \n","                        [[41679., 40191., 41296.],\n","                         [41755., 42017., 40673.],\n","                         [38138., 36455., 28872.]],\n","               \n","                        ...,\n","               \n","                        [[29626., 27812., 27601.],\n","                         [17565., 24242., 28379.],\n","                         [23783., 37166., 43626.]],\n","               \n","                        [[33251., 37683., 39080.],\n","                         [17589., 11306., 16549.],\n","                         [13829.,  9101., 22191.]],\n","               \n","                        [[37862., 21168., 23601.],\n","                         [28979., 10641.,     0.],\n","                         [39004., 29844., 21861.]]],\n","               \n","               \n","                       [[[36707., 33623., 27230.],\n","                         [25690., 34264., 31795.],\n","                         [20595., 30995., 33621.]],\n","               \n","                        [[23911., 33078., 36385.],\n","                         [24356., 33378., 37185.],\n","                         [26256., 29609., 36603.]],\n","               \n","                        [[25501., 26612., 36162.],\n","                         [32942., 36023., 37100.],\n","                         [28075., 31800., 37507.]],\n","               \n","                        ...,\n","               \n","                        [[29819., 30116., 35956.],\n","                         [37438., 30544., 35497.],\n","                         [37000., 30607., 28331.]],\n","               \n","                        [[27275., 33265., 30543.],\n","                         [34946., 36423., 27998.],\n","                         [29381., 33448., 25925.]],\n","               \n","                        [[28591., 35451., 40753.],\n","                         [27988., 33333., 36088.],\n","                         [26541., 28084., 31188.]]],\n","               \n","               \n","                       ...,\n","               \n","               \n","                       [[[26144., 34034., 24421.],\n","                         [27060., 45283., 29236.],\n","                         [21945., 32968., 31944.]],\n","               \n","                        [[26532., 26606., 46799.],\n","                         [26408., 24820., 40899.],\n","                         [25155., 27312., 42282.]],\n","               \n","                        [[33126., 37097., 35589.],\n","                         [33774., 36201., 31814.],\n","                         [41151., 30713., 46883.]],\n","               \n","                        ...,\n","               \n","                        [[33729., 28879., 40842.],\n","                         [36393., 31283., 41525.],\n","                         [38230., 38430., 34671.]],\n","               \n","                        [[11565., 55642.,  5539.],\n","                         [14713., 65535.,  2861.],\n","                         [ 1449., 39285., 10583.]],\n","               \n","                        [[47059., 20512., 29460.],\n","                         [39858., 22671., 45475.],\n","                         [27379., 22993., 42515.]]],\n","               \n","               \n","                       [[[25295.,   878., 29253.],\n","                         [19201., 11598., 29680.],\n","                         [43844., 20819., 25325.]],\n","               \n","                        [[53776., 34557., 24682.],\n","                         [44969., 37781., 33845.],\n","                         [26727., 32542., 53770.]],\n","               \n","                        [[54273., 34355., 29449.],\n","                         [42990., 42035., 51651.],\n","                         [35763., 48109., 32692.]],\n","               \n","                        ...,\n","               \n","                        [[30386., 51358., 35645.],\n","                         [43106., 15718., 34692.],\n","                         [52615., 47172., 42681.]],\n","               \n","                        [[36076., 30455., 20203.],\n","                         [43766., 52728., 32666.],\n","                         [27820., 39118., 32512.]],\n","               \n","                        [[18329., 13097.,     0.],\n","                         [24078., 23871., 20378.],\n","                         [26917., 25223., 14476.]]],\n","               \n","               \n","                       [[[26657., 35668., 33708.],\n","                         [34581., 38092., 45203.],\n","                         [43736., 34726., 39442.]],\n","               \n","                        [[45734., 32020., 49780.],\n","                         [40401., 39457., 30746.],\n","                         [23456., 33686., 30387.]],\n","               \n","                        [[20696., 18132., 19004.],\n","                         [ 8680.,  8680., 20591.],\n","                         [ 7094., 12290., 14132.]],\n","               \n","                        ...,\n","               \n","                        [[24268., 42568., 40510.],\n","                         [26925., 39361., 35759.],\n","                         [28744., 40169., 46558.]],\n","               \n","                        [[51896., 38603., 35001.],\n","                         [39483., 41161., 50352.],\n","                         [40567., 27594., 39480.]],\n","               \n","                        [[ 7770.,  7874., 13637.],\n","                         [ 6770.,  8879., 18003.],\n","                         [18106., 36444., 32353.]]]], device='cuda:0')),\n","              ('module.layer1.8.conv1.wrapped_module.bias',\n","               tensor([ 2.1475e+09,  2.1475e+09,  1.8218e+08, -5.4089e+08, -1.5866e+08,\n","                       -2.1475e+09, -5.1458e+08,  1.5526e+08, -1.3757e+09,  2.8621e+08,\n","                       -1.1628e+09, -1.8700e+09,  5.1033e+08, -2.1475e+09,  1.0163e+08,\n","                       -2.1475e+09], device='cuda:0')),\n","              ('module.layer1.8.conv2.num_forwards',\n","               tensor([40], device='cuda:0')),\n","              ('module.layer1.8.conv2.force_readjust',\n","               tensor(False, device='cuda:0')),\n","              ('module.layer1.8.conv2.output_scale',\n","               tensor([6190.1162], device='cuda:0')),\n","              ('module.layer1.8.conv2.output_zero_point',\n","               tensor([-28424.], device='cuda:0')),\n","              ('module.layer1.8.conv2.w_scale', tensor([[[[ 131190.7500]]],\n","               \n","               \n","                       [[[ 102690.8203]]],\n","               \n","               \n","                       [[[  73966.4453]]],\n","               \n","               \n","                       [[[ 136587.9531]]],\n","               \n","               \n","                       [[[1943284.3750]]],\n","               \n","               \n","                       [[[ 220765.4219]]],\n","               \n","               \n","                       [[[  56093.2891]]],\n","               \n","               \n","                       [[[  64233.6641]]],\n","               \n","               \n","                       [[[ 137783.7344]]],\n","               \n","               \n","                       [[[ 449508.0625]]],\n","               \n","               \n","                       [[[ 108584.5547]]],\n","               \n","               \n","                       [[[ 273914.0312]]],\n","               \n","               \n","                       [[[ 201313.1094]]],\n","               \n","               \n","                       [[[  96039.7891]]],\n","               \n","               \n","                       [[[  88630.7969]]],\n","               \n","               \n","                       [[[ 176270.7344]]]], device='cuda:0')),\n","              ('module.layer1.8.conv2.w_zero_point', tensor([[[[-25342.]]],\n","               \n","               \n","                       [[[-48704.]]],\n","               \n","               \n","                       [[[-30634.]]],\n","               \n","               \n","                       [[[-43473.]]],\n","               \n","               \n","                       [[[-29945.]]],\n","               \n","               \n","                       [[[-29149.]]],\n","               \n","               \n","                       [[[-23312.]]],\n","               \n","               \n","                       [[[-29823.]]],\n","               \n","               \n","                       [[[-38126.]]],\n","               \n","               \n","                       [[[-25589.]]],\n","               \n","               \n","                       [[[-45045.]]],\n","               \n","               \n","                       [[[-40222.]]],\n","               \n","               \n","                       [[[-44414.]]],\n","               \n","               \n","                       [[[-33433.]]],\n","               \n","               \n","                       [[[-25799.]]],\n","               \n","               \n","                       [[[-39530.]]]], device='cuda:0')),\n","              ('module.layer1.8.conv2.fp_bias',\n","               tensor([-0.3813,  1.3179,  0.1555,  0.6950,  0.0586, -0.1358, -0.9327,  1.2728,\n","                        0.0248,  0.0032,  1.1431,  0.2391,  0.0766,  0.6512, -0.0077,  0.0747],\n","                      device='cuda:0')),\n","              ('module.layer1.8.conv2.accum_scale', tensor([[[2.7459e+09]],\n","               \n","                       [[2.1493e+09]],\n","               \n","                       [[1.5481e+09]],\n","               \n","                       [[2.8588e+09]],\n","               \n","                       [[4.0673e+10]],\n","               \n","                       [[4.6207e+09]],\n","               \n","                       [[1.1740e+09]],\n","               \n","                       [[1.3444e+09]],\n","               \n","                       [[2.8838e+09]],\n","               \n","                       [[9.4083e+09]],\n","               \n","                       [[2.2727e+09]],\n","               \n","                       [[5.7331e+09]],\n","               \n","                       [[4.2135e+09]],\n","               \n","                       [[2.0101e+09]],\n","               \n","                       [[1.8551e+09]],\n","               \n","                       [[3.6894e+09]]], device='cuda:0')),\n","              ('module.layer1.8.conv2.is_simulated_quant_weight_shifted',\n","               tensor(False, device='cuda:0')),\n","              ('module.layer1.8.conv2.wrapped_module.weight',\n","               tensor([[[[22122., 22201., 22306.],\n","                         [22760., 22902., 23203.],\n","                         [23483., 22659., 22909.]],\n","               \n","                        [[18018., 19982., 21475.],\n","                         [19831., 20369., 19898.],\n","                         [19308., 18481., 19893.]],\n","               \n","                        [[36712., 48116., 41261.],\n","                         [50261., 65535., 52423.],\n","                         [41045., 36311., 36312.]],\n","               \n","                        ...,\n","               \n","                        [[10260.,  5191.,  3031.],\n","                         [33463., 29478., 26397.],\n","                         [32096., 16327., 36034.]],\n","               \n","                        [[25319., 25331., 25321.],\n","                         [25414., 25382., 25335.],\n","                         [25425., 25370., 25395.]],\n","               \n","                        [[25398., 25379., 25397.],\n","                         [25382., 25398., 25311.],\n","                         [25407., 25428., 25417.]]],\n","               \n","               \n","                       [[[45966., 50150., 47865.],\n","                         [43660., 47647., 45540.],\n","                         [47228., 50586., 46703.]],\n","               \n","                        [[48726., 53501., 52053.],\n","                         [46448., 52481., 51624.],\n","                         [44717., 50871., 49297.]],\n","               \n","                        [[44026., 39890., 50948.],\n","                         [54512., 45478., 51776.],\n","                         [60559., 59535., 54337.]],\n","               \n","                        ...,\n","               \n","                        [[51038., 50827., 41195.],\n","                         [54852., 62441., 43964.],\n","                         [41330., 48576., 38897.]],\n","               \n","                        [[48752., 48633., 48685.],\n","                         [48701., 48770., 48720.],\n","                         [48743., 48735., 48720.]],\n","               \n","                        [[48521., 48487., 48538.],\n","                         [48629., 48641., 48604.],\n","                         [48518., 48643., 48611.]]],\n","               \n","               \n","                       [[[32058., 31088., 31671.],\n","                         [33512., 33949., 33611.],\n","                         [33580., 33190., 33222.]],\n","               \n","                        [[30646., 29724., 30020.],\n","                         [33099., 32123., 31928.],\n","                         [31759., 29647., 29585.]],\n","               \n","                        [[27428., 31082., 32897.],\n","                         [26733., 33102., 41293.],\n","                         [22596., 32933., 37473.]],\n","               \n","                        ...,\n","               \n","                        [[34822., 30294., 17903.],\n","                         [26297., 24039., 19690.],\n","                         [32263., 21211., 26841.]],\n","               \n","                        [[30621., 30616., 30666.],\n","                         [30604., 30591., 30659.],\n","                         [30642., 30622., 30671.]],\n","               \n","                        [[30698., 30703., 30709.],\n","                         [30663., 30714., 30668.],\n","                         [30597., 30656., 30673.]]],\n","               \n","               \n","                       ...,\n","               \n","               \n","                       [[[28435., 26373., 27237.],\n","                         [31795., 30516., 30565.],\n","                         [34413., 32645., 32902.]],\n","               \n","                        [[29997., 25927., 26054.],\n","                         [28318., 24265., 25231.],\n","                         [31829., 25287., 25285.]],\n","               \n","                        [[49098., 57592., 52079.],\n","                         [44785., 55657., 42095.],\n","                         [28005., 47591., 41221.]],\n","               \n","                        ...,\n","               \n","                        [[30003., 28235., 30800.],\n","                         [ 8125.,  5486., 16305.],\n","                         [ 9647.,   476., 14724.]],\n","               \n","                        [[33341., 33394., 33423.],\n","                         [33435., 33313., 33421.],\n","                         [33453., 33480., 33426.]],\n","               \n","                        [[33290., 33257., 33372.],\n","                         [33402., 33272., 33363.],\n","                         [33303., 33359., 33342.]]],\n","               \n","               \n","                       [[[27606., 27831., 26735.],\n","                         [27328., 27776., 26440.],\n","                         [28065., 27512., 26236.]],\n","               \n","                        [[25777., 24774., 23268.],\n","                         [24555., 23658., 21991.],\n","                         [25866., 24666., 22953.]],\n","               \n","                        [[14113., 21604., 29107.],\n","                         [25236., 26432., 29414.],\n","                         [23044., 18976., 19051.]],\n","               \n","                        ...,\n","               \n","                        [[22385.,     0., 12536.],\n","                         [41794.,  4016., 27467.],\n","                         [33860.,  4740., 26634.]],\n","               \n","                        [[25804., 25786., 25813.],\n","                         [25821., 25821., 25843.],\n","                         [25778., 25808., 25784.]],\n","               \n","                        [[25943., 25916., 25918.],\n","                         [25932., 25925., 25923.],\n","                         [25941., 25906., 25863.]]],\n","               \n","               \n","                       [[[37274., 35195., 36248.],\n","                         [36575., 33291., 32616.],\n","                         [36445., 33924., 32866.]],\n","               \n","                        [[37428., 35699., 38689.],\n","                         [32827., 30211., 31001.],\n","                         [31554., 29219., 29542.]],\n","               \n","                        [[47105., 56653., 49327.],\n","                         [44478., 54437., 52823.],\n","                         [35381., 51306., 50081.]],\n","               \n","                        ...,\n","               \n","                        [[37259., 65535., 36326.],\n","                         [23025., 60112., 35873.],\n","                         [14213., 46214., 29099.]],\n","               \n","                        [[39567., 39496., 39502.],\n","                         [39492., 39492., 39556.],\n","                         [39512., 39501., 39504.]],\n","               \n","                        [[39553., 39463., 39562.],\n","                         [39553., 39399., 39625.],\n","                         [39622., 39558., 39610.]]]], device='cuda:0')),\n","              ('module.layer1.8.conv2.wrapped_module.bias',\n","               tensor([-1.0470e+09,  2.1475e+09,  2.4069e+08,  1.9869e+09,  2.1475e+09,\n","                       -6.2771e+08, -1.0951e+09,  1.7112e+09,  7.1535e+07,  3.0287e+07,\n","                        2.1475e+09,  1.3709e+09,  3.2267e+08,  1.3089e+09, -1.4236e+07,\n","                        2.7542e+08], device='cuda:0')),\n","              ('module.layer1.8.relu2.num_forwards',\n","               tensor([40], device='cuda:0')),\n","              ('module.layer1.8.relu2.force_readjust',\n","               tensor(False, device='cuda:0')),\n","              ('module.layer1.8.relu2.output_scale',\n","               tensor([7490.9233], device='cuda:0')),\n","              ('module.layer1.8.relu2.output_zero_point',\n","               tensor([0.], device='cuda:0')),\n","              ('module.layer1.8.residual_eltwiseadd.num_forwards',\n","               tensor([40], device='cuda:0')),\n","              ('module.layer1.8.residual_eltwiseadd.force_readjust',\n","               tensor(False, device='cuda:0')),\n","              ('module.layer1.8.residual_eltwiseadd.output_scale',\n","               tensor([7490.9233], device='cuda:0')),\n","              ('module.layer1.8.residual_eltwiseadd.output_zero_point',\n","               tensor([0.], device='cuda:0')),\n","              ('module.layer2.0.conv1.num_forwards',\n","               tensor([40], device='cuda:0')),\n","              ('module.layer2.0.conv1.force_readjust',\n","               tensor(False, device='cuda:0')),\n","              ('module.layer2.0.conv1.output_scale',\n","               tensor([23400.7637], device='cuda:0')),\n","              ('module.layer2.0.conv1.output_zero_point',\n","               tensor([0.], device='cuda:0')),\n","              ('module.layer2.0.conv1.w_scale', tensor([[[[532229.7500]]],\n","               \n","               \n","                       [[[597457.8750]]],\n","               \n","               \n","                       [[[519589.6562]]],\n","               \n","               \n","                       [[[427170.5938]]],\n","               \n","               \n","                       [[[412570.9062]]],\n","               \n","               \n","                       [[[340044.9375]]],\n","               \n","               \n","                       [[[453261.1250]]],\n","               \n","               \n","                       [[[399294.2812]]],\n","               \n","               \n","                       [[[437595.0625]]],\n","               \n","               \n","                       [[[390116.5938]]],\n","               \n","               \n","                       [[[493230.4375]]],\n","               \n","               \n","                       [[[435649.5938]]],\n","               \n","               \n","                       [[[371076.8438]]],\n","               \n","               \n","                       [[[499610.4375]]],\n","               \n","               \n","                       [[[451913.8438]]],\n","               \n","               \n","                       [[[611310.8750]]],\n","               \n","               \n","                       [[[363936.8125]]],\n","               \n","               \n","                       [[[393747.4062]]],\n","               \n","               \n","                       [[[597743.3125]]],\n","               \n","               \n","                       [[[541141.4375]]],\n","               \n","               \n","                       [[[424266.6562]]],\n","               \n","               \n","                       [[[283630.7188]]],\n","               \n","               \n","                       [[[536626.9375]]],\n","               \n","               \n","                       [[[406508.1250]]],\n","               \n","               \n","                       [[[480334.4062]]],\n","               \n","               \n","                       [[[633607.5625]]],\n","               \n","               \n","                       [[[242837.5312]]],\n","               \n","               \n","                       [[[404789.5312]]],\n","               \n","               \n","                       [[[455356.2500]]],\n","               \n","               \n","                       [[[709546.0625]]],\n","               \n","               \n","                       [[[435115.3750]]],\n","               \n","               \n","                       [[[524585.6250]]]], device='cuda:0')),\n","              ('module.layer2.0.conv1.w_zero_point', tensor([[[[-32325.]]],\n","               \n","               \n","                       [[[-37304.]]],\n","               \n","               \n","                       [[[-30116.]]],\n","               \n","               \n","                       [[[-30183.]]],\n","               \n","               \n","                       [[[-31850.]]],\n","               \n","               \n","                       [[[-35940.]]],\n","               \n","               \n","                       [[[-27648.]]],\n","               \n","               \n","                       [[[-27410.]]],\n","               \n","               \n","                       [[[-33673.]]],\n","               \n","               \n","                       [[[-33315.]]],\n","               \n","               \n","                       [[[-24031.]]],\n","               \n","               \n","                       [[[-32246.]]],\n","               \n","               \n","                       [[[-33830.]]],\n","               \n","               \n","                       [[[-27184.]]],\n","               \n","               \n","                       [[[-28677.]]],\n","               \n","               \n","                       [[[-26970.]]],\n","               \n","               \n","                       [[[-41176.]]],\n","               \n","               \n","                       [[[-38370.]]],\n","               \n","               \n","                       [[[-29998.]]],\n","               \n","               \n","                       [[[-30401.]]],\n","               \n","               \n","                       [[[-24634.]]],\n","               \n","               \n","                       [[[-42282.]]],\n","               \n","               \n","                       [[[-32132.]]],\n","               \n","               \n","                       [[[-30916.]]],\n","               \n","               \n","                       [[[-28408.]]],\n","               \n","               \n","                       [[[-28246.]]],\n","               \n","               \n","                       [[[-29125.]]],\n","               \n","               \n","                       [[[-36263.]]],\n","               \n","               \n","                       [[[-20816.]]],\n","               \n","               \n","                       [[[-29558.]]],\n","               \n","               \n","                       [[[-31764.]]],\n","               \n","               \n","                       [[[-30602.]]]], device='cuda:0')),\n","              ('module.layer2.0.conv1.fp_bias',\n","               tensor([-0.3136,  0.1518, -1.2373, -1.2207, -0.0150, -0.7198,  0.1807, -0.2573,\n","                       -1.5213,  0.7615, -0.6818,  0.5184, -0.0434, -0.3644, -0.5792,  0.6989,\n","                        1.5584, -0.9078,  0.6930,  1.9755, -0.2126,  0.1413, -0.5672,  0.0220,\n","                        0.0268, -1.0482, -0.6446,  0.1230, -1.8327,  0.1207, -2.1183,  1.8732],\n","                      device='cuda:0')),\n","              ('module.layer2.0.conv1.accum_scale', tensor([[[3.9869e+09]],\n","               \n","                       [[4.4755e+09]],\n","               \n","                       [[3.8922e+09]],\n","               \n","                       [[3.1999e+09]],\n","               \n","                       [[3.0905e+09]],\n","               \n","                       [[2.5473e+09]],\n","               \n","                       [[3.3953e+09]],\n","               \n","                       [[2.9911e+09]],\n","               \n","                       [[3.2780e+09]],\n","               \n","                       [[2.9223e+09]],\n","               \n","                       [[3.6948e+09]],\n","               \n","                       [[3.2634e+09]],\n","               \n","                       [[2.7797e+09]],\n","               \n","                       [[3.7425e+09]],\n","               \n","                       [[3.3853e+09]],\n","               \n","                       [[4.5793e+09]],\n","               \n","                       [[2.7262e+09]],\n","               \n","                       [[2.9495e+09]],\n","               \n","                       [[4.4776e+09]],\n","               \n","                       [[4.0536e+09]],\n","               \n","                       [[3.1781e+09]],\n","               \n","                       [[2.1247e+09]],\n","               \n","                       [[4.0198e+09]],\n","               \n","                       [[3.0451e+09]],\n","               \n","                       [[3.5981e+09]],\n","               \n","                       [[4.7463e+09]],\n","               \n","                       [[1.8191e+09]],\n","               \n","                       [[3.0322e+09]],\n","               \n","                       [[3.4110e+09]],\n","               \n","                       [[5.3152e+09]],\n","               \n","                       [[3.2594e+09]],\n","               \n","                       [[3.9296e+09]]], device='cuda:0')),\n","              ('module.layer2.0.conv1.is_simulated_quant_weight_shifted',\n","               tensor(False, device='cuda:0')),\n","              ('module.layer2.0.conv1.wrapped_module.weight',\n","               tensor([[[[50296., 31025., 18632.],\n","                         [32274.,  8773., 31274.],\n","                         [25010., 24734., 36075.]],\n","               \n","                        [[27914., 21212., 17162.],\n","                         [21337., 19803., 29034.],\n","                         [14109., 26702., 37836.]],\n","               \n","                        [[25481., 19340., 40780.],\n","                         [21377., 38409., 50786.],\n","                         [39812., 46073., 46848.]],\n","               \n","                        ...,\n","               \n","                        [[36499., 38443., 30716.],\n","                         [40701., 27431.,  7509.],\n","                         [22447., 13506., 22369.]],\n","               \n","                        [[65535., 44944., 40220.],\n","                         [36914.,  1832., 33278.],\n","                         [23870., 38068., 48021.]],\n","               \n","                        [[25891., 27728., 26065.],\n","                         [38082., 36776., 46031.],\n","                         [38326., 27659., 41285.]]],\n","               \n","               \n","                       [[[20711., 13972., 22736.],\n","                         [15193., 23253., 30079.],\n","                         [21238., 18813., 35969.]],\n","               \n","                        [[25114., 22861., 18997.],\n","                         [28358., 32276., 19389.],\n","                         [30040., 26839., 18961.]],\n","               \n","                        [[38724., 39456., 42352.],\n","                         [43466., 36140., 37797.],\n","                         [48496., 41235., 49730.]],\n","               \n","                        ...,\n","               \n","                        [[30946., 30900., 34307.],\n","                         [29748., 35799., 40327.],\n","                         [38180., 43035., 47119.]],\n","               \n","                        [[21810., 15262., 31479.],\n","                         [    0., 29329., 22002.],\n","                         [15086.,  8965., 32510.]],\n","               \n","                        [[46575., 35672., 40667.],\n","                         [44653., 36217., 44623.],\n","                         [34024., 33462., 37893.]]],\n","               \n","               \n","                       [[[35457., 42952., 31155.],\n","                         [38143., 39317., 33006.],\n","                         [40917., 38152., 33145.]],\n","               \n","                        [[48143., 46526., 51252.],\n","                         [55008., 43637., 50513.],\n","                         [44148., 44565., 45706.]],\n","               \n","                        [[11683., 26553., 34199.],\n","                         [15544., 27344., 31150.],\n","                         [ 8619., 21592., 26038.]],\n","               \n","                        ...,\n","               \n","                        [[18498., 26490., 34784.],\n","                         [16740., 24081., 25462.],\n","                         [26312., 27155., 25654.]],\n","               \n","                        [[24129., 26484., 24260.],\n","                         [22521., 19598., 16253.],\n","                         [11403.,   572., 19747.]],\n","               \n","                        [[40694., 41721., 43139.],\n","                         [34818., 38932., 38471.],\n","                         [26348., 20955., 21197.]]],\n","               \n","               \n","                       ...,\n","               \n","               \n","                       [[[27126., 20639., 12813.],\n","                         [28505., 29525., 10025.],\n","                         [31173., 20643., 16850.]],\n","               \n","                        [[    0.,  7869.,  5015.],\n","                         [14407., 17407., 14483.],\n","                         [29704., 28386., 19217.]],\n","               \n","                        [[56735., 51565., 37509.],\n","                         [47429., 44771., 48968.],\n","                         [49736., 58872., 54769.]],\n","               \n","                        ...,\n","               \n","                        [[43188., 45809., 34422.],\n","                         [32598., 23339., 38393.],\n","                         [17719., 26928., 41207.]],\n","               \n","                        [[16411., 10555., 18649.],\n","                         [11229., 24146., 13541.],\n","                         [31664., 13658., 16959.]],\n","               \n","                        [[43569., 41717., 39748.],\n","                         [54295., 42443., 43636.],\n","                         [51310., 59996., 49889.]]],\n","               \n","               \n","                       [[[34240., 34549., 17136.],\n","                         [32575., 26380., 23014.],\n","                         [17259., 22598., 29511.]],\n","               \n","                        [[22424., 23714., 23124.],\n","                         [19568., 31737., 46921.],\n","                         [27164., 43942., 60004.]],\n","               \n","                        [[28419., 25725., 40753.],\n","                         [31258., 46153., 46608.],\n","                         [34424., 36412., 42674.]],\n","               \n","                        ...,\n","               \n","                        [[16604., 12977.,  9115.],\n","                         [13656., 23530., 15249.],\n","                         [25705., 25942., 37314.]],\n","               \n","                        [[26454., 23841., 12401.],\n","                         [30021., 31798., 41210.],\n","                         [53553., 52030., 38407.]],\n","               \n","                        [[34863., 41090., 43994.],\n","                         [34961., 33510., 25913.],\n","                         [16981., 28521., 29775.]]],\n","               \n","               \n","                       [[[ 7439.,  5230.,  6422.],\n","                         [23684., 24820., 13644.],\n","                         [40476., 30542., 26591.]],\n","               \n","                        [[26073., 16789., 24663.],\n","                         [27951., 22333., 32657.],\n","                         [23413., 21855., 28916.]],\n","               \n","                        [[27645., 18014., 21348.],\n","                         [30094., 23455., 23460.],\n","                         [46223., 20537., 23125.]],\n","               \n","                        ...,\n","               \n","                        [[29485., 28505., 28511.],\n","                         [37646., 33359., 24443.],\n","                         [36738., 35398., 36815.]],\n","               \n","                        [[12863.,  1549., 12381.],\n","                         [ 5154., 10398.,  5231.],\n","                         [24345.,  6082., 14074.]],\n","               \n","                        [[18669., 24426., 26220.],\n","                         [26563., 28280., 18289.],\n","                         [40825., 33488., 14561.]]]], device='cuda:0')),\n","              ('module.layer2.0.conv1.wrapped_module.bias',\n","               tensor([-1.2501e+09,  6.7923e+08, -2.1475e+09, -2.1475e+09, -4.6237e+07,\n","                       -1.8335e+09,  6.1345e+08, -7.6954e+08, -2.1475e+09,  2.1475e+09,\n","                       -2.1475e+09,  1.6919e+09, -1.2062e+08, -1.3636e+09, -1.9609e+09,\n","                        2.1475e+09,  2.1475e+09, -2.1475e+09,  2.1475e+09,  2.1475e+09,\n","                       -6.7555e+08,  3.0014e+08, -2.1475e+09,  6.7144e+07,  9.6485e+07,\n","                       -2.1475e+09, -1.1725e+09,  3.7304e+08, -2.1475e+09,  6.4169e+08,\n","                       -2.1475e+09,  2.1475e+09], device='cuda:0')),\n","              ('module.layer2.0.conv2.num_forwards',\n","               tensor([40], device='cuda:0')),\n","              ('module.layer2.0.conv2.force_readjust',\n","               tensor(False, device='cuda:0')),\n","              ('module.layer2.0.conv2.output_scale',\n","               tensor([7630.3140], device='cuda:0')),\n","              ('module.layer2.0.conv2.output_zero_point',\n","               tensor([-28150.], device='cuda:0')),\n","              ('module.layer2.0.conv2.w_scale', tensor([[[[3.0253e+05]]],\n","               \n","               \n","                       [[[1.4774e+05]]],\n","               \n","               \n","                       [[[1.2004e+05]]],\n","               \n","               \n","                       [[[1.0509e+05]]],\n","               \n","               \n","                       [[[1.0833e+05]]],\n","               \n","               \n","                       [[[1.0948e+05]]],\n","               \n","               \n","                       [[[1.0082e+05]]],\n","               \n","               \n","                       [[[1.2196e+05]]],\n","               \n","               \n","                       [[[1.2954e+05]]],\n","               \n","               \n","                       [[[1.5425e+05]]],\n","               \n","               \n","                       [[[6.9906e+04]]],\n","               \n","               \n","                       [[[1.5102e+05]]],\n","               \n","               \n","                       [[[9.2481e+04]]],\n","               \n","               \n","                       [[[1.8851e+05]]],\n","               \n","               \n","                       [[[1.4324e+05]]],\n","               \n","               \n","                       [[[1.7538e+05]]],\n","               \n","               \n","                       [[[1.2918e+05]]],\n","               \n","               \n","                       [[[1.8649e+05]]],\n","               \n","               \n","                       [[[1.7378e+05]]],\n","               \n","               \n","                       [[[1.7089e+05]]],\n","               \n","               \n","                       [[[1.8883e+05]]],\n","               \n","               \n","                       [[[1.3679e+05]]],\n","               \n","               \n","                       [[[2.2948e+05]]],\n","               \n","               \n","                       [[[2.2306e+05]]],\n","               \n","               \n","                       [[[1.5607e+05]]],\n","               \n","               \n","                       [[[1.9853e+05]]],\n","               \n","               \n","                       [[[3.8680e+08]]],\n","               \n","               \n","                       [[[1.4826e+05]]],\n","               \n","               \n","                       [[[1.3251e+05]]],\n","               \n","               \n","                       [[[1.1937e+05]]],\n","               \n","               \n","                       [[[2.0661e+05]]],\n","               \n","               \n","                       [[[1.4812e+05]]]], device='cuda:0')),\n","              ('module.layer2.0.conv2.w_zero_point', tensor([[[[-37957.]]],\n","               \n","               \n","                       [[[-31412.]]],\n","               \n","               \n","                       [[[-24154.]]],\n","               \n","               \n","                       [[[-35177.]]],\n","               \n","               \n","                       [[[-29540.]]],\n","               \n","               \n","                       [[[-34461.]]],\n","               \n","               \n","                       [[[-29922.]]],\n","               \n","               \n","                       [[[-26689.]]],\n","               \n","               \n","                       [[[-26619.]]],\n","               \n","               \n","                       [[[-36860.]]],\n","               \n","               \n","                       [[[-32872.]]],\n","               \n","               \n","                       [[[-28986.]]],\n","               \n","               \n","                       [[[-30735.]]],\n","               \n","               \n","                       [[[-28575.]]],\n","               \n","               \n","                       [[[-28557.]]],\n","               \n","               \n","                       [[[-34907.]]],\n","               \n","               \n","                       [[[-35533.]]],\n","               \n","               \n","                       [[[-36256.]]],\n","               \n","               \n","                       [[[-26751.]]],\n","               \n","               \n","                       [[[-32777.]]],\n","               \n","               \n","                       [[[-24207.]]],\n","               \n","               \n","                       [[[-30193.]]],\n","               \n","               \n","                       [[[-31768.]]],\n","               \n","               \n","                       [[[-36465.]]],\n","               \n","               \n","                       [[[-24797.]]],\n","               \n","               \n","                       [[[-33354.]]],\n","               \n","               \n","                       [[[-27391.]]],\n","               \n","               \n","                       [[[-35015.]]],\n","               \n","               \n","                       [[[-27995.]]],\n","               \n","               \n","                       [[[-26760.]]],\n","               \n","               \n","                       [[[-31430.]]],\n","               \n","               \n","                       [[[-31312.]]]], device='cuda:0')),\n","              ('module.layer2.0.conv2.fp_bias',\n","               tensor([ 0.7113,  1.4785,  0.0834,  0.8207,  0.2750,  1.6346,  0.4279,  0.0854,\n","                        0.3189,  1.0900,  0.0754, -0.5480,  0.3695,  0.1296,  0.6606,  0.9535,\n","                        0.6076,  1.8258,  0.0177,  0.4116,  0.1102, -0.1408,  0.2118,  0.8184,\n","                        0.5609,  0.2279, -0.0023,  0.1846,  0.2595, -0.0197,  1.1834,  0.9338],\n","                      device='cuda:0')),\n","              ('module.layer2.0.conv2.accum_scale', tensor([[[7.0794e+09]],\n","               \n","                       [[3.4573e+09]],\n","               \n","                       [[2.8091e+09]],\n","               \n","                       [[2.4592e+09]],\n","               \n","                       [[2.5350e+09]],\n","               \n","                       [[2.5620e+09]],\n","               \n","                       [[2.3593e+09]],\n","               \n","                       [[2.8540e+09]],\n","               \n","                       [[3.0314e+09]],\n","               \n","                       [[3.6095e+09]],\n","               \n","                       [[1.6359e+09]],\n","               \n","                       [[3.5340e+09]],\n","               \n","                       [[2.1641e+09]],\n","               \n","                       [[4.4112e+09]],\n","               \n","                       [[3.3518e+09]],\n","               \n","                       [[4.1041e+09]],\n","               \n","                       [[3.0229e+09]],\n","               \n","                       [[4.3639e+09]],\n","               \n","                       [[4.0665e+09]],\n","               \n","                       [[3.9990e+09]],\n","               \n","                       [[4.4188e+09]],\n","               \n","                       [[3.2009e+09]],\n","               \n","                       [[5.3700e+09]],\n","               \n","                       [[5.2197e+09]],\n","               \n","                       [[3.6521e+09]],\n","               \n","                       [[4.6457e+09]],\n","               \n","                       [[9.0514e+12]],\n","               \n","                       [[3.4694e+09]],\n","               \n","                       [[3.1008e+09]],\n","               \n","                       [[2.7933e+09]],\n","               \n","                       [[4.8349e+09]],\n","               \n","                       [[3.4662e+09]]], device='cuda:0')),\n","              ('module.layer2.0.conv2.is_simulated_quant_weight_shifted',\n","               tensor(False, device='cuda:0')),\n","              ('module.layer2.0.conv2.wrapped_module.weight',\n","               tensor([[[[41458., 37326., 42926.],\n","                         [40244., 42372., 37127.],\n","                         [46467., 45761., 41776.]],\n","               \n","                        [[31906., 34978., 28719.],\n","                         [32994., 44049., 38362.],\n","                         [36230., 49451., 41911.]],\n","               \n","                        [[31349., 36894., 36175.],\n","                         [19723.,  7544., 20657.],\n","                         [ 9716.,   476., 19577.]],\n","               \n","                        ...,\n","               \n","                        [[41384., 35586., 32725.],\n","                         [35530., 30853., 33089.],\n","                         [42890., 44916., 39700.]],\n","               \n","                        [[33093., 27865., 37509.],\n","                         [28791., 33598., 32125.],\n","                         [14080., 32690., 37200.]],\n","               \n","                        [[43715., 58644., 52760.],\n","                         [46406., 65535., 52491.],\n","                         [20572., 24391., 30750.]]],\n","               \n","               \n","                       [[[36082., 30320., 22617.],\n","                         [32508., 14498., 12730.],\n","                         [22613.,  3935., 17893.]],\n","               \n","                        [[32432., 31262., 30925.],\n","                         [18984., 11062., 21810.],\n","                         [22783., 16696., 29612.]],\n","               \n","                        [[27611., 20853., 22732.],\n","                         [22762., 30957., 20684.],\n","                         [26414., 33906., 17852.]],\n","               \n","                        ...,\n","               \n","                        [[23508., 25408., 30522.],\n","                         [24429., 11963., 11017.],\n","                         [39570., 19983.,  4383.]],\n","               \n","                        [[46091., 27211., 20222.],\n","                         [15390., 13389.,  5557.],\n","                         [18349., 21533., 25545.]],\n","               \n","                        [[29956., 39611., 32920.],\n","                         [36126., 49545., 27538.],\n","                         [23517., 38202., 27856.]]],\n","               \n","               \n","                       [[[35399., 25762., 29870.],\n","                         [26265., 29411., 35061.],\n","                         [28838., 15671., 15210.]],\n","               \n","                        [[32265., 25348., 17692.],\n","                         [12110., 10039., 13879.],\n","                         [11163., 13522., 20595.]],\n","               \n","                        [[12510., 10096.,     0.],\n","                         [22474., 21991., 20414.],\n","                         [35877., 52337., 37136.]],\n","               \n","                        ...,\n","               \n","                        [[37284., 38096., 40889.],\n","                         [22973., 25216., 29731.],\n","                         [ 7713., 13140., 16608.]],\n","               \n","                        [[35821., 21352., 31176.],\n","                         [28388., 39666., 30581.],\n","                         [21968., 20848., 27115.]],\n","               \n","                        [[17435., 14531., 16786.],\n","                         [11561.,  6990.,  7424.],\n","                         [26359., 21201., 21624.]]],\n","               \n","               \n","                       ...,\n","               \n","               \n","                       [[[25658., 21666., 20399.],\n","                         [20376., 42728., 54330.],\n","                         [30283., 61658., 43585.]],\n","               \n","                        [[19361., 17089., 18914.],\n","                         [30825., 50514., 51949.],\n","                         [33776., 32912., 19353.]],\n","               \n","                        [[27318., 29872., 33050.],\n","                         [19540., 18898., 32507.],\n","                         [10261., 18753., 33316.]],\n","               \n","                        ...,\n","               \n","                        [[24180., 30839., 14476.],\n","                         [27139., 11828.,  9906.],\n","                         [30053., 29286., 16329.]],\n","               \n","                        [[23349.,  8126., 23917.],\n","                         [16448., 51756., 54682.],\n","                         [17571., 42061., 21341.]],\n","               \n","                        [[24240., 19549., 12127.],\n","                         [34607., 19543., 30692.],\n","                         [19969., 27912., 29306.]]],\n","               \n","               \n","                       [[[34672., 26797., 35815.],\n","                         [39113., 25111., 24460.],\n","                         [30122., 36359., 35649.]],\n","               \n","                        [[37127., 24105., 39113.],\n","                         [21591.,  1146., 40578.],\n","                         [13869.,  3031., 28179.]],\n","               \n","                        [[21516.,  6654., 28212.],\n","                         [30014., 16769., 24379.],\n","                         [39200., 27399., 26195.]],\n","               \n","                        ...,\n","               \n","                        [[32401., 17973., 36295.],\n","                         [15238.,     0., 31649.],\n","                         [20043., 11662., 40787.]],\n","               \n","                        [[27213., 25375., 33463.],\n","                         [21369., 19932., 28610.],\n","                         [36624., 21825., 29781.]],\n","               \n","                        [[28250., 41189., 44426.],\n","                         [13326., 12928., 47326.],\n","                         [14439., 13587., 32553.]]],\n","               \n","               \n","                       [[[17758., 30793., 41278.],\n","                         [ 8432., 20776., 27850.],\n","                         [19516., 24583., 32535.]],\n","               \n","                        [[35076., 23689., 23814.],\n","                         [40218., 16579., 20760.],\n","                         [45390., 27194., 22938.]],\n","               \n","                        [[38005., 33514., 38259.],\n","                         [46081., 30585., 26216.],\n","                         [43798., 38260., 21493.]],\n","               \n","                        ...,\n","               \n","                        [[33505., 28016., 48924.],\n","                         [37710., 20327., 29939.],\n","                         [37515., 10790.,  2776.]],\n","               \n","                        [[27431., 30454., 31492.],\n","                         [21527., 26588., 34407.],\n","                         [23706., 20738., 22501.]],\n","               \n","                        [[49062., 28730., 37621.],\n","                         [51032., 24223., 25733.],\n","                         [44850., 16940.,  6283.]]]], device='cuda:0')),\n","              ('module.layer2.0.conv2.wrapped_module.bias',\n","               tensor([ 2.1475e+09,  2.1475e+09,  2.3415e+08,  2.0182e+09,  6.9722e+08,\n","                        2.1475e+09,  1.0096e+09,  2.4375e+08,  9.6675e+08,  2.1475e+09,\n","                        1.2334e+08, -1.9365e+09,  7.9968e+08,  5.7185e+08,  2.1475e+09,\n","                        2.1475e+09,  1.8366e+09,  2.1475e+09,  7.2045e+07,  1.6461e+09,\n","                        4.8715e+08, -4.5061e+08,  1.1375e+09,  2.1475e+09,  2.0484e+09,\n","                        1.0587e+09, -2.1475e+09,  6.4040e+08,  8.0467e+08, -5.4917e+07,\n","                        2.1475e+09,  2.1475e+09], device='cuda:0')),\n","              ('module.layer2.0.relu2.num_forwards',\n","               tensor([40], device='cuda:0')),\n","              ('module.layer2.0.relu2.force_readjust',\n","               tensor(False, device='cuda:0')),\n","              ('module.layer2.0.relu2.output_scale',\n","               tensor([9073.3604], device='cuda:0')),\n","              ('module.layer2.0.relu2.output_zero_point',\n","               tensor([0.], device='cuda:0')),\n","              ('module.layer2.0.downsample.0.num_forwards',\n","               tensor([40], device='cuda:0')),\n","              ('module.layer2.0.downsample.0.force_readjust',\n","               tensor(False, device='cuda:0')),\n","              ('module.layer2.0.downsample.0.output_scale',\n","               tensor([9497.6680], device='cuda:0')),\n","              ('module.layer2.0.downsample.0.output_zero_point',\n","               tensor([-21349.], device='cuda:0')),\n","              ('module.layer2.0.downsample.0.w_scale',\n","               tensor([[[[6.3339e+04]]],\n","               \n","               \n","                       [[[1.3688e+05]]],\n","               \n","               \n","                       [[[3.2124e+05]]],\n","               \n","               \n","                       [[[4.3824e+05]]],\n","               \n","               \n","                       [[[1.8273e+05]]],\n","               \n","               \n","                       [[[1.2374e+05]]],\n","               \n","               \n","                       [[[2.7666e+05]]],\n","               \n","               \n","                       [[[1.6783e+05]]],\n","               \n","               \n","                       [[[1.1332e+05]]],\n","               \n","               \n","                       [[[9.1214e+04]]],\n","               \n","               \n","                       [[[1.3081e+05]]],\n","               \n","               \n","                       [[[1.0465e+05]]],\n","               \n","               \n","                       [[[1.2335e+05]]],\n","               \n","               \n","                       [[[1.1161e+05]]],\n","               \n","               \n","                       [[[1.4608e+05]]],\n","               \n","               \n","                       [[[7.7509e+04]]],\n","               \n","               \n","                       [[[2.6106e+05]]],\n","               \n","               \n","                       [[[1.1784e+05]]],\n","               \n","               \n","                       [[[1.5707e+05]]],\n","               \n","               \n","                       [[[1.1742e+05]]],\n","               \n","               \n","                       [[[5.6155e+04]]],\n","               \n","               \n","                       [[[2.3122e+05]]],\n","               \n","               \n","                       [[[1.6754e+05]]],\n","               \n","               \n","                       [[[4.2315e+05]]],\n","               \n","               \n","                       [[[3.9772e+05]]],\n","               \n","               \n","                       [[[9.4536e+05]]],\n","               \n","               \n","                       [[[3.7778e+08]]],\n","               \n","               \n","                       [[[1.1484e+05]]],\n","               \n","               \n","                       [[[7.7062e+04]]],\n","               \n","               \n","                       [[[9.6879e+04]]],\n","               \n","               \n","                       [[[9.3935e+04]]],\n","               \n","               \n","                       [[[3.3690e+05]]]], device='cuda:0')),\n","              ('module.layer2.0.downsample.0.w_zero_point',\n","               tensor([[[[-39927.]]],\n","               \n","               \n","                       [[[-32677.]]],\n","               \n","               \n","                       [[[-32739.]]],\n","               \n","               \n","                       [[[-43790.]]],\n","               \n","               \n","                       [[[-25061.]]],\n","               \n","               \n","                       [[[-36330.]]],\n","               \n","               \n","                       [[[-33906.]]],\n","               \n","               \n","                       [[[-25548.]]],\n","               \n","               \n","                       [[[-38182.]]],\n","               \n","               \n","                       [[[-32635.]]],\n","               \n","               \n","                       [[[-40421.]]],\n","               \n","               \n","                       [[[-26065.]]],\n","               \n","               \n","                       [[[-38545.]]],\n","               \n","               \n","                       [[[-16585.]]],\n","               \n","               \n","                       [[[-48068.]]],\n","               \n","               \n","                       [[[-39193.]]],\n","               \n","               \n","                       [[[-40148.]]],\n","               \n","               \n","                       [[[-31381.]]],\n","               \n","               \n","                       [[[-26272.]]],\n","               \n","               \n","                       [[[-30798.]]],\n","               \n","               \n","                       [[[-27295.]]],\n","               \n","               \n","                       [[[-21255.]]],\n","               \n","               \n","                       [[[-26796.]]],\n","               \n","               \n","                       [[[-40892.]]],\n","               \n","               \n","                       [[[-36211.]]],\n","               \n","               \n","                       [[[-38504.]]],\n","               \n","               \n","                       [[[-34456.]]],\n","               \n","               \n","                       [[[-28849.]]],\n","               \n","               \n","                       [[[-26905.]]],\n","               \n","               \n","                       [[[-24686.]]],\n","               \n","               \n","                       [[[-43689.]]],\n","               \n","               \n","                       [[[-29118.]]]], device='cuda:0')),\n","              ('module.layer2.0.downsample.0.fp_bias',\n","               tensor([ 1.5534e+00,  1.2326e+00, -7.8006e-02,  7.3776e-01,  3.4696e-01,\n","                       -7.6662e-02,  2.1585e-01, -2.5956e-01,  7.2422e-02, -7.0096e-01,\n","                       -3.0226e-02, -5.1034e-01,  6.5890e-01, -1.0542e+00,  1.7236e+00,\n","                        2.0761e+00,  5.6629e-01,  6.8770e-01, -8.4013e-01, -9.8360e-01,\n","                       -1.9155e+00, -2.5783e-01,  3.5782e-01,  5.4529e-01,  6.3588e-01,\n","                       -9.5813e-02, -1.8854e-03,  8.2768e-01, -3.2773e-01, -1.9618e-01,\n","                        1.1457e+00,  2.4443e-01], device='cuda:0')),\n","              ('module.layer2.0.downsample.0.accum_scale',\n","               tensor([[[4.7447e+08]],\n","               \n","                       [[1.0253e+09]],\n","               \n","                       [[2.4064e+09]],\n","               \n","                       [[3.2828e+09]],\n","               \n","                       [[1.3688e+09]],\n","               \n","                       [[9.2692e+08]],\n","               \n","                       [[2.0724e+09]],\n","               \n","                       [[1.2572e+09]],\n","               \n","                       [[8.4889e+08]],\n","               \n","                       [[6.8328e+08]],\n","               \n","                       [[9.7990e+08]],\n","               \n","                       [[7.8389e+08]],\n","               \n","                       [[9.2401e+08]],\n","               \n","                       [[8.3606e+08]],\n","               \n","                       [[1.0943e+09]],\n","               \n","                       [[5.8061e+08]],\n","               \n","                       [[1.9556e+09]],\n","               \n","                       [[8.8274e+08]],\n","               \n","                       [[1.1766e+09]],\n","               \n","                       [[8.7961e+08]],\n","               \n","                       [[4.2065e+08]],\n","               \n","                       [[1.7321e+09]],\n","               \n","                       [[1.2550e+09]],\n","               \n","                       [[3.1697e+09]],\n","               \n","                       [[2.9793e+09]],\n","               \n","                       [[7.0816e+09]],\n","               \n","                       [[2.8299e+12]],\n","               \n","                       [[8.6028e+08]],\n","               \n","                       [[5.7727e+08]],\n","               \n","                       [[7.2572e+08]],\n","               \n","                       [[7.0366e+08]],\n","               \n","                       [[2.5237e+09]]], device='cuda:0')),\n","              ('module.layer2.0.downsample.0.is_simulated_quant_weight_shifted',\n","               tensor(False, device='cuda:0')),\n","              ('module.layer2.0.downsample.0.wrapped_module.weight',\n","               tensor([[[[47384.]],\n","               \n","                        [[31969.]],\n","               \n","                        [[42386.]],\n","               \n","                        [[52629.]],\n","               \n","                        [[65535.]],\n","               \n","                        [[29232.]],\n","               \n","                        [[42391.]],\n","               \n","                        [[43473.]],\n","               \n","                        [[60074.]],\n","               \n","                        [[ 7677.]],\n","               \n","                        [[29552.]],\n","               \n","                        [[    0.]],\n","               \n","                        [[36103.]],\n","               \n","                        [[37168.]],\n","               \n","                        [[46856.]],\n","               \n","                        [[43957.]]],\n","               \n","               \n","                       [[[30046.]],\n","               \n","                        [[65535.]],\n","               \n","                        [[    0.]],\n","               \n","                        [[41181.]],\n","               \n","                        [[18547.]],\n","               \n","                        [[16719.]],\n","               \n","                        [[18825.]],\n","               \n","                        [[17938.]],\n","               \n","                        [[34444.]],\n","               \n","                        [[17579.]],\n","               \n","                        [[58930.]],\n","               \n","                        [[23784.]],\n","               \n","                        [[27037.]],\n","               \n","                        [[33532.]],\n","               \n","                        [[29349.]],\n","               \n","                        [[41141.]]],\n","               \n","               \n","                       [[[53666.]],\n","               \n","                        [[35927.]],\n","               \n","                        [[    0.]],\n","               \n","                        [[36599.]],\n","               \n","                        [[65535.]],\n","               \n","                        [[31169.]],\n","               \n","                        [[30952.]],\n","               \n","                        [[27523.]],\n","               \n","                        [[ 8749.]],\n","               \n","                        [[63992.]],\n","               \n","                        [[43370.]],\n","               \n","                        [[50133.]],\n","               \n","                        [[35604.]],\n","               \n","                        [[46122.]],\n","               \n","                        [[41657.]],\n","               \n","                        [[33297.]]],\n","               \n","               \n","                       [[[33512.]],\n","               \n","                        [[65535.]],\n","               \n","                        [[ 9145.]],\n","               \n","                        [[12112.]],\n","               \n","                        [[42883.]],\n","               \n","                        [[    0.]],\n","               \n","                        [[43271.]],\n","               \n","                        [[47803.]],\n","               \n","                        [[57511.]],\n","               \n","                        [[46882.]],\n","               \n","                        [[47359.]],\n","               \n","                        [[37596.]],\n","               \n","                        [[45239.]],\n","               \n","                        [[45920.]],\n","               \n","                        [[17390.]],\n","               \n","                        [[27158.]]],\n","               \n","               \n","                       [[[47851.]],\n","               \n","                        [[23235.]],\n","               \n","                        [[13380.]],\n","               \n","                        [[    0.]],\n","               \n","                        [[44599.]],\n","               \n","                        [[65535.]],\n","               \n","                        [[20606.]],\n","               \n","                        [[42539.]],\n","               \n","                        [[23352.]],\n","               \n","                        [[ 8619.]],\n","               \n","                        [[12262.]],\n","               \n","                        [[  134.]],\n","               \n","                        [[30338.]],\n","               \n","                        [[ 1015.]],\n","               \n","                        [[47385.]],\n","               \n","                        [[ 5219.]]],\n","               \n","               \n","                       [[[37439.]],\n","               \n","                        [[28357.]],\n","               \n","                        [[26772.]],\n","               \n","                        [[43678.]],\n","               \n","                        [[    0.]],\n","               \n","                        [[53356.]],\n","               \n","                        [[26644.]],\n","               \n","                        [[36116.]],\n","               \n","                        [[42081.]],\n","               \n","                        [[65535.]],\n","               \n","                        [[31465.]],\n","               \n","                        [[41972.]],\n","               \n","                        [[21345.]],\n","               \n","                        [[49580.]],\n","               \n","                        [[41088.]],\n","               \n","                        [[18766.]]],\n","               \n","               \n","                       [[[12165.]],\n","               \n","                        [[27840.]],\n","               \n","                        [[ 8673.]],\n","               \n","                        [[21518.]],\n","               \n","                        [[33650.]],\n","               \n","                        [[63939.]],\n","               \n","                        [[13526.]],\n","               \n","                        [[48558.]],\n","               \n","                        [[48266.]],\n","               \n","                        [[19620.]],\n","               \n","                        [[62687.]],\n","               \n","                        [[    0.]],\n","               \n","                        [[65535.]],\n","               \n","                        [[40561.]],\n","               \n","                        [[34757.]],\n","               \n","                        [[25365.]]],\n","               \n","               \n","                       [[[23513.]],\n","               \n","                        [[29201.]],\n","               \n","                        [[ 9901.]],\n","               \n","                        [[35761.]],\n","               \n","                        [[ 9000.]],\n","               \n","                        [[    0.]],\n","               \n","                        [[22751.]],\n","               \n","                        [[65535.]],\n","               \n","                        [[17495.]],\n","               \n","                        [[44656.]],\n","               \n","                        [[15875.]],\n","               \n","                        [[35109.]],\n","               \n","                        [[27916.]],\n","               \n","                        [[42828.]],\n","               \n","                        [[52349.]],\n","               \n","                        [[20374.]]],\n","               \n","               \n","                       [[[37567.]],\n","               \n","                        [[30005.]],\n","               \n","                        [[40119.]],\n","               \n","                        [[53503.]],\n","               \n","                        [[34583.]],\n","               \n","                        [[40754.]],\n","               \n","                        [[28868.]],\n","               \n","                        [[20792.]],\n","               \n","                        [[64417.]],\n","               \n","                        [[28670.]],\n","               \n","                        [[24617.]],\n","               \n","                        [[65535.]],\n","               \n","                        [[41864.]],\n","               \n","                        [[53863.]],\n","               \n","                        [[60719.]],\n","               \n","                        [[    0.]]],\n","               \n","               \n","                       [[[22158.]],\n","               \n","                        [[28590.]],\n","               \n","                        [[29480.]],\n","               \n","                        [[38714.]],\n","               \n","                        [[    0.]],\n","               \n","                        [[43556.]],\n","               \n","                        [[27201.]],\n","               \n","                        [[29268.]],\n","               \n","                        [[29098.]],\n","               \n","                        [[65535.]],\n","               \n","                        [[36725.]],\n","               \n","                        [[53174.]],\n","               \n","                        [[26937.]],\n","               \n","                        [[17728.]],\n","               \n","                        [[35516.]],\n","               \n","                        [[46542.]]],\n","               \n","               \n","                       [[[57990.]],\n","               \n","                        [[41822.]],\n","               \n","                        [[45623.]],\n","               \n","                        [[33556.]],\n","               \n","                        [[35799.]],\n","               \n","                        [[44204.]],\n","               \n","                        [[33869.]],\n","               \n","                        [[38269.]],\n","               \n","                        [[29007.]],\n","               \n","                        [[42203.]],\n","               \n","                        [[65535.]],\n","               \n","                        [[    0.]],\n","               \n","                        [[48050.]],\n","               \n","                        [[47691.]],\n","               \n","                        [[38652.]],\n","               \n","                        [[62471.]]],\n","               \n","               \n","                       [[[28633.]],\n","               \n","                        [[20806.]],\n","               \n","                        [[33130.]],\n","               \n","                        [[17901.]],\n","               \n","                        [[65535.]],\n","               \n","                        [[41681.]],\n","               \n","                        [[36792.]],\n","               \n","                        [[19329.]],\n","               \n","                        [[ 7840.]],\n","               \n","                        [[    0.]],\n","               \n","                        [[27568.]],\n","               \n","                        [[54259.]],\n","               \n","                        [[27149.]],\n","               \n","                        [[33855.]],\n","               \n","                        [[28111.]],\n","               \n","                        [[38396.]]],\n","               \n","               \n","                       [[[65535.]],\n","               \n","                        [[34463.]],\n","               \n","                        [[42460.]],\n","               \n","                        [[33111.]],\n","               \n","                        [[18042.]],\n","               \n","                        [[    0.]],\n","               \n","                        [[38358.]],\n","               \n","                        [[48016.]],\n","               \n","                        [[28952.]],\n","               \n","                        [[42352.]],\n","               \n","                        [[26212.]],\n","               \n","                        [[57554.]],\n","               \n","                        [[38346.]],\n","               \n","                        [[34611.]],\n","               \n","                        [[42865.]],\n","               \n","                        [[45052.]]],\n","               \n","               \n","                       [[[    0.]],\n","               \n","                        [[53579.]],\n","               \n","                        [[14819.]],\n","               \n","                        [[65535.]],\n","               \n","                        [[ 1953.]],\n","               \n","                        [[31389.]],\n","               \n","                        [[16555.]],\n","               \n","                        [[19728.]],\n","               \n","                        [[17868.]],\n","               \n","                        [[ 9988.]],\n","               \n","                        [[24197.]],\n","               \n","                        [[ 5851.]],\n","               \n","                        [[ 5647.]],\n","               \n","                        [[16766.]],\n","               \n","                        [[23058.]],\n","               \n","                        [[23527.]]],\n","               \n","               \n","                       [[[47941.]],\n","               \n","                        [[29469.]],\n","               \n","                        [[41346.]],\n","               \n","                        [[    0.]],\n","               \n","                        [[38939.]],\n","               \n","                        [[16740.]],\n","               \n","                        [[58973.]],\n","               \n","                        [[46276.]],\n","               \n","                        [[39645.]],\n","               \n","                        [[42657.]],\n","               \n","                        [[56442.]],\n","               \n","                        [[34644.]],\n","               \n","                        [[65535.]],\n","               \n","                        [[47160.]],\n","               \n","                        [[40368.]],\n","               \n","                        [[47352.]]],\n","               \n","               \n","                       [[[45797.]],\n","               \n","                        [[44659.]],\n","               \n","                        [[30961.]],\n","               \n","                        [[    0.]],\n","               \n","                        [[65535.]],\n","               \n","                        [[30479.]],\n","               \n","                        [[33547.]],\n","               \n","                        [[27189.]],\n","               \n","                        [[44489.]],\n","               \n","                        [[46011.]],\n","               \n","                        [[40823.]],\n","               \n","                        [[48232.]],\n","               \n","                        [[39618.]],\n","               \n","                        [[33770.]],\n","               \n","                        [[25118.]],\n","               \n","                        [[22224.]]],\n","               \n","               \n","                       [[[53768.]],\n","               \n","                        [[    0.]],\n","               \n","                        [[50348.]],\n","               \n","                        [[34775.]],\n","               \n","                        [[15197.]],\n","               \n","                        [[54281.]],\n","               \n","                        [[51533.]],\n","               \n","                        [[19887.]],\n","               \n","                        [[30987.]],\n","               \n","                        [[31749.]],\n","               \n","                        [[14831.]],\n","               \n","                        [[10176.]],\n","               \n","                        [[58382.]],\n","               \n","                        [[20617.]],\n","               \n","                        [[65535.]],\n","               \n","                        [[42409.]]],\n","               \n","               \n","                       [[[16437.]],\n","               \n","                        [[ 5618.]],\n","               \n","                        [[34819.]],\n","               \n","                        [[36786.]],\n","               \n","                        [[ 9697.]],\n","               \n","                        [[31617.]],\n","               \n","                        [[34055.]],\n","               \n","                        [[25003.]],\n","               \n","                        [[65535.]],\n","               \n","                        [[53106.]],\n","               \n","                        [[ 5329.]],\n","               \n","                        [[    0.]],\n","               \n","                        [[ 7535.]],\n","               \n","                        [[21344.]],\n","               \n","                        [[39358.]],\n","               \n","                        [[32971.]]],\n","               \n","               \n","                       [[[    0.]],\n","               \n","                        [[32392.]],\n","               \n","                        [[20271.]],\n","               \n","                        [[34074.]],\n","               \n","                        [[  525.]],\n","               \n","                        [[42755.]],\n","               \n","                        [[27872.]],\n","               \n","                        [[26687.]],\n","               \n","                        [[65535.]],\n","               \n","                        [[44709.]],\n","               \n","                        [[42114.]],\n","               \n","                        [[41353.]],\n","               \n","                        [[10787.]],\n","               \n","                        [[23616.]],\n","               \n","                        [[  390.]],\n","               \n","                        [[25237.]]],\n","               \n","               \n","                       [[[51065.]],\n","               \n","                        [[17613.]],\n","               \n","                        [[28600.]],\n","               \n","                        [[    0.]],\n","               \n","                        [[20502.]],\n","               \n","                        [[60908.]],\n","               \n","                        [[48128.]],\n","               \n","                        [[29944.]],\n","               \n","                        [[65535.]],\n","               \n","                        [[40269.]],\n","               \n","                        [[29342.]],\n","               \n","                        [[24101.]],\n","               \n","                        [[34477.]],\n","               \n","                        [[30717.]],\n","               \n","                        [[46212.]],\n","               \n","                        [[28685.]]],\n","               \n","               \n","                       [[[38994.]],\n","               \n","                        [[32252.]],\n","               \n","                        [[26512.]],\n","               \n","                        [[40424.]],\n","               \n","                        [[58923.]],\n","               \n","                        [[10910.]],\n","               \n","                        [[22312.]],\n","               \n","                        [[32664.]],\n","               \n","                        [[46853.]],\n","               \n","                        [[65535.]],\n","               \n","                        [[32022.]],\n","               \n","                        [[    0.]],\n","               \n","                        [[30961.]],\n","               \n","                        [[35514.]],\n","               \n","                        [[27502.]],\n","               \n","                        [[23117.]]],\n","               \n","               \n","                       [[[18536.]],\n","               \n","                        [[19365.]],\n","               \n","                        [[19089.]],\n","               \n","                        [[24271.]],\n","               \n","                        [[16914.]],\n","               \n","                        [[ 1856.]],\n","               \n","                        [[31392.]],\n","               \n","                        [[30095.]],\n","               \n","                        [[65535.]],\n","               \n","                        [[32655.]],\n","               \n","                        [[32925.]],\n","               \n","                        [[ 5806.]],\n","               \n","                        [[18880.]],\n","               \n","                        [[21324.]],\n","               \n","                        [[    0.]],\n","               \n","                        [[12356.]]],\n","               \n","               \n","                       [[[34716.]],\n","               \n","                        [[29555.]],\n","               \n","                        [[22177.]],\n","               \n","                        [[31656.]],\n","               \n","                        [[49527.]],\n","               \n","                        [[26878.]],\n","               \n","                        [[22785.]],\n","               \n","                        [[15853.]],\n","               \n","                        [[25278.]],\n","               \n","                        [[ 9022.]],\n","               \n","                        [[ 9715.]],\n","               \n","                        [[54602.]],\n","               \n","                        [[    0.]],\n","               \n","                        [[30036.]],\n","               \n","                        [[35508.]],\n","               \n","                        [[65535.]]],\n","               \n","               \n","                       [[[    0.]],\n","               \n","                        [[33177.]],\n","               \n","                        [[45703.]],\n","               \n","                        [[41806.]],\n","               \n","                        [[20680.]],\n","               \n","                        [[65535.]],\n","               \n","                        [[23023.]],\n","               \n","                        [[28210.]],\n","               \n","                        [[12323.]],\n","               \n","                        [[48934.]],\n","               \n","                        [[27181.]],\n","               \n","                        [[25583.]],\n","               \n","                        [[49685.]],\n","               \n","                        [[ 1226.]],\n","               \n","                        [[37112.]],\n","               \n","                        [[25431.]]],\n","               \n","               \n","                       [[[65535.]],\n","               \n","                        [[ 9774.]],\n","               \n","                        [[40849.]],\n","               \n","                        [[ 3197.]],\n","               \n","                        [[42738.]],\n","               \n","                        [[10926.]],\n","               \n","                        [[35722.]],\n","               \n","                        [[    0.]],\n","               \n","                        [[22068.]],\n","               \n","                        [[40212.]],\n","               \n","                        [[51026.]],\n","               \n","                        [[12914.]],\n","               \n","                        [[30290.]],\n","               \n","                        [[56078.]],\n","               \n","                        [[35759.]],\n","               \n","                        [[51868.]]],\n","               \n","               \n","                       [[[14452.]],\n","               \n","                        [[41210.]],\n","               \n","                        [[63640.]],\n","               \n","                        [[46670.]],\n","               \n","                        [[38282.]],\n","               \n","                        [[20431.]],\n","               \n","                        [[43041.]],\n","               \n","                        [[24573.]],\n","               \n","                        [[22863.]],\n","               \n","                        [[28805.]],\n","               \n","                        [[49971.]],\n","               \n","                        [[44812.]],\n","               \n","                        [[51332.]],\n","               \n","                        [[65535.]],\n","               \n","                        [[    0.]],\n","               \n","                        [[34913.]]],\n","               \n","               \n","                       [[[17090.]],\n","               \n","                        [[56972.]],\n","               \n","                        [[50586.]],\n","               \n","                        [[ 5291.]],\n","               \n","                        [[47593.]],\n","               \n","                        [[44695.]],\n","               \n","                        [[65535.]],\n","               \n","                        [[50838.]],\n","               \n","                        [[25860.]],\n","               \n","                        [[13958.]],\n","               \n","                        [[19165.]],\n","               \n","                        [[47078.]],\n","               \n","                        [[46765.]],\n","               \n","                        [[19103.]],\n","               \n","                        [[23579.]],\n","               \n","                        [[    0.]]],\n","               \n","               \n","                       [[[   97.]],\n","               \n","                        [[48248.]],\n","               \n","                        [[35333.]],\n","               \n","                        [[32761.]],\n","               \n","                        [[ 8703.]],\n","               \n","                        [[ 5300.]],\n","               \n","                        [[18484.]],\n","               \n","                        [[47766.]],\n","               \n","                        [[29937.]],\n","               \n","                        [[22689.]],\n","               \n","                        [[65535.]],\n","               \n","                        [[34864.]],\n","               \n","                        [[34045.]],\n","               \n","                        [[38603.]],\n","               \n","                        [[    0.]],\n","               \n","                        [[31448.]]],\n","               \n","               \n","                       [[[27942.]],\n","               \n","                        [[12830.]],\n","               \n","                        [[65535.]],\n","               \n","                        [[23120.]],\n","               \n","                        [[18755.]],\n","               \n","                        [[25115.]],\n","               \n","                        [[25938.]],\n","               \n","                        [[    0.]],\n","               \n","                        [[21990.]],\n","               \n","                        [[35949.]],\n","               \n","                        [[30224.]],\n","               \n","                        [[23692.]],\n","               \n","                        [[26994.]],\n","               \n","                        [[63946.]],\n","               \n","                        [[28968.]],\n","               \n","                        [[40653.]]],\n","               \n","               \n","                       [[[20644.]],\n","               \n","                        [[    0.]],\n","               \n","                        [[11167.]],\n","               \n","                        [[30186.]],\n","               \n","                        [[28205.]],\n","               \n","                        [[35353.]],\n","               \n","                        [[30685.]],\n","               \n","                        [[65535.]],\n","               \n","                        [[27859.]],\n","               \n","                        [[26377.]],\n","               \n","                        [[11809.]],\n","               \n","                        [[36113.]],\n","               \n","                        [[24753.]],\n","               \n","                        [[ 1528.]],\n","               \n","                        [[20862.]],\n","               \n","                        [[25483.]]],\n","               \n","               \n","                       [[[55599.]],\n","               \n","                        [[49566.]],\n","               \n","                        [[51278.]],\n","               \n","                        [[54350.]],\n","               \n","                        [[26368.]],\n","               \n","                        [[65535.]],\n","               \n","                        [[45497.]],\n","               \n","                        [[28347.]],\n","               \n","                        [[    0.]],\n","               \n","                        [[53147.]],\n","               \n","                        [[23656.]],\n","               \n","                        [[31898.]],\n","               \n","                        [[39599.]],\n","               \n","                        [[35629.]],\n","               \n","                        [[57514.]],\n","               \n","                        [[44566.]]],\n","               \n","               \n","                       [[[28939.]],\n","               \n","                        [[22929.]],\n","               \n","                        [[26184.]],\n","               \n","                        [[60043.]],\n","               \n","                        [[10782.]],\n","               \n","                        [[13657.]],\n","               \n","                        [[19043.]],\n","               \n","                        [[ 5677.]],\n","               \n","                        [[    0.]],\n","               \n","                        [[43514.]],\n","               \n","                        [[ 9371.]],\n","               \n","                        [[13362.]],\n","               \n","                        [[31456.]],\n","               \n","                        [[18172.]],\n","               \n","                        [[57554.]],\n","               \n","                        [[65535.]]]], device='cuda:0')),\n","              ('module.layer2.0.downsample.0.wrapped_module.bias',\n","               tensor([ 7.3704e+08,  1.2639e+09, -1.8771e+08,  2.1475e+09,  4.7493e+08,\n","                       -7.1059e+07,  4.4732e+08, -3.2631e+08,  6.1478e+07, -4.7895e+08,\n","                       -2.9618e+07, -4.0005e+08,  6.0883e+08, -8.8137e+08,  1.8861e+09,\n","                        1.2054e+09,  1.1074e+09,  6.0707e+08, -9.8849e+08, -8.6518e+08,\n","                       -8.0578e+08, -4.4658e+08,  4.4908e+08,  1.7284e+09,  1.8945e+09,\n","                       -6.7852e+08, -2.1475e+09,  7.1204e+08, -1.8919e+08, -1.4237e+08,\n","                        8.0616e+08,  6.1686e+08], device='cuda:0')),\n","              ('module.layer2.0.residual_eltwiseadd.num_forwards',\n","               tensor([40], device='cuda:0')),\n","              ('module.layer2.0.residual_eltwiseadd.force_readjust',\n","               tensor(False, device='cuda:0')),\n","              ('module.layer2.0.residual_eltwiseadd.output_scale',\n","               tensor([9073.3604], device='cuda:0')),\n","              ('module.layer2.0.residual_eltwiseadd.output_zero_point',\n","               tensor([0.], device='cuda:0')),\n","              ('module.layer2.1.conv1.num_forwards',\n","               tensor([40], device='cuda:0')),\n","              ('module.layer2.1.conv1.force_readjust',\n","               tensor(False, device='cuda:0')),\n","              ('module.layer2.1.conv1.output_scale',\n","               tensor([37820.2461], device='cuda:0')),\n","              ('module.layer2.1.conv1.output_zero_point',\n","               tensor([0.], device='cuda:0')),\n","              ('module.layer2.1.conv1.w_scale', tensor([[[[3.8288e+05]]],\n","               \n","               \n","                       [[[6.1115e+05]]],\n","               \n","               \n","                       [[[4.7970e+05]]],\n","               \n","               \n","                       [[[6.8426e+05]]],\n","               \n","               \n","                       [[[8.1803e+05]]],\n","               \n","               \n","                       [[[5.8174e+05]]],\n","               \n","               \n","                       [[[5.1415e+05]]],\n","               \n","               \n","                       [[[6.1282e+05]]],\n","               \n","               \n","                       [[[5.2600e+05]]],\n","               \n","               \n","                       [[[4.9717e+05]]],\n","               \n","               \n","                       [[[5.1981e+05]]],\n","               \n","               \n","                       [[[9.9103e+05]]],\n","               \n","               \n","                       [[[4.7060e+05]]],\n","               \n","               \n","                       [[[4.5040e+05]]],\n","               \n","               \n","                       [[[6.3288e+05]]],\n","               \n","               \n","                       [[[6.4200e+05]]],\n","               \n","               \n","                       [[[8.3107e+08]]],\n","               \n","               \n","                       [[[4.8726e+05]]],\n","               \n","               \n","                       [[[3.4304e+05]]],\n","               \n","               \n","                       [[[4.8896e+05]]],\n","               \n","               \n","                       [[[6.9664e+05]]],\n","               \n","               \n","                       [[[7.1685e+05]]],\n","               \n","               \n","                       [[[4.2106e+05]]],\n","               \n","               \n","                       [[[5.6003e+05]]],\n","               \n","               \n","                       [[[6.5418e+05]]],\n","               \n","               \n","                       [[[2.6040e+08]]],\n","               \n","               \n","                       [[[4.5368e+05]]],\n","               \n","               \n","                       [[[5.6658e+05]]],\n","               \n","               \n","                       [[[5.0068e+05]]],\n","               \n","               \n","                       [[[7.1232e+05]]],\n","               \n","               \n","                       [[[6.4255e+05]]],\n","               \n","               \n","                       [[[5.2492e+05]]]], device='cuda:0')),\n","              ('module.layer2.1.conv1.w_zero_point', tensor([[[[-33468.]]],\n","               \n","               \n","                       [[[-29189.]]],\n","               \n","               \n","                       [[[-34432.]]],\n","               \n","               \n","                       [[[-36094.]]],\n","               \n","               \n","                       [[[-33273.]]],\n","               \n","               \n","                       [[[-28352.]]],\n","               \n","               \n","                       [[[-25896.]]],\n","               \n","               \n","                       [[[-27650.]]],\n","               \n","               \n","                       [[[-30667.]]],\n","               \n","               \n","                       [[[-35574.]]],\n","               \n","               \n","                       [[[-25903.]]],\n","               \n","               \n","                       [[[-35569.]]],\n","               \n","               \n","                       [[[-27425.]]],\n","               \n","               \n","                       [[[-26520.]]],\n","               \n","               \n","                       [[[-34873.]]],\n","               \n","               \n","                       [[[-34445.]]],\n","               \n","               \n","                       [[[-44629.]]],\n","               \n","               \n","                       [[[-36432.]]],\n","               \n","               \n","                       [[[-36270.]]],\n","               \n","               \n","                       [[[-33076.]]],\n","               \n","               \n","                       [[[-31845.]]],\n","               \n","               \n","                       [[[-31029.]]],\n","               \n","               \n","                       [[[-19227.]]],\n","               \n","               \n","                       [[[-27535.]]],\n","               \n","               \n","                       [[[-34019.]]],\n","               \n","               \n","                       [[[-32061.]]],\n","               \n","               \n","                       [[[-35202.]]],\n","               \n","               \n","                       [[[-26409.]]],\n","               \n","               \n","                       [[[-30637.]]],\n","               \n","               \n","                       [[[-32588.]]],\n","               \n","               \n","                       [[[-35520.]]],\n","               \n","               \n","                       [[[-30964.]]]], device='cuda:0')),\n","              ('module.layer2.1.conv1.fp_bias',\n","               tensor([-2.1931e-01, -2.0550e-01, -2.2256e-02,  1.7712e-01,  4.7397e-01,\n","                       -3.8010e-01, -1.0607e-01, -5.8006e-01,  1.8404e-01,  9.7214e-02,\n","                       -4.3790e-01,  3.8751e-01, -4.2128e-01,  4.4122e-02, -2.4897e-01,\n","                        1.4562e-01, -1.8723e-04,  4.4838e-01,  1.0151e-01, -5.3239e-02,\n","                       -6.3444e-03,  3.4689e-01, -5.9315e-01, -1.0803e-01, -2.2685e-03,\n","                        4.8800e-02,  8.5850e-02, -4.0829e-01, -1.1963e-01, -1.3571e-03,\n","                        1.4721e-01,  2.9835e-01], device='cuda:0')),\n","              ('module.layer2.1.conv1.accum_scale', tensor([[[3.4740e+09]],\n","               \n","                       [[5.5452e+09]],\n","               \n","                       [[4.3525e+09]],\n","               \n","                       [[6.2085e+09]],\n","               \n","                       [[7.4223e+09]],\n","               \n","                       [[5.2783e+09]],\n","               \n","                       [[4.6651e+09]],\n","               \n","                       [[5.5603e+09]],\n","               \n","                       [[4.7726e+09]],\n","               \n","                       [[4.5110e+09]],\n","               \n","                       [[4.7164e+09]],\n","               \n","                       [[8.9920e+09]],\n","               \n","                       [[4.2699e+09]],\n","               \n","                       [[4.0866e+09]],\n","               \n","                       [[5.7424e+09]],\n","               \n","                       [[5.8251e+09]],\n","               \n","                       [[7.5406e+12]],\n","               \n","                       [[4.4211e+09]],\n","               \n","                       [[3.1125e+09]],\n","               \n","                       [[4.4365e+09]],\n","               \n","                       [[6.3209e+09]],\n","               \n","                       [[6.5042e+09]],\n","               \n","                       [[3.8204e+09]],\n","               \n","                       [[5.0814e+09]],\n","               \n","                       [[5.9356e+09]],\n","               \n","                       [[2.3627e+12]],\n","               \n","                       [[4.1164e+09]],\n","               \n","                       [[5.1408e+09]],\n","               \n","                       [[4.5428e+09]],\n","               \n","                       [[6.4631e+09]],\n","               \n","                       [[5.8301e+09]],\n","               \n","                       [[4.7628e+09]]], device='cuda:0')),\n","              ('module.layer2.1.conv1.is_simulated_quant_weight_shifted',\n","               tensor(False, device='cuda:0')),\n","              ('module.layer2.1.conv1.wrapped_module.weight',\n","               tensor([[[[2.5584e+04, 1.5947e+04, 2.3416e+04],\n","                         [3.2212e+04, 2.3717e+04, 2.4140e+04],\n","                         [3.5840e+04, 4.1395e+04, 3.1851e+04]],\n","               \n","                        [[4.2993e+04, 4.3838e+04, 4.1011e+04],\n","                         [3.5749e+04, 2.9071e+04, 4.5888e+04],\n","                         [3.2257e+04, 3.7330e+04, 3.7968e+04]],\n","               \n","                        [[2.1161e+04, 2.7825e+04, 3.3787e+04],\n","                         [3.1743e+04, 3.4859e+04, 3.8800e+04],\n","                         [3.5322e+04, 4.7926e+04, 4.2889e+04]],\n","               \n","                        ...,\n","               \n","                        [[4.0812e+04, 2.7967e+04, 3.5144e+04],\n","                         [5.4349e+04, 1.1085e+04, 3.2260e+04],\n","                         [4.9815e+04, 2.5007e+04, 5.0619e+04]],\n","               \n","                        [[1.2321e+04, 3.2614e+04, 2.2245e+04],\n","                         [2.6028e+04, 1.8533e+04, 3.3354e+04],\n","                         [4.7822e+04, 2.3246e+04, 4.7064e+04]],\n","               \n","                        [[2.5652e+04, 3.7302e+04, 3.7247e+04],\n","                         [2.9012e+04, 3.1977e+04, 3.3047e+04],\n","                         [3.9848e+04, 3.3773e+04, 3.3632e+04]]],\n","               \n","               \n","                       [[[3.0392e+04, 3.1705e+04, 2.1191e+04],\n","                         [3.0200e+04, 4.5790e+04, 2.0816e+04],\n","                         [2.8788e+04, 3.7807e+04, 3.4710e+03]],\n","               \n","                        [[3.5760e+04, 2.1615e+04, 2.9797e+04],\n","                         [4.2517e+04, 2.9800e+04, 1.1913e+04],\n","                         [4.0392e+04, 4.9804e+04, 1.4397e+04]],\n","               \n","                        [[2.8247e+04, 3.5960e+04, 4.5955e+04],\n","                         [3.6034e+04, 3.1427e+04, 3.3260e+04],\n","                         [2.7392e+04, 3.2766e+04, 4.4182e+04]],\n","               \n","                        ...,\n","               \n","                        [[2.7393e+04, 2.3535e+04, 1.9438e+04],\n","                         [2.3707e+04, 3.0546e+04, 3.4272e+04],\n","                         [3.5061e+04, 4.4196e+04, 1.6850e+04]],\n","               \n","                        [[2.5866e+04, 1.9266e+04, 2.3532e+04],\n","                         [1.7579e+04, 1.3775e+04, 6.4729e+04],\n","                         [4.0530e+03, 1.4942e+04, 4.7990e+04]],\n","               \n","                        [[3.0577e+04, 3.8515e+04, 3.6570e+04],\n","                         [3.5619e+04, 4.2521e+04, 4.6588e+04],\n","                         [3.2260e+04, 3.5970e+04, 4.0432e+04]]],\n","               \n","               \n","                       [[[3.5952e+04, 4.3884e+04, 4.5784e+04],\n","                         [3.8852e+04, 4.2066e+04, 4.7632e+04],\n","                         [3.9678e+04, 2.9740e+04, 4.9865e+04]],\n","               \n","                        [[3.0117e+04, 2.6225e+04, 2.8806e+04],\n","                         [3.9282e+04, 3.5722e+04, 4.4350e+04],\n","                         [3.8349e+04, 3.8371e+04, 3.4435e+04]],\n","               \n","                        [[4.3510e+04, 3.1997e+04, 2.7689e+04],\n","                         [4.1052e+04, 3.4224e+04, 3.1058e+04],\n","                         [3.0520e+04, 3.1032e+04, 2.7462e+04]],\n","               \n","                        ...,\n","               \n","                        [[2.2078e+04, 2.8676e+04, 1.5492e+04],\n","                         [3.1777e+04, 2.6152e+04, 1.5351e+04],\n","                         [4.0228e+04, 3.4612e+04, 3.3042e+04]],\n","               \n","                        [[2.6105e+04, 2.3176e+04, 2.1464e+04],\n","                         [4.0577e+04, 2.9021e+04, 2.5329e+04],\n","                         [5.3452e+04, 3.6697e+04, 3.7078e+04]],\n","               \n","                        [[2.6256e+04, 3.1390e+04, 4.0344e+04],\n","                         [2.8460e+04, 3.3263e+04, 3.6215e+04],\n","                         [2.6758e+04, 3.3394e+04, 3.6513e+04]]],\n","               \n","               \n","                       ...,\n","               \n","               \n","                       [[[6.4227e+04, 2.4355e+04, 8.9850e+03],\n","                         [5.5584e+04, 2.1268e+04, 1.3752e+04],\n","                         [3.1378e+04, 4.4908e+04, 2.0088e+04]],\n","               \n","                        [[3.3023e+04, 4.7569e+04, 3.5674e+04],\n","                         [3.1047e+04, 4.5046e+04, 3.3626e+04],\n","                         [2.7942e+04, 3.4136e+04, 1.8263e+04]],\n","               \n","                        [[4.2208e+04, 4.9099e+04, 3.9240e+04],\n","                         [5.0431e+04, 4.0780e+04, 3.4090e+04],\n","                         [2.5732e+04, 2.9828e+04, 2.9737e+04]],\n","               \n","                        ...,\n","               \n","                        [[3.7057e+04, 3.8955e+04, 2.4760e+04],\n","                         [1.9954e+04, 2.4793e+04, 2.0080e+04],\n","                         [3.3099e+04, 4.7918e+04, 5.1890e+04]],\n","               \n","                        [[2.8659e+04, 4.6666e+04, 3.3874e+04],\n","                         [2.4885e+04, 4.1727e+04, 3.0546e+04],\n","                         [2.2000e+01, 1.6664e+04, 3.0993e+04]],\n","               \n","                        [[3.8239e+04, 2.8250e+04, 1.8906e+04],\n","                         [3.7263e+04, 2.9718e+04, 2.9757e+04],\n","                         [4.0591e+04, 3.9315e+04, 3.8357e+04]]],\n","               \n","               \n","                       [[[5.0083e+04, 3.3698e+04, 3.5482e+04],\n","                         [4.9210e+04, 1.3087e+04, 3.5533e+04],\n","                         [3.9213e+04, 1.1075e+04, 2.6171e+04]],\n","               \n","                        [[2.2399e+04, 2.2256e+04, 3.0803e+04],\n","                         [2.8451e+04, 3.2860e+04, 3.4018e+04],\n","                         [3.6725e+04, 4.1272e+04, 3.2792e+04]],\n","               \n","                        [[3.7521e+04, 3.4050e+04, 3.6269e+04],\n","                         [3.0116e+04, 2.7261e+04, 2.2164e+04],\n","                         [3.5299e+04, 3.1618e+04, 2.8422e+04]],\n","               \n","                        ...,\n","               \n","                        [[5.6250e+04, 6.2817e+04, 1.3255e+04],\n","                         [5.6770e+04, 4.3617e+04, 0.0000e+00],\n","                         [5.0992e+04, 3.7721e+04, 1.2560e+03]],\n","               \n","                        [[1.0420e+04, 4.7982e+04, 5.0862e+04],\n","                         [4.1080e+03, 4.3523e+04, 5.3406e+04],\n","                         [1.5625e+04, 4.2362e+04, 3.0039e+04]],\n","               \n","                        [[1.9728e+04, 2.4801e+04, 3.5491e+04],\n","                         [2.0627e+04, 3.2795e+04, 4.3404e+04],\n","                         [2.4518e+04, 3.1237e+04, 4.4981e+04]]],\n","               \n","               \n","                       [[[3.1437e+04, 3.6658e+04, 2.3044e+04],\n","                         [1.8175e+04, 2.7298e+04, 2.5680e+04],\n","                         [3.1447e+04, 2.7625e+04, 3.7041e+04]],\n","               \n","                        [[3.0568e+04, 4.2010e+04, 2.6630e+04],\n","                         [3.2697e+04, 4.5777e+04, 2.8375e+04],\n","                         [3.9223e+04, 3.1339e+04, 2.0449e+04]],\n","               \n","                        [[4.0168e+04, 3.3470e+04, 2.6994e+04],\n","                         [3.9694e+04, 3.8873e+04, 3.9572e+04],\n","                         [4.3614e+04, 4.3883e+04, 3.6940e+04]],\n","               \n","                        ...,\n","               \n","                        [[3.7900e+03, 2.9359e+04, 2.9433e+04],\n","                         [5.6692e+04, 5.5079e+04, 2.8840e+04],\n","                         [2.8964e+04, 2.2069e+04, 1.2204e+04]],\n","               \n","                        [[6.5535e+04, 3.7838e+04, 1.6854e+04],\n","                         [3.9850e+04, 8.4700e+03, 3.1404e+04],\n","                         [1.0865e+04, 2.6946e+04, 4.4545e+04]],\n","               \n","                        [[3.2377e+04, 2.7523e+04, 3.6025e+04],\n","                         [3.2821e+04, 2.6592e+04, 2.5936e+04],\n","                         [3.3180e+04, 2.7416e+04, 2.6812e+04]]]], device='cuda:0')),\n","              ('module.layer2.1.conv1.wrapped_module.bias',\n","               tensor([-7.6189e+08, -1.1395e+09, -9.6868e+07,  1.0996e+09,  2.1475e+09,\n","                       -2.0063e+09, -4.9481e+08, -2.1475e+09,  8.7835e+08,  4.3853e+08,\n","                       -2.0653e+09,  2.1475e+09, -1.7988e+09,  1.8031e+08, -1.4297e+09,\n","                        8.4823e+08, -1.4118e+09,  1.9823e+09,  3.1594e+08, -2.3619e+08,\n","                       -4.0102e+07,  2.1475e+09, -2.1475e+09, -5.4896e+08, -1.3465e+07,\n","                        2.1475e+09,  3.5339e+08, -2.0990e+09, -5.4346e+08, -8.7711e+06,\n","                        8.5826e+08,  1.4210e+09], device='cuda:0')),\n","              ('module.layer2.1.conv2.num_forwards',\n","               tensor([40], device='cuda:0')),\n","              ('module.layer2.1.conv2.force_readjust',\n","               tensor(False, device='cuda:0')),\n","              ('module.layer2.1.conv2.output_scale',\n","               tensor([12305.1230], device='cuda:0')),\n","              ('module.layer2.1.conv2.output_zero_point',\n","               tensor([-27116.], device='cuda:0')),\n","              ('module.layer2.1.conv2.w_scale', tensor([[[[315358.5000]]],\n","               \n","               \n","                       [[[195039.1875]]],\n","               \n","               \n","                       [[[126528.4922]]],\n","               \n","               \n","                       [[[105838.9297]]],\n","               \n","               \n","                       [[[ 69826.4297]]],\n","               \n","               \n","                       [[[116030.6875]]],\n","               \n","               \n","                       [[[127201.5547]]],\n","               \n","               \n","                       [[[ 97550.5938]]],\n","               \n","               \n","                       [[[167435.3125]]],\n","               \n","               \n","                       [[[121136.8828]]],\n","               \n","               \n","                       [[[145897.0938]]],\n","               \n","               \n","                       [[[140008.2812]]],\n","               \n","               \n","                       [[[145732.0625]]],\n","               \n","               \n","                       [[[163056.8125]]],\n","               \n","               \n","                       [[[717158.0000]]],\n","               \n","               \n","                       [[[132533.9375]]],\n","               \n","               \n","                       [[[ 72534.9297]]],\n","               \n","               \n","                       [[[151234.5000]]],\n","               \n","               \n","                       [[[132633.7656]]],\n","               \n","               \n","                       [[[143493.2812]]],\n","               \n","               \n","                       [[[232675.4688]]],\n","               \n","               \n","                       [[[ 91218.8750]]],\n","               \n","               \n","                       [[[312450.2188]]],\n","               \n","               \n","                       [[[ 97403.2500]]],\n","               \n","               \n","                       [[[ 83759.9766]]],\n","               \n","               \n","                       [[[ 51485.1797]]],\n","               \n","               \n","                       [[[ 46050.3672]]],\n","               \n","               \n","                       [[[189352.2812]]],\n","               \n","               \n","                       [[[161081.2031]]],\n","               \n","               \n","                       [[[235486.9844]]],\n","               \n","               \n","                       [[[275191.9688]]],\n","               \n","               \n","                       [[[ 74087.5859]]]], device='cuda:0')),\n","              ('module.layer2.1.conv2.w_zero_point', tensor([[[[-34298.]]],\n","               \n","               \n","                       [[[-34531.]]],\n","               \n","               \n","                       [[[-35533.]]],\n","               \n","               \n","                       [[[-26925.]]],\n","               \n","               \n","                       [[[-28891.]]],\n","               \n","               \n","                       [[[-31919.]]],\n","               \n","               \n","                       [[[-33379.]]],\n","               \n","               \n","                       [[[-27638.]]],\n","               \n","               \n","                       [[[-25542.]]],\n","               \n","               \n","                       [[[-25767.]]],\n","               \n","               \n","                       [[[-24696.]]],\n","               \n","               \n","                       [[[-33206.]]],\n","               \n","               \n","                       [[[-28224.]]],\n","               \n","               \n","                       [[[-25436.]]],\n","               \n","               \n","                       [[[-35031.]]],\n","               \n","               \n","                       [[[-32671.]]],\n","               \n","               \n","                       [[[-29731.]]],\n","               \n","               \n","                       [[[-36947.]]],\n","               \n","               \n","                       [[[-28830.]]],\n","               \n","               \n","                       [[[-27941.]]],\n","               \n","               \n","                       [[[-38674.]]],\n","               \n","               \n","                       [[[-34283.]]],\n","               \n","               \n","                       [[[-33584.]]],\n","               \n","               \n","                       [[[-36558.]]],\n","               \n","               \n","                       [[[-30023.]]],\n","               \n","               \n","                       [[[-26941.]]],\n","               \n","               \n","                       [[[-17323.]]],\n","               \n","               \n","                       [[[-31653.]]],\n","               \n","               \n","                       [[[-30786.]]],\n","               \n","               \n","                       [[[-27993.]]],\n","               \n","               \n","                       [[[-25506.]]],\n","               \n","               \n","                       [[[-43374.]]]], device='cuda:0')),\n","              ('module.layer2.1.conv2.fp_bias',\n","               tensor([ 0.1025,  0.1116,  0.0929,  0.1198,  0.0331,  0.0311,  0.3401,  0.1181,\n","                        0.0257,  0.3083, -0.1069,  0.2421,  0.1245, -0.1597, -0.0274, -0.1385,\n","                        0.5887,  0.5765, -0.2252, -0.1257,  0.0885, -0.1065, -0.0372,  0.7598,\n","                        0.3979, -0.8329, -0.5819, -0.1349,  0.0667, -0.0505, -0.0893,  0.3531],\n","                      device='cuda:0')),\n","              ('module.layer2.1.conv2.accum_scale', tensor([[[1.1927e+10]],\n","               \n","                       [[7.3764e+09]],\n","               \n","                       [[4.7853e+09]],\n","               \n","                       [[4.0029e+09]],\n","               \n","                       [[2.6409e+09]],\n","               \n","                       [[4.3883e+09]],\n","               \n","                       [[4.8108e+09]],\n","               \n","                       [[3.6894e+09]],\n","               \n","                       [[6.3324e+09]],\n","               \n","                       [[4.5814e+09]],\n","               \n","                       [[5.5179e+09]],\n","               \n","                       [[5.2951e+09]],\n","               \n","                       [[5.5116e+09]],\n","               \n","                       [[6.1668e+09]],\n","               \n","                       [[2.7123e+10]],\n","               \n","                       [[5.0125e+09]],\n","               \n","                       [[2.7433e+09]],\n","               \n","                       [[5.7197e+09]],\n","               \n","                       [[5.0162e+09]],\n","               \n","                       [[5.4270e+09]],\n","               \n","                       [[8.7998e+09]],\n","               \n","                       [[3.4499e+09]],\n","               \n","                       [[1.1817e+10]],\n","               \n","                       [[3.6838e+09]],\n","               \n","                       [[3.1678e+09]],\n","               \n","                       [[1.9472e+09]],\n","               \n","                       [[1.7416e+09]],\n","               \n","                       [[7.1613e+09]],\n","               \n","                       [[6.0921e+09]],\n","               \n","                       [[8.9062e+09]],\n","               \n","                       [[1.0408e+10]],\n","               \n","                       [[2.8020e+09]]], device='cuda:0')),\n","              ('module.layer2.1.conv2.is_simulated_quant_weight_shifted',\n","               tensor(False, device='cuda:0')),\n","              ('module.layer2.1.conv2.wrapped_module.weight',\n","               tensor([[[[59337., 49936., 33286.],\n","                         [33921., 41579., 34603.],\n","                         [18256., 19589., 24053.]],\n","               \n","                        [[23255., 40864., 54771.],\n","                         [29799., 28563., 52787.],\n","                         [43334., 28109., 49041.]],\n","               \n","                        [[31184., 43915., 34705.],\n","                         [23063., 44758., 37595.],\n","                         [26476., 31788., 28300.]],\n","               \n","                        ...,\n","               \n","                        [[    0., 39828., 49364.],\n","                         [15895., 42511., 44901.],\n","                         [22335., 43865., 46172.]],\n","               \n","                        [[28522., 25274.,  5671.],\n","                         [44063., 30985., 19924.],\n","                         [52376., 36590., 31564.]],\n","               \n","                        [[25285., 31487., 38261.],\n","                         [35580., 31571., 29309.],\n","                         [36062., 41137., 41140.]]],\n","               \n","               \n","                       [[[34991., 31464., 39786.],\n","                         [26387., 28827., 30494.],\n","                         [24163., 27782., 22353.]],\n","               \n","                        [[38596., 36625., 47149.],\n","                         [36072., 27769., 42788.],\n","                         [41099., 29682., 26316.]],\n","               \n","                        [[41565., 37420., 31595.],\n","                         [38647., 39002., 32488.],\n","                         [29442., 29551., 28519.]],\n","               \n","                        ...,\n","               \n","                        [[42372., 28562., 26022.],\n","                         [35486., 28882., 30086.],\n","                         [33585., 31402., 33635.]],\n","               \n","                        [[35520., 32834., 23773.],\n","                         [40206., 37354., 31302.],\n","                         [40513., 41407., 38448.]],\n","               \n","                        [[12258., 27266., 32175.],\n","                         [25926., 30576., 29349.],\n","                         [28246., 27703., 33748.]]],\n","               \n","               \n","                       [[[38823., 26091., 26231.],\n","                         [28507., 20937., 30590.],\n","                         [40290., 29214., 37743.]],\n","               \n","                        [[49117., 38012., 25095.],\n","                         [26538., 38576., 41293.],\n","                         [ 9347., 23725., 32206.]],\n","               \n","                        [[30250., 32777., 31000.],\n","                         [31788., 43393., 18156.],\n","                         [33583., 22932., 15377.]],\n","               \n","                        ...,\n","               \n","                        [[19051., 38378., 31770.],\n","                         [32917., 42844., 53806.],\n","                         [39507., 41752., 38787.]],\n","               \n","                        [[26197., 20114., 18734.],\n","                         [32846., 35000., 45146.],\n","                         [55914., 56799., 51948.]],\n","               \n","                        [[41866., 29352., 23873.],\n","                         [36119., 27654., 26831.],\n","                         [36788., 44405., 51760.]]],\n","               \n","               \n","                       ...,\n","               \n","               \n","                       [[[33745., 27518., 25826.],\n","                         [21755., 13706., 10025.],\n","                         [31896., 25557., 28167.]],\n","               \n","                        [[34279., 25511., 15721.],\n","                         [23261., 20008., 21491.],\n","                         [16326., 25689., 30627.]],\n","               \n","                        [[18687., 19453., 30513.],\n","                         [27223., 25759., 32724.],\n","                         [25852., 22219., 19532.]],\n","               \n","                        ...,\n","               \n","                        [[23633., 28045., 37938.],\n","                         [26401., 31623., 37191.],\n","                         [29372., 28783., 25488.]],\n","               \n","                        [[25379., 37812., 41925.],\n","                         [36798., 62194., 54576.],\n","                         [24413., 56938., 37257.]],\n","               \n","                        [[32647., 32839., 39003.],\n","                         [27322., 51968., 65535.],\n","                         [25887., 45205., 31663.]]],\n","               \n","               \n","                       [[[ 5297., 52155., 12808.],\n","                         [15653., 41425., 27014.],\n","                         [34738., 43174., 39530.]],\n","               \n","                        [[65535., 37182., 23468.],\n","                         [60603., 44132., 17471.],\n","                         [34136., 39107., 14133.]],\n","               \n","                        [[32359., 25455., 30954.],\n","                         [25621., 16721., 17419.],\n","                         [16750.,  8224., 18993.]],\n","               \n","                        ...,\n","               \n","                        [[ 3016.,  3080., 15668.],\n","                         [31396., 44215., 32332.],\n","                         [47046., 59751., 34933.]],\n","               \n","                        [[12212., 20281., 28277.],\n","                         [34978., 35039., 24627.],\n","                         [37280., 27103.,  9932.]],\n","               \n","                        [[32779., 14270., 21748.],\n","                         [31998., 32046., 42675.],\n","                         [32026., 35116., 43452.]]],\n","               \n","               \n","                       [[[49120., 44732., 62095.],\n","                         [55041., 45181., 51792.],\n","                         [45706., 43002., 36200.]],\n","               \n","                        [[44951., 43789., 57367.],\n","                         [41507., 50671., 48476.],\n","                         [51611., 45043., 43140.]],\n","               \n","                        [[48164., 36545., 46592.],\n","                         [50416., 34431., 47502.],\n","                         [54838., 42925., 42803.]],\n","               \n","                        ...,\n","               \n","                        [[36005., 24969., 19468.],\n","                         [42461., 36257., 30988.],\n","                         [43058., 49066., 59024.]],\n","               \n","                        [[33846., 44153., 45553.],\n","                         [29844., 28007., 36284.],\n","                         [39950., 31352., 34542.]],\n","               \n","                        [[54714., 52608., 39509.],\n","                         [63557., 41789., 36066.],\n","                         [56327., 54555., 62536.]]]], device='cuda:0')),\n","              ('module.layer2.1.conv2.wrapped_module.bias',\n","               tensor([ 1.2228e+09,  8.2299e+08,  4.4433e+08,  4.7947e+08,  8.7508e+07,\n","                        1.3637e+08,  1.6361e+09,  4.3560e+08,  1.6247e+08,  1.4125e+09,\n","                       -5.8975e+08,  1.2822e+09,  6.8602e+08, -9.8460e+08, -7.4365e+08,\n","                       -6.9398e+08,  1.6150e+09,  2.1475e+09, -1.1297e+09, -6.8228e+08,\n","                        7.7909e+08, -3.6759e+08, -4.3991e+08,  2.1475e+09,  1.2603e+09,\n","                       -1.6217e+09, -1.0135e+09, -9.6611e+08,  4.0607e+08, -4.4975e+08,\n","                       -9.2986e+08,  9.8944e+08], device='cuda:0')),\n","              ('module.layer2.1.relu2.num_forwards',\n","               tensor([40], device='cuda:0')),\n","              ('module.layer2.1.relu2.force_readjust',\n","               tensor(False, device='cuda:0')),\n","              ('module.layer2.1.relu2.output_scale',\n","               tensor([8703.7500], device='cuda:0')),\n","              ('module.layer2.1.relu2.output_zero_point',\n","               tensor([0.], device='cuda:0')),\n","              ('module.layer2.1.residual_eltwiseadd.num_forwards',\n","               tensor([40], device='cuda:0')),\n","              ('module.layer2.1.residual_eltwiseadd.force_readjust',\n","               tensor(False, device='cuda:0')),\n","              ('module.layer2.1.residual_eltwiseadd.output_scale',\n","               tensor([8703.7500], device='cuda:0')),\n","              ('module.layer2.1.residual_eltwiseadd.output_zero_point',\n","               tensor([0.], device='cuda:0')),\n","              ('module.layer2.2.conv1.num_forwards',\n","               tensor([40], device='cuda:0')),\n","              ('module.layer2.2.conv1.force_readjust',\n","               tensor(False, device='cuda:0')),\n","              ('module.layer2.2.conv1.output_scale',\n","               tensor([38350.1602], device='cuda:0')),\n","              ('module.layer2.2.conv1.output_zero_point',\n","               tensor([0.], device='cuda:0')),\n","              ('module.layer2.2.conv1.w_scale', tensor([[[[8.3120e+05]]],\n","               \n","               \n","                       [[[4.1215e+05]]],\n","               \n","               \n","                       [[[4.7435e+05]]],\n","               \n","               \n","                       [[[4.9925e+05]]],\n","               \n","               \n","                       [[[5.4731e+05]]],\n","               \n","               \n","                       [[[5.8208e+05]]],\n","               \n","               \n","                       [[[7.1896e+05]]],\n","               \n","               \n","                       [[[5.4234e+05]]],\n","               \n","               \n","                       [[[6.6747e+05]]],\n","               \n","               \n","                       [[[5.1406e+05]]],\n","               \n","               \n","                       [[[7.3787e+05]]],\n","               \n","               \n","                       [[[8.3853e+05]]],\n","               \n","               \n","                       [[[8.3956e+05]]],\n","               \n","               \n","                       [[[7.6087e+05]]],\n","               \n","               \n","                       [[[7.9197e+05]]],\n","               \n","               \n","                       [[[8.1055e+05]]],\n","               \n","               \n","                       [[[6.7328e+05]]],\n","               \n","               \n","                       [[[6.0001e+05]]],\n","               \n","               \n","                       [[[5.5256e+05]]],\n","               \n","               \n","                       [[[7.4920e+05]]],\n","               \n","               \n","                       [[[5.3863e+05]]],\n","               \n","               \n","                       [[[8.2217e+05]]],\n","               \n","               \n","                       [[[4.2197e+09]]],\n","               \n","               \n","                       [[[3.7121e+05]]],\n","               \n","               \n","                       [[[5.0683e+05]]],\n","               \n","               \n","                       [[[4.9569e+05]]],\n","               \n","               \n","                       [[[6.2032e+05]]],\n","               \n","               \n","                       [[[5.6608e+05]]],\n","               \n","               \n","                       [[[5.7284e+05]]],\n","               \n","               \n","                       [[[5.2126e+05]]],\n","               \n","               \n","                       [[[3.6258e+05]]],\n","               \n","               \n","                       [[[7.4607e+05]]]], device='cuda:0')),\n","              ('module.layer2.2.conv1.w_zero_point', tensor([[[[-30774.]]],\n","               \n","               \n","                       [[[-32165.]]],\n","               \n","               \n","                       [[[-36129.]]],\n","               \n","               \n","                       [[[-26665.]]],\n","               \n","               \n","                       [[[-27803.]]],\n","               \n","               \n","                       [[[-32341.]]],\n","               \n","               \n","                       [[[-26859.]]],\n","               \n","               \n","                       [[[-29896.]]],\n","               \n","               \n","                       [[[-28271.]]],\n","               \n","               \n","                       [[[-35211.]]],\n","               \n","               \n","                       [[[-34618.]]],\n","               \n","               \n","                       [[[-29587.]]],\n","               \n","               \n","                       [[[-30422.]]],\n","               \n","               \n","                       [[[-34819.]]],\n","               \n","               \n","                       [[[-25895.]]],\n","               \n","               \n","                       [[[-35217.]]],\n","               \n","               \n","                       [[[-33067.]]],\n","               \n","               \n","                       [[[-26020.]]],\n","               \n","               \n","                       [[[-31378.]]],\n","               \n","               \n","                       [[[-37652.]]],\n","               \n","               \n","                       [[[-37529.]]],\n","               \n","               \n","                       [[[-35976.]]],\n","               \n","               \n","                       [[[-41390.]]],\n","               \n","               \n","                       [[[-25209.]]],\n","               \n","               \n","                       [[[-31488.]]],\n","               \n","               \n","                       [[[-38082.]]],\n","               \n","               \n","                       [[[-24572.]]],\n","               \n","               \n","                       [[[-35994.]]],\n","               \n","               \n","                       [[[-31290.]]],\n","               \n","               \n","                       [[[-32822.]]],\n","               \n","               \n","                       [[[-31749.]]],\n","               \n","               \n","                       [[[-27078.]]]], device='cuda:0')),\n","              ('module.layer2.2.conv1.fp_bias',\n","               tensor([-2.7832e-01,  3.8585e-01, -1.0921e-01, -1.9813e-01, -4.2277e-01,\n","                       -8.0176e-03,  9.0581e-03,  4.3854e-01, -6.7399e-01, -4.3058e-01,\n","                        4.0510e-02,  3.9719e-02,  3.6750e-01,  3.4565e-01, -7.3133e-01,\n","                        4.6225e-01,  2.2204e-01, -3.3405e-01, -1.2159e-01,  3.4466e-01,\n","                        4.1493e-01,  2.2558e-01,  3.9455e-05,  2.2025e-01, -3.0964e-01,\n","                        1.5385e-01,  1.8425e-01, -1.9759e-01, -2.5155e-01, -3.0609e-01,\n","                       -1.4558e-01, -1.9583e-01], device='cuda:0')),\n","              ('module.layer2.2.conv1.accum_scale', tensor([[[7.2346e+09]],\n","               \n","                       [[3.5873e+09]],\n","               \n","                       [[4.1286e+09]],\n","               \n","                       [[4.3453e+09]],\n","               \n","                       [[4.7637e+09]],\n","               \n","                       [[5.0663e+09]],\n","               \n","                       [[6.2577e+09]],\n","               \n","                       [[4.7204e+09]],\n","               \n","                       [[5.8095e+09]],\n","               \n","                       [[4.4742e+09]],\n","               \n","                       [[6.4222e+09]],\n","               \n","                       [[7.2983e+09]],\n","               \n","                       [[7.3073e+09]],\n","               \n","                       [[6.6224e+09]],\n","               \n","                       [[6.8931e+09]],\n","               \n","                       [[7.0548e+09]],\n","               \n","                       [[5.8601e+09]],\n","               \n","                       [[5.2223e+09]],\n","               \n","                       [[4.8093e+09]],\n","               \n","                       [[6.5208e+09]],\n","               \n","                       [[4.6881e+09]],\n","               \n","                       [[7.1560e+09]],\n","               \n","                       [[3.6728e+13]],\n","               \n","                       [[3.2309e+09]],\n","               \n","                       [[4.4113e+09]],\n","               \n","                       [[4.3144e+09]],\n","               \n","                       [[5.3991e+09]],\n","               \n","                       [[4.9270e+09]],\n","               \n","                       [[4.9858e+09]],\n","               \n","                       [[4.5369e+09]],\n","               \n","                       [[3.1558e+09]],\n","               \n","                       [[6.4936e+09]]], device='cuda:0')),\n","              ('module.layer2.2.conv1.is_simulated_quant_weight_shifted',\n","               tensor(False, device='cuda:0')),\n","              ('module.layer2.2.conv1.wrapped_module.weight',\n","               tensor([[[[34250., 16291., 14765.],\n","                         [45579., 34166., 33444.],\n","                         [49855., 33803., 39616.]],\n","               \n","                        [[53055., 46806., 17408.],\n","                         [42252., 38583., 28125.],\n","                         [33214., 31996., 30517.]],\n","               \n","                        [[19255., 21769., 38202.],\n","                         [35646., 35167., 45339.],\n","                         [36711., 48832., 50800.]],\n","               \n","                        ...,\n","               \n","                        [[22355., 20659., 16281.],\n","                         [61610., 65535., 37362.],\n","                         [51983., 58412., 43013.]],\n","               \n","                        [[ 6677.,  7165., 26754.],\n","                         [22085., 19660., 18693.],\n","                         [40664., 57292., 45111.]],\n","               \n","                        [[39232., 37337., 40159.],\n","                         [35122., 26991., 22072.],\n","                         [36699., 32508., 29857.]]],\n","               \n","               \n","                       [[[34566., 16361., 42437.],\n","                         [29561., 24664., 30106.],\n","                         [38991., 30797., 26160.]],\n","               \n","                        [[34155., 22146., 33760.],\n","                         [29445., 24992., 31366.],\n","                         [31747., 28345., 17085.]],\n","               \n","                        [[32999., 33481., 35492.],\n","                         [35842., 36531., 30563.],\n","                         [19691., 23715., 16936.]],\n","               \n","                        ...,\n","               \n","                        [[45066., 24272., 21879.],\n","                         [38520., 14817., 30708.],\n","                         [28269., 44385., 57396.]],\n","               \n","                        [[14697., 15881., 14216.],\n","                         [37198., 57643., 49567.],\n","                         [36731., 32859., 34544.]],\n","               \n","                        [[33365., 27229., 30008.],\n","                         [38792., 37990., 26082.],\n","                         [26125., 25255., 15136.]]],\n","               \n","               \n","                       [[[34383., 33741., 46207.],\n","                         [35711., 29485., 26864.],\n","                         [22272., 17034., 21555.]],\n","               \n","                        [[42387., 48461., 44298.],\n","                         [26771., 40859., 37159.],\n","                         [29262., 42821., 34338.]],\n","               \n","                        [[26081., 23475., 28720.],\n","                         [46072., 43726., 47576.],\n","                         [39896., 38174., 38826.]],\n","               \n","                        ...,\n","               \n","                        [[25863., 18008., 13392.],\n","                         [64167., 23139.,  6545.],\n","                         [51435., 33924., 32824.]],\n","               \n","                        [[32041., 14836., 18779.],\n","                         [23869., 19754., 21437.],\n","                         [51444., 48377., 40879.]],\n","               \n","                        [[37312., 46904., 53660.],\n","                         [42861., 41629., 47698.],\n","                         [35187., 34487., 39097.]]],\n","               \n","               \n","                       ...,\n","               \n","               \n","                       [[[36680., 39466., 31441.],\n","                         [29774., 28685., 42198.],\n","                         [10769., 16623., 21517.]],\n","               \n","                        [[31659., 37671., 23332.],\n","                         [17853., 20076., 21673.],\n","                         [30607., 39790., 23340.]],\n","               \n","                        [[38092., 32046., 39449.],\n","                         [26873., 18272., 22443.],\n","                         [33723., 31624., 31029.]],\n","               \n","                        ...,\n","               \n","                        [[12271., 19335., 44225.],\n","                         [35074., 21572., 30636.],\n","                         [42446., 15294., 33334.]],\n","               \n","                        [[55347., 31207., 45857.],\n","                         [29578., 45947., 36981.],\n","                         [50737., 47317., 45774.]],\n","               \n","                        [[37081., 47414., 47968.],\n","                         [26283., 26793., 21723.],\n","                         [29712., 31527., 33118.]]],\n","               \n","               \n","                       [[[30764., 40016., 26620.],\n","                         [21617., 33921., 33202.],\n","                         [13532., 34256., 45002.]],\n","               \n","                        [[36384., 25460., 25099.],\n","                         [37267., 33739., 19797.],\n","                         [31583., 38700., 25697.]],\n","               \n","                        [[31700., 35811., 37497.],\n","                         [35947., 34337., 35749.],\n","                         [39603., 21327., 24226.]],\n","               \n","                        ...,\n","               \n","                        [[27195., 35461., 30548.],\n","                         [24035., 28828., 18554.],\n","                         [30718., 18355., 33544.]],\n","               \n","                        [[25923., 28840., 31531.],\n","                         [28410., 35866., 31948.],\n","                         [25512., 46991., 41326.]],\n","               \n","                        [[42565., 37543., 36143.],\n","                         [41570., 34385., 18476.],\n","                         [38256., 40475., 18181.]]],\n","               \n","               \n","                       [[[25277., 19927., 29822.],\n","                         [22961., 18444., 30131.],\n","                         [22951., 21293., 34383.]],\n","               \n","                        [[15200., 13227.,   765.],\n","                         [47086., 39368., 14097.],\n","                         [37496., 38824., 22990.]],\n","               \n","                        [[35345., 30450., 34937.],\n","                         [42585., 43706., 51833.],\n","                         [25117., 34515., 35770.]],\n","               \n","                        ...,\n","               \n","                        [[43789., 31531., 15130.],\n","                         [10877.,  2132., 24930.],\n","                         [25903., 34720., 47570.]],\n","               \n","                        [[14180.,  7237., 14446.],\n","                         [ 9946.,  3408., 20940.],\n","                         [30875., 33622., 39639.]],\n","               \n","                        [[26003., 35931., 31188.],\n","                         [19602., 22716., 20792.],\n","                         [24991., 21091., 18410.]]]], device='cuda:0')),\n","              ('module.layer2.2.conv1.wrapped_module.bias',\n","               tensor([-2.0135e+09,  1.3841e+09, -4.5086e+08, -8.6092e+08, -2.0140e+09,\n","                       -4.0619e+07,  5.6682e+07,  2.0701e+09, -2.1475e+09, -1.9265e+09,\n","                        2.6017e+08,  2.8988e+08,  2.1475e+09,  2.1475e+09, -2.1475e+09,\n","                        2.1475e+09,  1.3012e+09, -1.7445e+09, -5.8479e+08,  2.1475e+09,\n","                        1.9452e+09,  1.6143e+09,  1.4491e+09,  7.1161e+08, -1.3659e+09,\n","                        6.6375e+08,  9.9477e+08, -9.7351e+08, -1.2542e+09, -1.3887e+09,\n","                       -4.5943e+08, -1.2717e+09], device='cuda:0')),\n","              ('module.layer2.2.conv2.num_forwards',\n","               tensor([40], device='cuda:0')),\n","              ('module.layer2.2.conv2.force_readjust',\n","               tensor(False, device='cuda:0')),\n","              ('module.layer2.2.conv2.output_scale',\n","               tensor([12188.0283], device='cuda:0')),\n","              ('module.layer2.2.conv2.output_zero_point',\n","               tensor([-26529.], device='cuda:0')),\n","              ('module.layer2.2.conv2.w_scale', tensor([[[[  190663.7031]]],\n","               \n","               \n","                       [[[  143906.4375]]],\n","               \n","               \n","                       [[[  151462.4062]]],\n","               \n","               \n","                       [[[  175234.3125]]],\n","               \n","               \n","                       [[[   68856.0312]]],\n","               \n","               \n","                       [[[   66812.8906]]],\n","               \n","               \n","                       [[[  257460.4531]]],\n","               \n","               \n","                       [[[  124445.9141]]],\n","               \n","               \n","                       [[[  123345.9688]]],\n","               \n","               \n","                       [[[   71731.1797]]],\n","               \n","               \n","                       [[[  136746.5625]]],\n","               \n","               \n","                       [[[  158754.9531]]],\n","               \n","               \n","                       [[[  126636.6484]]],\n","               \n","               \n","                       [[[  107978.9531]]],\n","               \n","               \n","                       [[[  194130.7812]]],\n","               \n","               \n","                       [[[   97253.1250]]],\n","               \n","               \n","                       [[[   98526.6875]]],\n","               \n","               \n","                       [[[  175186.3906]]],\n","               \n","               \n","                       [[[   84079.9922]]],\n","               \n","               \n","                       [[[   68238.4219]]],\n","               \n","               \n","                       [[[  252721.5000]]],\n","               \n","               \n","                       [[[  116613.8750]]],\n","               \n","               \n","                       [[[  221262.5938]]],\n","               \n","               \n","                       [[[  141565.4844]]],\n","               \n","               \n","                       [[[  139497.0938]]],\n","               \n","               \n","                       [[[   52482.0352]]],\n","               \n","               \n","                       [[[   49470.0430]]],\n","               \n","               \n","                       [[[  291646.6875]]],\n","               \n","               \n","                       [[[  244383.2812]]],\n","               \n","               \n","                       [[[  114066.9688]]],\n","               \n","               \n","                       [[[10999591.0000]]],\n","               \n","               \n","                       [[[  102229.1406]]]], device='cuda:0')),\n","              ('module.layer2.2.conv2.w_zero_point', tensor([[[[-30991.]]],\n","               \n","               \n","                       [[[-32824.]]],\n","               \n","               \n","                       [[[-39570.]]],\n","               \n","               \n","                       [[[-35101.]]],\n","               \n","               \n","                       [[[-32302.]]],\n","               \n","               \n","                       [[[-33589.]]],\n","               \n","               \n","                       [[[-30507.]]],\n","               \n","               \n","                       [[[-37157.]]],\n","               \n","               \n","                       [[[-27632.]]],\n","               \n","               \n","                       [[[-32186.]]],\n","               \n","               \n","                       [[[-34443.]]],\n","               \n","               \n","                       [[[-33560.]]],\n","               \n","               \n","                       [[[-41777.]]],\n","               \n","               \n","                       [[[-33205.]]],\n","               \n","               \n","                       [[[-38575.]]],\n","               \n","               \n","                       [[[-23180.]]],\n","               \n","               \n","                       [[[-25884.]]],\n","               \n","               \n","                       [[[-35531.]]],\n","               \n","               \n","                       [[[-29672.]]],\n","               \n","               \n","                       [[[-28397.]]],\n","               \n","               \n","                       [[[-31419.]]],\n","               \n","               \n","                       [[[-29103.]]],\n","               \n","               \n","                       [[[-29849.]]],\n","               \n","               \n","                       [[[-25870.]]],\n","               \n","               \n","                       [[[-28504.]]],\n","               \n","               \n","                       [[[-16175.]]],\n","               \n","               \n","                       [[[-23687.]]],\n","               \n","               \n","                       [[[-34352.]]],\n","               \n","               \n","                       [[[-33652.]]],\n","               \n","               \n","                       [[[-39997.]]],\n","               \n","               \n","                       [[[-33094.]]],\n","               \n","               \n","                       [[[-28537.]]]], device='cuda:0')),\n","              ('module.layer2.2.conv2.fp_bias',\n","               tensor([-0.0481,  0.1880,  0.4748,  0.2426, -0.1824, -0.2315,  0.0884,  0.4187,\n","                       -0.0691, -0.0372,  0.4500,  0.1372,  0.2553, -0.1885,  0.0914, -0.6076,\n","                       -0.0255,  0.3631, -0.2162,  0.4215, -0.0232, -0.1516,  0.1137, -0.4513,\n","                        0.1195, -0.1995, -0.2382, -0.0196,  0.0757,  0.0806,  0.0060, -0.0870],\n","                      device='cuda:0')),\n","              ('module.layer2.2.conv2.accum_scale', tensor([[[7.3120e+09]],\n","               \n","                       [[5.5188e+09]],\n","               \n","                       [[5.8086e+09]],\n","               \n","                       [[6.7203e+09]],\n","               \n","                       [[2.6406e+09]],\n","               \n","                       [[2.5623e+09]],\n","               \n","                       [[9.8736e+09]],\n","               \n","                       [[4.7725e+09]],\n","               \n","                       [[4.7303e+09]],\n","               \n","                       [[2.7509e+09]],\n","               \n","                       [[5.2443e+09]],\n","               \n","                       [[6.0883e+09]],\n","               \n","                       [[4.8565e+09]],\n","               \n","                       [[4.1410e+09]],\n","               \n","                       [[7.4449e+09]],\n","               \n","                       [[3.7297e+09]],\n","               \n","                       [[3.7785e+09]],\n","               \n","                       [[6.7184e+09]],\n","               \n","                       [[3.2245e+09]],\n","               \n","                       [[2.6170e+09]],\n","               \n","                       [[9.6919e+09]],\n","               \n","                       [[4.4722e+09]],\n","               \n","                       [[8.4855e+09]],\n","               \n","                       [[5.4291e+09]],\n","               \n","                       [[5.3497e+09]],\n","               \n","                       [[2.0127e+09]],\n","               \n","                       [[1.8972e+09]],\n","               \n","                       [[1.1185e+10]],\n","               \n","                       [[9.3721e+09]],\n","               \n","                       [[4.3745e+09]],\n","               \n","                       [[4.2184e+11]],\n","               \n","                       [[3.9205e+09]]], device='cuda:0')),\n","              ('module.layer2.2.conv2.is_simulated_quant_weight_shifted',\n","               tensor(False, device='cuda:0')),\n","              ('module.layer2.2.conv2.wrapped_module.weight',\n","               tensor([[[[40718., 32595., 30280.],\n","                         [37577., 30249., 30669.],\n","                         [41134., 34795., 33792.]],\n","               \n","                        [[43767., 28160., 26418.],\n","                         [24953., 28016., 38472.],\n","                         [50957., 63652., 44059.]],\n","               \n","                        [[35351., 33890., 31573.],\n","                         [18991., 33723., 30867.],\n","                         [41158., 51562., 31560.]],\n","               \n","                        ...,\n","               \n","                        [[33035., 21653., 16406.],\n","                         [43050., 27851., 17102.],\n","                         [46705., 49584., 42572.]],\n","               \n","                        [[48041., 21679., 26709.],\n","                         [47861., 28754., 31219.],\n","                         [34840., 30528., 21180.]],\n","               \n","                        [[13786., 29889., 23944.],\n","                         [19851., 25815., 20158.],\n","                         [23784., 24979., 27235.]]],\n","               \n","               \n","                       [[[32028., 28119., 24251.],\n","                         [32987., 33704., 33284.],\n","                         [30221., 23823., 28833.]],\n","               \n","                        [[52092., 31298., 46389.],\n","                         [43768., 29893., 28588.],\n","                         [51414., 38462., 32192.]],\n","               \n","                        [[40619., 37345., 36099.],\n","                         [26714., 28151., 31755.],\n","                         [35402., 44735., 46178.]],\n","               \n","                        ...,\n","               \n","                        [[40739., 44240., 48474.],\n","                         [28555., 33321., 34617.],\n","                         [25512., 32632., 22153.]],\n","               \n","                        [[21223., 34295., 41554.],\n","                         [36300., 36646., 28503.],\n","                         [27585., 27699., 12750.]],\n","               \n","                        [[21990., 34229., 50513.],\n","                         [34111., 36493., 43141.],\n","                         [37301., 34111., 40690.]]],\n","               \n","               \n","                       [[[43437., 28019., 23414.],\n","                         [53809., 34513., 29029.],\n","                         [43747., 38313., 33024.]],\n","               \n","                        [[44362., 43112., 40389.],\n","                         [39923., 58647., 58275.],\n","                         [22846., 24739., 34944.]],\n","               \n","                        [[35169., 36613., 36923.],\n","                         [33652., 34280., 37228.],\n","                         [24427., 22876., 27553.]],\n","               \n","                        ...,\n","               \n","                        [[24524., 28912., 42381.],\n","                         [34738., 40976., 55002.],\n","                         [24726., 23225., 27332.]],\n","               \n","                        [[26660., 25848., 20396.],\n","                         [45588., 59340., 40878.],\n","                         [33965., 58319., 59951.]],\n","               \n","                        [[49171., 45286., 37217.],\n","                         [17056., 23251., 10920.],\n","                         [20925., 21717.,     0.]]],\n","               \n","               \n","                       ...,\n","               \n","               \n","                       [[[37833., 42179., 37574.],\n","                         [32909., 38002., 38057.],\n","                         [32209., 38697., 34585.]],\n","               \n","                        [[34942., 52329., 32643.],\n","                         [42494., 43942., 46479.],\n","                         [28512., 24699., 26636.]],\n","               \n","                        [[42909., 40211., 52205.],\n","                         [28751., 31538., 40149.],\n","                         [31085., 39475., 44148.]],\n","               \n","                        ...,\n","               \n","                        [[35964., 36884., 28774.],\n","                         [36576., 30079., 23575.],\n","                         [40664., 46085., 37066.]],\n","               \n","                        [[36808., 32996., 26650.],\n","                         [37714., 35355., 38707.],\n","                         [38692., 34842., 33129.]],\n","               \n","                        [[40264., 33559., 22642.],\n","                         [39558., 39514., 33025.],\n","                         [33382., 37638., 26590.]]],\n","               \n","               \n","                       [[[33308., 34379., 32913.],\n","                         [28835., 30450., 30254.],\n","                         [27550., 30488., 30905.]],\n","               \n","                        [[38556., 48491., 42041.],\n","                         [23228., 45320., 30987.],\n","                         [34420., 36689., 22135.]],\n","               \n","                        [[30569., 47998., 47061.],\n","                         [21062., 34436., 33453.],\n","                         [31910., 33614., 35112.]],\n","               \n","                        ...,\n","               \n","                        [[44710., 43444., 55607.],\n","                         [28676., 20227., 31088.],\n","                         [37276., 26445., 32680.]],\n","               \n","                        [[30184., 39202., 28063.],\n","                         [35749., 46824., 20258.],\n","                         [40984., 36849., 28722.]],\n","               \n","                        [[52116., 37440., 35157.],\n","                         [36978., 25774., 30955.],\n","                         [24310., 23027., 30856.]]],\n","               \n","               \n","                       [[[31013., 22881.,  9714.],\n","                         [35155., 28882., 20463.],\n","                         [35056., 32693., 27809.]],\n","               \n","                        [[15952., 11486., 43190.],\n","                         [30024., 33911., 50035.],\n","                         [43394., 32936., 50918.]],\n","               \n","                        [[18243., 19683., 19442.],\n","                         [31296., 34553., 21182.],\n","                         [27860., 21777.,  9633.]],\n","               \n","                        ...,\n","               \n","                        [[ 9658., 18623., 26092.],\n","                         [ 9685., 10657., 18957.],\n","                         [34635., 36658., 31622.]],\n","               \n","                        [[ 5212., 41999., 28596.],\n","                         [17379., 52691., 46315.],\n","                         [29167., 44585., 54674.]],\n","               \n","                        [[51933., 34261., 22917.],\n","                         [45270., 42932., 31777.],\n","                         [41115., 30245., 29668.]]]], device='cuda:0')),\n","              ('module.layer2.2.conv2.wrapped_module.bias',\n","               tensor([-3.5195e+08,  1.0375e+09,  2.1475e+09,  1.6301e+09, -4.8171e+08,\n","                       -5.9307e+08,  8.7308e+08,  1.9983e+09, -3.2690e+08, -1.0235e+08,\n","                        2.1475e+09,  8.3531e+08,  1.2398e+09, -7.8046e+08,  6.8020e+08,\n","                       -2.1475e+09, -9.6178e+07,  2.1475e+09, -6.9698e+08,  1.1031e+09,\n","                       -2.2522e+08, -6.7799e+08,  9.6474e+08, -2.1475e+09,  6.3903e+08,\n","                       -4.0151e+08, -4.5198e+08, -2.1908e+08,  7.0975e+08,  3.5246e+08,\n","                        2.1475e+09, -3.4097e+08], device='cuda:0')),\n","              ('module.layer2.2.relu2.num_forwards',\n","               tensor([40], device='cuda:0')),\n","              ('module.layer2.2.relu2.force_readjust',\n","               tensor(False, device='cuda:0')),\n","              ('module.layer2.2.relu2.output_scale',\n","               tensor([8264.9346], device='cuda:0')),\n","              ('module.layer2.2.relu2.output_zero_point',\n","               tensor([0.], device='cuda:0')),\n","              ('module.layer2.2.residual_eltwiseadd.num_forwards',\n","               tensor([40], device='cuda:0')),\n","              ('module.layer2.2.residual_eltwiseadd.force_readjust',\n","               tensor(False, device='cuda:0')),\n","              ('module.layer2.2.residual_eltwiseadd.output_scale',\n","               tensor([8264.9346], device='cuda:0')),\n","              ('module.layer2.2.residual_eltwiseadd.output_zero_point',\n","               tensor([0.], device='cuda:0')),\n","              ('module.layer2.3.conv1.num_forwards',\n","               tensor([40], device='cuda:0')),\n","              ('module.layer2.3.conv1.force_readjust',\n","               tensor(False, device='cuda:0')),\n","              ('module.layer2.3.conv1.output_scale',\n","               tensor([39548.9141], device='cuda:0')),\n","              ('module.layer2.3.conv1.output_zero_point',\n","               tensor([0.], device='cuda:0')),\n","              ('module.layer2.3.conv1.w_scale', tensor([[[[ 593241.8125]]],\n","               \n","               \n","                       [[[ 595312.0625]]],\n","               \n","               \n","                       [[[ 991049.5000]]],\n","               \n","               \n","                       [[[ 800453.1250]]],\n","               \n","               \n","                       [[[ 704460.3125]]],\n","               \n","               \n","                       [[[ 965124.8125]]],\n","               \n","               \n","                       [[[ 582586.2500]]],\n","               \n","               \n","                       [[[1004030.0625]]],\n","               \n","               \n","                       [[[ 459745.5938]]],\n","               \n","               \n","                       [[[ 531115.5625]]],\n","               \n","               \n","                       [[[ 691609.2500]]],\n","               \n","               \n","                       [[[ 616872.0000]]],\n","               \n","               \n","                       [[[ 470508.5000]]],\n","               \n","               \n","                       [[[ 668408.6250]]],\n","               \n","               \n","                       [[[ 485905.3125]]],\n","               \n","               \n","                       [[[ 776195.7500]]],\n","               \n","               \n","                       [[[ 684260.3750]]],\n","               \n","               \n","                       [[[ 577679.2500]]],\n","               \n","               \n","                       [[[ 712784.2500]]],\n","               \n","               \n","                       [[[1019060.6250]]],\n","               \n","               \n","                       [[[ 650353.5000]]],\n","               \n","               \n","                       [[[ 510873.9688]]],\n","               \n","               \n","                       [[[ 482101.6875]]],\n","               \n","               \n","                       [[[ 454196.2812]]],\n","               \n","               \n","                       [[[ 613036.4375]]],\n","               \n","               \n","                       [[[ 509481.0938]]],\n","               \n","               \n","                       [[[ 390353.8438]]],\n","               \n","               \n","                       [[[ 890015.5000]]],\n","               \n","               \n","                       [[[ 475850.7188]]],\n","               \n","               \n","                       [[[ 532935.9375]]],\n","               \n","               \n","                       [[[ 556480.6875]]],\n","               \n","               \n","                       [[[ 861503.8125]]]], device='cuda:0')),\n","              ('module.layer2.3.conv1.w_zero_point', tensor([[[[-37263.]]],\n","               \n","               \n","                       [[[-32917.]]],\n","               \n","               \n","                       [[[-24309.]]],\n","               \n","               \n","                       [[[-33503.]]],\n","               \n","               \n","                       [[[-31082.]]],\n","               \n","               \n","                       [[[-30899.]]],\n","               \n","               \n","                       [[[-30727.]]],\n","               \n","               \n","                       [[[-30225.]]],\n","               \n","               \n","                       [[[-30742.]]],\n","               \n","               \n","                       [[[-33674.]]],\n","               \n","               \n","                       [[[-38468.]]],\n","               \n","               \n","                       [[[-25844.]]],\n","               \n","               \n","                       [[[-26718.]]],\n","               \n","               \n","                       [[[-29793.]]],\n","               \n","               \n","                       [[[-37374.]]],\n","               \n","               \n","                       [[[-30298.]]],\n","               \n","               \n","                       [[[-31094.]]],\n","               \n","               \n","                       [[[-33167.]]],\n","               \n","               \n","                       [[[-23193.]]],\n","               \n","               \n","                       [[[-26430.]]],\n","               \n","               \n","                       [[[-27152.]]],\n","               \n","               \n","                       [[[-31577.]]],\n","               \n","               \n","                       [[[-35394.]]],\n","               \n","               \n","                       [[[-26889.]]],\n","               \n","               \n","                       [[[-28010.]]],\n","               \n","               \n","                       [[[-38281.]]],\n","               \n","               \n","                       [[[-25068.]]],\n","               \n","               \n","                       [[[-31404.]]],\n","               \n","               \n","                       [[[-28232.]]],\n","               \n","               \n","                       [[[-34539.]]],\n","               \n","               \n","                       [[[-26370.]]],\n","               \n","               \n","                       [[[-37648.]]]], device='cuda:0')),\n","              ('module.layer2.3.conv1.fp_bias',\n","               tensor([-0.1104,  0.0239, -0.3264, -0.5926, -0.1061, -0.4344, -0.1575, -0.4253,\n","                       -0.2706, -0.2299, -0.0495,  0.1093, -0.6884,  0.6544,  0.4385,  0.0328,\n","                        0.3622,  0.1377, -0.5351, -0.6403, -0.0142,  0.2752,  0.4412, -0.3384,\n","                        0.1691, -0.1707,  0.0537, -0.0102,  0.0526,  0.4465,  0.2093,  0.3574],\n","                      device='cuda:0')),\n","              ('module.layer2.3.conv1.accum_scale', tensor([[[4.9031e+09]],\n","               \n","                       [[4.9202e+09]],\n","               \n","                       [[8.1910e+09]],\n","               \n","                       [[6.6157e+09]],\n","               \n","                       [[5.8223e+09]],\n","               \n","                       [[7.9767e+09]],\n","               \n","                       [[4.8150e+09]],\n","               \n","                       [[8.2982e+09]],\n","               \n","                       [[3.7998e+09]],\n","               \n","                       [[4.3896e+09]],\n","               \n","                       [[5.7161e+09]],\n","               \n","                       [[5.0984e+09]],\n","               \n","                       [[3.8887e+09]],\n","               \n","                       [[5.5244e+09]],\n","               \n","                       [[4.0160e+09]],\n","               \n","                       [[6.4152e+09]],\n","               \n","                       [[5.6554e+09]],\n","               \n","                       [[4.7745e+09]],\n","               \n","                       [[5.8911e+09]],\n","               \n","                       [[8.4225e+09]],\n","               \n","                       [[5.3751e+09]],\n","               \n","                       [[4.2223e+09]],\n","               \n","                       [[3.9845e+09]],\n","               \n","                       [[3.7539e+09]],\n","               \n","                       [[5.0667e+09]],\n","               \n","                       [[4.2108e+09]],\n","               \n","                       [[3.2262e+09]],\n","               \n","                       [[7.3559e+09]],\n","               \n","                       [[3.9329e+09]],\n","               \n","                       [[4.4047e+09]],\n","               \n","                       [[4.5993e+09]],\n","               \n","                       [[7.1203e+09]]], device='cuda:0')),\n","              ('module.layer2.3.conv1.is_simulated_quant_weight_shifted',\n","               tensor(False, device='cuda:0')),\n","              ('module.layer2.3.conv1.wrapped_module.weight',\n","               tensor([[[[47951., 44249., 29007.],\n","                         [29843., 52617., 49939.],\n","                         [43905., 35420., 46913.]],\n","               \n","                        [[45225., 55693., 28720.],\n","                         [20958., 36710., 40466.],\n","                         [35367., 30371., 35858.]],\n","               \n","                        [[52188., 49596., 45367.],\n","                         [46387., 50559., 41138.],\n","                         [35611., 56597., 56235.]],\n","               \n","                        ...,\n","               \n","                        [[39212., 33079., 19699.],\n","                         [32898., 36387., 47484.],\n","                         [32583., 32567., 42275.]],\n","               \n","                        [[47068., 49308., 56074.],\n","                         [31682., 35668., 41658.],\n","                         [22486.,     0.,  7489.]],\n","               \n","                        [[43288., 40505., 30198.],\n","                         [32600., 37893., 31292.],\n","                         [26628., 23608., 26014.]]],\n","               \n","               \n","                       [[[33696., 24791.,     0.],\n","                         [34726., 35542., 29252.],\n","                         [35606., 38902., 43768.]],\n","               \n","                        [[42626., 28430., 18391.],\n","                         [40200., 44045., 23487.],\n","                         [50700., 65535., 62098.]],\n","               \n","                        [[34973., 39659., 40401.],\n","                         [33057., 42628., 39440.],\n","                         [40693., 44018., 44645.]],\n","               \n","                        ...,\n","               \n","                        [[20480., 41225., 34570.],\n","                         [49122., 37518., 18998.],\n","                         [45751., 30324., 28771.]],\n","               \n","                        [[39926., 38558., 45460.],\n","                         [45373., 25119., 22868.],\n","                         [19841.,  3844., 19974.]],\n","               \n","                        [[24936., 26685., 35411.],\n","                         [31061., 25332., 30999.],\n","                         [34766., 30140., 25851.]]],\n","               \n","               \n","                       [[[10476., 28337., 25215.],\n","                         [ 4203., 23840., 27285.],\n","                         [ 2446., 16497., 39039.]],\n","               \n","                        [[33466., 32409., 36167.],\n","                         [31148., 32642., 41661.],\n","                         [28605., 16039., 30304.]],\n","               \n","                        [[29023., 34073., 44537.],\n","                         [38433., 43114., 41268.],\n","                         [31428., 36902., 33662.]],\n","               \n","                        ...,\n","               \n","                        [[ 9048., 21291., 25449.],\n","                         [10767., 24384., 32970.],\n","                         [11710., 28201., 52384.]],\n","               \n","                        [[27225., 25814., 18314.],\n","                         [49580., 58125., 50676.],\n","                         [ 5666., 28417., 28614.]],\n","               \n","                        [[33767., 30122., 35814.],\n","                         [34140., 27976., 28060.],\n","                         [22308., 18859., 17466.]]],\n","               \n","               \n","                       ...,\n","               \n","               \n","                       [[[45454., 28817., 31565.],\n","                         [43131., 32997., 24748.],\n","                         [37700., 41063., 20885.]],\n","               \n","                        [[35871., 26710., 24854.],\n","                         [44365., 34239., 22088.],\n","                         [41746., 33869., 35051.]],\n","               \n","                        [[34009., 32331., 38664.],\n","                         [27520., 33945., 49189.],\n","                         [23701., 25778., 43375.]],\n","               \n","                        ...,\n","               \n","                        [[36904., 41742., 34088.],\n","                         [46708., 40619., 25301.],\n","                         [43194., 41950., 31516.]],\n","               \n","                        [[41180., 23244., 18455.],\n","                         [43552., 32650., 13987.],\n","                         [24430., 38598., 17502.]],\n","               \n","                        [[22299., 27451., 23137.],\n","                         [30033., 33634., 24002.],\n","                         [31669., 35885., 27199.]]],\n","               \n","               \n","                       [[[29655., 29764., 23175.],\n","                         [29159., 21632., 23369.],\n","                         [24581., 11060., 22641.]],\n","               \n","                        [[15467., 22153., 38350.],\n","                         [11882., 19046., 25293.],\n","                         [24734., 20692., 20589.]],\n","               \n","                        [[17246., 16485., 16691.],\n","                         [16766., 27858., 33952.],\n","                         [24948., 25988., 24719.]],\n","               \n","                        ...,\n","               \n","                        [[44763., 18718., 16599.],\n","                         [29527.,  6063., 47972.],\n","                         [33020., 34315., 65535.]],\n","               \n","                        [[24573., 21539., 11806.],\n","                         [20266., 14716., 10215.],\n","                         [18230., 19077., 10103.]],\n","               \n","                        [[27254., 24495., 21871.],\n","                         [22042., 19684., 15786.],\n","                         [18748., 24052., 20383.]]],\n","               \n","               \n","                       [[[36965., 39805., 28193.],\n","                         [50004., 58916., 47627.],\n","                         [29984., 41198., 38049.]],\n","               \n","                        [[35956., 43786., 52378.],\n","                         [34544., 55315., 63461.],\n","                         [37194., 44781., 57403.]],\n","               \n","                        [[33004., 33060., 37318.],\n","                         [28316., 29449., 37660.],\n","                         [30259., 29162., 41414.]],\n","               \n","                        ...,\n","               \n","                        [[55238., 36914., 30918.],\n","                         [54617., 31575., 22737.],\n","                         [23392., 21357., 30050.]],\n","               \n","                        [[38266., 28033., 25355.],\n","                         [49895.,     0., 12818.],\n","                         [65535., 22383., 27106.]],\n","               \n","                        [[42189., 33056., 39057.],\n","                         [35989., 28447., 39165.],\n","                         [40537., 35513., 37445.]]]], device='cuda:0')),\n","              ('module.layer2.3.conv1.wrapped_module.bias',\n","               tensor([-5.4115e+08,  1.1754e+08, -2.1475e+09, -2.1475e+09, -6.1802e+08,\n","                       -2.1475e+09, -7.5852e+08, -2.1475e+09, -1.0283e+09, -1.0091e+09,\n","                       -2.8318e+08,  5.5739e+08, -2.1475e+09,  2.1475e+09,  1.7610e+09,\n","                        2.1073e+08,  2.0484e+09,  6.5732e+08, -2.1475e+09, -2.1475e+09,\n","                       -7.6589e+07,  1.1620e+09,  1.7578e+09, -1.2703e+09,  8.5691e+08,\n","                       -7.1880e+08,  1.7333e+08, -7.4929e+07,  2.0679e+08,  1.9667e+09,\n","                        9.6252e+08,  2.1475e+09], device='cuda:0')),\n","              ('module.layer2.3.conv2.num_forwards',\n","               tensor([40], device='cuda:0')),\n","              ('module.layer2.3.conv2.force_readjust',\n","               tensor(False, device='cuda:0')),\n","              ('module.layer2.3.conv2.output_scale',\n","               tensor([13494.8701], device='cuda:0')),\n","              ('module.layer2.3.conv2.output_zero_point',\n","               tensor([-30799.], device='cuda:0')),\n","              ('module.layer2.3.conv2.w_scale', tensor([[[[128409.6562]]],\n","               \n","               \n","                       [[[241530.7188]]],\n","               \n","               \n","                       [[[144314.6250]]],\n","               \n","               \n","                       [[[ 82355.1562]]],\n","               \n","               \n","                       [[[ 77514.7422]]],\n","               \n","               \n","                       [[[125760.2812]]],\n","               \n","               \n","                       [[[105697.8828]]],\n","               \n","               \n","                       [[[108019.9531]]],\n","               \n","               \n","                       [[[ 52971.7734]]],\n","               \n","               \n","                       [[[ 87183.3672]]],\n","               \n","               \n","                       [[[ 86299.9844]]],\n","               \n","               \n","                       [[[139899.0312]]],\n","               \n","               \n","                       [[[121573.8750]]],\n","               \n","               \n","                       [[[177029.0781]]],\n","               \n","               \n","                       [[[198555.3281]]],\n","               \n","               \n","                       [[[501851.0312]]],\n","               \n","               \n","                       [[[127322.2734]]],\n","               \n","               \n","                       [[[102702.9531]]],\n","               \n","               \n","                       [[[ 39764.3008]]],\n","               \n","               \n","                       [[[162314.4688]]],\n","               \n","               \n","                       [[[377601.0938]]],\n","               \n","               \n","                       [[[ 70088.6797]]],\n","               \n","               \n","                       [[[127883.6094]]],\n","               \n","               \n","                       [[[109434.7422]]],\n","               \n","               \n","                       [[[167104.2031]]],\n","               \n","               \n","                       [[[163330.6562]]],\n","               \n","               \n","                       [[[ 85183.8906]]],\n","               \n","               \n","                       [[[330651.1562]]],\n","               \n","               \n","                       [[[136575.3125]]],\n","               \n","               \n","                       [[[111364.7031]]],\n","               \n","               \n","                       [[[122738.9453]]],\n","               \n","               \n","                       [[[100064.9531]]]], device='cuda:0')),\n","              ('module.layer2.3.conv2.w_zero_point', tensor([[[[-26521.]]],\n","               \n","               \n","                       [[[-36467.]]],\n","               \n","               \n","                       [[[-34851.]]],\n","               \n","               \n","                       [[[-20604.]]],\n","               \n","               \n","                       [[[-28693.]]],\n","               \n","               \n","                       [[[-32526.]]],\n","               \n","               \n","                       [[[-27062.]]],\n","               \n","               \n","                       [[[-29601.]]],\n","               \n","               \n","                       [[[-40417.]]],\n","               \n","               \n","                       [[[-33128.]]],\n","               \n","               \n","                       [[[-20265.]]],\n","               \n","               \n","                       [[[-33221.]]],\n","               \n","               \n","                       [[[-34347.]]],\n","               \n","               \n","                       [[[-29331.]]],\n","               \n","               \n","                       [[[-33632.]]],\n","               \n","               \n","                       [[[-27168.]]],\n","               \n","               \n","                       [[[-30767.]]],\n","               \n","               \n","                       [[[-39653.]]],\n","               \n","               \n","                       [[[-28889.]]],\n","               \n","               \n","                       [[[-29702.]]],\n","               \n","               \n","                       [[[-34465.]]],\n","               \n","               \n","                       [[[-27100.]]],\n","               \n","               \n","                       [[[-36465.]]],\n","               \n","               \n","                       [[[-32599.]]],\n","               \n","               \n","                       [[[-30698.]]],\n","               \n","               \n","                       [[[-27750.]]],\n","               \n","               \n","                       [[[-24046.]]],\n","               \n","               \n","                       [[[-39162.]]],\n","               \n","               \n","                       [[[-32497.]]],\n","               \n","               \n","                       [[[-26365.]]],\n","               \n","               \n","                       [[[-27246.]]],\n","               \n","               \n","                       [[[-24458.]]]], device='cuda:0')),\n","              ('module.layer2.3.conv2.fp_bias',\n","               tensor([ 0.0578,  0.0734,  0.4741, -0.1018, -0.2713,  0.1148, -0.1087,  0.1147,\n","                       -0.3202, -0.2311, -0.1553,  0.0903,  0.2611, -0.0799, -0.0584, -0.0672,\n","                        0.1687,  0.5817,  0.0551, -0.2479, -0.0723, -0.0734, -0.1963,  0.3566,\n","                       -0.0349,  0.2214, -0.1309,  0.1417, -0.1663,  0.0148, -0.2536, -0.1435],\n","                      device='cuda:0')),\n","              ('module.layer2.3.conv2.accum_scale', tensor([[[5.0785e+09]],\n","               \n","                       [[9.5523e+09]],\n","               \n","                       [[5.7075e+09]],\n","               \n","                       [[3.2571e+09]],\n","               \n","                       [[3.0656e+09]],\n","               \n","                       [[4.9737e+09]],\n","               \n","                       [[4.1802e+09]],\n","               \n","                       [[4.2721e+09]],\n","               \n","                       [[2.0950e+09]],\n","               \n","                       [[3.4480e+09]],\n","               \n","                       [[3.4131e+09]],\n","               \n","                       [[5.5329e+09]],\n","               \n","                       [[4.8081e+09]],\n","               \n","                       [[7.0013e+09]],\n","               \n","                       [[7.8526e+09]],\n","               \n","                       [[1.9848e+10]],\n","               \n","                       [[5.0355e+09]],\n","               \n","                       [[4.0618e+09]],\n","               \n","                       [[1.5726e+09]],\n","               \n","                       [[6.4194e+09]],\n","               \n","                       [[1.4934e+10]],\n","               \n","                       [[2.7719e+09]],\n","               \n","                       [[5.0577e+09]],\n","               \n","                       [[4.3280e+09]],\n","               \n","                       [[6.6088e+09]],\n","               \n","                       [[6.4596e+09]],\n","               \n","                       [[3.3689e+09]],\n","               \n","                       [[1.3077e+10]],\n","               \n","                       [[5.4014e+09]],\n","               \n","                       [[4.4044e+09]],\n","               \n","                       [[4.8542e+09]],\n","               \n","                       [[3.9575e+09]]], device='cuda:0')),\n","              ('module.layer2.3.conv2.is_simulated_quant_weight_shifted',\n","               tensor(False, device='cuda:0')),\n","              ('module.layer2.3.conv2.wrapped_module.weight',\n","               tensor([[[[25727., 25362., 27915.],\n","                         [30231., 31160., 33604.],\n","                         [38836., 38203., 19426.]],\n","               \n","                        [[34074., 32836., 25016.],\n","                         [28507., 19877., 16163.],\n","                         [29495., 34398., 37758.]],\n","               \n","                        [[30731., 29326., 29441.],\n","                         [22164., 21200., 22940.],\n","                         [16193., 16184., 19617.]],\n","               \n","                        ...,\n","               \n","                        [[24768., 13502., 14333.],\n","                         [33559., 17501., 22407.],\n","                         [27699., 21499., 23419.]],\n","               \n","                        [[34754., 26528., 30722.],\n","                         [11917., 20079., 27193.],\n","                         [13658., 32839., 33200.]],\n","               \n","                        [[30483., 38303., 27489.],\n","                         [25085., 27690., 28379.],\n","                         [28619., 28917., 29735.]]],\n","               \n","               \n","                       [[[43374., 38552., 29134.],\n","                         [36020., 37058., 41889.],\n","                         [47637., 47695., 47045.]],\n","               \n","                        [[32488., 34477., 24246.],\n","                         [41010., 31325., 20756.],\n","                         [41528., 43099., 43262.]],\n","               \n","                        [[30880., 35585., 35035.],\n","                         [28105., 27201., 25738.],\n","                         [28525., 27914., 27302.]],\n","               \n","                        ...,\n","               \n","                        [[45019., 37319., 34667.],\n","                         [16330., 24806., 36313.],\n","                         [16550., 25327., 39660.]],\n","               \n","                        [[48807., 33631., 25800.],\n","                         [45808., 29917., 21378.],\n","                         [26068., 26144., 26816.]],\n","               \n","                        [[44021., 47004., 41608.],\n","                         [45666., 41471., 42288.],\n","                         [36305., 40101., 44775.]]],\n","               \n","               \n","                       [[[30509., 36462., 41944.],\n","                         [29862., 30747., 42800.],\n","                         [36646., 22912., 48266.]],\n","               \n","                        [[48311., 40224., 24869.],\n","                         [42849., 39460., 17947.],\n","                         [50356., 47863., 23994.]],\n","               \n","                        [[27213., 34976., 31608.],\n","                         [35913., 39920., 39178.],\n","                         [23580., 26304., 27569.]],\n","               \n","                        ...,\n","               \n","                        [[37187., 44051., 41088.],\n","                         [28854., 33941., 33761.],\n","                         [10288., 28603., 32910.]],\n","               \n","                        [[39371., 44344., 33695.],\n","                         [50353., 45843., 27298.],\n","                         [54823., 45409., 37222.]],\n","               \n","                        [[32909., 32512., 24418.],\n","                         [33346., 21177., 11372.],\n","                         [65535., 36211., 17671.]]],\n","               \n","               \n","                       ...,\n","               \n","               \n","                       [[[20308., 18876., 22385.],\n","                         [16065., 17281., 25520.],\n","                         [14330., 21636., 36477.]],\n","               \n","                        [[21545., 30117., 33584.],\n","                         [22299., 33435., 35816.],\n","                         [23691., 12960., 14243.]],\n","               \n","                        [[33893., 32059., 25387.],\n","                         [32121., 29785., 25016.],\n","                         [25104., 24049., 21002.]],\n","               \n","                        ...,\n","               \n","                        [[ 5759., 13271., 25280.],\n","                         [11792., 15930., 12239.],\n","                         [24998., 18904., 24871.]],\n","               \n","                        [[30264., 47261., 43332.],\n","                         [11782., 20849., 29383.],\n","                         [ 4754.,  7643., 20526.]],\n","               \n","                        [[40749., 24947.,  6694.],\n","                         [18651., 22557., 35457.],\n","                         [17509., 30329., 31567.]]],\n","               \n","               \n","                       [[[29014., 13633., 19764.],\n","                         [35776., 22966., 31862.],\n","                         [32534., 25345., 36380.]],\n","               \n","                        [[23877., 21621., 32163.],\n","                         [23660., 30660., 34816.],\n","                         [39388., 49978., 44259.]],\n","               \n","                        [[16571., 19290., 28151.],\n","                         [28260., 36605., 46311.],\n","                         [26882., 35756., 42890.]],\n","               \n","                        ...,\n","               \n","                        [[35560., 35260., 21688.],\n","                         [37320., 33677., 26373.],\n","                         [27121., 33180., 36743.]],\n","               \n","                        [[41591., 22683., 28147.],\n","                         [36570., 15590., 23302.],\n","                         [23010.,  6523., 15402.]],\n","               \n","                        [[19182., 44055., 46768.],\n","                         [11031., 47744., 47778.],\n","                         [ 6812., 40891., 31182.]]],\n","               \n","               \n","                       [[[24408., 25941., 29829.],\n","                         [30590., 16495., 16960.],\n","                         [32164., 32526., 33560.]],\n","               \n","                        [[30488., 26411., 18908.],\n","                         [32450., 27852., 14277.],\n","                         [42298., 39237., 32507.]],\n","               \n","                        [[19973., 26540., 22741.],\n","                         [21192., 22055., 19873.],\n","                         [21701., 19696., 16137.]],\n","               \n","                        ...,\n","               \n","                        [[10182., 25541., 21155.],\n","                         [17100., 25242.,  2999.],\n","                         [22157., 18159.,     0.]],\n","               \n","                        [[18325., 22319., 14664.],\n","                         [20970., 29108., 15487.],\n","                         [10780., 28767., 25537.]],\n","               \n","                        [[20277., 13376., 14748.],\n","                         [37136., 22585., 19031.],\n","                         [17911., 18653., 19960.]]]], device='cuda:0')),\n","              ('module.layer2.3.conv2.wrapped_module.bias',\n","               tensor([ 2.9357e+08,  7.0124e+08,  2.1475e+09, -3.3171e+08, -8.3173e+08,\n","                        5.7100e+08, -4.5425e+08,  4.8996e+08, -6.7075e+08, -7.9690e+08,\n","                       -5.3019e+08,  4.9961e+08,  1.2554e+09, -5.5929e+08, -4.5841e+08,\n","                       -1.3329e+09,  8.4956e+08,  2.1475e+09,  8.6575e+07, -1.5911e+09,\n","                       -1.0795e+09, -2.0359e+08, -9.9283e+08,  1.5435e+09, -2.3040e+08,\n","                        1.4304e+09, -4.4091e+08,  1.8535e+09, -8.9819e+08,  6.4989e+07,\n","                       -1.2312e+09, -5.6796e+08], device='cuda:0')),\n","              ('module.layer2.3.relu2.num_forwards',\n","               tensor([40], device='cuda:0')),\n","              ('module.layer2.3.relu2.force_readjust',\n","               tensor(False, device='cuda:0')),\n","              ('module.layer2.3.relu2.output_scale',\n","               tensor([7970.0718], device='cuda:0')),\n","              ('module.layer2.3.relu2.output_zero_point',\n","               tensor([0.], device='cuda:0')),\n","              ('module.layer2.3.residual_eltwiseadd.num_forwards',\n","               tensor([40], device='cuda:0')),\n","              ('module.layer2.3.residual_eltwiseadd.force_readjust',\n","               tensor(False, device='cuda:0')),\n","              ('module.layer2.3.residual_eltwiseadd.output_scale',\n","               tensor([7970.0718], device='cuda:0')),\n","              ('module.layer2.3.residual_eltwiseadd.output_zero_point',\n","               tensor([0.], device='cuda:0')),\n","              ('module.layer2.4.conv1.num_forwards',\n","               tensor([40], device='cuda:0')),\n","              ('module.layer2.4.conv1.force_readjust',\n","               tensor(False, device='cuda:0')),\n","              ('module.layer2.4.conv1.output_scale',\n","               tensor([42853.3945], device='cuda:0')),\n","              ('module.layer2.4.conv1.output_zero_point',\n","               tensor([0.], device='cuda:0')),\n","              ('module.layer2.4.conv1.w_scale', tensor([[[[1017971.2500]]],\n","               \n","               \n","                       [[[ 982130.0625]]],\n","               \n","               \n","                       [[[ 593201.8125]]],\n","               \n","               \n","                       [[[1771860.2500]]],\n","               \n","               \n","                       [[[ 807487.7500]]],\n","               \n","               \n","                       [[[ 651798.4375]]],\n","               \n","               \n","                       [[[ 816591.3125]]],\n","               \n","               \n","                       [[[ 605558.1250]]],\n","               \n","               \n","                       [[[ 904613.8750]]],\n","               \n","               \n","                       [[[ 862693.4375]]],\n","               \n","               \n","                       [[[ 734096.6250]]],\n","               \n","               \n","                       [[[ 530342.8125]]],\n","               \n","               \n","                       [[[ 528926.2500]]],\n","               \n","               \n","                       [[[ 817527.6250]]],\n","               \n","               \n","                       [[[ 430479.7812]]],\n","               \n","               \n","                       [[[ 477758.3438]]],\n","               \n","               \n","                       [[[ 784951.4375]]],\n","               \n","               \n","                       [[[ 905870.5000]]],\n","               \n","               \n","                       [[[1794603.6250]]],\n","               \n","               \n","                       [[[ 557282.3750]]],\n","               \n","               \n","                       [[[1000372.4375]]],\n","               \n","               \n","                       [[[ 951663.2500]]],\n","               \n","               \n","                       [[[ 861345.6875]]],\n","               \n","               \n","                       [[[ 876845.0625]]],\n","               \n","               \n","                       [[[1055487.0000]]],\n","               \n","               \n","                       [[[ 991329.8750]]],\n","               \n","               \n","                       [[[1140329.6250]]],\n","               \n","               \n","                       [[[ 568465.6250]]],\n","               \n","               \n","                       [[[ 718713.5000]]],\n","               \n","               \n","                       [[[ 859960.7500]]],\n","               \n","               \n","                       [[[1306590.5000]]],\n","               \n","               \n","                       [[[1397224.7500]]]], device='cuda:0')),\n","              ('module.layer2.4.conv1.w_zero_point', tensor([[[[-31452.]]],\n","               \n","               \n","                       [[[-29973.]]],\n","               \n","               \n","                       [[[-30098.]]],\n","               \n","               \n","                       [[[-26995.]]],\n","               \n","               \n","                       [[[-32267.]]],\n","               \n","               \n","                       [[[-28274.]]],\n","               \n","               \n","                       [[[-32663.]]],\n","               \n","               \n","                       [[[-34207.]]],\n","               \n","               \n","                       [[[-27870.]]],\n","               \n","               \n","                       [[[-33375.]]],\n","               \n","               \n","                       [[[-31188.]]],\n","               \n","               \n","                       [[[-24543.]]],\n","               \n","               \n","                       [[[-30997.]]],\n","               \n","               \n","                       [[[-30618.]]],\n","               \n","               \n","                       [[[-33232.]]],\n","               \n","               \n","                       [[[-32669.]]],\n","               \n","               \n","                       [[[-35954.]]],\n","               \n","               \n","                       [[[-34789.]]],\n","               \n","               \n","                       [[[-30474.]]],\n","               \n","               \n","                       [[[-29762.]]],\n","               \n","               \n","                       [[[-32084.]]],\n","               \n","               \n","                       [[[-34022.]]],\n","               \n","               \n","                       [[[-30456.]]],\n","               \n","               \n","                       [[[-30163.]]],\n","               \n","               \n","                       [[[-32616.]]],\n","               \n","               \n","                       [[[-29432.]]],\n","               \n","               \n","                       [[[-23531.]]],\n","               \n","               \n","                       [[[-27130.]]],\n","               \n","               \n","                       [[[-33337.]]],\n","               \n","               \n","                       [[[-32018.]]],\n","               \n","               \n","                       [[[-31019.]]],\n","               \n","               \n","                       [[[-30840.]]]], device='cuda:0')),\n","              ('module.layer2.4.conv1.fp_bias',\n","               tensor([-0.4213, -0.7618, -0.1156, -0.6688,  0.1177, -1.0026,  0.1638, -0.2890,\n","                       -0.1492, -0.1551,  0.0526,  0.5726,  0.3280,  0.1732,  0.1979, -0.3404,\n","                        0.7181, -0.1292,  0.0876,  0.1857,  0.4831,  0.5537, -0.2150,  0.2877,\n","                        0.0298, -0.5933, -0.5855,  0.2303, -0.2268, -0.1556, -0.7149, -0.1749],\n","                      device='cuda:0')),\n","              ('module.layer2.4.conv1.accum_scale', tensor([[[8.1133e+09]],\n","               \n","                       [[7.8276e+09]],\n","               \n","                       [[4.7279e+09]],\n","               \n","                       [[1.4122e+10]],\n","               \n","                       [[6.4357e+09]],\n","               \n","                       [[5.1949e+09]],\n","               \n","                       [[6.5083e+09]],\n","               \n","                       [[4.8263e+09]],\n","               \n","                       [[7.2098e+09]],\n","               \n","                       [[6.8757e+09]],\n","               \n","                       [[5.8508e+09]],\n","               \n","                       [[4.2269e+09]],\n","               \n","                       [[4.2156e+09]],\n","               \n","                       [[6.5158e+09]],\n","               \n","                       [[3.4310e+09]],\n","               \n","                       [[3.8078e+09]],\n","               \n","                       [[6.2561e+09]],\n","               \n","                       [[7.2199e+09]],\n","               \n","                       [[1.4303e+10]],\n","               \n","                       [[4.4416e+09]],\n","               \n","                       [[7.9730e+09]],\n","               \n","                       [[7.5848e+09]],\n","               \n","                       [[6.8650e+09]],\n","               \n","                       [[6.9885e+09]],\n","               \n","                       [[8.4123e+09]],\n","               \n","                       [[7.9010e+09]],\n","               \n","                       [[9.0885e+09]],\n","               \n","                       [[4.5307e+09]],\n","               \n","                       [[5.7282e+09]],\n","               \n","                       [[6.8539e+09]],\n","               \n","                       [[1.0414e+10]],\n","               \n","                       [[1.1136e+10]]], device='cuda:0')),\n","              ('module.layer2.4.conv1.is_simulated_quant_weight_shifted',\n","               tensor(False, device='cuda:0')),\n","              ('module.layer2.4.conv1.wrapped_module.weight',\n","               tensor([[[[35140., 25748., 25596.],\n","                         [28641., 43216., 36304.],\n","                         [18228., 16692., 16374.]],\n","               \n","                        [[45962., 39425., 42483.],\n","                         [40432., 46236., 47248.],\n","                         [34427., 31104., 44110.]],\n","               \n","                        [[44479., 44560., 44675.],\n","                         [25915., 30776., 24107.],\n","                         [25031., 38890., 41214.]],\n","               \n","                        ...,\n","               \n","                        [[16721., 44074., 39504.],\n","                         [36577., 39868., 30116.],\n","                         [47579., 25993., 12403.]],\n","               \n","                        [[25319., 38773., 34031.],\n","                         [17947., 26959., 32553.],\n","                         [19935., 38615., 40679.]],\n","               \n","                        [[43796., 43422., 34512.],\n","                         [39879., 35671., 29286.],\n","                         [20969., 22807., 23018.]]],\n","               \n","               \n","                       [[[34252., 27696., 25146.],\n","                         [42511., 21689., 36339.],\n","                         [37722., 23799., 38909.]],\n","               \n","                        [[43359., 37243., 29159.],\n","                         [47523., 42983., 32272.],\n","                         [41832., 34851., 38140.]],\n","               \n","                        [[26503., 34829., 31532.],\n","                         [26008., 21323., 24586.],\n","                         [28727., 17913., 19005.]],\n","               \n","                        ...,\n","               \n","                        [[19081., 23938., 20186.],\n","                         [ 8982., 35634., 52523.],\n","                         [ 7673., 31549., 50520.]],\n","               \n","                        [[26166., 31384., 22639.],\n","                         [30451., 20579., 16691.],\n","                         [63947., 43813., 33266.]],\n","               \n","                        [[32921., 30982., 29879.],\n","                         [33415., 38741., 39796.],\n","                         [56579., 40068., 36435.]]],\n","               \n","               \n","                       [[[10206., 18761., 29045.],\n","                         [25081., 31297., 31921.],\n","                         [46439., 39206., 35432.]],\n","               \n","                        [[32095., 35853., 42344.],\n","                         [38309., 23224., 33658.],\n","                         [21695., 21669., 37893.]],\n","               \n","                        [[28885., 35690., 37895.],\n","                         [23015., 30728., 23732.],\n","                         [26732., 36719., 26541.]],\n","               \n","                        ...,\n","               \n","                        [[20362., 32059., 33967.],\n","                         [28124., 40898., 24528.],\n","                         [43242., 35562., 12595.]],\n","               \n","                        [[19297., 44128., 43929.],\n","                         [20231., 37355., 21011.],\n","                         [32827., 22338., 17398.]],\n","               \n","                        [[34447., 33554., 13007.],\n","                         [42905., 25745., 13168.],\n","                         [31312., 16247., 24424.]]],\n","               \n","               \n","                       ...,\n","               \n","               \n","                       [[[23703., 39470., 34906.],\n","                         [25210., 44948., 48823.],\n","                         [16900., 32829., 46666.]],\n","               \n","                        [[49553., 26700., 11612.],\n","                         [43377., 33836., 17914.],\n","                         [37223., 31213., 26418.]],\n","               \n","                        [[27683., 40162., 53404.],\n","                         [26064., 37072., 54860.],\n","                         [40179., 33080., 31804.]],\n","               \n","                        ...,\n","               \n","                        [[26092., 21087., 21090.],\n","                         [15170., 24885., 39954.],\n","                         [15826., 32225., 51940.]],\n","               \n","                        [[ 3591., 33132., 65535.],\n","                         [ 8625., 10746., 47510.],\n","                         [    0.,  7869., 27320.]],\n","               \n","                        [[19961., 42013., 46333.],\n","                         [16486., 24124., 37325.],\n","                         [22359., 29597., 32332.]]],\n","               \n","               \n","                       [[[31819., 44116., 52712.],\n","                         [15272., 25099., 29401.],\n","                         [19245., 27828., 27723.]],\n","               \n","                        [[26967., 52077., 61174.],\n","                         [17495., 42108., 53475.],\n","                         [14631., 26210., 35630.]],\n","               \n","                        [[26064., 24066., 13577.],\n","                         [29175., 25845., 23766.],\n","                         [27590., 24689., 22539.]],\n","               \n","                        ...,\n","               \n","                        [[10576., 12870., 21092.],\n","                         [17037., 22382., 24784.],\n","                         [33049., 30531., 29621.]],\n","               \n","                        [[56528., 48940., 39949.],\n","                         [38208., 34012., 29079.],\n","                         [27296., 41211., 31026.]],\n","               \n","                        [[29383., 36522., 34694.],\n","                         [38809., 37117., 42635.],\n","                         [47773., 43691., 46710.]]],\n","               \n","               \n","                       [[[35827., 25500., 32943.],\n","                         [31585., 40182., 42036.],\n","                         [19621., 26995., 33136.]],\n","               \n","                        [[25462., 19312., 23225.],\n","                         [38301., 45647., 43175.],\n","                         [40619., 50764., 39323.]],\n","               \n","                        [[38252., 55780., 54131.],\n","                         [32987., 47974., 38343.],\n","                         [10377., 21174., 31151.]],\n","               \n","                        ...,\n","               \n","                        [[ 7827., 29152., 30783.],\n","                         [24183., 40514., 37454.],\n","                         [21706., 34045., 38687.]],\n","               \n","                        [[ 5738., 35122., 30137.],\n","                         [41860., 60763., 36553.],\n","                         [56547., 57121., 28955.]],\n","               \n","                        [[15542., 16932., 14281.],\n","                         [ 7388., 26452., 40362.],\n","                         [16169., 34949., 51865.]]]], device='cuda:0')),\n","              ('module.layer2.4.conv1.wrapped_module.bias',\n","               tensor([-2.1475e+09, -2.1475e+09, -5.4667e+08, -2.1475e+09,  7.5757e+08,\n","                       -2.1475e+09,  1.0660e+09, -1.3948e+09, -1.0760e+09, -1.0667e+09,\n","                        3.0796e+08,  2.1475e+09,  1.3826e+09,  1.1286e+09,  6.7906e+08,\n","                       -1.2964e+09,  2.1475e+09, -9.3255e+08,  1.2533e+09,  8.2478e+08,\n","                        2.1475e+09,  2.1475e+09, -1.4758e+09,  2.0108e+09,  2.5077e+08,\n","                       -2.1475e+09, -2.1475e+09,  1.0434e+09, -1.2990e+09, -1.0662e+09,\n","                       -2.1475e+09, -1.9473e+09], device='cuda:0')),\n","              ('module.layer2.4.conv2.num_forwards',\n","               tensor([40], device='cuda:0')),\n","              ('module.layer2.4.conv2.force_readjust',\n","               tensor(False, device='cuda:0')),\n","              ('module.layer2.4.conv2.output_scale',\n","               tensor([14551.0352], device='cuda:0')),\n","              ('module.layer2.4.conv2.output_zero_point',\n","               tensor([-30492.], device='cuda:0')),\n","              ('module.layer2.4.conv2.w_scale', tensor([[[[ 89643.9219]]],\n","               \n","               \n","                       [[[234941.1250]]],\n","               \n","               \n","                       [[[ 77766.5859]]],\n","               \n","               \n","                       [[[198184.8438]]],\n","               \n","               \n","                       [[[ 66825.0078]]],\n","               \n","               \n","                       [[[ 48153.7812]]],\n","               \n","               \n","                       [[[123440.1875]]],\n","               \n","               \n","                       [[[112974.8594]]],\n","               \n","               \n","                       [[[114077.7734]]],\n","               \n","               \n","                       [[[ 48466.8320]]],\n","               \n","               \n","                       [[[155961.9375]]],\n","               \n","               \n","                       [[[136045.8125]]],\n","               \n","               \n","                       [[[ 89812.2656]]],\n","               \n","               \n","                       [[[110228.2734]]],\n","               \n","               \n","                       [[[112024.6484]]],\n","               \n","               \n","                       [[[132086.7500]]],\n","               \n","               \n","                       [[[ 96097.1797]]],\n","               \n","               \n","                       [[[160055.4375]]],\n","               \n","               \n","                       [[[ 63861.2539]]],\n","               \n","               \n","                       [[[148539.6250]]],\n","               \n","               \n","                       [[[556132.8750]]],\n","               \n","               \n","                       [[[ 93991.5078]]],\n","               \n","               \n","                       [[[488196.2188]]],\n","               \n","               \n","                       [[[174419.4375]]],\n","               \n","               \n","                       [[[118383.3281]]],\n","               \n","               \n","                       [[[160083.7656]]],\n","               \n","               \n","                       [[[ 61582.4648]]],\n","               \n","               \n","                       [[[465757.5000]]],\n","               \n","               \n","                       [[[117956.1875]]],\n","               \n","               \n","                       [[[145788.1719]]],\n","               \n","               \n","                       [[[139929.6094]]],\n","               \n","               \n","                       [[[ 75546.6328]]]], device='cuda:0')),\n","              ('module.layer2.4.conv2.w_zero_point', tensor([[[[-44105.]]],\n","               \n","               \n","                       [[[-39258.]]],\n","               \n","               \n","                       [[[-29246.]]],\n","               \n","               \n","                       [[[-27562.]]],\n","               \n","               \n","                       [[[-35380.]]],\n","               \n","               \n","                       [[[-26764.]]],\n","               \n","               \n","                       [[[-32474.]]],\n","               \n","               \n","                       [[[-24547.]]],\n","               \n","               \n","                       [[[-31985.]]],\n","               \n","               \n","                       [[[-28609.]]],\n","               \n","               \n","                       [[[-28671.]]],\n","               \n","               \n","                       [[[-32846.]]],\n","               \n","               \n","                       [[[-26695.]]],\n","               \n","               \n","                       [[[-23337.]]],\n","               \n","               \n","                       [[[-28995.]]],\n","               \n","               \n","                       [[[-35237.]]],\n","               \n","               \n","                       [[[-32052.]]],\n","               \n","               \n","                       [[[-30724.]]],\n","               \n","               \n","                       [[[-24411.]]],\n","               \n","               \n","                       [[[-32454.]]],\n","               \n","               \n","                       [[[-29895.]]],\n","               \n","               \n","                       [[[-25862.]]],\n","               \n","               \n","                       [[[-26590.]]],\n","               \n","               \n","                       [[[-32970.]]],\n","               \n","               \n","                       [[[-31324.]]],\n","               \n","               \n","                       [[[-31543.]]],\n","               \n","               \n","                       [[[-31729.]]],\n","               \n","               \n","                       [[[-29248.]]],\n","               \n","               \n","                       [[[-33422.]]],\n","               \n","               \n","                       [[[-24973.]]],\n","               \n","               \n","                       [[[-40187.]]],\n","               \n","               \n","                       [[[-32353.]]]], device='cuda:0')),\n","              ('module.layer2.4.conv2.fp_bias',\n","               tensor([ 0.1699,  0.2111,  0.3886, -0.0138,  0.0418,  0.1615, -0.0459, -0.0528,\n","                       -0.1861,  0.0480, -0.0027, -0.1141, -0.2534, -0.2506,  0.0621,  0.0334,\n","                       -0.0391,  0.0665, -0.1875, -0.2606, -0.0215, -0.5219, -0.0069,  0.2185,\n","                        0.1208,  0.2163,  0.1820,  0.0770, -0.1374, -0.0480, -0.0300,  0.3144],\n","                      device='cuda:0')),\n","              ('module.layer2.4.conv2.accum_scale', tensor([[[3.8415e+09]],\n","               \n","                       [[1.0068e+10]],\n","               \n","                       [[3.3326e+09]],\n","               \n","                       [[8.4929e+09]],\n","               \n","                       [[2.8637e+09]],\n","               \n","                       [[2.0636e+09]],\n","               \n","                       [[5.2898e+09]],\n","               \n","                       [[4.8414e+09]],\n","               \n","                       [[4.8886e+09]],\n","               \n","                       [[2.0770e+09]],\n","               \n","                       [[6.6835e+09]],\n","               \n","                       [[5.8300e+09]],\n","               \n","                       [[3.8488e+09]],\n","               \n","                       [[4.7237e+09]],\n","               \n","                       [[4.8006e+09]],\n","               \n","                       [[5.6604e+09]],\n","               \n","                       [[4.1181e+09]],\n","               \n","                       [[6.8589e+09]],\n","               \n","                       [[2.7367e+09]],\n","               \n","                       [[6.3654e+09]],\n","               \n","                       [[2.3832e+10]],\n","               \n","                       [[4.0279e+09]],\n","               \n","                       [[2.0921e+10]],\n","               \n","                       [[7.4745e+09]],\n","               \n","                       [[5.0731e+09]],\n","               \n","                       [[6.8601e+09]],\n","               \n","                       [[2.6390e+09]],\n","               \n","                       [[1.9959e+10]],\n","               \n","                       [[5.0548e+09]],\n","               \n","                       [[6.2475e+09]],\n","               \n","                       [[5.9965e+09]],\n","               \n","                       [[3.2374e+09]]], device='cuda:0')),\n","              ('module.layer2.4.conv2.is_simulated_quant_weight_shifted',\n","               tensor(False, device='cuda:0')),\n","              ('module.layer2.4.conv2.wrapped_module.weight',\n","               tensor([[[[37642., 33364., 38662.],\n","                         [34373., 31354., 38827.],\n","                         [33360., 33038., 42231.]],\n","               \n","                        [[58924., 61751., 57155.],\n","                         [43183., 50473., 50434.],\n","                         [33187., 35863., 33939.]],\n","               \n","                        [[54914., 42797., 43317.],\n","                         [60701., 34841., 35696.],\n","                         [44076., 32498., 33146.]],\n","               \n","                        ...,\n","               \n","                        [[44858., 56933., 46837.],\n","                         [33690., 42848., 32171.],\n","                         [21534., 40042., 36312.]],\n","               \n","                        [[47854., 46269., 44703.],\n","                         [43310., 39214., 39900.],\n","                         [47392., 45228., 45229.]],\n","               \n","                        [[33548., 41672., 38606.],\n","                         [47160., 48666., 43076.],\n","                         [45872., 43840., 43140.]]],\n","               \n","               \n","                       [[[35939., 30668., 24087.],\n","                         [36398., 36991., 27437.],\n","                         [32997., 30327., 22858.]],\n","               \n","                        [[37350., 47038., 45240.],\n","                         [29720., 40300., 47686.],\n","                         [37139., 50939., 54048.]],\n","               \n","                        [[44784., 25685., 23628.],\n","                         [46816., 32985., 26968.],\n","                         [56212., 47586., 38738.]],\n","               \n","                        ...,\n","               \n","                        [[26531., 49503., 61746.],\n","                         [29683., 33874., 47351.],\n","                         [39052., 21726., 36356.]],\n","               \n","                        [[46672., 42760., 37154.],\n","                         [43318., 40499., 36332.],\n","                         [36589., 36855., 37294.]],\n","               \n","                        [[35023., 38804., 38914.],\n","                         [34910., 34824., 36403.],\n","                         [42095., 35227., 36884.]]],\n","               \n","               \n","                       [[[14399., 27152., 17445.],\n","                         [24102., 28879., 19392.],\n","                         [28412., 35448., 24299.]],\n","               \n","                        [[21115., 19297.,  8046.],\n","                         [18056., 14969., 11631.],\n","                         [20554., 12807.,  9565.]],\n","               \n","                        [[33168., 22238., 22852.],\n","                         [45130., 22743., 34883.],\n","                         [46349., 36294., 23287.]],\n","               \n","                        ...,\n","               \n","                        [[40143., 35226.,  9939.],\n","                         [27015., 32810., 15392.],\n","                         [16320., 31627., 46791.]],\n","               \n","                        [[30487., 20175., 20231.],\n","                         [29331., 26839., 24637.],\n","                         [30934., 28025., 27573.]],\n","               \n","                        [[31227., 28538., 25013.],\n","                         [22839., 26366., 25863.],\n","                         [16585., 22750., 26598.]]],\n","               \n","               \n","                       ...,\n","               \n","               \n","                       [[[35200., 27883., 29886.],\n","                         [24870., 19354., 17014.],\n","                         [30771., 30504., 23640.]],\n","               \n","                        [[32789., 36268., 30573.],\n","                         [41540., 33004., 27393.],\n","                         [33407., 24576., 30505.]],\n","               \n","                        [[ 4133.,     0., 26980.],\n","                         [27862., 21597., 29778.],\n","                         [21077.,  4548., 12065.]],\n","               \n","                        ...,\n","               \n","                        [[29519., 32075., 34730.],\n","                         [18639., 20131., 37843.],\n","                         [12198.,  8413., 23085.]],\n","               \n","                        [[17703., 16603., 20958.],\n","                         [15475., 15776., 18674.],\n","                         [17296., 17884., 17726.]],\n","               \n","                        [[22169., 19065., 25097.],\n","                         [24659., 22092., 25366.],\n","                         [15921., 23183., 27829.]]],\n","               \n","               \n","                       [[[33937., 38424., 41541.],\n","                         [33560., 33961., 37214.],\n","                         [25828., 29647., 24592.]],\n","               \n","                        [[38813., 42340., 39163.],\n","                         [44572., 36899., 38753.],\n","                         [40419., 32389., 36283.]],\n","               \n","                        [[32477., 27065., 24686.],\n","                         [48128., 31357., 31729.],\n","                         [52664., 27512., 40119.]],\n","               \n","                        ...,\n","               \n","                        [[39618., 45718., 44317.],\n","                         [48286., 39877., 35665.],\n","                         [37750., 34384., 20034.]],\n","               \n","                        [[38176., 41768., 44120.],\n","                         [38655., 36784., 33525.],\n","                         [38265., 35136., 29452.]],\n","               \n","                        [[26689., 37493., 42596.],\n","                         [26557., 35693., 44183.],\n","                         [32455., 37651., 43703.]]],\n","               \n","               \n","                       [[[32480., 28281., 24304.],\n","                         [24221., 17790., 15737.],\n","                         [39024., 26672., 15726.]],\n","               \n","                        [[26556., 21304., 18379.],\n","                         [41219., 38251., 25852.],\n","                         [38725., 43633., 36595.]],\n","               \n","                        [[27040., 30765., 40147.],\n","                         [37123., 36068., 37119.],\n","                         [32504., 35571., 30207.]],\n","               \n","                        ...,\n","               \n","                        [[ 6087.,  7761., 14085.],\n","                         [25378., 37597., 48567.],\n","                         [25354., 35338., 54173.]],\n","               \n","                        [[25351., 27956., 34268.],\n","                         [20789., 20225., 27590.],\n","                         [22651., 23746., 22502.]],\n","               \n","                        [[22206., 29738., 24264.],\n","                         [31602., 31108., 30696.],\n","                         [43998., 45963., 41064.]]]], device='cuda:0')),\n","              ('module.layer2.4.conv2.wrapped_module.bias',\n","               tensor([ 6.5254e+08,  2.1255e+09,  1.2949e+09, -1.1707e+08,  1.1962e+08,\n","                        3.3317e+08, -2.4286e+08, -2.5571e+08, -9.0957e+08,  9.9756e+07,\n","                       -1.8050e+07, -6.6540e+08, -9.7530e+08, -1.1839e+09,  2.9796e+08,\n","                        1.8899e+08, -1.6105e+08,  4.5612e+08, -5.1305e+08, -1.6591e+09,\n","                       -5.1196e+08, -2.1021e+09, -1.4445e+08,  1.6330e+09,  6.1290e+08,\n","                        1.4837e+09,  4.8018e+08,  1.5377e+09, -6.9461e+08, -2.9995e+08,\n","                       -1.8001e+08,  1.0179e+09], device='cuda:0')),\n","              ('module.layer2.4.relu2.num_forwards',\n","               tensor([40], device='cuda:0')),\n","              ('module.layer2.4.relu2.force_readjust',\n","               tensor(False, device='cuda:0')),\n","              ('module.layer2.4.relu2.output_scale',\n","               tensor([7689.5796], device='cuda:0')),\n","              ('module.layer2.4.relu2.output_zero_point',\n","               tensor([0.], device='cuda:0')),\n","              ('module.layer2.4.residual_eltwiseadd.num_forwards',\n","               tensor([40], device='cuda:0')),\n","              ('module.layer2.4.residual_eltwiseadd.force_readjust',\n","               tensor(False, device='cuda:0')),\n","              ('module.layer2.4.residual_eltwiseadd.output_scale',\n","               tensor([7689.5796], device='cuda:0')),\n","              ('module.layer2.4.residual_eltwiseadd.output_zero_point',\n","               tensor([0.], device='cuda:0')),\n","              ('module.layer2.5.conv1.num_forwards',\n","               tensor([40], device='cuda:0')),\n","              ('module.layer2.5.conv1.force_readjust',\n","               tensor(False, device='cuda:0')),\n","              ('module.layer2.5.conv1.output_scale',\n","               tensor([42812.4023], device='cuda:0')),\n","              ('module.layer2.5.conv1.output_zero_point',\n","               tensor([0.], device='cuda:0')),\n","              ('module.layer2.5.conv1.w_scale', tensor([[[[ 964646.4375]]],\n","               \n","               \n","                       [[[1005046.0625]]],\n","               \n","               \n","                       [[[ 362102.4062]]],\n","               \n","               \n","                       [[[ 701727.5625]]],\n","               \n","               \n","                       [[[ 927719.5000]]],\n","               \n","               \n","                       [[[1371349.5000]]],\n","               \n","               \n","                       [[[ 782308.6250]]],\n","               \n","               \n","                       [[[1078463.6250]]],\n","               \n","               \n","                       [[[1101035.2500]]],\n","               \n","               \n","                       [[[ 822003.5625]]],\n","               \n","               \n","                       [[[ 849522.1250]]],\n","               \n","               \n","                       [[[ 761005.8750]]],\n","               \n","               \n","                       [[[ 751064.8125]]],\n","               \n","               \n","                       [[[ 392572.1875]]],\n","               \n","               \n","                       [[[ 542158.0000]]],\n","               \n","               \n","                       [[[1143104.5000]]],\n","               \n","               \n","                       [[[ 831532.3125]]],\n","               \n","               \n","                       [[[ 542239.1875]]],\n","               \n","               \n","                       [[[ 720743.9375]]],\n","               \n","               \n","                       [[[ 987991.7500]]],\n","               \n","               \n","                       [[[1069967.3750]]],\n","               \n","               \n","                       [[[1100375.5000]]],\n","               \n","               \n","                       [[[ 877726.8750]]],\n","               \n","               \n","                       [[[ 851084.8125]]],\n","               \n","               \n","                       [[[ 695844.1875]]],\n","               \n","               \n","                       [[[ 825930.0625]]],\n","               \n","               \n","                       [[[ 594082.2500]]],\n","               \n","               \n","                       [[[ 798184.8750]]],\n","               \n","               \n","                       [[[1596611.1250]]],\n","               \n","               \n","                       [[[1184409.6250]]],\n","               \n","               \n","                       [[[1075698.3750]]],\n","               \n","               \n","                       [[[ 838823.1875]]]], device='cuda:0')),\n","              ('module.layer2.5.conv1.w_zero_point', tensor([[[[-27585.]]],\n","               \n","               \n","                       [[[-30664.]]],\n","               \n","               \n","                       [[[-25128.]]],\n","               \n","               \n","                       [[[-27868.]]],\n","               \n","               \n","                       [[[-34124.]]],\n","               \n","               \n","                       [[[-28036.]]],\n","               \n","               \n","                       [[[-37731.]]],\n","               \n","               \n","                       [[[-30762.]]],\n","               \n","               \n","                       [[[-34206.]]],\n","               \n","               \n","                       [[[-24873.]]],\n","               \n","               \n","                       [[[-35703.]]],\n","               \n","               \n","                       [[[-29202.]]],\n","               \n","               \n","                       [[[-31557.]]],\n","               \n","               \n","                       [[[-29575.]]],\n","               \n","               \n","                       [[[-32230.]]],\n","               \n","               \n","                       [[[-35754.]]],\n","               \n","               \n","                       [[[-30139.]]],\n","               \n","               \n","                       [[[-27393.]]],\n","               \n","               \n","                       [[[-31961.]]],\n","               \n","               \n","                       [[[-28964.]]],\n","               \n","               \n","                       [[[-32994.]]],\n","               \n","               \n","                       [[[-38778.]]],\n","               \n","               \n","                       [[[-32888.]]],\n","               \n","               \n","                       [[[-29095.]]],\n","               \n","               \n","                       [[[-34999.]]],\n","               \n","               \n","                       [[[-29663.]]],\n","               \n","               \n","                       [[[-29858.]]],\n","               \n","               \n","                       [[[-32346.]]],\n","               \n","               \n","                       [[[-32714.]]],\n","               \n","               \n","                       [[[-27151.]]],\n","               \n","               \n","                       [[[-37144.]]],\n","               \n","               \n","                       [[[-31965.]]]], device='cuda:0')),\n","              ('module.layer2.5.conv1.fp_bias',\n","               tensor([ 0.2092,  0.1384,  0.1523,  0.0230,  0.3162,  0.0454,  0.1086, -0.5491,\n","                        0.3112, -1.3281,  0.6631, -0.4109,  0.1092,  0.0812,  0.3159,  0.8091,\n","                        0.3608,  0.6603, -0.0179, -0.8236,  0.0969,  0.1535,  0.3886, -0.2876,\n","                        0.4871, -0.0156, -0.0573, -0.4070,  0.2682, -0.7860,  0.7386,  0.0571],\n","                      device='cuda:0')),\n","              ('module.layer2.5.conv1.accum_scale', tensor([[[7.4177e+09]],\n","               \n","                       [[7.7284e+09]],\n","               \n","                       [[2.7844e+09]],\n","               \n","                       [[5.3960e+09]],\n","               \n","                       [[7.1338e+09]],\n","               \n","                       [[1.0545e+10]],\n","               \n","                       [[6.0156e+09]],\n","               \n","                       [[8.2929e+09]],\n","               \n","                       [[8.4665e+09]],\n","               \n","                       [[6.3209e+09]],\n","               \n","                       [[6.5325e+09]],\n","               \n","                       [[5.8518e+09]],\n","               \n","                       [[5.7754e+09]],\n","               \n","                       [[3.0187e+09]],\n","               \n","                       [[4.1690e+09]],\n","               \n","                       [[8.7900e+09]],\n","               \n","                       [[6.3941e+09]],\n","               \n","                       [[4.1696e+09]],\n","               \n","                       [[5.5422e+09]],\n","               \n","                       [[7.5972e+09]],\n","               \n","                       [[8.2276e+09]],\n","               \n","                       [[8.4614e+09]],\n","               \n","                       [[6.7494e+09]],\n","               \n","                       [[6.5445e+09]],\n","               \n","                       [[5.3507e+09]],\n","               \n","                       [[6.3511e+09]],\n","               \n","                       [[4.5682e+09]],\n","               \n","                       [[6.1377e+09]],\n","               \n","                       [[1.2277e+10]],\n","               \n","                       [[9.1076e+09]],\n","               \n","                       [[8.2717e+09]],\n","               \n","                       [[6.4502e+09]]], device='cuda:0')),\n","              ('module.layer2.5.conv1.is_simulated_quant_weight_shifted',\n","               tensor(False, device='cuda:0')),\n","              ('module.layer2.5.conv1.wrapped_module.weight',\n","               tensor([[[[25726., 35842., 41669.],\n","                         [31398., 55947., 65535.],\n","                         [40421., 56635., 55077.]],\n","               \n","                        [[39444., 39794., 53657.],\n","                         [45321., 47182., 54270.],\n","                         [32534., 27694., 26902.]],\n","               \n","                        [[14019., 12546., 13382.],\n","                         [16351., 12455., 15788.],\n","                         [10343.,  6038., 10797.]],\n","               \n","                        ...,\n","               \n","                        [[44839., 37382., 24776.],\n","                         [28592., 14481.,  9293.],\n","                         [31918., 14539.,   821.]],\n","               \n","                        [[12836., 35204., 26713.],\n","                         [ 9565., 20022., 19283.],\n","                         [ 6559., 14784., 21738.]],\n","               \n","                        [[33331., 36512., 37259.],\n","                         [22745., 20944., 21707.],\n","                         [27832., 22331., 23850.]]],\n","               \n","               \n","                       [[[32314., 29813., 13108.],\n","                         [39342., 30364., 16323.],\n","                         [40710., 39151.,  9552.]],\n","               \n","                        [[38853., 50170., 24966.],\n","                         [31283., 48239., 26489.],\n","                         [25570., 44305., 34741.]],\n","               \n","                        [[23506., 26963., 30048.],\n","                         [27317., 31256., 37071.],\n","                         [28328., 23637., 34666.]],\n","               \n","                        ...,\n","               \n","                        [[30607., 32618.,  2615.],\n","                         [39158., 29643.,  5278.],\n","                         [14353., 26787., 40761.]],\n","               \n","                        [[40906.,  6557., 24851.],\n","                         [59268., 24932., 21827.],\n","                         [65535., 28527., 26030.]],\n","               \n","                        [[25930., 38195., 43917.],\n","                         [24876., 42112., 54064.],\n","                         [29282., 33267., 40968.]]],\n","               \n","               \n","                       [[[25663., 25663., 24844.],\n","                         [24487., 28501., 28878.],\n","                         [21436., 23386., 15299.]],\n","               \n","                        [[34243., 22255., 22137.],\n","                         [33082., 24608., 31148.],\n","                         [27887., 32358., 29215.]],\n","               \n","                        [[22575., 15056., 17386.],\n","                         [23602., 15083., 14858.],\n","                         [29768., 37188., 23138.]],\n","               \n","                        ...,\n","               \n","                        [[15671., 28050., 22300.],\n","                         [17153., 10163., 20534.],\n","                         [26735., 11015., 28201.]],\n","               \n","                        [[19762., 34214., 22834.],\n","                         [10014., 27604., 16803.],\n","                         [28679., 41396., 32579.]],\n","               \n","                        [[10265., 17860., 24676.],\n","                         [23753., 23172., 25135.],\n","                         [36029., 34126., 27330.]]],\n","               \n","               \n","                       ...,\n","               \n","               \n","                       [[[12939., 12700., 28172.],\n","                         [20496., 27599., 30460.],\n","                         [27121., 24644., 26940.]],\n","               \n","                        [[35301., 56485., 34394.],\n","                         [30569., 46453., 38239.],\n","                         [25880., 36110., 19753.]],\n","               \n","                        [[21902., 18286.,  6500.],\n","                         [37449., 26565., 16544.],\n","                         [38355., 29489., 25633.]],\n","               \n","                        ...,\n","               \n","                        [[29071., 32079., 29191.],\n","                         [18982., 21695., 16918.],\n","                         [12599., 23992., 16281.]],\n","               \n","                        [[59260., 39319., 35677.],\n","                         [34917., 40689., 31108.],\n","                         [20942., 26393., 14035.]],\n","               \n","                        [[19697., 27782., 27637.],\n","                         [23965., 30253., 21277.],\n","                         [18721., 19538., 10197.]]],\n","               \n","               \n","                       [[[39439., 21826., 27533.],\n","                         [43673., 25339., 42946.],\n","                         [43825., 42973., 56529.]],\n","               \n","                        [[40112., 31042., 37461.],\n","                         [44397., 40008., 39430.],\n","                         [33304., 28897., 21994.]],\n","               \n","                        [[33232., 38803., 48002.],\n","                         [46845., 51116., 54304.],\n","                         [37321., 32817., 27811.]],\n","               \n","                        ...,\n","               \n","                        [[33118., 37413., 37808.],\n","                         [26172., 21168., 36001.],\n","                         [37512., 27029., 49529.]],\n","               \n","                        [[ 8549.,     0.,  7788.],\n","                         [18437.,  9210.,  5975.],\n","                         [32700., 18047., 20367.]],\n","               \n","                        [[31492., 26143., 30868.],\n","                         [34735., 26909., 28075.],\n","                         [54566., 44850., 46831.]]],\n","               \n","               \n","                       [[[20991., 10038., 17493.],\n","                         [40397., 27653., 23510.],\n","                         [45073., 26054., 28474.]],\n","               \n","                        [[40208., 36934., 44824.],\n","                         [53089., 35868., 43911.],\n","                         [15998.,  9163., 18010.]],\n","               \n","                        [[65535., 54745., 42686.],\n","                         [36861., 27852., 20503.],\n","                         [19175., 14256., 12910.]],\n","               \n","                        ...,\n","               \n","                        [[16540., 14252., 25350.],\n","                         [21686., 26872., 44222.],\n","                         [42118., 52620., 37474.]],\n","               \n","                        [[19790.,  2275., 17291.],\n","                         [32174., 15683., 26234.],\n","                         [34505., 26368., 33479.]],\n","               \n","                        [[34719., 44061., 39042.],\n","                         [34189., 38946., 32270.],\n","                         [29041., 26110., 24691.]]]], device='cuda:0')),\n","              ('module.layer2.5.conv1.wrapped_module.bias',\n","               tensor([ 1.5521e+09,  1.0693e+09,  4.2413e+08,  1.2437e+08,  2.1475e+09,\n","                        4.7893e+08,  6.5320e+08, -2.1475e+09,  2.1475e+09, -2.1475e+09,\n","                        2.1475e+09, -2.1475e+09,  6.3072e+08,  2.4505e+08,  1.3171e+09,\n","                        2.1475e+09,  2.1475e+09,  2.1475e+09, -9.9396e+07, -2.1475e+09,\n","                        7.9764e+08,  1.2987e+09,  2.1475e+09, -1.8819e+09,  2.1475e+09,\n","                       -9.9355e+07, -2.6160e+08, -2.1475e+09,  2.1475e+09, -2.1475e+09,\n","                        2.1475e+09,  3.6821e+08], device='cuda:0')),\n","              ('module.layer2.5.conv2.num_forwards',\n","               tensor([40], device='cuda:0')),\n","              ('module.layer2.5.conv2.force_readjust',\n","               tensor(False, device='cuda:0')),\n","              ('module.layer2.5.conv2.output_scale',\n","               tensor([17516.7715], device='cuda:0')),\n","              ('module.layer2.5.conv2.output_zero_point',\n","               tensor([-31611.], device='cuda:0')),\n","              ('module.layer2.5.conv2.w_scale', tensor([[[[234017.1719]]],\n","               \n","               \n","                       [[[ 99084.9844]]],\n","               \n","               \n","                       [[[103306.8750]]],\n","               \n","               \n","                       [[[220175.8125]]],\n","               \n","               \n","                       [[[ 86392.9531]]],\n","               \n","               \n","                       [[[ 77351.0469]]],\n","               \n","               \n","                       [[[126988.3906]]],\n","               \n","               \n","                       [[[ 68328.5469]]],\n","               \n","               \n","                       [[[ 98251.0312]]],\n","               \n","               \n","                       [[[176883.4531]]],\n","               \n","               \n","                       [[[127405.4766]]],\n","               \n","               \n","                       [[[103124.1328]]],\n","               \n","               \n","                       [[[ 92449.2891]]],\n","               \n","               \n","                       [[[280745.7812]]],\n","               \n","               \n","                       [[[160660.2344]]],\n","               \n","               \n","                       [[[117858.4453]]],\n","               \n","               \n","                       [[[ 62979.6172]]],\n","               \n","               \n","                       [[[168769.2969]]],\n","               \n","               \n","                       [[[105110.3125]]],\n","               \n","               \n","                       [[[139707.9062]]],\n","               \n","               \n","                       [[[151365.3438]]],\n","               \n","               \n","                       [[[123406.0781]]],\n","               \n","               \n","                       [[[355461.5000]]],\n","               \n","               \n","                       [[[119549.0859]]],\n","               \n","               \n","                       [[[161880.1250]]],\n","               \n","               \n","                       [[[ 96400.9531]]],\n","               \n","               \n","                       [[[114963.6953]]],\n","               \n","               \n","                       [[[145163.3906]]],\n","               \n","               \n","                       [[[182910.8594]]],\n","               \n","               \n","                       [[[114079.9922]]],\n","               \n","               \n","                       [[[139636.3438]]],\n","               \n","               \n","                       [[[ 69961.7656]]]], device='cuda:0')),\n","              ('module.layer2.5.conv2.w_zero_point', tensor([[[[-35890.]]],\n","               \n","               \n","                       [[[-26772.]]],\n","               \n","               \n","                       [[[-31844.]]],\n","               \n","               \n","                       [[[-33820.]]],\n","               \n","               \n","                       [[[-31535.]]],\n","               \n","               \n","                       [[[-28076.]]],\n","               \n","               \n","                       [[[-36505.]]],\n","               \n","               \n","                       [[[-28310.]]],\n","               \n","               \n","                       [[[-24323.]]],\n","               \n","               \n","                       [[[-30067.]]],\n","               \n","               \n","                       [[[-27587.]]],\n","               \n","               \n","                       [[[-29338.]]],\n","               \n","               \n","                       [[[-34284.]]],\n","               \n","               \n","                       [[[-35681.]]],\n","               \n","               \n","                       [[[-35899.]]],\n","               \n","               \n","                       [[[-26301.]]],\n","               \n","               \n","                       [[[-23467.]]],\n","               \n","               \n","                       [[[-37072.]]],\n","               \n","               \n","                       [[[-29430.]]],\n","               \n","               \n","                       [[[-36858.]]],\n","               \n","               \n","                       [[[-36030.]]],\n","               \n","               \n","                       [[[-36135.]]],\n","               \n","               \n","                       [[[-33109.]]],\n","               \n","               \n","                       [[[-33438.]]],\n","               \n","               \n","                       [[[-27759.]]],\n","               \n","               \n","                       [[[-24647.]]],\n","               \n","               \n","                       [[[-33162.]]],\n","               \n","               \n","                       [[[-32479.]]],\n","               \n","               \n","                       [[[-38121.]]],\n","               \n","               \n","                       [[[-33273.]]],\n","               \n","               \n","                       [[[-38558.]]],\n","               \n","               \n","                       [[[-26462.]]]], device='cuda:0')),\n","              ('module.layer2.5.conv2.fp_bias',\n","               tensor([ 0.0735, -0.0730,  0.1514, -0.0315,  0.0877,  0.1191,  0.1793,  0.1641,\n","                       -0.1921, -0.1782,  0.1482,  0.2608,  0.2009, -0.0217,  0.2327,  0.0951,\n","                        0.1332,  0.0996, -0.1860,  0.1566, -0.0861,  0.2062,  0.0094,  0.0814,\n","                        0.1158,  0.1114,  0.1489, -0.0020, -0.0876,  0.0035,  0.0613,  0.0110],\n","                      device='cuda:0')),\n","              ('module.layer2.5.conv2.accum_scale', tensor([[[1.0019e+10]],\n","               \n","                       [[4.2421e+09]],\n","               \n","                       [[4.4228e+09]],\n","               \n","                       [[9.4263e+09]],\n","               \n","                       [[3.6987e+09]],\n","               \n","                       [[3.3116e+09]],\n","               \n","                       [[5.4367e+09]],\n","               \n","                       [[2.9253e+09]],\n","               \n","                       [[4.2064e+09]],\n","               \n","                       [[7.5728e+09]],\n","               \n","                       [[5.4545e+09]],\n","               \n","                       [[4.4150e+09]],\n","               \n","                       [[3.9580e+09]],\n","               \n","                       [[1.2019e+10]],\n","               \n","                       [[6.8783e+09]],\n","               \n","                       [[5.0458e+09]],\n","               \n","                       [[2.6963e+09]],\n","               \n","                       [[7.2254e+09]],\n","               \n","                       [[4.5000e+09]],\n","               \n","                       [[5.9812e+09]],\n","               \n","                       [[6.4803e+09]],\n","               \n","                       [[5.2833e+09]],\n","               \n","                       [[1.5218e+10]],\n","               \n","                       [[5.1182e+09]],\n","               \n","                       [[6.9305e+09]],\n","               \n","                       [[4.1272e+09]],\n","               \n","                       [[4.9219e+09]],\n","               \n","                       [[6.2148e+09]],\n","               \n","                       [[7.8309e+09]],\n","               \n","                       [[4.8840e+09]],\n","               \n","                       [[5.9782e+09]],\n","               \n","                       [[2.9952e+09]]], device='cuda:0')),\n","              ('module.layer2.5.conv2.is_simulated_quant_weight_shifted',\n","               tensor(False, device='cuda:0')),\n","              ('module.layer2.5.conv2.wrapped_module.weight',\n","               tensor([[[[19710., 36726., 36521.],\n","                         [29064., 52267., 46856.],\n","                         [24876., 36236., 37799.]],\n","               \n","                        [[20052., 28972., 29351.],\n","                         [27619., 41920., 40353.],\n","                         [49728., 57111., 51064.]],\n","               \n","                        [[30437., 24935., 61811.],\n","                         [27199., 36576., 52393.],\n","                         [42509., 42566., 42155.]],\n","               \n","                        ...,\n","               \n","                        [[31148., 26360., 21356.],\n","                         [23023., 24829., 21472.],\n","                         [25546., 35151., 35258.]],\n","               \n","                        [[29666., 34670., 28367.],\n","                         [36482., 41543., 31541.],\n","                         [33580., 39885., 36572.]],\n","               \n","                        [[15048.,  9203.,  4359.],\n","                         [10364.,  4598., 10648.],\n","                         [12800., 11337., 12152.]]],\n","               \n","               \n","                       [[[14630., 25202., 30099.],\n","                         [23103., 31343., 32683.],\n","                         [32070., 34608., 34623.]],\n","               \n","                        [[32134., 51438., 54234.],\n","                         [24032., 45223., 46552.],\n","                         [25217., 37996., 39755.]],\n","               \n","                        [[30494., 22235., 19048.],\n","                         [34364., 35183., 30667.],\n","                         [45247., 47985., 39972.]],\n","               \n","                        ...,\n","               \n","                        [[32290., 31071., 30422.],\n","                         [32165., 31152., 35159.],\n","                         [29387., 30007., 37655.]],\n","               \n","                        [[26294., 30440., 27989.],\n","                         [23300., 35163., 40373.],\n","                         [33731., 49631., 61231.]],\n","               \n","                        [[36601., 45636., 44859.],\n","                         [27116., 42703., 30822.],\n","                         [40789., 48296., 41082.]]],\n","               \n","               \n","                       [[[27777., 28387., 26450.],\n","                         [25679., 35165., 32213.],\n","                         [33655., 40175., 36113.]],\n","               \n","                        [[31890., 29156., 19029.],\n","                         [18968., 19535., 15491.],\n","                         [26865., 40960., 38713.]],\n","               \n","                        [[33306., 34720., 42401.],\n","                         [20995., 18428., 44218.],\n","                         [20902., 19357., 28693.]],\n","               \n","                        ...,\n","               \n","                        [[23812., 24955., 23699.],\n","                         [30270., 33291., 28369.],\n","                         [39065., 39436., 31023.]],\n","               \n","                        [[22585., 20229., 28526.],\n","                         [24519., 28638., 36238.],\n","                         [35435., 42531., 44919.]],\n","               \n","                        [[16389., 27626., 35317.],\n","                         [25419., 28561., 25669.],\n","                         [29950., 26933., 28111.]]],\n","               \n","               \n","                       ...,\n","               \n","               \n","                       [[[32325., 36646., 34054.],\n","                         [32680., 26438., 33467.],\n","                         [31591., 32155., 36573.]],\n","               \n","                        [[51391., 48303., 35406.],\n","                         [44843., 34957., 31744.],\n","                         [32221., 22084., 20146.]],\n","               \n","                        [[59529., 34626., 26961.],\n","                         [61061., 47237., 26118.],\n","                         [65535., 49202., 27519.]],\n","               \n","                        ...,\n","               \n","                        [[29998., 22899., 19425.],\n","                         [37629., 28915., 23496.],\n","                         [41664., 29349., 24885.]],\n","               \n","                        [[27414., 34515., 31799.],\n","                         [31091., 36260., 31052.],\n","                         [28945., 30691., 27633.]],\n","               \n","                        [[33198., 53623., 34603.],\n","                         [36741., 39237., 37200.],\n","                         [29032., 22249., 27324.]]],\n","               \n","               \n","                       [[[27353., 25198., 34924.],\n","                         [26652., 27687., 38310.],\n","                         [29210., 33416., 42299.]],\n","               \n","                        [[50227., 40920., 29419.],\n","                         [40738., 32295., 39081.],\n","                         [33225., 36032., 33065.]],\n","               \n","                        [[23941., 22368., 15441.],\n","                         [33334., 39903., 36424.],\n","                         [33959., 35362., 50981.]],\n","               \n","                        ...,\n","               \n","                        [[30002., 25838., 25296.],\n","                         [30379., 24950., 19916.],\n","                         [35358., 32201., 28317.]],\n","               \n","                        [[29005., 34157., 42309.],\n","                         [34855., 35002., 41730.],\n","                         [33354., 25045., 25224.]],\n","               \n","                        [[50653., 50060., 36155.],\n","                         [39646., 39633., 37436.],\n","                         [27708., 37377., 37579.]]],\n","               \n","               \n","                       [[[25725., 25586., 27399.],\n","                         [29901., 29096., 31082.],\n","                         [29273., 32788., 33725.]],\n","               \n","                        [[22511., 29451., 17309.],\n","                         [23316., 22173., 22030.],\n","                         [31425., 23548., 25515.]],\n","               \n","                        [[45211., 37574., 50447.],\n","                         [27116., 29514., 47076.],\n","                         [ 3103.,   395.,     0.]],\n","               \n","                        ...,\n","               \n","                        [[24133., 22946., 23131.],\n","                         [19602., 16763., 18360.],\n","                         [22386., 24945., 22272.]],\n","               \n","                        [[23908., 23231., 26922.],\n","                         [28651., 25391., 25130.],\n","                         [23039., 23204., 17012.]],\n","               \n","                        [[32877., 36975., 44413.],\n","                         [22153., 39005., 45046.],\n","                         [25228., 32264., 41607.]]]], device='cuda:0')),\n","              ('module.layer2.5.conv2.wrapped_module.bias',\n","               tensor([ 7.3674e+08, -3.0962e+08,  6.6940e+08, -2.9717e+08,  3.2441e+08,\n","                        3.9433e+08,  9.7486e+08,  4.8004e+08, -8.0816e+08, -1.3492e+09,\n","                        8.0823e+08,  1.1513e+09,  7.9497e+08, -2.6122e+08,  1.6005e+09,\n","                        4.7983e+08,  3.5903e+08,  7.1983e+08, -8.3720e+08,  9.3690e+08,\n","                       -5.5811e+08,  1.0895e+09,  1.4257e+08,  4.1663e+08,  8.0224e+08,\n","                        4.5987e+08,  7.3282e+08, -1.2186e+07, -6.8587e+08,  1.6996e+07,\n","                        3.6644e+08,  3.2999e+07], device='cuda:0')),\n","              ('module.layer2.5.relu2.num_forwards',\n","               tensor([40], device='cuda:0')),\n","              ('module.layer2.5.relu2.force_readjust',\n","               tensor(False, device='cuda:0')),\n","              ('module.layer2.5.relu2.output_scale',\n","               tensor([7574.8726], device='cuda:0')),\n","              ('module.layer2.5.relu2.output_zero_point',\n","               tensor([0.], device='cuda:0')),\n","              ('module.layer2.5.residual_eltwiseadd.num_forwards',\n","               tensor([40], device='cuda:0')),\n","              ('module.layer2.5.residual_eltwiseadd.force_readjust',\n","               tensor(False, device='cuda:0')),\n","              ('module.layer2.5.residual_eltwiseadd.output_scale',\n","               tensor([7574.8726], device='cuda:0')),\n","              ('module.layer2.5.residual_eltwiseadd.output_zero_point',\n","               tensor([0.], device='cuda:0')),\n","              ('module.layer2.6.conv1.num_forwards',\n","               tensor([40], device='cuda:0')),\n","              ('module.layer2.6.conv1.force_readjust',\n","               tensor(False, device='cuda:0')),\n","              ('module.layer2.6.conv1.output_scale',\n","               tensor([49045.9023], device='cuda:0')),\n","              ('module.layer2.6.conv1.output_zero_point',\n","               tensor([0.], device='cuda:0')),\n","              ('module.layer2.6.conv1.w_scale', tensor([[[[ 958206.5625]]],\n","               \n","               \n","                       [[[ 494686.2500]]],\n","               \n","               \n","                       [[[ 757487.3750]]],\n","               \n","               \n","                       [[[ 766828.2500]]],\n","               \n","               \n","                       [[[ 805352.3750]]],\n","               \n","               \n","                       [[[ 922051.0625]]],\n","               \n","               \n","                       [[[ 812904.7500]]],\n","               \n","               \n","                       [[[ 805316.2500]]],\n","               \n","               \n","                       [[[ 724920.9375]]],\n","               \n","               \n","                       [[[ 659778.0000]]],\n","               \n","               \n","                       [[[ 786904.5000]]],\n","               \n","               \n","                       [[[ 706451.1875]]],\n","               \n","               \n","                       [[[1234552.7500]]],\n","               \n","               \n","                       [[[ 995339.8750]]],\n","               \n","               \n","                       [[[1399217.1250]]],\n","               \n","               \n","                       [[[ 937189.2500]]],\n","               \n","               \n","                       [[[ 834768.4375]]],\n","               \n","               \n","                       [[[ 722856.1250]]],\n","               \n","               \n","                       [[[ 711071.6250]]],\n","               \n","               \n","                       [[[ 624477.4375]]],\n","               \n","               \n","                       [[[1442224.5000]]],\n","               \n","               \n","                       [[[ 914763.1250]]],\n","               \n","               \n","                       [[[ 924478.7500]]],\n","               \n","               \n","                       [[[ 658503.2500]]],\n","               \n","               \n","                       [[[ 591529.8750]]],\n","               \n","               \n","                       [[[ 925720.5625]]],\n","               \n","               \n","                       [[[ 998300.3750]]],\n","               \n","               \n","                       [[[ 596905.6250]]],\n","               \n","               \n","                       [[[1349684.0000]]],\n","               \n","               \n","                       [[[ 461812.0625]]],\n","               \n","               \n","                       [[[ 588461.3750]]],\n","               \n","               \n","                       [[[1349670.8750]]]], device='cuda:0')),\n","              ('module.layer2.6.conv1.w_zero_point', tensor([[[[-28905.]]],\n","               \n","               \n","                       [[[-25550.]]],\n","               \n","               \n","                       [[[-32502.]]],\n","               \n","               \n","                       [[[-27194.]]],\n","               \n","               \n","                       [[[-34277.]]],\n","               \n","               \n","                       [[[-32076.]]],\n","               \n","               \n","                       [[[-24848.]]],\n","               \n","               \n","                       [[[-28907.]]],\n","               \n","               \n","                       [[[-27027.]]],\n","               \n","               \n","                       [[[-27219.]]],\n","               \n","               \n","                       [[[-32561.]]],\n","               \n","               \n","                       [[[-32318.]]],\n","               \n","               \n","                       [[[-34313.]]],\n","               \n","               \n","                       [[[-35148.]]],\n","               \n","               \n","                       [[[-28131.]]],\n","               \n","               \n","                       [[[-35682.]]],\n","               \n","               \n","                       [[[-28036.]]],\n","               \n","               \n","                       [[[-29122.]]],\n","               \n","               \n","                       [[[-22339.]]],\n","               \n","               \n","                       [[[-32520.]]],\n","               \n","               \n","                       [[[-26700.]]],\n","               \n","               \n","                       [[[-27101.]]],\n","               \n","               \n","                       [[[-28834.]]],\n","               \n","               \n","                       [[[-27103.]]],\n","               \n","               \n","                       [[[-26879.]]],\n","               \n","               \n","                       [[[-32409.]]],\n","               \n","               \n","                       [[[-26505.]]],\n","               \n","               \n","                       [[[-32819.]]],\n","               \n","               \n","                       [[[-30705.]]],\n","               \n","               \n","                       [[[-27823.]]],\n","               \n","               \n","                       [[[-32072.]]],\n","               \n","               \n","                       [[[-30385.]]]], device='cuda:0')),\n","              ('module.layer2.6.conv1.fp_bias',\n","               tensor([-0.1172, -0.4433, -0.2534, -0.5116,  0.2642,  0.1202, -0.6605,  0.2568,\n","                       -0.3979,  0.5049, -0.6309,  0.2085, -0.0523, -0.0595, -0.0711,  0.2638,\n","                        0.2084, -0.0076, -0.0304, -0.2647, -0.2975, -0.1163,  0.0436,  0.1713,\n","                        0.2284,  0.2147,  0.1033, -0.0682, -0.0064,  0.1437, -0.1300, -0.3293],\n","                      device='cuda:0')),\n","              ('module.layer2.6.conv1.accum_scale', tensor([[[7.2583e+09]],\n","               \n","                       [[3.7472e+09]],\n","               \n","                       [[5.7379e+09]],\n","               \n","                       [[5.8086e+09]],\n","               \n","                       [[6.1004e+09]],\n","               \n","                       [[6.9844e+09]],\n","               \n","                       [[6.1576e+09]],\n","               \n","                       [[6.1002e+09]],\n","               \n","                       [[5.4912e+09]],\n","               \n","                       [[4.9977e+09]],\n","               \n","                       [[5.9607e+09]],\n","               \n","                       [[5.3513e+09]],\n","               \n","                       [[9.3516e+09]],\n","               \n","                       [[7.5396e+09]],\n","               \n","                       [[1.0599e+10]],\n","               \n","                       [[7.0991e+09]],\n","               \n","                       [[6.3233e+09]],\n","               \n","                       [[5.4755e+09]],\n","               \n","                       [[5.3863e+09]],\n","               \n","                       [[4.7303e+09]],\n","               \n","                       [[1.0925e+10]],\n","               \n","                       [[6.9292e+09]],\n","               \n","                       [[7.0028e+09]],\n","               \n","                       [[4.9881e+09]],\n","               \n","                       [[4.4808e+09]],\n","               \n","                       [[7.0122e+09]],\n","               \n","                       [[7.5620e+09]],\n","               \n","                       [[4.5215e+09]],\n","               \n","                       [[1.0224e+10]],\n","               \n","                       [[3.4982e+09]],\n","               \n","                       [[4.4575e+09]],\n","               \n","                       [[1.0224e+10]]], device='cuda:0')),\n","              ('module.layer2.6.conv1.is_simulated_quant_weight_shifted',\n","               tensor(False, device='cuda:0')),\n","              ('module.layer2.6.conv1.wrapped_module.weight',\n","               tensor([[[[14542., 19552., 23025.],\n","                         [14652., 15278., 19168.],\n","                         [10109.,  1016., 12002.]],\n","               \n","                        [[23849., 30542., 29957.],\n","                         [34944., 32799., 20374.],\n","                         [40591., 35544., 23498.]],\n","               \n","                        [[50999., 48211., 30258.],\n","                         [47720., 36239.,  9890.],\n","                         [26748., 13774.,     0.]],\n","               \n","                        ...,\n","               \n","                        [[38793., 32371., 33184.],\n","                         [50600., 45413., 44002.],\n","                         [50332., 50933., 33977.]],\n","               \n","                        [[17639.,  8996., 13651.],\n","                         [21981., 22518., 24220.],\n","                         [22340., 15598., 37638.]],\n","               \n","                        [[34521., 36720., 34761.],\n","                         [29091., 33689., 32565.],\n","                         [33785., 36406., 29470.]]],\n","               \n","               \n","                       [[[24297., 28131., 32774.],\n","                         [32696., 36224., 31243.],\n","                         [15516., 23703., 10494.]],\n","               \n","                        [[30190., 24468., 21877.],\n","                         [39476., 47476., 38815.],\n","                         [30537., 39628., 33555.]],\n","               \n","                        [[21897., 14133., 15340.],\n","                         [23382., 11733., 22735.],\n","                         [25236., 24480., 38944.]],\n","               \n","                        ...,\n","               \n","                        [[65535., 56281., 11619.],\n","                         [26783., 18320., 15004.],\n","                         [12863., 27536., 27937.]],\n","               \n","                        [[32484., 35000., 38449.],\n","                         [47907., 21161., 31905.],\n","                         [10527.,  9484., 10336.]],\n","               \n","                        [[ 5425.,     0., 22322.],\n","                         [24991., 13809., 26360.],\n","                         [38160., 31178., 31414.]]],\n","               \n","               \n","                       [[[18460., 18733., 24872.],\n","                         [27938., 24352., 21203.],\n","                         [28684., 41287., 22833.]],\n","               \n","                        [[28928., 41966., 28152.],\n","                         [42013., 44799., 21421.],\n","                         [33159., 36937., 24292.]],\n","               \n","                        [[24030., 20431.,  9553.],\n","                         [29212., 27775., 32128.],\n","                         [20055., 24762., 30769.]],\n","               \n","                        ...,\n","               \n","                        [[48286., 16415., 20595.],\n","                         [35640., 38802., 43014.],\n","                         [25509., 58595., 57893.]],\n","               \n","                        [[47869., 33578., 39433.],\n","                         [35913., 23965., 52760.],\n","                         [27384., 22817., 34800.]],\n","               \n","                        [[28412., 48777., 45728.],\n","                         [38278., 44718., 34274.],\n","                         [44776., 30343., 16160.]]],\n","               \n","               \n","                       ...,\n","               \n","               \n","                       [[[22727., 18847., 23611.],\n","                         [28032., 27701., 26789.],\n","                         [30040., 35073., 27436.]],\n","               \n","                        [[22058., 18564., 11485.],\n","                         [28341., 20821., 21196.],\n","                         [36842., 26334., 36971.]],\n","               \n","                        [[11165., 10823., 13471.],\n","                         [30175., 33093., 15440.],\n","                         [26254., 55642., 44456.]],\n","               \n","                        ...,\n","               \n","                        [[29279., 25057., 25818.],\n","                         [11133., 20458., 29989.],\n","                         [19456., 16815., 20344.]],\n","               \n","                        [[27613., 31546., 36904.],\n","                         [36481., 28930., 22868.],\n","                         [39443., 10648., 15299.]],\n","               \n","                        [[21990., 25592., 24238.],\n","                         [22807., 24734., 20136.],\n","                         [31488., 34381., 29769.]]],\n","               \n","               \n","                       [[[11514., 42938., 51920.],\n","                         [22877., 38401., 32278.],\n","                         [33324., 47619., 33373.]],\n","               \n","                        [[19448., 35304., 41543.],\n","                         [33293., 32942., 30857.],\n","                         [32194., 32988., 36934.]],\n","               \n","                        [[35336., 29616., 39663.],\n","                         [32866., 27803., 35256.],\n","                         [27724., 25961., 30744.]],\n","               \n","                        ...,\n","               \n","                        [[32822., 36219., 34237.],\n","                         [20798., 39131., 29365.],\n","                         [21873., 36528., 24018.]],\n","               \n","                        [[39368., 32571., 12785.],\n","                         [24573., 28986., 24033.],\n","                         [27313., 47483., 48365.]],\n","               \n","                        [[31335., 30306., 31202.],\n","                         [32830., 37056., 28343.],\n","                         [25757., 42562., 28887.]]],\n","               \n","               \n","                       [[[29123., 23992., 35436.],\n","                         [29296., 20444., 41603.],\n","                         [34716., 24933., 35839.]],\n","               \n","                        [[24443., 34244., 37026.],\n","                         [37607., 30237., 34335.],\n","                         [44008., 38233., 40262.]],\n","               \n","                        [[43116., 45315., 42526.],\n","                         [21029., 30106., 41440.],\n","                         [13471., 21614., 38607.]],\n","               \n","                        ...,\n","               \n","                        [[22178., 18456., 15047.],\n","                         [36900., 36271., 27134.],\n","                         [29524., 30666., 14160.]],\n","               \n","                        [[26093., 41632., 46436.],\n","                         [26684., 36618., 47206.],\n","                         [25111., 36209., 39278.]],\n","               \n","                        [[33892., 46569., 34289.],\n","                         [31032., 34581., 40484.],\n","                         [24098., 21960., 34256.]]]], device='cuda:0')),\n","              ('module.layer2.6.conv1.wrapped_module.bias',\n","               tensor([-8.5038e+08, -1.6612e+09, -1.4537e+09, -2.1475e+09,  1.6120e+09,\n","                        8.3963e+08, -2.1475e+09,  1.5665e+09, -2.1475e+09,  2.1475e+09,\n","                       -2.1475e+09,  1.1159e+09, -4.8897e+08, -4.4848e+08, -7.5377e+08,\n","                        1.8725e+09,  1.3179e+09, -4.1718e+07, -1.6398e+08, -1.2523e+09,\n","                       -2.1475e+09, -8.0562e+08,  3.0544e+08,  8.5428e+08,  1.0233e+09,\n","                        1.5054e+09,  7.8089e+08, -3.0840e+08, -6.5849e+07,  5.0261e+08,\n","                       -5.7961e+08, -2.1475e+09], device='cuda:0')),\n","              ('module.layer2.6.conv2.num_forwards',\n","               tensor([40], device='cuda:0')),\n","              ('module.layer2.6.conv2.force_readjust',\n","               tensor(False, device='cuda:0')),\n","              ('module.layer2.6.conv2.output_scale',\n","               tensor([15287.5342], device='cuda:0')),\n","              ('module.layer2.6.conv2.output_zero_point',\n","               tensor([-28704.], device='cuda:0')),\n","              ('module.layer2.6.conv2.w_scale', tensor([[[[153684.3281]]],\n","               \n","               \n","                       [[[121818.9375]]],\n","               \n","               \n","                       [[[101909.9531]]],\n","               \n","               \n","                       [[[107177.0078]]],\n","               \n","               \n","                       [[[100079.4688]]],\n","               \n","               \n","                       [[[ 59988.0547]]],\n","               \n","               \n","                       [[[129258.0234]]],\n","               \n","               \n","                       [[[132937.1562]]],\n","               \n","               \n","                       [[[ 51627.0859]]],\n","               \n","               \n","                       [[[ 64962.7812]]],\n","               \n","               \n","                       [[[118301.9062]]],\n","               \n","               \n","                       [[[ 97237.9453]]],\n","               \n","               \n","                       [[[ 38371.5664]]],\n","               \n","               \n","                       [[[154752.2031]]],\n","               \n","               \n","                       [[[ 52160.5352]]],\n","               \n","               \n","                       [[[206410.4688]]],\n","               \n","               \n","                       [[[ 78999.9453]]],\n","               \n","               \n","                       [[[ 78543.3828]]],\n","               \n","               \n","                       [[[ 49540.5391]]],\n","               \n","               \n","                       [[[ 83694.2500]]],\n","               \n","               \n","                       [[[ 95043.6172]]],\n","               \n","               \n","                       [[[189510.4531]]],\n","               \n","               \n","                       [[[202060.3906]]],\n","               \n","               \n","                       [[[ 98807.1328]]],\n","               \n","               \n","                       [[[143379.8594]]],\n","               \n","               \n","                       [[[117024.9141]]],\n","               \n","               \n","                       [[[ 47955.3789]]],\n","               \n","               \n","                       [[[531886.8750]]],\n","               \n","               \n","                       [[[101064.6172]]],\n","               \n","               \n","                       [[[ 54705.6914]]],\n","               \n","               \n","                       [[[148134.3594]]],\n","               \n","               \n","                       [[[ 94668.6562]]]], device='cuda:0')),\n","              ('module.layer2.6.conv2.w_zero_point', tensor([[[[-28236.]]],\n","               \n","               \n","                       [[[-31061.]]],\n","               \n","               \n","                       [[[-26816.]]],\n","               \n","               \n","                       [[[-31913.]]],\n","               \n","               \n","                       [[[-29305.]]],\n","               \n","               \n","                       [[[-32885.]]],\n","               \n","               \n","                       [[[-29781.]]],\n","               \n","               \n","                       [[[-40553.]]],\n","               \n","               \n","                       [[[-26976.]]],\n","               \n","               \n","                       [[[-26426.]]],\n","               \n","               \n","                       [[[-35157.]]],\n","               \n","               \n","                       [[[-33174.]]],\n","               \n","               \n","                       [[[-20857.]]],\n","               \n","               \n","                       [[[-24645.]]],\n","               \n","               \n","                       [[[-29969.]]],\n","               \n","               \n","                       [[[-32525.]]],\n","               \n","               \n","                       [[[-28567.]]],\n","               \n","               \n","                       [[[-36116.]]],\n","               \n","               \n","                       [[[-26682.]]],\n","               \n","               \n","                       [[[-31712.]]],\n","               \n","               \n","                       [[[-26111.]]],\n","               \n","               \n","                       [[[-36425.]]],\n","               \n","               \n","                       [[[-31388.]]],\n","               \n","               \n","                       [[[-28232.]]],\n","               \n","               \n","                       [[[-24325.]]],\n","               \n","               \n","                       [[[-31241.]]],\n","               \n","               \n","                       [[[-30811.]]],\n","               \n","               \n","                       [[[-38639.]]],\n","               \n","               \n","                       [[[-32897.]]],\n","               \n","               \n","                       [[[-38282.]]],\n","               \n","               \n","                       [[[-28515.]]],\n","               \n","               \n","                       [[[-29974.]]]], device='cuda:0')),\n","              ('module.layer2.6.conv2.fp_bias',\n","               tensor([ 0.0272,  0.0510,  0.1065, -0.1330,  0.1541,  0.2052, -0.1057,  0.0391,\n","                       -0.2168,  0.4455,  0.1220, -0.1260, -0.1394, -0.1448, -0.0823, -0.1370,\n","                       -0.2301,  0.0821, -0.4506,  0.1826, -0.2618,  0.1910, -0.0013,  0.0620,\n","                        0.1333,  0.0565, -0.3582,  0.0229, -0.1151,  0.1341, -0.0724,  0.0639],\n","                      device='cuda:0')),\n","              ('module.layer2.6.conv2.accum_scale', tensor([[[7.5376e+09]],\n","               \n","                       [[5.9747e+09]],\n","               \n","                       [[4.9983e+09]],\n","               \n","                       [[5.2566e+09]],\n","               \n","                       [[4.9085e+09]],\n","               \n","                       [[2.9422e+09]],\n","               \n","                       [[6.3396e+09]],\n","               \n","                       [[6.5200e+09]],\n","               \n","                       [[2.5321e+09]],\n","               \n","                       [[3.1862e+09]],\n","               \n","                       [[5.8022e+09]],\n","               \n","                       [[4.7691e+09]],\n","               \n","                       [[1.8820e+09]],\n","               \n","                       [[7.5900e+09]],\n","               \n","                       [[2.5583e+09]],\n","               \n","                       [[1.0124e+10]],\n","               \n","                       [[3.8746e+09]],\n","               \n","                       [[3.8522e+09]],\n","               \n","                       [[2.4298e+09]],\n","               \n","                       [[4.1049e+09]],\n","               \n","                       [[4.6615e+09]],\n","               \n","                       [[9.2947e+09]],\n","               \n","                       [[9.9102e+09]],\n","               \n","                       [[4.8461e+09]],\n","               \n","                       [[7.0322e+09]],\n","               \n","                       [[5.7396e+09]],\n","               \n","                       [[2.3520e+09]],\n","               \n","                       [[2.6087e+10]],\n","               \n","                       [[4.9568e+09]],\n","               \n","                       [[2.6831e+09]],\n","               \n","                       [[7.2654e+09]],\n","               \n","                       [[4.6431e+09]]], device='cuda:0')),\n","              ('module.layer2.6.conv2.is_simulated_quant_weight_shifted',\n","               tensor(False, device='cuda:0')),\n","              ('module.layer2.6.conv2.wrapped_module.weight',\n","               tensor([[[[38654., 38059., 37608.],\n","                         [45082., 31435., 18779.],\n","                         [36500., 24392.,  7609.]],\n","               \n","                        [[34613., 29624., 34593.],\n","                         [23576., 30201., 29428.],\n","                         [34707., 39810., 34628.]],\n","               \n","                        [[18652., 12289., 26992.],\n","                         [30711., 33968., 32321.],\n","                         [37171., 41055., 47429.]],\n","               \n","                        ...,\n","               \n","                        [[29051., 19691., 36976.],\n","                         [22908., 22018., 40302.],\n","                         [30272., 31473., 47434.]],\n","               \n","                        [[33311., 33150., 56619.],\n","                         [42300., 56472., 64483.],\n","                         [35614., 52906., 60249.]],\n","               \n","                        [[17840., 27941., 24221.],\n","                         [21311., 27888., 26633.],\n","                         [19833., 25243., 24684.]]],\n","               \n","               \n","                       [[[35968., 30947., 28523.],\n","                         [43292., 29881., 27233.],\n","                         [48768., 38118., 30411.]],\n","               \n","                        [[54316., 57270., 41968.],\n","                         [58464., 56688., 40297.],\n","                         [64096., 58663., 55381.]],\n","               \n","                        [[44027., 37849., 45692.],\n","                         [31894., 27126., 34778.],\n","                         [27798., 39535., 53077.]],\n","               \n","                        ...,\n","               \n","                        [[36353., 18775., 15535.],\n","                         [39858., 10683.,     0.],\n","                         [38061., 17067., 10181.]],\n","               \n","                        [[17942.,  9248.,  7424.],\n","                         [47380., 26984.,  4315.],\n","                         [54886., 35269., 20798.]],\n","               \n","                        [[27271., 39390., 32536.],\n","                         [30098., 37147., 34876.],\n","                         [39310., 34110., 29721.]]],\n","               \n","               \n","                       [[[15700., 23181., 29260.],\n","                         [22873., 30639., 35296.],\n","                         [26560., 33037., 42042.]],\n","               \n","                        [[19324., 29892., 31744.],\n","                         [23646., 25395., 43928.],\n","                         [22204., 31266., 43216.]],\n","               \n","                        [[37731., 36451., 26857.],\n","                         [35622., 26209., 24220.],\n","                         [25826., 19732., 27274.]],\n","               \n","                        ...,\n","               \n","                        [[38853., 63407., 47668.],\n","                         [42169., 65535., 55892.],\n","                         [30188., 55325., 44966.]],\n","               \n","                        [[ 9524., 10471., 26888.],\n","                         [    0., 18622., 26235.],\n","                         [21250., 39603., 39197.]],\n","               \n","                        [[31365., 30653., 37891.],\n","                         [31688., 33365., 38507.],\n","                         [27108., 31691., 36599.]]],\n","               \n","               \n","                       ...,\n","               \n","               \n","                       [[[31713., 30410., 32295.],\n","                         [30239., 40946., 41225.],\n","                         [29596., 41968., 45864.]],\n","               \n","                        [[56640., 49088., 35308.],\n","                         [53663., 52444., 46060.],\n","                         [52510., 48058., 42176.]],\n","               \n","                        [[38220., 42894., 41894.],\n","                         [50339., 55684., 55799.],\n","                         [50636., 55610., 47003.]],\n","               \n","                        ...,\n","               \n","                        [[27976., 32943., 32749.],\n","                         [33892., 31512., 38191.],\n","                         [42064., 21606., 22096.]],\n","               \n","                        [[41688., 37735., 24620.],\n","                         [47019., 20400., 15122.],\n","                         [26971.,     0.,  7229.]],\n","               \n","                        [[40392., 36934., 33314.],\n","                         [39200., 38512., 34138.],\n","                         [33869., 36577., 38486.]]],\n","               \n","               \n","                       [[[24703., 16115., 18189.],\n","                         [22097., 11060., 18758.],\n","                         [27174., 16217., 23412.]],\n","               \n","                        [[25684., 15373., 14671.],\n","                         [30831., 17889.,  9188.],\n","                         [38190., 35858., 31268.]],\n","               \n","                        [[35859., 36276., 22240.],\n","                         [49181., 46631., 34926.],\n","                         [52701., 46867., 28917.]],\n","               \n","                        ...,\n","               \n","                        [[56289., 38162., 23769.],\n","                         [31557., 30316., 25319.],\n","                         [22547., 47915., 51259.]],\n","               \n","                        [[17929., 12010., 18968.],\n","                         [17567.,  7636., 26987.],\n","                         [24961., 24836., 44898.]],\n","               \n","                        [[15972., 26105., 33429.],\n","                         [17672., 23645., 28186.],\n","                         [23063., 27272., 23963.]]],\n","               \n","               \n","                       [[[31173., 28031., 29701.],\n","                         [38928., 48395., 55843.],\n","                         [33490., 51733., 54853.]],\n","               \n","                        [[33818., 28197., 16160.],\n","                         [13036., 11769.,  5781.],\n","                         [12262., 15174., 14234.]],\n","               \n","                        [[13682., 11068.,     0.],\n","                         [ 7954., 14653., 10053.],\n","                         [20142., 26056., 22731.]],\n","               \n","                        ...,\n","               \n","                        [[50300., 49561., 65535.],\n","                         [15747., 21574., 34425.],\n","                         [17708., 14923., 13682.]],\n","               \n","                        [[47146., 45018., 30503.],\n","                         [39663., 52724., 42249.],\n","                         [28191., 41669., 38166.]],\n","               \n","                        [[22514., 28456., 32292.],\n","                         [23919., 29186., 30268.],\n","                         [19034., 23354., 28964.]]]], device='cuda:0')),\n","              ('module.layer2.6.conv2.wrapped_module.bias',\n","               tensor([ 2.0538e+08,  3.0453e+08,  5.3255e+08, -6.9939e+08,  7.5626e+08,\n","                        6.0363e+08, -6.7034e+08,  2.5520e+08, -5.4900e+08,  1.4193e+09,\n","                        7.0788e+08, -6.0115e+08, -2.6238e+08, -1.0994e+09, -2.1056e+08,\n","                       -1.3869e+09, -8.9164e+08,  3.1617e+08, -1.0948e+09,  7.4949e+08,\n","                       -1.2202e+09,  1.7749e+09, -1.3262e+07,  3.0053e+08,  9.3739e+08,\n","                        3.2422e+08, -8.4237e+08,  5.9838e+08, -5.7061e+08,  3.5981e+08,\n","                       -5.2606e+08,  2.9647e+08], device='cuda:0')),\n","              ('module.layer2.6.relu2.num_forwards',\n","               tensor([40], device='cuda:0')),\n","              ('module.layer2.6.relu2.force_readjust',\n","               tensor(False, device='cuda:0')),\n","              ('module.layer2.6.relu2.output_scale',\n","               tensor([7246.3657], device='cuda:0')),\n","              ('module.layer2.6.relu2.output_zero_point',\n","               tensor([0.], device='cuda:0')),\n","              ('module.layer2.6.residual_eltwiseadd.num_forwards',\n","               tensor([40], device='cuda:0')),\n","              ('module.layer2.6.residual_eltwiseadd.force_readjust',\n","               tensor(False, device='cuda:0')),\n","              ('module.layer2.6.residual_eltwiseadd.output_scale',\n","               tensor([7246.3657], device='cuda:0')),\n","              ('module.layer2.6.residual_eltwiseadd.output_zero_point',\n","               tensor([0.], device='cuda:0')),\n","              ('module.layer2.7.conv1.num_forwards',\n","               tensor([40], device='cuda:0')),\n","              ('module.layer2.7.conv1.force_readjust',\n","               tensor(False, device='cuda:0')),\n","              ('module.layer2.7.conv1.output_scale',\n","               tensor([54129.7930], device='cuda:0')),\n","              ('module.layer2.7.conv1.output_zero_point',\n","               tensor([0.], device='cuda:0')),\n","              ('module.layer2.7.conv1.w_scale', tensor([[[[1558497.0000]]],\n","               \n","               \n","                       [[[ 708035.9375]]],\n","               \n","               \n","                       [[[ 636286.6875]]],\n","               \n","               \n","                       [[[1502478.1250]]],\n","               \n","               \n","                       [[[1440258.5000]]],\n","               \n","               \n","                       [[[2409394.0000]]],\n","               \n","               \n","                       [[[ 778509.0000]]],\n","               \n","               \n","                       [[[ 700810.8750]]],\n","               \n","               \n","                       [[[ 845695.9375]]],\n","               \n","               \n","                       [[[1134163.6250]]],\n","               \n","               \n","                       [[[ 900134.6250]]],\n","               \n","               \n","                       [[[1660335.6250]]],\n","               \n","               \n","                       [[[1279321.6250]]],\n","               \n","               \n","                       [[[1343476.3750]]],\n","               \n","               \n","                       [[[ 797340.8125]]],\n","               \n","               \n","                       [[[1584233.5000]]],\n","               \n","               \n","                       [[[1220224.7500]]],\n","               \n","               \n","                       [[[ 940304.4375]]],\n","               \n","               \n","                       [[[ 969666.3125]]],\n","               \n","               \n","                       [[[ 740277.3125]]],\n","               \n","               \n","                       [[[ 747194.8750]]],\n","               \n","               \n","                       [[[ 584203.8125]]],\n","               \n","               \n","                       [[[ 574655.1875]]],\n","               \n","               \n","                       [[[1250889.1250]]],\n","               \n","               \n","                       [[[ 945172.6875]]],\n","               \n","               \n","                       [[[1264240.5000]]],\n","               \n","               \n","                       [[[ 772152.5000]]],\n","               \n","               \n","                       [[[ 854772.4375]]],\n","               \n","               \n","                       [[[1010017.1250]]],\n","               \n","               \n","                       [[[ 647296.2500]]],\n","               \n","               \n","                       [[[1272549.5000]]],\n","               \n","               \n","                       [[[ 994992.0625]]]], device='cuda:0')),\n","              ('module.layer2.7.conv1.w_zero_point', tensor([[[[-27594.]]],\n","               \n","               \n","                       [[[-29441.]]],\n","               \n","               \n","                       [[[-33243.]]],\n","               \n","               \n","                       [[[-32446.]]],\n","               \n","               \n","                       [[[-31582.]]],\n","               \n","               \n","                       [[[-35095.]]],\n","               \n","               \n","                       [[[-30569.]]],\n","               \n","               \n","                       [[[-30943.]]],\n","               \n","               \n","                       [[[-34657.]]],\n","               \n","               \n","                       [[[-23994.]]],\n","               \n","               \n","                       [[[-28970.]]],\n","               \n","               \n","                       [[[-32385.]]],\n","               \n","               \n","                       [[[-29125.]]],\n","               \n","               \n","                       [[[-32315.]]],\n","               \n","               \n","                       [[[-29987.]]],\n","               \n","               \n","                       [[[-30376.]]],\n","               \n","               \n","                       [[[-30160.]]],\n","               \n","               \n","                       [[[-32126.]]],\n","               \n","               \n","                       [[[-32342.]]],\n","               \n","               \n","                       [[[-33362.]]],\n","               \n","               \n","                       [[[-30368.]]],\n","               \n","               \n","                       [[[-25495.]]],\n","               \n","               \n","                       [[[-24489.]]],\n","               \n","               \n","                       [[[-32752.]]],\n","               \n","               \n","                       [[[-27840.]]],\n","               \n","               \n","                       [[[-24135.]]],\n","               \n","               \n","                       [[[-37397.]]],\n","               \n","               \n","                       [[[-31207.]]],\n","               \n","               \n","                       [[[-33291.]]],\n","               \n","               \n","                       [[[-28725.]]],\n","               \n","               \n","                       [[[-31116.]]],\n","               \n","               \n","                       [[[-32447.]]]], device='cuda:0')),\n","              ('module.layer2.7.conv1.fp_bias',\n","               tensor([-0.3439,  0.3228,  0.5181,  0.0259, -0.4062, -0.1100, -0.1551,  0.2000,\n","                        0.0182,  0.0598, -0.7050, -0.1906, -0.2341,  0.2808, -0.0362, -0.3267,\n","                       -0.2483,  0.0514,  0.1346,  0.2173,  0.2908, -0.3498, -0.3427,  0.0438,\n","                        0.0867, -0.2656,  0.0744,  0.1707,  0.3964,  0.2025,  0.0871, -0.1121],\n","                      device='cuda:0')),\n","              ('module.layer2.7.conv1.accum_scale', tensor([[[1.1293e+10]],\n","               \n","                       [[5.1307e+09]],\n","               \n","                       [[4.6108e+09]],\n","               \n","                       [[1.0888e+10]],\n","               \n","                       [[1.0437e+10]],\n","               \n","                       [[1.7459e+10]],\n","               \n","                       [[5.6414e+09]],\n","               \n","                       [[5.0783e+09]],\n","               \n","                       [[6.1282e+09]],\n","               \n","                       [[8.2186e+09]],\n","               \n","                       [[6.5227e+09]],\n","               \n","                       [[1.2031e+10]],\n","               \n","                       [[9.2704e+09]],\n","               \n","                       [[9.7353e+09]],\n","               \n","                       [[5.7778e+09]],\n","               \n","                       [[1.1480e+10]],\n","               \n","                       [[8.8422e+09]],\n","               \n","                       [[6.8138e+09]],\n","               \n","                       [[7.0266e+09]],\n","               \n","                       [[5.3643e+09]],\n","               \n","                       [[5.4144e+09]],\n","               \n","                       [[4.2334e+09]],\n","               \n","                       [[4.1642e+09]],\n","               \n","                       [[9.0644e+09]],\n","               \n","                       [[6.8491e+09]],\n","               \n","                       [[9.1611e+09]],\n","               \n","                       [[5.5953e+09]],\n","               \n","                       [[6.1940e+09]],\n","               \n","                       [[7.3190e+09]],\n","               \n","                       [[4.6905e+09]],\n","               \n","                       [[9.2214e+09]],\n","               \n","                       [[7.2101e+09]]], device='cuda:0')),\n","              ('module.layer2.7.conv1.is_simulated_quant_weight_shifted',\n","               tensor(False, device='cuda:0')),\n","              ('module.layer2.7.conv1.wrapped_module.weight',\n","               tensor([[[[32701., 24546., 25926.],\n","                         [24365., 23477., 23220.],\n","                         [17257., 32257., 38717.]],\n","               \n","                        [[32283., 30853., 38608.],\n","                         [40653., 55616., 54221.],\n","                         [23612., 31782., 31395.]],\n","               \n","                        [[24474., 27349., 33110.],\n","                         [37296., 34375., 34861.],\n","                         [33111., 25314., 28455.]],\n","               \n","                        ...,\n","               \n","                        [[45304., 15434.,     0.],\n","                         [24847., 14794., 10502.],\n","                         [23706., 29618., 35838.]],\n","               \n","                        [[ 1587., 18361., 28719.],\n","                         [22166., 16204., 26734.],\n","                         [42103., 30873., 26306.]],\n","               \n","                        [[28007., 25064., 18811.],\n","                         [21769., 22892., 24358.],\n","                         [25281., 25492., 24278.]]],\n","               \n","               \n","                       [[[16890., 17577., 27038.],\n","                         [14880., 23227., 29506.],\n","                         [23542., 42442., 32034.]],\n","               \n","                        [[21188., 31922., 27580.],\n","                         [30582., 37887., 27778.],\n","                         [29033., 40521., 28864.]],\n","               \n","                        [[13973., 27255., 26314.],\n","                         [31919., 35109., 26121.],\n","                         [49553., 30999., 18653.]],\n","               \n","                        ...,\n","               \n","                        [[20089., 34405., 47243.],\n","                         [10459., 15385., 36399.],\n","                         [12891., 14919., 20057.]],\n","               \n","                        [[27967., 23817., 26134.],\n","                         [39349., 33598., 51546.],\n","                         [31740., 23607., 45115.]],\n","               \n","                        [[19646., 17152., 13405.],\n","                         [41552., 27335., 14477.],\n","                         [40519., 25890., 15696.]]],\n","               \n","               \n","                       [[[35823., 48229., 36620.],\n","                         [45364., 33857., 22616.],\n","                         [21927., 24432., 38261.]],\n","               \n","                        [[42584., 19903., 14791.],\n","                         [26937., 18421., 20223.],\n","                         [34837., 37572., 33057.]],\n","               \n","                        [[17744., 20640., 24400.],\n","                         [27954., 26873., 30475.],\n","                         [38293., 34940., 49154.]],\n","               \n","                        ...,\n","               \n","                        [[20350., 48203., 17765.],\n","                         [49901., 51215., 32491.],\n","                         [25883., 15461., 38065.]],\n","               \n","                        [[25130., 28836., 28403.],\n","                         [28911., 15811.,  4097.],\n","                         [38733., 17477., 27848.]],\n","               \n","                        [[26453., 17782., 28245.],\n","                         [27696., 26677., 36448.],\n","                         [40672., 43964., 41456.]]],\n","               \n","               \n","                       ...,\n","               \n","               \n","                       [[[24114., 27459., 49131.],\n","                         [13287.,  8533., 21639.],\n","                         [19979., 20622., 18115.]],\n","               \n","                        [[16110., 17927., 19499.],\n","                         [27422., 29602., 33530.],\n","                         [33506., 16104., 23352.]],\n","               \n","                        [[31461., 50021., 43383.],\n","                         [33628., 34087., 32350.],\n","                         [34156., 13190., 20736.]],\n","               \n","                        ...,\n","               \n","                        [[21639., 20952., 42445.],\n","                         [34996., 14739., 10694.],\n","                         [21804., 22082., 25868.]],\n","               \n","                        [[48587., 31512., 20552.],\n","                         [30131., 28436., 22443.],\n","                         [25726., 26542., 21814.]],\n","               \n","                        [[38964., 32400., 22345.],\n","                         [20329., 26596., 24198.],\n","                         [17447., 25988., 18419.]]],\n","               \n","               \n","                       [[[50933., 54450., 52696.],\n","                         [39961., 48415., 39185.],\n","                         [38511., 45263., 38280.]],\n","               \n","                        [[32437., 33271., 40059.],\n","                         [24389., 19793., 26344.],\n","                         [28536., 20053., 30912.]],\n","               \n","                        [[36067., 32162., 25482.],\n","                         [35946., 21276., 17721.],\n","                         [21474., 13978., 17258.]],\n","               \n","                        ...,\n","               \n","                        [[32600., 27284., 34690.],\n","                         [28146., 26196., 30252.],\n","                         [22393., 29695., 41532.]],\n","               \n","                        [[21668., 32464., 14215.],\n","                         [37535., 49000., 40318.],\n","                         [26400., 48697., 42976.]],\n","               \n","                        [[48303., 34539., 28899.],\n","                         [57963., 40090., 30630.],\n","                         [42376., 28851., 25562.]]],\n","               \n","               \n","                       [[[47455., 31211., 31355.],\n","                         [28492., 15343., 28662.],\n","                         [34101., 18560., 35408.]],\n","               \n","                        [[32890., 50906., 58266.],\n","                         [39915., 47268., 44003.],\n","                         [35449., 32810., 19475.]],\n","               \n","                        [[22869., 25772., 31733.],\n","                         [31445., 24343., 19389.],\n","                         [32713., 37547., 31613.]],\n","               \n","                        ...,\n","               \n","                        [[36990., 25686., 22635.],\n","                         [30942., 23716., 26788.],\n","                         [44105., 27902., 31273.]],\n","               \n","                        [[23468., 27960., 30818.],\n","                         [38816., 39149., 38736.],\n","                         [38492., 28302., 31241.]],\n","               \n","                        [[41876., 38604., 39306.],\n","                         [30987., 32110., 38263.],\n","                         [27894., 43757., 49480.]]]], device='cuda:0')),\n","              ('module.layer2.7.conv1.wrapped_module.bias',\n","               tensor([-2.1475e+09,  1.6561e+09,  2.1475e+09,  2.8172e+08, -2.1475e+09,\n","                       -1.9200e+09, -8.7517e+08,  1.0155e+09,  1.1134e+08,  4.9115e+08,\n","                       -2.1475e+09, -2.1475e+09, -2.1475e+09,  2.1475e+09, -2.0908e+08,\n","                       -2.1475e+09, -2.1475e+09,  3.5001e+08,  9.4570e+08,  1.1659e+09,\n","                        1.5746e+09, -1.4806e+09, -1.4269e+09,  3.9670e+08,  5.9362e+08,\n","                       -2.1475e+09,  4.1603e+08,  1.0572e+09,  2.1475e+09,  9.4989e+08,\n","                        8.0292e+08, -8.0850e+08], device='cuda:0')),\n","              ('module.layer2.7.conv2.num_forwards',\n","               tensor([40], device='cuda:0')),\n","              ('module.layer2.7.conv2.force_readjust',\n","               tensor(False, device='cuda:0')),\n","              ('module.layer2.7.conv2.output_scale',\n","               tensor([17508.0957], device='cuda:0')),\n","              ('module.layer2.7.conv2.output_zero_point',\n","               tensor([-29100.], device='cuda:0')),\n","              ('module.layer2.7.conv2.w_scale', tensor([[[[ 122780.5312]]],\n","               \n","               \n","                       [[[2479458.0000]]],\n","               \n","               \n","                       [[[ 712317.8750]]],\n","               \n","               \n","                       [[[  74912.4375]]],\n","               \n","               \n","                       [[[  55437.9570]]],\n","               \n","               \n","                       [[[  46775.4297]]],\n","               \n","               \n","                       [[[ 147624.8750]]],\n","               \n","               \n","                       [[[  79359.4375]]],\n","               \n","               \n","                       [[[ 103801.8828]]],\n","               \n","               \n","                       [[[  53932.3359]]],\n","               \n","               \n","                       [[[ 131026.2969]]],\n","               \n","               \n","                       [[[  49082.5664]]],\n","               \n","               \n","                       [[[ 128812.4141]]],\n","               \n","               \n","                       [[[ 173414.4531]]],\n","               \n","               \n","                       [[[  76994.9219]]],\n","               \n","               \n","                       [[[ 123642.1094]]],\n","               \n","               \n","                       [[[ 136805.8438]]],\n","               \n","               \n","                       [[[  81231.7969]]],\n","               \n","               \n","                       [[[  36056.4336]]],\n","               \n","               \n","                       [[[  90847.7578]]],\n","               \n","               \n","                       [[[  82013.8594]]],\n","               \n","               \n","                       [[[  65077.0273]]],\n","               \n","               \n","                       [[[ 211755.8281]]],\n","               \n","               \n","                       [[[ 109367.8125]]],\n","               \n","               \n","                       [[[  60564.5977]]],\n","               \n","               \n","                       [[[  83353.7422]]],\n","               \n","               \n","                       [[[ 241831.5000]]],\n","               \n","               \n","                       [[[ 182748.6562]]],\n","               \n","               \n","                       [[[ 154424.1094]]],\n","               \n","               \n","                       [[[ 127604.2031]]],\n","               \n","               \n","                       [[[  83612.5938]]],\n","               \n","               \n","                       [[[ 193741.5000]]]], device='cuda:0')),\n","              ('module.layer2.7.conv2.w_zero_point', tensor([[[[-39011.]]],\n","               \n","               \n","                       [[[-40573.]]],\n","               \n","               \n","                       [[[-23298.]]],\n","               \n","               \n","                       [[[-26369.]]],\n","               \n","               \n","                       [[[-24194.]]],\n","               \n","               \n","                       [[[-28380.]]],\n","               \n","               \n","                       [[[-32956.]]],\n","               \n","               \n","                       [[[-32464.]]],\n","               \n","               \n","                       [[[-34157.]]],\n","               \n","               \n","                       [[[-27084.]]],\n","               \n","               \n","                       [[[-32839.]]],\n","               \n","               \n","                       [[[-18487.]]],\n","               \n","               \n","                       [[[-30823.]]],\n","               \n","               \n","                       [[[-35595.]]],\n","               \n","               \n","                       [[[-37393.]]],\n","               \n","               \n","                       [[[-31142.]]],\n","               \n","               \n","                       [[[-31749.]]],\n","               \n","               \n","                       [[[-27037.]]],\n","               \n","               \n","                       [[[-33004.]]],\n","               \n","               \n","                       [[[-29572.]]],\n","               \n","               \n","                       [[[-24851.]]],\n","               \n","               \n","                       [[[-29334.]]],\n","               \n","               \n","                       [[[-26026.]]],\n","               \n","               \n","                       [[[-39829.]]],\n","               \n","               \n","                       [[[-26997.]]],\n","               \n","               \n","                       [[[-32140.]]],\n","               \n","               \n","                       [[[-30666.]]],\n","               \n","               \n","                       [[[-32826.]]],\n","               \n","               \n","                       [[[-27659.]]],\n","               \n","               \n","                       [[[-30492.]]],\n","               \n","               \n","                       [[[-30331.]]],\n","               \n","               \n","                       [[[-33629.]]]], device='cuda:0')),\n","              ('module.layer2.7.conv2.fp_bias',\n","               tensor([ 0.1420,  0.0111,  0.0667, -0.2914, -0.0443,  0.0918, -0.0551,  0.1196,\n","                       -0.0480,  0.2957,  0.0067, -0.1049, -0.0257,  0.0275,  0.1363,  0.0068,\n","                       -0.1692, -0.0524, -0.1814,  0.1582, -0.0905,  0.1794,  0.0178,  0.2433,\n","                        0.0121,  0.1382,  0.1709, -0.0719,  0.0189, -0.0477,  0.0417, -0.0137],\n","                      device='cuda:0')),\n","              ('module.layer2.7.conv2.accum_scale', tensor([[[6.6461e+09]],\n","               \n","                       [[1.3421e+11]],\n","               \n","                       [[3.8558e+10]],\n","               \n","                       [[4.0550e+09]],\n","               \n","                       [[3.0008e+09]],\n","               \n","                       [[2.5319e+09]],\n","               \n","                       [[7.9909e+09]],\n","               \n","                       [[4.2957e+09]],\n","               \n","                       [[5.6188e+09]],\n","               \n","                       [[2.9193e+09]],\n","               \n","                       [[7.0924e+09]],\n","               \n","                       [[2.6568e+09]],\n","               \n","                       [[6.9726e+09]],\n","               \n","                       [[9.3869e+09]],\n","               \n","                       [[4.1677e+09]],\n","               \n","                       [[6.6927e+09]],\n","               \n","                       [[7.4053e+09]],\n","               \n","                       [[4.3971e+09]],\n","               \n","                       [[1.9517e+09]],\n","               \n","                       [[4.9176e+09]],\n","               \n","                       [[4.4394e+09]],\n","               \n","                       [[3.5226e+09]],\n","               \n","                       [[1.1462e+10]],\n","               \n","                       [[5.9201e+09]],\n","               \n","                       [[3.2783e+09]],\n","               \n","                       [[4.5119e+09]],\n","               \n","                       [[1.3090e+10]],\n","               \n","                       [[9.8921e+09]],\n","               \n","                       [[8.3589e+09]],\n","               \n","                       [[6.9072e+09]],\n","               \n","                       [[4.5259e+09]],\n","               \n","                       [[1.0487e+10]]], device='cuda:0')),\n","              ('module.layer2.7.conv2.is_simulated_quant_weight_shifted',\n","               tensor(False, device='cuda:0')),\n","              ('module.layer2.7.conv2.wrapped_module.weight',\n","               tensor([[[[58540., 52731., 45074.],\n","                         [50895., 45083., 43653.],\n","                         [49653., 46686., 42780.]],\n","               \n","                        [[34308., 29697., 42989.],\n","                         [36458., 28890., 32902.],\n","                         [42000., 33081., 43164.]],\n","               \n","                        [[52973., 54652., 46800.],\n","                         [24275., 28186., 32214.],\n","                         [24133., 23582., 33853.]],\n","               \n","                        ...,\n","               \n","                        [[38637., 37590., 39257.],\n","                         [37111., 44826., 31639.],\n","                         [35248., 42671., 36800.]],\n","               \n","                        [[46039., 39408., 32376.],\n","                         [45609., 42206., 36220.],\n","                         [30786., 33072., 38531.]],\n","               \n","                        [[33074., 29248., 34348.],\n","                         [38722., 30700., 32569.],\n","                         [50314., 49464., 45948.]]],\n","               \n","               \n","                       [[[38175., 41486., 41624.],\n","                         [40424., 43952., 46749.],\n","                         [41716., 43021., 44855.]],\n","               \n","                        [[46034., 40983., 40515.],\n","                         [43334., 43747., 42824.],\n","                         [50175., 45917., 42099.]],\n","               \n","                        [[52085., 50121., 48828.],\n","                         [46753., 40769., 42390.],\n","                         [43576., 35773., 39144.]],\n","               \n","                        ...,\n","               \n","                        [[44060., 37883., 36271.],\n","                         [43824., 32516., 35187.],\n","                         [40531., 34996., 34054.]],\n","               \n","                        [[45935., 38951., 38000.],\n","                         [38988., 36557., 37625.],\n","                         [41001., 41534., 40249.]],\n","               \n","                        [[41027., 37198., 37148.],\n","                         [51685., 44633., 44548.],\n","                         [56068., 50819., 49545.]]],\n","               \n","               \n","                       [[[31638., 27883., 26477.],\n","                         [26858., 23739., 21408.],\n","                         [20045., 18274., 19622.]],\n","               \n","                        [[29590., 37277., 31091.],\n","                         [25476., 33491., 26882.],\n","                         [29422., 23483., 30554.]],\n","               \n","                        [[26678., 10855.,  3933.],\n","                         [38209., 22546., 13139.],\n","                         [31267., 20135., 16354.]],\n","               \n","                        ...,\n","               \n","                        [[35547., 38371., 36637.],\n","                         [37195., 40121., 43026.],\n","                         [14560., 25746., 29196.]],\n","               \n","                        [[15462., 15703., 16218.],\n","                         [28270., 29028., 28255.],\n","                         [25403., 31966., 27235.]],\n","               \n","                        [[14846., 22000., 18460.],\n","                         [23602., 24109., 19078.],\n","                         [24347., 26089., 19855.]]],\n","               \n","               \n","                       ...,\n","               \n","               \n","                       [[[37382., 43123., 38545.],\n","                         [37812., 41428., 46786.],\n","                         [29815., 33395., 38080.]],\n","               \n","                        [[18792., 22680., 17281.],\n","                         [23179., 21493., 23697.],\n","                         [22109., 23054., 19463.]],\n","               \n","                        [[27394., 33989., 22060.],\n","                         [16262., 21757., 26337.],\n","                         [17531., 38522., 42080.]],\n","               \n","                        ...,\n","               \n","                        [[29944., 26319., 20950.],\n","                         [32289., 33661., 38063.],\n","                         [12900., 33802., 40485.]],\n","               \n","                        [[18509., 16181., 16080.],\n","                         [18723., 20391., 27940.],\n","                         [17374., 24684., 35743.]],\n","               \n","                        [[32100., 31496., 21591.],\n","                         [32551., 29568., 22449.],\n","                         [41446., 29754., 19170.]]],\n","               \n","               \n","                       [[[25389., 26403., 32580.],\n","                         [24447., 29078., 37109.],\n","                         [23967., 26443., 36179.]],\n","               \n","                        [[30029., 37048., 39273.],\n","                         [34226., 46048., 44682.],\n","                         [46353., 60237., 39415.]],\n","               \n","                        [[32271., 19901.,  9572.],\n","                         [27254., 23353.,  8056.],\n","                         [33362., 24317., 17053.]],\n","               \n","                        ...,\n","               \n","                        [[33623., 27906., 31064.],\n","                         [27203., 15896., 34572.],\n","                         [27880., 26400., 26296.]],\n","               \n","                        [[24051., 25373., 20363.],\n","                         [27232., 27475., 28408.],\n","                         [50141., 45161., 41603.]],\n","               \n","                        [[32528., 39124., 45466.],\n","                         [35170., 37371., 44377.],\n","                         [17668., 15182., 24582.]]],\n","               \n","               \n","                       [[[36212., 39521., 35381.],\n","                         [30109., 27796., 26269.],\n","                         [30883., 29778., 27204.]],\n","               \n","                        [[35517., 56661., 55399.],\n","                         [41091., 47997., 37485.],\n","                         [49212., 37077., 30594.]],\n","               \n","                        [[34543., 42012., 53119.],\n","                         [49111., 49356., 37316.],\n","                         [43849., 35683., 25145.]],\n","               \n","                        ...,\n","               \n","                        [[33096., 36088., 30677.],\n","                         [41910., 51341., 40908.],\n","                         [17490., 26271., 29419.]],\n","               \n","                        [[40944., 48104., 45607.],\n","                         [45979., 48077., 54051.],\n","                         [43451., 40506., 51370.]],\n","               \n","                        [[33267., 37699., 33411.],\n","                         [17682., 34736., 31263.],\n","                         [17321., 35144., 34549.]]]], device='cuda:0')),\n","              ('module.layer2.7.conv2.wrapped_module.bias',\n","               tensor([ 9.4362e+08,  1.4963e+09,  2.1475e+09, -1.1817e+09, -1.3295e+08,\n","                        2.3236e+08, -4.4011e+08,  5.1376e+08, -2.6985e+08,  8.6330e+08,\n","                        4.7296e+07, -2.7857e+08, -1.7888e+08,  2.5816e+08,  5.6825e+08,\n","                        4.5202e+07, -1.2529e+09, -2.3043e+08, -3.5412e+08,  7.7772e+08,\n","                       -4.0181e+08,  6.3186e+08,  2.0440e+08,  1.4404e+09,  3.9595e+07,\n","                        6.2358e+08,  2.1475e+09, -7.1162e+08,  1.5837e+08, -3.2931e+08,\n","                        1.8862e+08, -1.4330e+08], device='cuda:0')),\n","              ('module.layer2.7.relu2.num_forwards',\n","               tensor([40], device='cuda:0')),\n","              ('module.layer2.7.relu2.force_readjust',\n","               tensor(False, device='cuda:0')),\n","              ('module.layer2.7.relu2.output_scale',\n","               tensor([6997.6113], device='cuda:0')),\n","              ('module.layer2.7.relu2.output_zero_point',\n","               tensor([0.], device='cuda:0')),\n","              ('module.layer2.7.residual_eltwiseadd.num_forwards',\n","               tensor([40], device='cuda:0')),\n","              ('module.layer2.7.residual_eltwiseadd.force_readjust',\n","               tensor(False, device='cuda:0')),\n","              ('module.layer2.7.residual_eltwiseadd.output_scale',\n","               tensor([6997.6113], device='cuda:0')),\n","              ('module.layer2.7.residual_eltwiseadd.output_zero_point',\n","               tensor([0.], device='cuda:0')),\n","              ('module.layer2.8.conv1.num_forwards',\n","               tensor([40], device='cuda:0')),\n","              ('module.layer2.8.conv1.force_readjust',\n","               tensor(False, device='cuda:0')),\n","              ('module.layer2.8.conv1.output_scale',\n","               tensor([53455.3242], device='cuda:0')),\n","              ('module.layer2.8.conv1.output_zero_point',\n","               tensor([0.], device='cuda:0')),\n","              ('module.layer2.8.conv1.w_scale', tensor([[[[6.7731e+05]]],\n","               \n","               \n","                       [[[1.0563e+06]]],\n","               \n","               \n","                       [[[4.6157e+07]]],\n","               \n","               \n","                       [[[6.9817e+05]]],\n","               \n","               \n","                       [[[8.7260e+05]]],\n","               \n","               \n","                       [[[8.3756e+05]]],\n","               \n","               \n","                       [[[1.0279e+06]]],\n","               \n","               \n","                       [[[1.5400e+06]]],\n","               \n","               \n","                       [[[1.2393e+06]]],\n","               \n","               \n","                       [[[9.0517e+05]]],\n","               \n","               \n","                       [[[7.9703e+08]]],\n","               \n","               \n","                       [[[1.0471e+08]]],\n","               \n","               \n","                       [[[8.9054e+05]]],\n","               \n","               \n","                       [[[1.0693e+06]]],\n","               \n","               \n","                       [[[9.9174e+05]]],\n","               \n","               \n","                       [[[7.8495e+05]]],\n","               \n","               \n","                       [[[1.3590e+06]]],\n","               \n","               \n","                       [[[1.1284e+06]]],\n","               \n","               \n","                       [[[7.2520e+05]]],\n","               \n","               \n","                       [[[7.5557e+05]]],\n","               \n","               \n","                       [[[1.2667e+06]]],\n","               \n","               \n","                       [[[1.8193e+06]]],\n","               \n","               \n","                       [[[8.9608e+05]]],\n","               \n","               \n","                       [[[7.7864e+05]]],\n","               \n","               \n","                       [[[9.1783e+05]]],\n","               \n","               \n","                       [[[8.6535e+05]]],\n","               \n","               \n","                       [[[1.8941e+06]]],\n","               \n","               \n","                       [[[1.5635e+06]]],\n","               \n","               \n","                       [[[1.0609e+06]]],\n","               \n","               \n","                       [[[1.3321e+06]]],\n","               \n","               \n","                       [[[1.0210e+06]]],\n","               \n","               \n","                       [[[6.9319e+05]]]], device='cuda:0')),\n","              ('module.layer2.8.conv1.w_zero_point', tensor([[[[-31496.]]],\n","               \n","               \n","                       [[[-26640.]]],\n","               \n","               \n","                       [[[-33749.]]],\n","               \n","               \n","                       [[[-30154.]]],\n","               \n","               \n","                       [[[-29437.]]],\n","               \n","               \n","                       [[[-25938.]]],\n","               \n","               \n","                       [[[-24492.]]],\n","               \n","               \n","                       [[[-25691.]]],\n","               \n","               \n","                       [[[-33306.]]],\n","               \n","               \n","                       [[[-30548.]]],\n","               \n","               \n","                       [[[-30016.]]],\n","               \n","               \n","                       [[[-30980.]]],\n","               \n","               \n","                       [[[-29715.]]],\n","               \n","               \n","                       [[[-32729.]]],\n","               \n","               \n","                       [[[-33512.]]],\n","               \n","               \n","                       [[[-27690.]]],\n","               \n","               \n","                       [[[-31664.]]],\n","               \n","               \n","                       [[[-32884.]]],\n","               \n","               \n","                       [[[-30955.]]],\n","               \n","               \n","                       [[[-28209.]]],\n","               \n","               \n","                       [[[-31035.]]],\n","               \n","               \n","                       [[[-35572.]]],\n","               \n","               \n","                       [[[-26438.]]],\n","               \n","               \n","                       [[[-32281.]]],\n","               \n","               \n","                       [[[-40331.]]],\n","               \n","               \n","                       [[[-34272.]]],\n","               \n","               \n","                       [[[-33396.]]],\n","               \n","               \n","                       [[[-28865.]]],\n","               \n","               \n","                       [[[-29269.]]],\n","               \n","               \n","                       [[[-30738.]]],\n","               \n","               \n","                       [[[-31966.]]],\n","               \n","               \n","                       [[[-24392.]]]], device='cuda:0')),\n","              ('module.layer2.8.conv1.fp_bias',\n","               tensor([ 0.6030,  0.9180, -0.0638,  0.2510,  0.3309,  0.3731, -0.1374,  0.1190,\n","                       -0.3481,  0.2808, -0.0050, -0.0255,  0.3839, -0.4292, -0.6369,  0.0529,\n","                       -0.2876,  0.2639,  0.2691, -0.0225,  0.1790,  0.1050, -0.0739, -0.0541,\n","                        0.1889,  0.1375,  0.0163, -0.1959, -0.7664, -0.4363,  0.1222,  0.1255],\n","                      device='cuda:0')),\n","              ('module.layer2.8.conv1.accum_scale', tensor([[[4.7395e+09]],\n","               \n","                       [[7.3918e+09]],\n","               \n","                       [[3.2299e+11]],\n","               \n","                       [[4.8855e+09]],\n","               \n","                       [[6.1061e+09]],\n","               \n","                       [[5.8609e+09]],\n","               \n","                       [[7.1932e+09]],\n","               \n","                       [[1.0776e+10]],\n","               \n","                       [[8.6724e+09]],\n","               \n","                       [[6.3340e+09]],\n","               \n","                       [[5.5773e+12]],\n","               \n","                       [[7.3269e+11]],\n","               \n","                       [[6.2316e+09]],\n","               \n","                       [[7.4828e+09]],\n","               \n","                       [[6.9398e+09]],\n","               \n","                       [[5.4927e+09]],\n","               \n","                       [[9.5100e+09]],\n","               \n","                       [[7.8963e+09]],\n","               \n","                       [[5.0747e+09]],\n","               \n","                       [[5.2872e+09]],\n","               \n","                       [[8.8639e+09]],\n","               \n","                       [[1.2731e+10]],\n","               \n","                       [[6.2704e+09]],\n","               \n","                       [[5.4486e+09]],\n","               \n","                       [[6.4226e+09]],\n","               \n","                       [[6.0554e+09]],\n","               \n","                       [[1.3254e+10]],\n","               \n","                       [[1.0941e+10]],\n","               \n","                       [[7.4235e+09]],\n","               \n","                       [[9.3215e+09]],\n","               \n","                       [[7.1445e+09]],\n","               \n","                       [[4.8507e+09]]], device='cuda:0')),\n","              ('module.layer2.8.conv1.is_simulated_quant_weight_shifted',\n","               tensor(False, device='cuda:0')),\n","              ('module.layer2.8.conv1.wrapped_module.weight',\n","               tensor([[[[41194., 53123., 44457.],\n","                         [17278., 27487., 34894.],\n","                         [    0.,  2504., 23198.]],\n","               \n","                        [[25996., 32423., 23372.],\n","                         [21497., 23624., 23085.],\n","                         [31775., 34030., 38945.]],\n","               \n","                        [[54383., 28793., 27748.],\n","                         [42764., 33867., 32976.],\n","                         [25198., 24342., 18740.]],\n","               \n","                        ...,\n","               \n","                        [[30939., 27348.,  8721.],\n","                         [27390., 34594., 16945.],\n","                         [34019., 28136., 30820.]],\n","               \n","                        [[20852., 26989., 44337.],\n","                         [29914., 40698., 45518.],\n","                         [31285., 24801., 19564.]],\n","               \n","                        [[37768., 42395., 27069.],\n","                         [29880., 35919., 30209.],\n","                         [24017., 22773., 26358.]]],\n","               \n","               \n","                       [[[31305.,  8055., 31749.],\n","                         [14911.,  5919., 25426.],\n","                         [20630.,  6019., 24053.]],\n","               \n","                        [[21268., 17400., 27185.],\n","                         [14122.,  6254., 17129.],\n","                         [13163.,  7482., 24878.]],\n","               \n","                        [[18208., 20175., 19050.],\n","                         [18729., 23086., 18092.],\n","                         [20355., 28730., 21496.]],\n","               \n","                        ...,\n","               \n","                        [[21329., 13803., 20228.],\n","                         [17841., 12211., 18565.],\n","                         [19363., 14570., 23559.]],\n","               \n","                        [[20653., 50233., 16805.],\n","                         [39632., 65535., 35836.],\n","                         [20306., 48181., 14433.]],\n","               \n","                        [[13218., 13022., 12170.],\n","                         [14673., 18726., 20612.],\n","                         [ 3508.,  9875., 19940.]]],\n","               \n","               \n","                       [[[35412., 25057., 35229.],\n","                         [31388., 25125., 36935.],\n","                         [28438., 33759., 37996.]],\n","               \n","                        [[32035., 42115., 24139.],\n","                         [37504., 56645., 43666.],\n","                         [47070., 60938., 47331.]],\n","               \n","                        [[25058., 43307., 44932.],\n","                         [28385., 42070., 41641.],\n","                         [25229., 39055., 36852.]],\n","               \n","                        ...,\n","               \n","                        [[28530., 34439., 29200.],\n","                         [25291., 36523., 29018.],\n","                         [26239., 47954., 23787.]],\n","               \n","                        [[18626., 43086., 52011.],\n","                         [40503., 52813., 52352.],\n","                         [63887., 58174., 47054.]],\n","               \n","                        [[29015., 24902., 17242.],\n","                         [30822., 23731., 29132.],\n","                         [27795., 27564., 36258.]]],\n","               \n","               \n","                       ...,\n","               \n","               \n","                       [[[32934., 39364., 48689.],\n","                         [40897., 58295., 51301.],\n","                         [19621., 48319., 49855.]],\n","               \n","                        [[34562., 26353., 25712.],\n","                         [41298., 41644., 33415.],\n","                         [23457., 29856., 20472.]],\n","               \n","                        [[38837., 44474., 44589.],\n","                         [38817., 45939., 48256.],\n","                         [22448., 20168., 17045.]],\n","               \n","                        ...,\n","               \n","                        [[17309., 26957., 17450.],\n","                         [33043., 29312., 19104.],\n","                         [42793., 42362., 37912.]],\n","               \n","                        [[29622., 17861., 21870.],\n","                         [32126., 10469., 13847.],\n","                         [45292., 27758., 22396.]],\n","               \n","                        [[41224., 48606., 38935.],\n","                         [37339., 44783., 36657.],\n","                         [34001., 39327., 29621.]]],\n","               \n","               \n","                       [[[40879., 24208.,  2626.],\n","                         [49732., 41205., 20113.],\n","                         [31718., 36497., 29096.]],\n","               \n","                        [[19321., 20076., 29410.],\n","                         [25393., 39909., 41881.],\n","                         [25511., 54598., 53614.]],\n","               \n","                        [[23308., 52568., 49998.],\n","                         [33863., 36548., 21245.],\n","                         [37687., 26168., 11509.]],\n","               \n","                        ...,\n","               \n","                        [[50843., 52214., 45955.],\n","                         [41645., 30749., 20311.],\n","                         [16356., 13311.,  8076.]],\n","               \n","                        [[25623., 49512., 41017.],\n","                         [33690., 25224.,  9460.],\n","                         [55967., 39249.,  8594.]],\n","               \n","                        [[21722., 27496., 23195.],\n","                         [ 7619., 16547., 12632.],\n","                         [27805., 32923., 21504.]]],\n","               \n","               \n","                       [[[34939., 32984., 20458.],\n","                         [29804., 44497., 23935.],\n","                         [34529., 46383., 31397.]],\n","               \n","                        [[34685., 27533., 19556.],\n","                         [36368., 31591., 26554.],\n","                         [37399., 33107., 26543.]],\n","               \n","                        [[22688., 22636., 24874.],\n","                         [20720., 10416., 15457.],\n","                         [19293., 12145., 15329.]],\n","               \n","                        ...,\n","               \n","                        [[ 4141.,  5090.,  2371.],\n","                         [20568., 11986., 16339.],\n","                         [26104., 18646., 21030.]],\n","               \n","                        [[16036.,  6852., 25253.],\n","                         [18351.,  6217., 32262.],\n","                         [20793.,  6786., 28870.]],\n","               \n","                        [[16296., 16869., 23828.],\n","                         [25293., 14731., 19317.],\n","                         [35164., 18654., 13362.]]]], device='cuda:0')),\n","              ('module.layer2.8.conv1.wrapped_module.bias',\n","               tensor([ 2.1475e+09,  2.1475e+09, -2.1475e+09,  1.2264e+09,  2.0207e+09,\n","                        2.1475e+09, -9.8820e+08,  1.2824e+09, -2.1475e+09,  1.7788e+09,\n","                       -2.1475e+09, -2.1475e+09,  2.1475e+09, -2.1475e+09, -2.1475e+09,\n","                        2.9033e+08, -2.1475e+09,  2.0840e+09,  1.3654e+09, -1.1917e+08,\n","                        1.5869e+09,  1.3372e+09, -4.6369e+08, -2.9472e+08,  1.2130e+09,\n","                        8.3274e+08,  2.1642e+08, -2.1435e+09, -2.1475e+09, -2.1475e+09,\n","                        8.7330e+08,  6.0854e+08], device='cuda:0')),\n","              ('module.layer2.8.conv2.num_forwards',\n","               tensor([40], device='cuda:0')),\n","              ('module.layer2.8.conv2.force_readjust',\n","               tensor(False, device='cuda:0')),\n","              ('module.layer2.8.conv2.output_scale',\n","               tensor([18088.2480], device='cuda:0')),\n","              ('module.layer2.8.conv2.output_zero_point',\n","               tensor([-27754.], device='cuda:0')),\n","              ('module.layer2.8.conv2.w_scale', tensor([[[[122058.3594]]],\n","               \n","               \n","                       [[[163539.6875]]],\n","               \n","               \n","                       [[[ 85978.1484]]],\n","               \n","               \n","                       [[[179364.7656]]],\n","               \n","               \n","                       [[[ 98151.9453]]],\n","               \n","               \n","                       [[[ 87979.8672]]],\n","               \n","               \n","                       [[[ 75343.5703]]],\n","               \n","               \n","                       [[[ 64227.4062]]],\n","               \n","               \n","                       [[[ 71456.4062]]],\n","               \n","               \n","                       [[[806149.9375]]],\n","               \n","               \n","                       [[[100984.3359]]],\n","               \n","               \n","                       [[[144738.9062]]],\n","               \n","               \n","                       [[[112925.1250]]],\n","               \n","               \n","                       [[[229518.0312]]],\n","               \n","               \n","                       [[[ 99902.3984]]],\n","               \n","               \n","                       [[[178927.8906]]],\n","               \n","               \n","                       [[[227435.0312]]],\n","               \n","               \n","                       [[[376010.6562]]],\n","               \n","               \n","                       [[[ 63179.3750]]],\n","               \n","               \n","                       [[[ 65837.0625]]],\n","               \n","               \n","                       [[[ 45513.4805]]],\n","               \n","               \n","                       [[[166940.8438]]],\n","               \n","               \n","                       [[[ 82799.7500]]],\n","               \n","               \n","                       [[[150000.4375]]],\n","               \n","               \n","                       [[[149912.5781]]],\n","               \n","               \n","                       [[[105697.1875]]],\n","               \n","               \n","                       [[[ 84703.9531]]],\n","               \n","               \n","                       [[[120312.4531]]],\n","               \n","               \n","                       [[[195971.0156]]],\n","               \n","               \n","                       [[[140039.6719]]],\n","               \n","               \n","                       [[[124670.2188]]],\n","               \n","               \n","                       [[[ 59246.5391]]]], device='cuda:0')),\n","              ('module.layer2.8.conv2.w_zero_point', tensor([[[[-23554.]]],\n","               \n","               \n","                       [[[-35766.]]],\n","               \n","               \n","                       [[[-27398.]]],\n","               \n","               \n","                       [[[-33238.]]],\n","               \n","               \n","                       [[[-27841.]]],\n","               \n","               \n","                       [[[-30397.]]],\n","               \n","               \n","                       [[[-24061.]]],\n","               \n","               \n","                       [[[-26935.]]],\n","               \n","               \n","                       [[[-33938.]]],\n","               \n","               \n","                       [[[-20819.]]],\n","               \n","               \n","                       [[[-31463.]]],\n","               \n","               \n","                       [[[-32595.]]],\n","               \n","               \n","                       [[[-39279.]]],\n","               \n","               \n","                       [[[-42877.]]],\n","               \n","               \n","                       [[[-40374.]]],\n","               \n","               \n","                       [[[-39866.]]],\n","               \n","               \n","                       [[[-35288.]]],\n","               \n","               \n","                       [[[-30474.]]],\n","               \n","               \n","                       [[[-27256.]]],\n","               \n","               \n","                       [[[-23392.]]],\n","               \n","               \n","                       [[[-34146.]]],\n","               \n","               \n","                       [[[-32120.]]],\n","               \n","               \n","                       [[[-32941.]]],\n","               \n","               \n","                       [[[-25184.]]],\n","               \n","               \n","                       [[[-36373.]]],\n","               \n","               \n","                       [[[-36200.]]],\n","               \n","               \n","                       [[[-37977.]]],\n","               \n","               \n","                       [[[-30370.]]],\n","               \n","               \n","                       [[[-31189.]]],\n","               \n","               \n","                       [[[-29247.]]],\n","               \n","               \n","                       [[[-31784.]]],\n","               \n","               \n","                       [[[-26990.]]]], device='cuda:0')),\n","              ('module.layer2.8.conv2.fp_bias',\n","               tensor([-0.1355,  0.0399, -0.0077,  0.0819,  0.0535,  0.0909, -0.1797, -0.0798,\n","                        0.2253,  0.0063, -0.0349,  0.1800,  0.1691,  0.0383,  0.2159,  0.0548,\n","                        0.0935,  0.0583, -0.1207, -0.2450, -0.1043,  0.0907,  0.0173, -0.0114,\n","                        0.1104,  0.1016,  0.4128, -0.2306,  0.0059, -0.0403,  0.0176, -0.1674],\n","                      device='cuda:0')),\n","              ('module.layer2.8.conv2.accum_scale', tensor([[[6.5247e+09]],\n","               \n","                       [[8.7421e+09]],\n","               \n","                       [[4.5960e+09]],\n","               \n","                       [[9.5880e+09]],\n","               \n","                       [[5.2467e+09]],\n","               \n","                       [[4.7030e+09]],\n","               \n","                       [[4.0275e+09]],\n","               \n","                       [[3.4333e+09]],\n","               \n","                       [[3.8197e+09]],\n","               \n","                       [[4.3093e+10]],\n","               \n","                       [[5.3982e+09]],\n","               \n","                       [[7.7371e+09]],\n","               \n","                       [[6.0364e+09]],\n","               \n","                       [[1.2269e+10]],\n","               \n","                       [[5.3403e+09]],\n","               \n","                       [[9.5646e+09]],\n","               \n","                       [[1.2158e+10]],\n","               \n","                       [[2.0100e+10]],\n","               \n","                       [[3.3773e+09]],\n","               \n","                       [[3.5193e+09]],\n","               \n","                       [[2.4329e+09]],\n","               \n","                       [[8.9239e+09]],\n","               \n","                       [[4.4261e+09]],\n","               \n","                       [[8.0183e+09]],\n","               \n","                       [[8.0136e+09]],\n","               \n","                       [[5.6501e+09]],\n","               \n","                       [[4.5279e+09]],\n","               \n","                       [[6.4313e+09]],\n","               \n","                       [[1.0476e+10]],\n","               \n","                       [[7.4859e+09]],\n","               \n","                       [[6.6643e+09]],\n","               \n","                       [[3.1670e+09]]], device='cuda:0')),\n","              ('module.layer2.8.conv2.is_simulated_quant_weight_shifted',\n","               tensor(False, device='cuda:0')),\n","              ('module.layer2.8.conv2.wrapped_module.weight',\n","               tensor([[[[29190., 29486., 30767.],\n","                         [34414., 38468., 34700.],\n","                         [42585., 47704., 32015.]],\n","               \n","                        [[17348., 19088., 17205.],\n","                         [ 6768., 12487., 15230.],\n","                         [ 6634., 13041., 11277.]],\n","               \n","                        [[23182., 23002., 20610.],\n","                         [24701., 24802., 23074.],\n","                         [24071., 25403., 25022.]],\n","               \n","                        ...,\n","               \n","                        [[34637., 35330., 31456.],\n","                         [30751., 35300., 31583.],\n","                         [26596., 23488., 24892.]],\n","               \n","                        [[ 3022., 36465., 57685.],\n","                         [ 7032., 38920., 54010.],\n","                         [16319., 28833., 33268.]],\n","               \n","                        [[39575., 31490., 38917.],\n","                         [38451., 25637., 32534.],\n","                         [43232., 36836., 39046.]]],\n","               \n","               \n","                       [[[36872., 43511., 30635.],\n","                         [21861., 34197., 32017.],\n","                         [26013., 38233., 49310.]],\n","               \n","                        [[36159., 29658., 31690.],\n","                         [ 8734.,     0.,  7515.],\n","                         [20794., 14536., 25452.]],\n","               \n","                        [[32710., 34171., 35270.],\n","                         [33730., 35946., 36547.],\n","                         [36200., 37418., 36663.]],\n","               \n","                        ...,\n","               \n","                        [[30114., 32292., 31632.],\n","                         [31482., 32920., 37043.],\n","                         [24619., 28288., 32560.]],\n","               \n","                        [[32601., 30255., 32056.],\n","                         [20966., 26140., 22661.],\n","                         [50261., 36235., 31133.]],\n","               \n","                        [[25600., 21769., 35099.],\n","                         [35356., 25893., 36867.],\n","                         [33072., 25029., 33779.]]],\n","               \n","               \n","                       [[[ 9137., 12527., 25630.],\n","                         [ 6382., 15005., 22095.],\n","                         [14287.,  1600., 11204.]],\n","               \n","                        [[34433., 39838., 48619.],\n","                         [48557., 57273., 65535.],\n","                         [44422., 54749., 62612.]],\n","               \n","                        [[27869., 27977., 28425.],\n","                         [27937., 27965., 28744.],\n","                         [27608., 27045., 26965.]],\n","               \n","                        ...,\n","               \n","                        [[33554., 26905., 19541.],\n","                         [35878., 33850., 28903.],\n","                         [38552., 36949., 32549.]],\n","               \n","                        [[16475., 29681., 34743.],\n","                         [24142., 37736., 28164.],\n","                         [33811., 38368., 35861.]],\n","               \n","                        [[ 8067.,  2656., 24875.],\n","                         [15094., 13016., 28904.],\n","                         [13849., 19105., 32577.]]],\n","               \n","               \n","                       ...,\n","               \n","               \n","                       [[[15718., 21622., 38717.],\n","                         [ 8212., 31779., 33600.],\n","                         [31192., 34196., 36367.]],\n","               \n","                        [[29635., 38035., 30530.],\n","                         [42752., 48976., 38589.],\n","                         [38469., 42806., 25809.]],\n","               \n","                        [[28951., 30056., 30661.],\n","                         [29525., 30032., 29978.],\n","                         [29552., 29344., 29313.]],\n","               \n","                        ...,\n","               \n","                        [[23617., 20833., 26233.],\n","                         [26635., 22845., 24283.],\n","                         [21711., 16796., 17015.]],\n","               \n","                        [[26166., 17070., 19215.],\n","                         [43713., 47992., 35481.],\n","                         [20296., 27284., 21613.]],\n","               \n","                        [[45928., 50299., 35241.],\n","                         [33294., 48687., 23405.],\n","                         [23904., 41953., 11297.]]],\n","               \n","               \n","                       [[[38828., 39555., 42279.],\n","                         [33604., 24495., 31921.],\n","                         [37579., 31559., 41070.]],\n","               \n","                        [[13518., 16987., 47848.],\n","                         [32458., 34022., 65535.],\n","                         [30970., 32049., 62865.]],\n","               \n","                        [[30780., 31504., 30597.],\n","                         [30582., 31399., 30430.],\n","                         [29691., 30068., 30504.]],\n","               \n","                        ...,\n","               \n","                        [[33673., 33034., 29150.],\n","                         [28663., 29725., 31010.],\n","                         [20533., 22007., 23214.]],\n","               \n","                        [[24778., 39870., 44871.],\n","                         [21394., 39435., 43960.],\n","                         [25196., 36669., 36907.]],\n","               \n","                        [[38838., 37851., 27354.],\n","                         [42018., 42417., 31398.],\n","                         [33197., 33062., 20466.]]],\n","               \n","               \n","                       [[[13874.,  6490.,  5730.],\n","                         [28767., 38540., 47677.],\n","                         [26509., 40750., 65535.]],\n","               \n","                        [[27103., 27807., 26453.],\n","                         [22988., 16817.,  8962.],\n","                         [28465., 17265., 11394.]],\n","               \n","                        [[26511., 27078., 27083.],\n","                         [28247., 27039., 26339.],\n","                         [27169., 26826., 26087.]],\n","               \n","                        ...,\n","               \n","                        [[22713., 25643., 27099.],\n","                         [25309., 34307., 33311.],\n","                         [34479., 34516., 33409.]],\n","               \n","                        [[16538., 13732., 12247.],\n","                         [25849., 26072., 19638.],\n","                         [40527., 42928., 21786.]],\n","               \n","                        [[17207., 24065., 37637.],\n","                         [14983., 21933., 33711.],\n","                         [18433., 26618., 38820.]]]], device='cuda:0')),\n","              ('module.layer2.8.conv2.wrapped_module.bias',\n","               tensor([-8.8422e+08,  3.4893e+08, -3.5590e+07,  7.8509e+08,  2.8058e+08,\n","                        4.2729e+08, -7.2381e+08, -2.7399e+08,  8.6068e+08,  2.6995e+08,\n","                       -1.8840e+08,  1.3928e+09,  1.0205e+09,  4.6973e+08,  1.1529e+09,\n","                        5.2449e+08,  1.1366e+09,  1.1718e+09, -4.0772e+08, -8.6214e+08,\n","                       -2.5364e+08,  8.0907e+08,  7.6538e+07, -9.1593e+07,  8.8495e+08,\n","                        5.7394e+08,  1.8690e+09, -1.4827e+09,  6.1724e+07, -3.0161e+08,\n","                        1.1698e+08, -5.3026e+08], device='cuda:0')),\n","              ('module.layer2.8.relu2.num_forwards',\n","               tensor([40], device='cuda:0')),\n","              ('module.layer2.8.relu2.force_readjust',\n","               tensor(False, device='cuda:0')),\n","              ('module.layer2.8.relu2.output_scale',\n","               tensor([6860.4292], device='cuda:0')),\n","              ('module.layer2.8.relu2.output_zero_point',\n","               tensor([0.], device='cuda:0')),\n","              ('module.layer2.8.residual_eltwiseadd.num_forwards',\n","               tensor([40], device='cuda:0')),\n","              ('module.layer2.8.residual_eltwiseadd.force_readjust',\n","               tensor(False, device='cuda:0')),\n","              ('module.layer2.8.residual_eltwiseadd.output_scale',\n","               tensor([6860.4292], device='cuda:0')),\n","              ('module.layer2.8.residual_eltwiseadd.output_zero_point',\n","               tensor([0.], device='cuda:0')),\n","              ('module.layer3.0.conv1.num_forwards',\n","               tensor([40], device='cuda:0')),\n","              ('module.layer3.0.conv1.force_readjust',\n","               tensor(False, device='cuda:0')),\n","              ('module.layer3.0.conv1.output_scale',\n","               tensor([24317.6152], device='cuda:0')),\n","              ('module.layer3.0.conv1.output_zero_point',\n","               tensor([0.], device='cuda:0')),\n","              ('module.layer3.0.conv1.w_scale', tensor([[[[ 728083.8125]]],\n","               \n","               \n","                       [[[ 864605.5000]]],\n","               \n","               \n","                       [[[ 723560.8125]]],\n","               \n","               \n","                       [[[ 611123.3750]]],\n","               \n","               \n","                       [[[1016283.0000]]],\n","               \n","               \n","                       [[[ 577813.1250]]],\n","               \n","               \n","                       [[[ 664458.5625]]],\n","               \n","               \n","                       [[[ 761886.0000]]],\n","               \n","               \n","                       [[[ 691961.7500]]],\n","               \n","               \n","                       [[[1142922.0000]]],\n","               \n","               \n","                       [[[ 817547.0000]]],\n","               \n","               \n","                       [[[ 836114.6875]]],\n","               \n","               \n","                       [[[ 656681.5000]]],\n","               \n","               \n","                       [[[ 684506.5000]]],\n","               \n","               \n","                       [[[ 605985.1250]]],\n","               \n","               \n","                       [[[ 797691.8125]]],\n","               \n","               \n","                       [[[ 805410.2500]]],\n","               \n","               \n","                       [[[ 725653.4375]]],\n","               \n","               \n","                       [[[1097145.6250]]],\n","               \n","               \n","                       [[[ 687317.8750]]],\n","               \n","               \n","                       [[[ 716189.6875]]],\n","               \n","               \n","                       [[[ 651171.1875]]],\n","               \n","               \n","                       [[[ 972243.7500]]],\n","               \n","               \n","                       [[[ 737629.6250]]],\n","               \n","               \n","                       [[[ 679450.5625]]],\n","               \n","               \n","                       [[[ 939855.0625]]],\n","               \n","               \n","                       [[[ 678462.0000]]],\n","               \n","               \n","                       [[[ 543157.5000]]],\n","               \n","               \n","                       [[[ 689383.4375]]],\n","               \n","               \n","                       [[[ 842208.6875]]],\n","               \n","               \n","                       [[[ 611785.8750]]],\n","               \n","               \n","                       [[[ 839829.3750]]],\n","               \n","               \n","                       [[[ 944539.3750]]],\n","               \n","               \n","                       [[[ 663834.2500]]],\n","               \n","               \n","                       [[[ 573264.1875]]],\n","               \n","               \n","                       [[[ 790493.0625]]],\n","               \n","               \n","                       [[[ 792077.5000]]],\n","               \n","               \n","                       [[[ 771002.3750]]],\n","               \n","               \n","                       [[[ 767023.7500]]],\n","               \n","               \n","                       [[[ 823787.3750]]],\n","               \n","               \n","                       [[[ 698103.6875]]],\n","               \n","               \n","                       [[[ 981065.2500]]],\n","               \n","               \n","                       [[[ 763928.6250]]],\n","               \n","               \n","                       [[[ 625677.0000]]],\n","               \n","               \n","                       [[[ 759217.1875]]],\n","               \n","               \n","                       [[[ 642915.1250]]],\n","               \n","               \n","                       [[[ 884108.3750]]],\n","               \n","               \n","                       [[[ 719915.1875]]],\n","               \n","               \n","                       [[[ 713158.6250]]],\n","               \n","               \n","                       [[[ 851782.1250]]],\n","               \n","               \n","                       [[[ 538898.8750]]],\n","               \n","               \n","                       [[[ 704129.7500]]],\n","               \n","               \n","                       [[[ 724617.9375]]],\n","               \n","               \n","                       [[[ 760627.0625]]],\n","               \n","               \n","                       [[[ 653477.5000]]],\n","               \n","               \n","                       [[[ 750003.6875]]],\n","               \n","               \n","                       [[[ 637170.1250]]],\n","               \n","               \n","                       [[[ 687817.8125]]],\n","               \n","               \n","                       [[[ 622010.0000]]],\n","               \n","               \n","                       [[[ 796021.3125]]],\n","               \n","               \n","                       [[[ 714473.0625]]],\n","               \n","               \n","                       [[[ 661644.6250]]],\n","               \n","               \n","                       [[[ 665708.6250]]],\n","               \n","               \n","                       [[[ 482447.0625]]]], device='cuda:0')),\n","              ('module.layer3.0.conv1.w_zero_point', tensor([[[[-26860.]]],\n","               \n","               \n","                       [[[-35542.]]],\n","               \n","               \n","                       [[[-28536.]]],\n","               \n","               \n","                       [[[-27125.]]],\n","               \n","               \n","                       [[[-28877.]]],\n","               \n","               \n","                       [[[-34235.]]],\n","               \n","               \n","                       [[[-27240.]]],\n","               \n","               \n","                       [[[-31994.]]],\n","               \n","               \n","                       [[[-22740.]]],\n","               \n","               \n","                       [[[-30507.]]],\n","               \n","               \n","                       [[[-39602.]]],\n","               \n","               \n","                       [[[-28968.]]],\n","               \n","               \n","                       [[[-31362.]]],\n","               \n","               \n","                       [[[-27526.]]],\n","               \n","               \n","                       [[[-29622.]]],\n","               \n","               \n","                       [[[-33076.]]],\n","               \n","               \n","                       [[[-29337.]]],\n","               \n","               \n","                       [[[-27052.]]],\n","               \n","               \n","                       [[[-23841.]]],\n","               \n","               \n","                       [[[-28120.]]],\n","               \n","               \n","                       [[[-32210.]]],\n","               \n","               \n","                       [[[-24544.]]],\n","               \n","               \n","                       [[[-36329.]]],\n","               \n","               \n","                       [[[-32101.]]],\n","               \n","               \n","                       [[[-27125.]]],\n","               \n","               \n","                       [[[-29577.]]],\n","               \n","               \n","                       [[[-30200.]]],\n","               \n","               \n","                       [[[-22454.]]],\n","               \n","               \n","                       [[[-35096.]]],\n","               \n","               \n","                       [[[-27444.]]],\n","               \n","               \n","                       [[[-25984.]]],\n","               \n","               \n","                       [[[-26300.]]],\n","               \n","               \n","                       [[[-28709.]]],\n","               \n","               \n","                       [[[-30174.]]],\n","               \n","               \n","                       [[[-24433.]]],\n","               \n","               \n","                       [[[-30579.]]],\n","               \n","               \n","                       [[[-34731.]]],\n","               \n","               \n","                       [[[-33037.]]],\n","               \n","               \n","                       [[[-33883.]]],\n","               \n","               \n","                       [[[-33152.]]],\n","               \n","               \n","                       [[[-34319.]]],\n","               \n","               \n","                       [[[-27864.]]],\n","               \n","               \n","                       [[[-27335.]]],\n","               \n","               \n","                       [[[-31354.]]],\n","               \n","               \n","                       [[[-26515.]]],\n","               \n","               \n","                       [[[-30085.]]],\n","               \n","               \n","                       [[[-26067.]]],\n","               \n","               \n","                       [[[-27927.]]],\n","               \n","               \n","                       [[[-37473.]]],\n","               \n","               \n","                       [[[-41535.]]],\n","               \n","               \n","                       [[[-24983.]]],\n","               \n","               \n","                       [[[-27719.]]],\n","               \n","               \n","                       [[[-35816.]]],\n","               \n","               \n","                       [[[-26616.]]],\n","               \n","               \n","                       [[[-32183.]]],\n","               \n","               \n","                       [[[-29397.]]],\n","               \n","               \n","                       [[[-31579.]]],\n","               \n","               \n","                       [[[-32010.]]],\n","               \n","               \n","                       [[[-28298.]]],\n","               \n","               \n","                       [[[-25245.]]],\n","               \n","               \n","                       [[[-28761.]]],\n","               \n","               \n","                       [[[-32933.]]],\n","               \n","               \n","                       [[[-28987.]]],\n","               \n","               \n","                       [[[-20226.]]]], device='cuda:0')),\n","              ('module.layer3.0.conv1.fp_bias',\n","               tensor([-1.3087,  0.3994,  0.4704, -0.0452,  0.7907, -0.3001, -0.7177, -0.0298,\n","                       -0.2321,  0.4260,  0.4874, -0.4519, -0.4781, -0.0421,  0.4106,  0.3920,\n","                       -0.9714, -0.1606, -0.6796,  0.1034,  0.4163, -0.0852,  0.9711,  0.2611,\n","                       -0.0993, -0.4703,  0.0657, -1.4273,  0.7409, -1.1488, -0.2981,  0.0588,\n","                       -0.6838,  0.0937, -0.2530,  0.6801,  0.8123, -0.0049,  0.5316, -0.7827,\n","                       -0.2588, -0.1922, -0.7491, -0.2128,  0.6914,  0.4302,  0.2299,  0.5350,\n","                        0.9258,  0.7856, -0.8005, -0.1179, -0.3720, -0.3614, -0.2464, -0.3836,\n","                        0.6962,  0.1610, -0.2807, -0.4706,  0.2289,  1.7385,  0.3865, -0.4275],\n","                      device='cuda:0')),\n","              ('module.layer3.0.conv1.accum_scale', tensor([[[4.9950e+09]],\n","               \n","                       [[5.9316e+09]],\n","               \n","                       [[4.9639e+09]],\n","               \n","                       [[4.1926e+09]],\n","               \n","                       [[6.9721e+09]],\n","               \n","                       [[3.9640e+09]],\n","               \n","                       [[4.5585e+09]],\n","               \n","                       [[5.2269e+09]],\n","               \n","                       [[4.7472e+09]],\n","               \n","                       [[7.8409e+09]],\n","               \n","                       [[5.6087e+09]],\n","               \n","                       [[5.7361e+09]],\n","               \n","                       [[4.5051e+09]],\n","               \n","                       [[4.6960e+09]],\n","               \n","                       [[4.1573e+09]],\n","               \n","                       [[5.4725e+09]],\n","               \n","                       [[5.5255e+09]],\n","               \n","                       [[4.9783e+09]],\n","               \n","                       [[7.5269e+09]],\n","               \n","                       [[4.7153e+09]],\n","               \n","                       [[4.9134e+09]],\n","               \n","                       [[4.4673e+09]],\n","               \n","                       [[6.6700e+09]],\n","               \n","                       [[5.0605e+09]],\n","               \n","                       [[4.6613e+09]],\n","               \n","                       [[6.4478e+09]],\n","               \n","                       [[4.6545e+09]],\n","               \n","                       [[3.7263e+09]],\n","               \n","                       [[4.7295e+09]],\n","               \n","                       [[5.7779e+09]],\n","               \n","                       [[4.1971e+09]],\n","               \n","                       [[5.7616e+09]],\n","               \n","                       [[6.4799e+09]],\n","               \n","                       [[4.5542e+09]],\n","               \n","                       [[3.9328e+09]],\n","               \n","                       [[5.4231e+09]],\n","               \n","                       [[5.4340e+09]],\n","               \n","                       [[5.2894e+09]],\n","               \n","                       [[5.2621e+09]],\n","               \n","                       [[5.6515e+09]],\n","               \n","                       [[4.7893e+09]],\n","               \n","                       [[6.7305e+09]],\n","               \n","                       [[5.2409e+09]],\n","               \n","                       [[4.2924e+09]],\n","               \n","                       [[5.2086e+09]],\n","               \n","                       [[4.4107e+09]],\n","               \n","                       [[6.0654e+09]],\n","               \n","                       [[4.9389e+09]],\n","               \n","                       [[4.8926e+09]],\n","               \n","                       [[5.8436e+09]],\n","               \n","                       [[3.6971e+09]],\n","               \n","                       [[4.8306e+09]],\n","               \n","                       [[4.9712e+09]],\n","               \n","                       [[5.2182e+09]],\n","               \n","                       [[4.4831e+09]],\n","               \n","                       [[5.1453e+09]],\n","               \n","                       [[4.3713e+09]],\n","               \n","                       [[4.7187e+09]],\n","               \n","                       [[4.2673e+09]],\n","               \n","                       [[5.4610e+09]],\n","               \n","                       [[4.9016e+09]],\n","               \n","                       [[4.5392e+09]],\n","               \n","                       [[4.5670e+09]],\n","               \n","                       [[3.3098e+09]]], device='cuda:0')),\n","              ('module.layer3.0.conv1.is_simulated_quant_weight_shifted',\n","               tensor(False, device='cuda:0')),\n","              ('module.layer3.0.conv1.wrapped_module.weight',\n","               tensor([[[[30097., 18980., 17262.],\n","                         [28957., 23355., 20661.],\n","                         [30957., 32526., 19956.]],\n","               \n","                        [[32682., 30578., 29428.],\n","                         [39398., 32902., 28977.],\n","                         [37226., 44870., 37211.]],\n","               \n","                        [[33723., 38261., 39226.],\n","                         [33503., 35897., 33631.],\n","                         [31005., 34423., 28432.]],\n","               \n","                        ...,\n","               \n","                        [[18345., 39217., 40264.],\n","                         [37302., 35476., 43482.],\n","                         [43483., 40776., 34267.]],\n","               \n","                        [[13289., 38323., 39000.],\n","                         [19981., 19299., 21861.],\n","                         [17058.,     0., 11438.]],\n","               \n","                        [[34588., 34598., 37032.],\n","                         [38708., 33244., 38525.],\n","                         [24327., 18383., 27248.]]],\n","               \n","               \n","                       [[[19908., 19894., 17667.],\n","                         [33471., 28823., 40759.],\n","                         [34485., 32172., 45324.]],\n","               \n","                        [[33790., 32209., 33228.],\n","                         [27692., 28394., 32800.],\n","                         [42413., 42709., 42971.]],\n","               \n","                        [[30025., 41081., 35306.],\n","                         [35448., 34553., 28140.],\n","                         [31716., 33904., 31051.]],\n","               \n","                        ...,\n","               \n","                        [[44119., 43976., 47692.],\n","                         [52391., 52916., 48164.],\n","                         [47171., 49906., 40190.]],\n","               \n","                        [[42296., 38689., 36063.],\n","                         [25115., 28181., 16904.],\n","                         [34618., 19963., 29060.]],\n","               \n","                        [[ 2153., 17053., 10147.],\n","                         [12564., 24244., 18651.],\n","                         [21885., 25900., 21213.]]],\n","               \n","               \n","                       [[[23149., 20192., 23029.],\n","                         [29389., 27410., 39433.],\n","                         [29290., 35840., 35293.]],\n","               \n","                        [[36127., 19248.,  7520.],\n","                         [32655., 16851., 19032.],\n","                         [41517., 35232., 45514.]],\n","               \n","                        [[35251., 20947., 18654.],\n","                         [21770., 17281., 18806.],\n","                         [31416., 24748., 30314.]],\n","               \n","                        ...,\n","               \n","                        [[34946., 49417., 39387.],\n","                         [33315., 38533., 32049.],\n","                         [29374., 28824., 25592.]],\n","               \n","                        [[ 8651., 10203., 17437.],\n","                         [22631., 28261., 24437.],\n","                         [34142., 33953., 42018.]],\n","               \n","                        [[24654., 35057., 26276.],\n","                         [17520., 13084., 21900.],\n","                         [14024., 18921., 20401.]]],\n","               \n","               \n","                       ...,\n","               \n","               \n","                       [[[40313., 40159., 48495.],\n","                         [48180., 32748., 33747.],\n","                         [43050., 33371., 27960.]],\n","               \n","                        [[24768., 22402., 31917.],\n","                         [26177., 20159., 33902.],\n","                         [27221., 16185., 29699.]],\n","               \n","                        [[37899., 37972., 34192.],\n","                         [38943., 33111., 26796.],\n","                         [38611., 33194., 26957.]],\n","               \n","                        ...,\n","               \n","                        [[36783., 35684., 42971.],\n","                         [32960., 38222., 29381.],\n","                         [32328., 32778., 31692.]],\n","               \n","                        [[42912., 28361., 22145.],\n","                         [45793., 35317., 16824.],\n","                         [50019., 35857., 23623.]],\n","               \n","                        [[45672., 34963., 27415.],\n","                         [36605., 34748., 22344.],\n","                         [38167., 37432., 28276.]]],\n","               \n","               \n","                       [[[14466., 15298., 16031.],\n","                         [19411., 24182., 51185.],\n","                         [29331., 50935., 57524.]],\n","               \n","                        [[37330., 23985., 22844.],\n","                         [38481., 24144., 24644.],\n","                         [33036., 11128., 13152.]],\n","               \n","                        [[ 7959.,  4578., 14649.],\n","                         [ 5779., 13315., 10949.],\n","                         [25363., 15880., 25307.]],\n","               \n","                        ...,\n","               \n","                        [[23196., 18493., 22377.],\n","                         [25614., 13197., 27577.],\n","                         [34151., 29930., 36718.]],\n","               \n","                        [[12761., 16826., 13323.],\n","                         [33442., 39858., 40118.],\n","                         [40247., 55289., 53847.]],\n","               \n","                        [[41686., 30582., 34932.],\n","                         [32794., 29802., 31767.],\n","                         [27478., 21933., 29283.]]],\n","               \n","               \n","                       [[[18443., 24430., 26074.],\n","                         [28199., 27320., 25967.],\n","                         [27167., 30103., 20271.]],\n","               \n","                        [[ 8902., 10252., 18029.],\n","                         [21064., 20668., 23678.],\n","                         [30032., 30655., 37975.]],\n","               \n","                        [[39138., 35736., 33415.],\n","                         [20583., 18644., 17996.],\n","                         [12007.,  8175., 10103.]],\n","               \n","                        ...,\n","               \n","                        [[18686., 14251., 16790.],\n","                         [14959., 15863., 15701.],\n","                         [13444., 18010., 21806.]],\n","               \n","                        [[18768., 30691., 28411.],\n","                         [23360., 23838., 21854.],\n","                         [23113., 23940., 19377.]],\n","               \n","                        [[22661., 23850., 12334.],\n","                         [28641., 21216., 15814.],\n","                         [26761., 15711., 12837.]]]], device='cuda:0')),\n","              ('module.layer3.0.conv1.wrapped_module.bias',\n","               tensor([-2.1475e+09,  2.1475e+09,  2.1475e+09, -1.8948e+08,  2.1475e+09,\n","                       -1.1896e+09, -2.1475e+09, -1.5562e+08, -1.1020e+09,  2.1475e+09,\n","                        2.1475e+09, -2.1475e+09, -2.1475e+09, -1.9765e+08,  1.7069e+09,\n","                        2.1454e+09, -2.1475e+09, -7.9946e+08, -2.1475e+09,  4.8735e+08,\n","                        2.0452e+09, -3.8042e+08,  2.1475e+09,  1.3211e+09, -4.6290e+08,\n","                       -2.1475e+09,  3.0567e+08, -2.1475e+09,  2.1475e+09, -2.1475e+09,\n","                       -1.2513e+09,  3.3863e+08, -2.1475e+09,  4.2688e+08, -9.9509e+08,\n","                        2.1475e+09,  2.1475e+09, -2.5842e+07,  2.1475e+09, -2.1475e+09,\n","                       -1.2393e+09, -1.2936e+09, -2.1475e+09, -9.1327e+08,  2.1475e+09,\n","                        1.8974e+09,  1.3942e+09,  2.1475e+09,  2.1475e+09,  2.1475e+09,\n","                       -2.1475e+09, -5.6947e+08, -1.8492e+09, -1.8857e+09, -1.1045e+09,\n","                       -1.9738e+09,  2.1475e+09,  7.5983e+08, -1.1978e+09, -2.1475e+09,\n","                        1.1218e+09,  2.1475e+09,  1.7652e+09, -1.4150e+09], device='cuda:0')),\n","              ('module.layer3.0.conv2.num_forwards',\n","               tensor([40], device='cuda:0')),\n","              ('module.layer3.0.conv2.force_readjust',\n","               tensor(False, device='cuda:0')),\n","              ('module.layer3.0.conv2.output_scale',\n","               tensor([7569.6299], device='cuda:0')),\n","              ('module.layer3.0.conv2.output_zero_point',\n","               tensor([-26257.], device='cuda:0')),\n","              ('module.layer3.0.conv2.w_scale', tensor([[[[1.0674e+05]]],\n","               \n","               \n","                       [[[1.0299e+05]]],\n","               \n","               \n","                       [[[1.7845e+05]]],\n","               \n","               \n","                       [[[1.2936e+05]]],\n","               \n","               \n","                       [[[1.1132e+05]]],\n","               \n","               \n","                       [[[1.5333e+05]]],\n","               \n","               \n","                       [[[1.6739e+05]]],\n","               \n","               \n","                       [[[2.1051e+09]]],\n","               \n","               \n","                       [[[9.8213e+04]]],\n","               \n","               \n","                       [[[1.3890e+09]]],\n","               \n","               \n","                       [[[1.6513e+05]]],\n","               \n","               \n","                       [[[9.8238e+04]]],\n","               \n","               \n","                       [[[1.3059e+05]]],\n","               \n","               \n","                       [[[9.1327e+04]]],\n","               \n","               \n","                       [[[1.5809e+05]]],\n","               \n","               \n","                       [[[1.0912e+05]]],\n","               \n","               \n","                       [[[1.4345e+05]]],\n","               \n","               \n","                       [[[1.1631e+05]]],\n","               \n","               \n","                       [[[1.2202e+05]]],\n","               \n","               \n","                       [[[1.2356e+05]]],\n","               \n","               \n","                       [[[9.7795e+04]]],\n","               \n","               \n","                       [[[1.5031e+05]]],\n","               \n","               \n","                       [[[1.4216e+05]]],\n","               \n","               \n","                       [[[1.5167e+05]]],\n","               \n","               \n","                       [[[1.8950e+05]]],\n","               \n","               \n","                       [[[2.4414e+05]]],\n","               \n","               \n","                       [[[1.3952e+05]]],\n","               \n","               \n","                       [[[1.5133e+05]]],\n","               \n","               \n","                       [[[1.3283e+05]]],\n","               \n","               \n","                       [[[1.2678e+05]]],\n","               \n","               \n","                       [[[1.1758e+05]]],\n","               \n","               \n","                       [[[1.5324e+05]]],\n","               \n","               \n","                       [[[1.2166e+05]]],\n","               \n","               \n","                       [[[1.4565e+05]]],\n","               \n","               \n","                       [[[1.6801e+05]]],\n","               \n","               \n","                       [[[1.0052e+05]]],\n","               \n","               \n","                       [[[1.1452e+05]]],\n","               \n","               \n","                       [[[1.6201e+05]]],\n","               \n","               \n","                       [[[1.1410e+05]]],\n","               \n","               \n","                       [[[1.2234e+05]]],\n","               \n","               \n","                       [[[1.5080e+05]]],\n","               \n","               \n","                       [[[1.2243e+05]]],\n","               \n","               \n","                       [[[1.0849e+05]]],\n","               \n","               \n","                       [[[1.4304e+05]]],\n","               \n","               \n","                       [[[2.7959e+08]]],\n","               \n","               \n","                       [[[1.3880e+05]]],\n","               \n","               \n","                       [[[2.3191e+08]]],\n","               \n","               \n","                       [[[2.4484e+08]]],\n","               \n","               \n","                       [[[1.1296e+05]]],\n","               \n","               \n","                       [[[6.9757e+08]]],\n","               \n","               \n","                       [[[1.4653e+05]]],\n","               \n","               \n","                       [[[4.4173e+08]]],\n","               \n","               \n","                       [[[1.5405e+05]]],\n","               \n","               \n","                       [[[1.4490e+05]]],\n","               \n","               \n","                       [[[8.8103e+08]]],\n","               \n","               \n","                       [[[1.2582e+05]]],\n","               \n","               \n","                       [[[3.2077e+05]]],\n","               \n","               \n","                       [[[1.3520e+05]]],\n","               \n","               \n","                       [[[1.0871e+05]]],\n","               \n","               \n","                       [[[1.3764e+05]]],\n","               \n","               \n","                       [[[1.2152e+05]]],\n","               \n","               \n","                       [[[5.3331e+08]]],\n","               \n","               \n","                       [[[1.3149e+05]]],\n","               \n","               \n","                       [[[1.2170e+05]]]], device='cuda:0')),\n","              ('module.layer3.0.conv2.w_zero_point', tensor([[[[-26805.]]],\n","               \n","               \n","                       [[[-24697.]]],\n","               \n","               \n","                       [[[-32350.]]],\n","               \n","               \n","                       [[[-25785.]]],\n","               \n","               \n","                       [[[-23593.]]],\n","               \n","               \n","                       [[[-32675.]]],\n","               \n","               \n","                       [[[-28404.]]],\n","               \n","               \n","                       [[[-29567.]]],\n","               \n","               \n","                       [[[-22868.]]],\n","               \n","               \n","                       [[[-24427.]]],\n","               \n","               \n","                       [[[-26387.]]],\n","               \n","               \n","                       [[[-21871.]]],\n","               \n","               \n","                       [[[-25759.]]],\n","               \n","               \n","                       [[[-26657.]]],\n","               \n","               \n","                       [[[-26293.]]],\n","               \n","               \n","                       [[[-32151.]]],\n","               \n","               \n","                       [[[-33238.]]],\n","               \n","               \n","                       [[[-26273.]]],\n","               \n","               \n","                       [[[-31279.]]],\n","               \n","               \n","                       [[[-31838.]]],\n","               \n","               \n","                       [[[-27728.]]],\n","               \n","               \n","                       [[[-22766.]]],\n","               \n","               \n","                       [[[-29933.]]],\n","               \n","               \n","                       [[[-31781.]]],\n","               \n","               \n","                       [[[-40667.]]],\n","               \n","               \n","                       [[[-33314.]]],\n","               \n","               \n","                       [[[-31757.]]],\n","               \n","               \n","                       [[[-27733.]]],\n","               \n","               \n","                       [[[-26986.]]],\n","               \n","               \n","                       [[[-31957.]]],\n","               \n","               \n","                       [[[-27349.]]],\n","               \n","               \n","                       [[[-32018.]]],\n","               \n","               \n","                       [[[-35235.]]],\n","               \n","               \n","                       [[[-31766.]]],\n","               \n","               \n","                       [[[-33584.]]],\n","               \n","               \n","                       [[[-23513.]]],\n","               \n","               \n","                       [[[-28125.]]],\n","               \n","               \n","                       [[[-34483.]]],\n","               \n","               \n","                       [[[-28773.]]],\n","               \n","               \n","                       [[[-30796.]]],\n","               \n","               \n","                       [[[-29120.]]],\n","               \n","               \n","                       [[[-25949.]]],\n","               \n","               \n","                       [[[-29178.]]],\n","               \n","               \n","                       [[[-30076.]]],\n","               \n","               \n","                       [[[-25230.]]],\n","               \n","               \n","                       [[[-30039.]]],\n","               \n","               \n","                       [[[-37940.]]],\n","               \n","               \n","                       [[[-41615.]]],\n","               \n","               \n","                       [[[-31062.]]],\n","               \n","               \n","                       [[[-28872.]]],\n","               \n","               \n","                       [[[-32815.]]],\n","               \n","               \n","                       [[[-24858.]]],\n","               \n","               \n","                       [[[-30836.]]],\n","               \n","               \n","                       [[[-24573.]]],\n","               \n","               \n","                       [[[-19843.]]],\n","               \n","               \n","                       [[[-32259.]]],\n","               \n","               \n","                       [[[-29209.]]],\n","               \n","               \n","                       [[[-25576.]]],\n","               \n","               \n","                       [[[-29839.]]],\n","               \n","               \n","                       [[[-27271.]]],\n","               \n","               \n","                       [[[-24621.]]],\n","               \n","               \n","                       [[[-24576.]]],\n","               \n","               \n","                       [[[-23048.]]],\n","               \n","               \n","                       [[[-23181.]]]], device='cuda:0')),\n","              ('module.layer3.0.conv2.fp_bias',\n","               tensor([ 4.8027e-01, -9.3377e-02,  3.6498e-01,  4.8065e-01,  1.2731e-01,\n","                       -1.1368e-01,  2.6372e-02, -2.4309e-03,  6.3337e-01, -1.8282e-03,\n","                        1.3937e-01, -2.0918e-02,  3.3177e-01, -6.1819e-02, -2.0890e-01,\n","                        9.2682e-02,  7.7287e-01, -1.0127e-01,  6.5857e-02,  5.2935e-01,\n","                       -5.5540e-01,  3.4520e-01, -2.2132e-01, -2.5901e-01,  1.6120e+00,\n","                        8.3786e-01,  7.0218e-01,  3.2578e-01, -1.2312e-01,  6.9355e-01,\n","                       -1.0356e-01,  4.2654e-01,  3.6808e-01, -1.8496e-01,  3.4523e-01,\n","                        3.4904e-02,  3.4002e-01,  6.5843e-01,  8.0904e-02, -6.3028e-01,\n","                       -1.1723e-01,  1.0015e-01, -2.7914e-01,  3.3809e-01, -3.7148e-03,\n","                        2.5120e-01,  8.6007e-05,  1.1266e-03,  4.0108e-01, -1.9938e-03,\n","                        4.6657e-02, -2.1901e-03, -2.9864e-01,  6.8848e-01, -2.6391e-03,\n","                        4.5241e-01, -6.7968e-02,  3.0224e-01, -1.1730e-01,  1.1745e-01,\n","                        2.7839e-01, -2.2489e-03, -2.4756e-01, -1.2899e-01], device='cuda:0')),\n","              ('module.layer3.0.conv2.accum_scale', tensor([[[2.5957e+09]],\n","               \n","                       [[2.5044e+09]],\n","               \n","                       [[4.3395e+09]],\n","               \n","                       [[3.1457e+09]],\n","               \n","                       [[2.7070e+09]],\n","               \n","                       [[3.7286e+09]],\n","               \n","                       [[4.0706e+09]],\n","               \n","                       [[5.1192e+13]],\n","               \n","                       [[2.3883e+09]],\n","               \n","                       [[3.3776e+13]],\n","               \n","                       [[4.0156e+09]],\n","               \n","                       [[2.3889e+09]],\n","               \n","                       [[3.1756e+09]],\n","               \n","                       [[2.2209e+09]],\n","               \n","                       [[3.8444e+09]],\n","               \n","                       [[2.6536e+09]],\n","               \n","                       [[3.4883e+09]],\n","               \n","                       [[2.8283e+09]],\n","               \n","                       [[2.9672e+09]],\n","               \n","                       [[3.0048e+09]],\n","               \n","                       [[2.3782e+09]],\n","               \n","                       [[3.6551e+09]],\n","               \n","                       [[3.4570e+09]],\n","               \n","                       [[3.6884e+09]],\n","               \n","                       [[4.6082e+09]],\n","               \n","                       [[5.9369e+09]],\n","               \n","                       [[3.3928e+09]],\n","               \n","                       [[3.6801e+09]],\n","               \n","                       [[3.2301e+09]],\n","               \n","                       [[3.0830e+09]],\n","               \n","                       [[2.8592e+09]],\n","               \n","                       [[3.7264e+09]],\n","               \n","                       [[2.9584e+09]],\n","               \n","                       [[3.5418e+09]],\n","               \n","                       [[4.0856e+09]],\n","               \n","                       [[2.4444e+09]],\n","               \n","                       [[2.7849e+09]],\n","               \n","                       [[3.9398e+09]],\n","               \n","                       [[2.7747e+09]],\n","               \n","                       [[2.9750e+09]],\n","               \n","                       [[3.6671e+09]],\n","               \n","                       [[2.9771e+09]],\n","               \n","                       [[2.6383e+09]],\n","               \n","                       [[3.4784e+09]],\n","               \n","                       [[6.7989e+12]],\n","               \n","                       [[3.3754e+09]],\n","               \n","                       [[5.6394e+12]],\n","               \n","                       [[5.9539e+12]],\n","               \n","                       [[2.7470e+09]],\n","               \n","                       [[1.6963e+13]],\n","               \n","                       [[3.5633e+09]],\n","               \n","                       [[1.0742e+13]],\n","               \n","                       [[3.7461e+09]],\n","               \n","                       [[3.5236e+09]],\n","               \n","                       [[2.1425e+13]],\n","               \n","                       [[3.0596e+09]],\n","               \n","                       [[7.8004e+09]],\n","               \n","                       [[3.2876e+09]],\n","               \n","                       [[2.6437e+09]],\n","               \n","                       [[3.3470e+09]],\n","               \n","                       [[2.9550e+09]],\n","               \n","                       [[1.2969e+13]],\n","               \n","                       [[3.1974e+09]],\n","               \n","                       [[2.9595e+09]]], device='cuda:0')),\n","              ('module.layer3.0.conv2.is_simulated_quant_weight_shifted',\n","               tensor(False, device='cuda:0')),\n","              ('module.layer3.0.conv2.wrapped_module.weight',\n","               tensor([[[[32800., 24655., 25333.],\n","                         [18896., 21130., 22849.],\n","                         [21504., 10532., 22452.]],\n","               \n","                        [[25179., 15284., 16330.],\n","                         [23746., 18170., 26568.],\n","                         [30177., 24746., 26318.]],\n","               \n","                        [[43502., 30448., 25791.],\n","                         [22304., 22860., 37192.],\n","                         [30757., 42538., 32551.]],\n","               \n","                        ...,\n","               \n","                        [[29694., 25832., 21213.],\n","                         [ 8550., 12877., 16174.],\n","                         [12029., 13463., 20600.]],\n","               \n","                        [[17288., 30336., 27402.],\n","                         [28476., 35700., 41611.],\n","                         [41762., 34573., 37955.]],\n","               \n","                        [[27088., 26328., 45418.],\n","                         [26964., 32815., 36392.],\n","                         [14476., 31975., 29946.]]],\n","               \n","               \n","                       [[[33124., 27932., 23909.],\n","                         [23200., 22729., 26884.],\n","                         [12684.,  9219., 14988.]],\n","               \n","                        [[26244., 23788.,  9716.],\n","                         [25059., 33365., 22508.],\n","                         [10007., 14193., 17160.]],\n","               \n","                        [[29842., 35399., 35573.],\n","                         [38727., 23956., 14346.],\n","                         [37039., 43977., 38861.]],\n","               \n","                        ...,\n","               \n","                        [[ 7259., 18141., 24829.],\n","                         [22050., 37889., 23984.],\n","                         [37576., 41823., 28509.]],\n","               \n","                        [[21812., 33227., 22056.],\n","                         [26306., 17940., 16612.],\n","                         [34498., 29342., 25599.]],\n","               \n","                        [[36086., 29087., 22888.],\n","                         [24913., 22059., 25737.],\n","                         [14266., 15273., 26864.]]],\n","               \n","               \n","                       [[[48186., 40041., 52116.],\n","                         [26749., 27924., 21078.],\n","                         [24757., 35436., 35431.]],\n","               \n","                        [[40347., 28639., 29343.],\n","                         [40002., 23075., 17930.],\n","                         [38776., 27742., 21942.]],\n","               \n","                        [[21486., 20832., 38584.],\n","                         [12126., 21784., 57395.],\n","                         [ 8194., 40240., 52249.]],\n","               \n","                        ...,\n","               \n","                        [[34739., 40338., 27814.],\n","                         [37516., 24941., 31857.],\n","                         [46989., 19633., 34816.]],\n","               \n","                        [[35184., 37601., 33059.],\n","                         [15479., 23745., 44150.],\n","                         [32362., 39854., 35929.]],\n","               \n","                        [[25955., 22607., 30326.],\n","                         [27380., 45482., 39776.],\n","                         [27399., 57331., 35561.]]],\n","               \n","               \n","                       ...,\n","               \n","               \n","                       [[[12667., 16474., 19325.],\n","                         [20156., 26232., 23641.],\n","                         [20176., 21111., 30112.]],\n","               \n","                        [[40228., 42276., 32797.],\n","                         [30567., 51064., 37969.],\n","                         [24307., 42191., 35103.]],\n","               \n","                        [[19831., 10896.,  3484.],\n","                         [14890., 14187., 21476.],\n","                         [16677., 16937., 25721.]],\n","               \n","                        ...,\n","               \n","                        [[45692., 34108., 27694.],\n","                         [13336., 22635., 27581.],\n","                         [22480., 32466., 40398.]],\n","               \n","                        [[29019., 36427., 38598.],\n","                         [37521., 37448., 26000.],\n","                         [24062., 24175., 27708.]],\n","               \n","                        [[27824., 35917., 31048.],\n","                         [18387., 19556., 33471.],\n","                         [12251., 18877., 32900.]]],\n","               \n","               \n","                       [[[15222., 19696., 25723.],\n","                         [23099., 10606., 20933.],\n","                         [12796., 25696., 23974.]],\n","               \n","                        [[27980., 46819., 49045.],\n","                         [21446., 14611., 17732.],\n","                         [10232.,  7649., 18463.]],\n","               \n","                        [[33157., 29967., 14735.],\n","                         [23518., 10602., 11482.],\n","                         [14567., 24717., 27398.]],\n","               \n","                        ...,\n","               \n","                        [[43079., 33408., 28400.],\n","                         [42266., 37042., 15410.],\n","                         [23769., 33896., 23823.]],\n","               \n","                        [[20935., 30544., 34878.],\n","                         [11655.,  5781.,  6749.],\n","                         [20136., 11256., 21807.]],\n","               \n","                        [[ 9585.,  8326.,  7424.],\n","                         [ 9628., 18330., 23913.],\n","                         [ 9610., 20753., 10262.]]],\n","               \n","               \n","                       [[[26124., 15117., 16483.],\n","                         [32255., 14832., 20210.],\n","                         [26645., 10149., 19754.]],\n","               \n","                        [[23352., 29709., 28760.],\n","                         [26738., 27737., 19192.],\n","                         [21374., 17747., 28632.]],\n","               \n","                        [[43782., 24410.,     0.],\n","                         [28392., 38101., 13638.],\n","                         [ 4858., 33010., 25688.]],\n","               \n","                        ...,\n","               \n","                        [[24192., 26190., 33440.],\n","                         [13524., 23963., 22761.],\n","                         [ 9130., 24448., 11390.]],\n","               \n","                        [[   95., 26104., 35869.],\n","                         [ 6195., 22056., 24316.],\n","                         [ 2810., 31758., 19936.]],\n","               \n","                        [[16845., 23959., 21610.],\n","                         [26479., 51332., 45364.],\n","                         [39759., 33511., 53847.]]]], device='cuda:0')),\n","              ('module.layer3.0.conv2.wrapped_module.bias',\n","               tensor([ 1.2466e+09, -2.3385e+08,  1.5838e+09,  1.5120e+09,  3.4464e+08,\n","                       -4.2386e+08,  1.0735e+08, -2.1475e+09,  1.5127e+09, -2.1475e+09,\n","                        5.5964e+08, -4.9971e+07,  1.0536e+09, -1.3729e+08, -8.0310e+08,\n","                        2.4595e+08,  2.1475e+09, -2.8642e+08,  1.9541e+08,  1.5906e+09,\n","                       -1.3208e+09,  1.2617e+09, -7.6509e+08, -9.5531e+08,  2.1475e+09,\n","                        2.1475e+09,  2.1475e+09,  1.1989e+09, -3.9769e+08,  2.1382e+09,\n","                       -2.9609e+08,  1.5895e+09,  1.0889e+09, -6.5511e+08,  1.4105e+09,\n","                        8.5320e+07,  9.4692e+08,  2.1475e+09,  2.2448e+08, -1.8751e+09,\n","                       -4.2987e+08,  2.9817e+08, -7.3646e+08,  1.1760e+09, -2.1475e+09,\n","                        8.4789e+08,  4.8503e+08,  2.1475e+09,  1.1018e+09, -2.1475e+09,\n","                        1.6625e+08, -2.1475e+09, -1.1187e+09,  2.1475e+09, -2.1475e+09,\n","                        1.3842e+09, -5.3017e+08,  9.9365e+08, -3.1011e+08,  3.9311e+08,\n","                        8.2264e+08, -2.1475e+09, -7.9156e+08, -3.8175e+08], device='cuda:0')),\n","              ('module.layer3.0.relu2.num_forwards',\n","               tensor([40], device='cuda:0')),\n","              ('module.layer3.0.relu2.force_readjust',\n","               tensor(False, device='cuda:0')),\n","              ('module.layer3.0.relu2.output_scale',\n","               tensor([9668.0859], device='cuda:0')),\n","              ('module.layer3.0.relu2.output_zero_point',\n","               tensor([0.], device='cuda:0')),\n","              ('module.layer3.0.downsample.0.num_forwards',\n","               tensor([40], device='cuda:0')),\n","              ('module.layer3.0.downsample.0.force_readjust',\n","               tensor(False, device='cuda:0')),\n","              ('module.layer3.0.downsample.0.output_scale',\n","               tensor([12698.3271], device='cuda:0')),\n","              ('module.layer3.0.downsample.0.output_zero_point',\n","               tensor([-24342.], device='cuda:0')),\n","              ('module.layer3.0.downsample.0.w_scale',\n","               tensor([[[[2.4598e+05]]],\n","               \n","               \n","                       [[[4.5813e+05]]],\n","               \n","               \n","                       [[[2.3180e+05]]],\n","               \n","               \n","                       [[[2.3402e+05]]],\n","               \n","               \n","                       [[[2.9250e+05]]],\n","               \n","               \n","                       [[[2.0181e+05]]],\n","               \n","               \n","                       [[[2.6044e+05]]],\n","               \n","               \n","                       [[[2.5041e+08]]],\n","               \n","               \n","                       [[[2.3403e+05]]],\n","               \n","               \n","                       [[[2.0772e+08]]],\n","               \n","               \n","                       [[[4.6741e+05]]],\n","               \n","               \n","                       [[[2.2377e+05]]],\n","               \n","               \n","                       [[[2.0708e+05]]],\n","               \n","               \n","                       [[[2.9790e+05]]],\n","               \n","               \n","                       [[[2.5998e+05]]],\n","               \n","               \n","                       [[[2.1769e+05]]],\n","               \n","               \n","                       [[[1.8632e+05]]],\n","               \n","               \n","                       [[[1.8099e+05]]],\n","               \n","               \n","                       [[[3.1900e+05]]],\n","               \n","               \n","                       [[[1.6080e+05]]],\n","               \n","               \n","                       [[[2.5480e+05]]],\n","               \n","               \n","                       [[[1.1005e+05]]],\n","               \n","               \n","                       [[[3.1646e+05]]],\n","               \n","               \n","                       [[[2.2340e+05]]],\n","               \n","               \n","                       [[[1.5317e+05]]],\n","               \n","               \n","                       [[[1.1428e+05]]],\n","               \n","               \n","                       [[[2.1393e+05]]],\n","               \n","               \n","                       [[[1.7341e+05]]],\n","               \n","               \n","                       [[[1.8092e+05]]],\n","               \n","               \n","                       [[[2.1114e+05]]],\n","               \n","               \n","                       [[[4.7444e+05]]],\n","               \n","               \n","                       [[[3.7755e+05]]],\n","               \n","               \n","                       [[[1.5598e+05]]],\n","               \n","               \n","                       [[[2.5758e+05]]],\n","               \n","               \n","                       [[[4.9619e+05]]],\n","               \n","               \n","                       [[[2.1834e+05]]],\n","               \n","               \n","                       [[[4.4056e+05]]],\n","               \n","               \n","                       [[[1.3079e+05]]],\n","               \n","               \n","                       [[[2.7450e+05]]],\n","               \n","               \n","                       [[[4.0167e+05]]],\n","               \n","               \n","                       [[[1.0860e+05]]],\n","               \n","               \n","                       [[[1.6988e+05]]],\n","               \n","               \n","                       [[[2.3450e+05]]],\n","               \n","               \n","                       [[[1.5759e+05]]],\n","               \n","               \n","                       [[[6.3908e+08]]],\n","               \n","               \n","                       [[[3.6400e+05]]],\n","               \n","               \n","                       [[[5.3223e+08]]],\n","               \n","               \n","                       [[[2.9551e+08]]],\n","               \n","               \n","                       [[[2.0978e+05]]],\n","               \n","               \n","                       [[[4.1486e+08]]],\n","               \n","               \n","                       [[[2.6741e+05]]],\n","               \n","               \n","                       [[[8.1791e+08]]],\n","               \n","               \n","                       [[[1.7556e+05]]],\n","               \n","               \n","                       [[[2.8708e+05]]],\n","               \n","               \n","                       [[[7.2966e+08]]],\n","               \n","               \n","                       [[[1.5521e+05]]],\n","               \n","               \n","                       [[[1.3649e+06]]],\n","               \n","               \n","                       [[[4.2834e+05]]],\n","               \n","               \n","                       [[[2.7487e+05]]],\n","               \n","               \n","                       [[[5.1725e+05]]],\n","               \n","               \n","                       [[[3.3467e+05]]],\n","               \n","               \n","                       [[[3.3035e+08]]],\n","               \n","               \n","                       [[[3.7193e+05]]],\n","               \n","               \n","                       [[[2.1102e+05]]]], device='cuda:0')),\n","              ('module.layer3.0.downsample.0.w_zero_point',\n","               tensor([[[[-25101.]]],\n","               \n","               \n","                       [[[-33914.]]],\n","               \n","               \n","                       [[[-29357.]]],\n","               \n","               \n","                       [[[-32771.]]],\n","               \n","               \n","                       [[[-29118.]]],\n","               \n","               \n","                       [[[-37145.]]],\n","               \n","               \n","                       [[[-25490.]]],\n","               \n","               \n","                       [[[-36344.]]],\n","               \n","               \n","                       [[[-32987.]]],\n","               \n","               \n","                       [[[-47409.]]],\n","               \n","               \n","                       [[[-27841.]]],\n","               \n","               \n","                       [[[-22998.]]],\n","               \n","               \n","                       [[[-18656.]]],\n","               \n","               \n","                       [[[-32552.]]],\n","               \n","               \n","                       [[[-31201.]]],\n","               \n","               \n","                       [[[-27890.]]],\n","               \n","               \n","                       [[[-34208.]]],\n","               \n","               \n","                       [[[-27705.]]],\n","               \n","               \n","                       [[[-32633.]]],\n","               \n","               \n","                       [[[-25360.]]],\n","               \n","               \n","                       [[[-28575.]]],\n","               \n","               \n","                       [[[-29138.]]],\n","               \n","               \n","                       [[[-32914.]]],\n","               \n","               \n","                       [[[-27046.]]],\n","               \n","               \n","                       [[[-17904.]]],\n","               \n","               \n","                       [[[-18459.]]],\n","               \n","               \n","                       [[[-32138.]]],\n","               \n","               \n","                       [[[-34241.]]],\n","               \n","               \n","                       [[[-23902.]]],\n","               \n","               \n","                       [[[-31531.]]],\n","               \n","               \n","                       [[[-27713.]]],\n","               \n","               \n","                       [[[-27914.]]],\n","               \n","               \n","                       [[[-21066.]]],\n","               \n","               \n","                       [[[-35584.]]],\n","               \n","               \n","                       [[[-42763.]]],\n","               \n","               \n","                       [[[-31623.]]],\n","               \n","               \n","                       [[[-34964.]]],\n","               \n","               \n","                       [[[-19100.]]],\n","               \n","               \n","                       [[[-32940.]]],\n","               \n","               \n","                       [[[-35477.]]],\n","               \n","               \n","                       [[[-16544.]]],\n","               \n","               \n","                       [[[-25954.]]],\n","               \n","               \n","                       [[[-33792.]]],\n","               \n","               \n","                       [[[-48048.]]],\n","               \n","               \n","                       [[[-26687.]]],\n","               \n","               \n","                       [[[-33082.]]],\n","               \n","               \n","                       [[[-36185.]]],\n","               \n","               \n","                       [[[-42874.]]],\n","               \n","               \n","                       [[[-20587.]]],\n","               \n","               \n","                       [[[-21939.]]],\n","               \n","               \n","                       [[[-32595.]]],\n","               \n","               \n","                       [[[-18490.]]],\n","               \n","               \n","                       [[[-26844.]]],\n","               \n","               \n","                       [[[-28185.]]],\n","               \n","               \n","                       [[[-11751.]]],\n","               \n","               \n","                       [[[-23526.]]],\n","               \n","               \n","                       [[[-34809.]]],\n","               \n","               \n","                       [[[-26720.]]],\n","               \n","               \n","                       [[[-25104.]]],\n","               \n","               \n","                       [[[-21475.]]],\n","               \n","               \n","                       [[[-37929.]]],\n","               \n","               \n","                       [[[-32812.]]],\n","               \n","               \n","                       [[[-38550.]]],\n","               \n","               \n","                       [[[-24712.]]]], device='cuda:0')),\n","              ('module.layer3.0.downsample.0.fp_bias',\n","               tensor([-3.0078e-02, -3.2715e-01,  2.8255e-02,  4.6658e-01, -3.2473e-01,\n","                        4.2696e-01, -4.8205e-01, -9.8226e-04,  2.3097e-01,  1.6191e-04,\n","                       -3.5530e-01,  1.7635e-01, -5.1592e-02,  4.5442e-02, -3.0233e-01,\n","                       -2.2274e-01,  4.0453e-01, -1.3794e-01,  2.5057e-02,  1.3957e-01,\n","                       -2.2624e-01,  2.5613e-01, -4.1849e-02,  3.4257e-02, -9.8627e-02,\n","                       -1.4832e-01,  7.6346e-01,  7.4992e-01,  2.6611e-01,  4.9891e-01,\n","                       -3.7679e-01,  2.4973e-01, -4.5713e-01,  3.6466e-01,  3.4891e-01,\n","                       -1.5528e-01, -1.3418e-01, -2.9025e-01, -2.5998e-01, -1.0281e-01,\n","                       -1.4123e+00, -8.2708e-01,  8.9785e-02,  1.2946e+00, -2.6626e-03,\n","                        6.5163e-01, -1.5124e-03, -3.6953e-04, -3.7057e-01, -1.8839e-03,\n","                       -1.0888e-01, -2.0526e-03,  3.5680e-01,  2.5941e-01, -2.5732e-03,\n","                        9.4931e-02,  1.4432e-02, -1.1471e-01,  2.4775e-01,  5.9389e-02,\n","                        4.3024e-01, -5.2832e-04, -1.4939e-01, -2.7636e-01], device='cuda:0')),\n","              ('module.layer3.0.downsample.0.accum_scale',\n","               tensor([[[1.6875e+09]],\n","               \n","                       [[3.1430e+09]],\n","               \n","                       [[1.5902e+09]],\n","               \n","                       [[1.6055e+09]],\n","               \n","                       [[2.0066e+09]],\n","               \n","                       [[1.3845e+09]],\n","               \n","                       [[1.7867e+09]],\n","               \n","                       [[1.7179e+12]],\n","               \n","                       [[1.6056e+09]],\n","               \n","                       [[1.4251e+12]],\n","               \n","                       [[3.2066e+09]],\n","               \n","                       [[1.5351e+09]],\n","               \n","                       [[1.4206e+09]],\n","               \n","                       [[2.0438e+09]],\n","               \n","                       [[1.7836e+09]],\n","               \n","                       [[1.4934e+09]],\n","               \n","                       [[1.2783e+09]],\n","               \n","                       [[1.2417e+09]],\n","               \n","                       [[2.1885e+09]],\n","               \n","                       [[1.1032e+09]],\n","               \n","                       [[1.7480e+09]],\n","               \n","                       [[7.5501e+08]],\n","               \n","                       [[2.1711e+09]],\n","               \n","                       [[1.5326e+09]],\n","               \n","                       [[1.0508e+09]],\n","               \n","                       [[7.8398e+08]],\n","               \n","                       [[1.4677e+09]],\n","               \n","                       [[1.1897e+09]],\n","               \n","                       [[1.2412e+09]],\n","               \n","                       [[1.4485e+09]],\n","               \n","                       [[3.2549e+09]],\n","               \n","                       [[2.5902e+09]],\n","               \n","                       [[1.0701e+09]],\n","               \n","                       [[1.7671e+09]],\n","               \n","                       [[3.4041e+09]],\n","               \n","                       [[1.4979e+09]],\n","               \n","                       [[3.0225e+09]],\n","               \n","                       [[8.9730e+08]],\n","               \n","                       [[1.8832e+09]],\n","               \n","                       [[2.7556e+09]],\n","               \n","                       [[7.4504e+08]],\n","               \n","                       [[1.1654e+09]],\n","               \n","                       [[1.6088e+09]],\n","               \n","                       [[1.0811e+09]],\n","               \n","                       [[4.3844e+12]],\n","               \n","                       [[2.4972e+09]],\n","               \n","                       [[3.6513e+12]],\n","               \n","                       [[2.0273e+12]],\n","               \n","                       [[1.4392e+09]],\n","               \n","                       [[2.8461e+12]],\n","               \n","                       [[1.8345e+09]],\n","               \n","                       [[5.6112e+12]],\n","               \n","                       [[1.2044e+09]],\n","               \n","                       [[1.9695e+09]],\n","               \n","                       [[5.0058e+12]],\n","               \n","                       [[1.0648e+09]],\n","               \n","                       [[9.3639e+09]],\n","               \n","                       [[2.9386e+09]],\n","               \n","                       [[1.8857e+09]],\n","               \n","                       [[3.5485e+09]],\n","               \n","                       [[2.2960e+09]],\n","               \n","                       [[2.2664e+12]],\n","               \n","                       [[2.5516e+09]],\n","               \n","                       [[1.4477e+09]]], device='cuda:0')),\n","              ('module.layer3.0.downsample.0.is_simulated_quant_weight_shifted',\n","               tensor(False, device='cuda:0')),\n","              ('module.layer3.0.downsample.0.wrapped_module.weight',\n","               tensor([[[[14113.]],\n","               \n","                        [[48634.]],\n","               \n","                        [[    0.]],\n","               \n","                        ...,\n","               \n","                        [[23932.]],\n","               \n","                        [[32015.]],\n","               \n","                        [[45565.]]],\n","               \n","               \n","                       [[[49250.]],\n","               \n","                        [[43956.]],\n","               \n","                        [[34119.]],\n","               \n","                        ...,\n","               \n","                        [[21145.]],\n","               \n","                        [[ 1474.]],\n","               \n","                        [[12851.]]],\n","               \n","               \n","                       [[[39380.]],\n","               \n","                        [[23853.]],\n","               \n","                        [[16366.]],\n","               \n","                        ...,\n","               \n","                        [[35683.]],\n","               \n","                        [[ 7389.]],\n","               \n","                        [[59894.]]],\n","               \n","               \n","                       ...,\n","               \n","               \n","                       [[[45314.]],\n","               \n","                        [[16714.]],\n","               \n","                        [[16049.]],\n","               \n","                        ...,\n","               \n","                        [[ 4302.]],\n","               \n","                        [[24335.]],\n","               \n","                        [[40307.]]],\n","               \n","               \n","                       [[[35979.]],\n","               \n","                        [[32075.]],\n","               \n","                        [[57798.]],\n","               \n","                        ...,\n","               \n","                        [[34498.]],\n","               \n","                        [[29495.]],\n","               \n","                        [[24609.]]],\n","               \n","               \n","                       [[[28075.]],\n","               \n","                        [[ 5600.]],\n","               \n","                        [[34085.]],\n","               \n","                        ...,\n","               \n","                        [[17911.]],\n","               \n","                        [[ 9884.]],\n","               \n","                        [[51984.]]]], device='cuda:0')),\n","              ('module.layer3.0.downsample.0.wrapped_module.bias',\n","               tensor([-5.0758e+07, -1.0282e+09,  4.4932e+07,  7.4907e+08, -6.5162e+08,\n","                        5.9113e+08, -8.6130e+08, -1.6875e+09,  3.7084e+08,  2.3074e+08,\n","                       -1.1393e+09,  2.7073e+08, -7.3293e+07,  9.2873e+07, -5.3922e+08,\n","                       -3.3264e+08,  5.1709e+08, -1.7128e+08,  5.4837e+07,  1.5396e+08,\n","                       -3.9547e+08,  1.9338e+08, -9.0858e+07,  5.2502e+07, -1.0364e+08,\n","                       -1.1628e+08,  1.1205e+09,  8.9215e+08,  3.3030e+08,  7.2269e+08,\n","                       -1.2264e+09,  6.4685e+08, -4.8917e+08,  6.4440e+08,  1.1877e+09,\n","                       -2.3260e+08, -4.0554e+08, -2.6044e+08, -4.8959e+08, -2.8332e+08,\n","                       -1.0523e+09, -9.6392e+08,  1.4444e+08,  1.3997e+09, -2.1475e+09,\n","                        1.6273e+09, -2.1475e+09, -7.4916e+08, -5.3331e+08, -2.1475e+09,\n","                       -1.9975e+08, -2.1475e+09,  4.2973e+08,  5.1090e+08, -2.1475e+09,\n","                        1.0108e+08,  1.3514e+08, -3.3709e+08,  4.6719e+08,  2.1075e+08,\n","                        9.8781e+08, -1.1974e+09, -3.8118e+08, -4.0008e+08], device='cuda:0')),\n","              ('module.layer3.0.residual_eltwiseadd.num_forwards',\n","               tensor([40], device='cuda:0')),\n","              ('module.layer3.0.residual_eltwiseadd.force_readjust',\n","               tensor(False, device='cuda:0')),\n","              ('module.layer3.0.residual_eltwiseadd.output_scale',\n","               tensor([9668.0859], device='cuda:0')),\n","              ('module.layer3.0.residual_eltwiseadd.output_zero_point',\n","               tensor([0.], device='cuda:0')),\n","              ('module.layer3.1.conv1.num_forwards',\n","               tensor([40], device='cuda:0')),\n","              ('module.layer3.1.conv1.force_readjust',\n","               tensor(False, device='cuda:0')),\n","              ('module.layer3.1.conv1.output_scale',\n","               tensor([42989.8125], device='cuda:0')),\n","              ('module.layer3.1.conv1.output_zero_point',\n","               tensor([0.], device='cuda:0')),\n","              ('module.layer3.1.conv1.w_scale', tensor([[[[ 762679.9375]]],\n","               \n","               \n","                       [[[ 792134.3125]]],\n","               \n","               \n","                       [[[ 739661.2500]]],\n","               \n","               \n","                       [[[ 506658.9375]]],\n","               \n","               \n","                       [[[ 632364.1875]]],\n","               \n","               \n","                       [[[ 773277.9375]]],\n","               \n","               \n","                       [[[ 629675.2500]]],\n","               \n","               \n","                       [[[1093040.0000]]],\n","               \n","               \n","                       [[[ 698665.6250]]],\n","               \n","               \n","                       [[[ 780913.0000]]],\n","               \n","               \n","                       [[[ 968449.8125]]],\n","               \n","               \n","                       [[[ 605985.8125]]],\n","               \n","               \n","                       [[[ 991913.7500]]],\n","               \n","               \n","                       [[[ 547958.0000]]],\n","               \n","               \n","                       [[[ 824901.8125]]],\n","               \n","               \n","                       [[[ 470615.1875]]],\n","               \n","               \n","                       [[[ 946331.1250]]],\n","               \n","               \n","                       [[[ 816064.0000]]],\n","               \n","               \n","                       [[[ 697043.5625]]],\n","               \n","               \n","                       [[[ 906678.7500]]],\n","               \n","               \n","                       [[[ 916305.6250]]],\n","               \n","               \n","                       [[[ 789055.5625]]],\n","               \n","               \n","                       [[[ 624317.5625]]],\n","               \n","               \n","                       [[[ 804388.5000]]],\n","               \n","               \n","                       [[[ 792143.8750]]],\n","               \n","               \n","                       [[[ 775230.5000]]],\n","               \n","               \n","                       [[[ 686557.6875]]],\n","               \n","               \n","                       [[[ 731941.4375]]],\n","               \n","               \n","                       [[[ 797630.3750]]],\n","               \n","               \n","                       [[[1104590.1250]]],\n","               \n","               \n","                       [[[ 629383.5000]]],\n","               \n","               \n","                       [[[ 931191.1250]]],\n","               \n","               \n","                       [[[ 860887.2500]]],\n","               \n","               \n","                       [[[1174325.7500]]],\n","               \n","               \n","                       [[[1014811.1250]]],\n","               \n","               \n","                       [[[ 889313.4375]]],\n","               \n","               \n","                       [[[ 630858.3750]]],\n","               \n","               \n","                       [[[ 823398.4375]]],\n","               \n","               \n","                       [[[1054022.1250]]],\n","               \n","               \n","                       [[[ 666022.3125]]],\n","               \n","               \n","                       [[[1259979.3750]]],\n","               \n","               \n","                       [[[ 889860.0625]]],\n","               \n","               \n","                       [[[ 828619.6875]]],\n","               \n","               \n","                       [[[ 648124.3750]]],\n","               \n","               \n","                       [[[ 740781.8125]]],\n","               \n","               \n","                       [[[ 668212.0000]]],\n","               \n","               \n","                       [[[ 708733.1250]]],\n","               \n","               \n","                       [[[ 700284.9375]]],\n","               \n","               \n","                       [[[1007863.8750]]],\n","               \n","               \n","                       [[[ 693122.1875]]],\n","               \n","               \n","                       [[[ 610820.3125]]],\n","               \n","               \n","                       [[[ 685095.0000]]],\n","               \n","               \n","                       [[[ 846022.0000]]],\n","               \n","               \n","                       [[[ 767881.0625]]],\n","               \n","               \n","                       [[[ 737642.1875]]],\n","               \n","               \n","                       [[[ 975931.0000]]],\n","               \n","               \n","                       [[[ 622832.3750]]],\n","               \n","               \n","                       [[[ 702271.8750]]],\n","               \n","               \n","                       [[[1354138.6250]]],\n","               \n","               \n","                       [[[ 994123.1250]]],\n","               \n","               \n","                       [[[ 613633.7500]]],\n","               \n","               \n","                       [[[ 669642.6250]]],\n","               \n","               \n","                       [[[ 773225.6875]]],\n","               \n","               \n","                       [[[ 607870.6875]]]], device='cuda:0')),\n","              ('module.layer3.1.conv1.w_zero_point', tensor([[[[-33809.]]],\n","               \n","               \n","                       [[[-32278.]]],\n","               \n","               \n","                       [[[-31480.]]],\n","               \n","               \n","                       [[[-27600.]]],\n","               \n","               \n","                       [[[-23374.]]],\n","               \n","               \n","                       [[[-33642.]]],\n","               \n","               \n","                       [[[-32197.]]],\n","               \n","               \n","                       [[[-30809.]]],\n","               \n","               \n","                       [[[-25919.]]],\n","               \n","               \n","                       [[[-30920.]]],\n","               \n","               \n","                       [[[-33373.]]],\n","               \n","               \n","                       [[[-28823.]]],\n","               \n","               \n","                       [[[-31578.]]],\n","               \n","               \n","                       [[[-32621.]]],\n","               \n","               \n","                       [[[-35073.]]],\n","               \n","               \n","                       [[[-37688.]]],\n","               \n","               \n","                       [[[-31539.]]],\n","               \n","               \n","                       [[[-28960.]]],\n","               \n","               \n","                       [[[-35584.]]],\n","               \n","               \n","                       [[[-33805.]]],\n","               \n","               \n","                       [[[-33177.]]],\n","               \n","               \n","                       [[[-29405.]]],\n","               \n","               \n","                       [[[-27363.]]],\n","               \n","               \n","                       [[[-35548.]]],\n","               \n","               \n","                       [[[-23065.]]],\n","               \n","               \n","                       [[[-30429.]]],\n","               \n","               \n","                       [[[-36620.]]],\n","               \n","               \n","                       [[[-29756.]]],\n","               \n","               \n","                       [[[-27019.]]],\n","               \n","               \n","                       [[[-28255.]]],\n","               \n","               \n","                       [[[-29487.]]],\n","               \n","               \n","                       [[[-28494.]]],\n","               \n","               \n","                       [[[-28555.]]],\n","               \n","               \n","                       [[[-29880.]]],\n","               \n","               \n","                       [[[-29110.]]],\n","               \n","               \n","                       [[[-28782.]]],\n","               \n","               \n","                       [[[-24642.]]],\n","               \n","               \n","                       [[[-28432.]]],\n","               \n","               \n","                       [[[-35234.]]],\n","               \n","               \n","                       [[[-29327.]]],\n","               \n","               \n","                       [[[-28577.]]],\n","               \n","               \n","                       [[[-34687.]]],\n","               \n","               \n","                       [[[-31756.]]],\n","               \n","               \n","                       [[[-25203.]]],\n","               \n","               \n","                       [[[-33705.]]],\n","               \n","               \n","                       [[[-30040.]]],\n","               \n","               \n","                       [[[-26065.]]],\n","               \n","               \n","                       [[[-33307.]]],\n","               \n","               \n","                       [[[-29882.]]],\n","               \n","               \n","                       [[[-32952.]]],\n","               \n","               \n","                       [[[-28106.]]],\n","               \n","               \n","                       [[[-34424.]]],\n","               \n","               \n","                       [[[-30627.]]],\n","               \n","               \n","                       [[[-28454.]]],\n","               \n","               \n","                       [[[-29953.]]],\n","               \n","               \n","                       [[[-23933.]]],\n","               \n","               \n","                       [[[-28653.]]],\n","               \n","               \n","                       [[[-26798.]]],\n","               \n","               \n","                       [[[-27003.]]],\n","               \n","               \n","                       [[[-34121.]]],\n","               \n","               \n","                       [[[-30609.]]],\n","               \n","               \n","                       [[[-28144.]]],\n","               \n","               \n","                       [[[-30308.]]],\n","               \n","               \n","                       [[[-23761.]]]], device='cuda:0')),\n","              ('module.layer3.1.conv1.fp_bias',\n","               tensor([-0.0683, -0.3784, -0.0934, -0.4602, -0.4025,  0.0845, -0.7780, -0.3072,\n","                       -0.2370, -0.0056,  0.1474, -0.2922, -0.2799, -0.5943,  0.3391, -0.0742,\n","                        0.0442, -0.2204, -0.2758,  0.2281, -0.1662,  0.0383,  0.0676, -0.1585,\n","                       -0.4809, -0.3251, -0.0848, -0.3105,  0.0150,  0.1239,  0.0022,  0.1646,\n","                       -0.4597, -0.1584,  0.1387, -0.3858, -0.1861,  0.2432,  0.0482,  0.2519,\n","                       -0.3508,  0.0650,  0.2869, -0.5372, -0.2361,  0.0028,  0.1021,  0.0195,\n","                       -0.6772, -0.2736, -0.3222,  0.0455, -0.1133, -0.4120, -0.6873, -0.3928,\n","                       -0.2711, -0.1811, -0.1826,  0.2752, -0.2782, -0.0836,  0.0216, -0.3421],\n","                      device='cuda:0')),\n","              ('module.layer3.1.conv1.accum_scale', tensor([[[7.3737e+09]],\n","               \n","                       [[7.6584e+09]],\n","               \n","                       [[7.1511e+09]],\n","               \n","                       [[4.8984e+09]],\n","               \n","                       [[6.1138e+09]],\n","               \n","                       [[7.4761e+09]],\n","               \n","                       [[6.0878e+09]],\n","               \n","                       [[1.0568e+10]],\n","               \n","                       [[6.7548e+09]],\n","               \n","                       [[7.5499e+09]],\n","               \n","                       [[9.3631e+09]],\n","               \n","                       [[5.8587e+09]],\n","               \n","                       [[9.5899e+09]],\n","               \n","                       [[5.2977e+09]],\n","               \n","                       [[7.9752e+09]],\n","               \n","                       [[4.5499e+09]],\n","               \n","                       [[9.1492e+09]],\n","               \n","                       [[7.8898e+09]],\n","               \n","                       [[6.7391e+09]],\n","               \n","                       [[8.7658e+09]],\n","               \n","                       [[8.8589e+09]],\n","               \n","                       [[7.6287e+09]],\n","               \n","                       [[6.0360e+09]],\n","               \n","                       [[7.7769e+09]],\n","               \n","                       [[7.6585e+09]],\n","               \n","                       [[7.4950e+09]],\n","               \n","                       [[6.6377e+09]],\n","               \n","                       [[7.0765e+09]],\n","               \n","                       [[7.7116e+09]],\n","               \n","                       [[1.0679e+10]],\n","               \n","                       [[6.0849e+09]],\n","               \n","                       [[9.0028e+09]],\n","               \n","                       [[8.3231e+09]],\n","               \n","                       [[1.1353e+10]],\n","               \n","                       [[9.8113e+09]],\n","               \n","                       [[8.5980e+09]],\n","               \n","                       [[6.0992e+09]],\n","               \n","                       [[7.9607e+09]],\n","               \n","                       [[1.0190e+10]],\n","               \n","                       [[6.4392e+09]],\n","               \n","                       [[1.2182e+10]],\n","               \n","                       [[8.6032e+09]],\n","               \n","                       [[8.0112e+09]],\n","               \n","                       [[6.2661e+09]],\n","               \n","                       [[7.1619e+09]],\n","               \n","                       [[6.4603e+09]],\n","               \n","                       [[6.8521e+09]],\n","               \n","                       [[6.7704e+09]],\n","               \n","                       [[9.7441e+09]],\n","               \n","                       [[6.7012e+09]],\n","               \n","                       [[5.9055e+09]],\n","               \n","                       [[6.6236e+09]],\n","               \n","                       [[8.1794e+09]],\n","               \n","                       [[7.4239e+09]],\n","               \n","                       [[7.1316e+09]],\n","               \n","                       [[9.4354e+09]],\n","               \n","                       [[6.0216e+09]],\n","               \n","                       [[6.7896e+09]],\n","               \n","                       [[1.3092e+10]],\n","               \n","                       [[9.6113e+09]],\n","               \n","                       [[5.9327e+09]],\n","               \n","                       [[6.4742e+09]],\n","               \n","                       [[7.4756e+09]],\n","               \n","                       [[5.8769e+09]]], device='cuda:0')),\n","              ('module.layer3.1.conv1.is_simulated_quant_weight_shifted',\n","               tensor(False, device='cuda:0')),\n","              ('module.layer3.1.conv1.wrapped_module.weight',\n","               tensor([[[[29634., 36758., 31023.],\n","                         [20674., 31776., 27246.],\n","                         [17316., 25393., 21441.]],\n","               \n","                        [[34095., 35662., 34251.],\n","                         [30262., 36358., 39105.],\n","                         [31267., 32502., 38297.]],\n","               \n","                        [[31913., 38230., 38689.],\n","                         [40050., 36411., 35197.],\n","                         [42317., 38676., 49696.]],\n","               \n","                        ...,\n","               \n","                        [[33861., 33823., 33792.],\n","                         [33813., 33833., 33831.],\n","                         [33764., 33805., 33794.]],\n","               \n","                        [[23232., 27951., 36126.],\n","                         [34017., 33646., 42497.],\n","                         [29920., 26605., 39732.]],\n","               \n","                        [[26472., 29032., 38927.],\n","                         [21140., 41661., 35961.],\n","                         [31402., 36020., 36884.]]],\n","               \n","               \n","                       [[[28385., 34654., 29793.],\n","                         [34211., 35267., 33460.],\n","                         [19049., 19361.,  9359.]],\n","               \n","                        [[20820., 25190., 28037.],\n","                         [28572., 30591., 30630.],\n","                         [27134., 24855., 24986.]],\n","               \n","                        [[29264., 36455., 50317.],\n","                         [27117., 42208., 29851.],\n","                         [65535., 62012., 59847.]],\n","               \n","                        ...,\n","               \n","                        [[32265., 32350., 32392.],\n","                         [32377., 32368., 32369.],\n","                         [32322., 32341., 32346.]],\n","               \n","                        [[36042., 25885., 25910.],\n","                         [38913., 34491., 30467.],\n","                         [45341., 38169., 34469.]],\n","               \n","                        [[32175., 31149., 19259.],\n","                         [42211., 20496.,  5362.],\n","                         [56589., 42831., 25347.]]],\n","               \n","               \n","                       [[[29211., 29966., 19330.],\n","                         [25685., 35521., 25838.],\n","                         [26327., 39042., 38442.]],\n","               \n","                        [[32240., 29853., 29670.],\n","                         [22231., 26789., 30510.],\n","                         [28260., 31212., 27747.]],\n","               \n","                        [[32675., 38804., 27071.],\n","                         [38642., 31233., 24117.],\n","                         [65535., 51950., 25118.]],\n","               \n","                        ...,\n","               \n","                        [[31460., 31466., 31420.],\n","                         [31442., 31432., 31410.],\n","                         [31433., 31404., 31414.]],\n","               \n","                        [[33132., 27587., 20133.],\n","                         [26282., 38507., 37548.],\n","                         [17827., 23042., 28070.]],\n","               \n","                        [[30131., 39460.,  5752.],\n","                         [25725., 33201., 24265.],\n","                         [24373., 20820., 40626.]]],\n","               \n","               \n","                       ...,\n","               \n","               \n","                       [[[    0.,  5745., 23485.],\n","                         [21288., 28622., 46678.],\n","                         [28540., 43827., 57739.]],\n","               \n","                        [[17003., 26660., 25563.],\n","                         [25890., 19404., 20405.],\n","                         [31097., 19606., 21444.]],\n","               \n","                        [[43916., 29010., 50828.],\n","                         [48359., 43688., 47588.],\n","                         [11759., 28946., 25106.]],\n","               \n","                        ...,\n","               \n","                        [[28182., 28133., 28137.],\n","                         [28198., 28162., 28123.],\n","                         [28157., 28125., 28096.]],\n","               \n","                        [[15837., 20188., 19457.],\n","                         [19761., 19573., 27791.],\n","                         [26484., 20665., 45264.]],\n","               \n","                        [[11032., 29991., 36617.],\n","                         [23649., 22646., 40084.],\n","                         [41201., 34010., 44203.]]],\n","               \n","               \n","                       [[[26356., 39464., 36784.],\n","                         [21991., 38780., 26580.],\n","                         [32641., 56141., 50788.]],\n","               \n","                        [[23453., 22734., 30830.],\n","                         [26421., 24077., 27724.],\n","                         [42412., 34464., 27629.]],\n","               \n","                        [[26536., 40135., 34629.],\n","                         [43054., 40190., 23878.],\n","                         [53817., 13569.,  5491.]],\n","               \n","                        ...,\n","               \n","                        [[30289., 30305., 30254.],\n","                         [30276., 30265., 30273.],\n","                         [30272., 30282., 30348.]],\n","               \n","                        [[28913., 24577., 25288.],\n","                         [23404., 23722., 25628.],\n","                         [16996., 31019., 35663.]],\n","               \n","                        [[44344., 40364., 22737.],\n","                         [36368., 44411., 14986.],\n","                         [33365., 28095., 15218.]]],\n","               \n","               \n","                       [[[25110., 28364., 32715.],\n","                         [23030., 21847., 31104.],\n","                         [23019., 12390., 22003.]],\n","               \n","                        [[24030., 21620., 22843.],\n","                         [22506., 24368., 25516.],\n","                         [28014., 25883., 17756.]],\n","               \n","                        [[ 7685., 22517., 32665.],\n","                         [31240., 31185., 28941.],\n","                         [31873., 11841.,  5431.]],\n","               \n","                        ...,\n","               \n","                        [[23709., 23805., 23784.],\n","                         [23705., 23768., 23770.],\n","                         [23796., 23758., 23729.]],\n","               \n","                        [[42502., 23493., 19778.],\n","                         [28826., 21458., 21149.],\n","                         [21975., 28866., 35825.]],\n","               \n","                        [[17732., 27445., 18485.],\n","                         [17147., 33487., 29044.],\n","                         [ 9112., 27699., 39037.]]]], device='cuda:0')),\n","              ('module.layer3.1.conv1.wrapped_module.bias',\n","               tensor([-5.0383e+08, -2.1475e+09, -6.6791e+08, -2.1475e+09, -2.1475e+09,\n","                        6.3156e+08, -2.1475e+09, -2.1475e+09, -1.6008e+09, -4.2152e+07,\n","                        1.3798e+09, -1.7118e+09, -2.1475e+09, -2.1475e+09,  2.1475e+09,\n","                       -3.3739e+08,  4.0474e+08, -1.7392e+09, -1.8586e+09,  1.9995e+09,\n","                       -1.4727e+09,  2.9212e+08,  4.0819e+08, -1.2324e+09, -2.1475e+09,\n","                       -2.1475e+09, -5.6294e+08, -2.1475e+09,  1.1540e+08,  1.3235e+09,\n","                        1.3119e+07,  1.4819e+09, -2.1475e+09, -1.7987e+09,  1.3611e+09,\n","                       -2.1475e+09, -1.1353e+09,  1.9357e+09,  4.9162e+08,  1.6222e+09,\n","                       -2.1475e+09,  5.5879e+08,  2.1475e+09, -2.1475e+09, -1.6913e+09,\n","                        1.8356e+07,  6.9947e+08,  1.3188e+08, -2.1475e+09, -1.8332e+09,\n","                       -1.9025e+09,  3.0135e+08, -9.2695e+08, -2.1475e+09, -2.1475e+09,\n","                       -2.1475e+09, -1.6323e+09, -1.2298e+09, -2.1475e+09,  2.1475e+09,\n","                       -1.6505e+09, -5.4096e+08,  1.6178e+08, -2.0103e+09], device='cuda:0')),\n","              ('module.layer3.1.conv2.num_forwards',\n","               tensor([40], device='cuda:0')),\n","              ('module.layer3.1.conv2.force_readjust',\n","               tensor(False, device='cuda:0')),\n","              ('module.layer3.1.conv2.output_scale',\n","               tensor([11951.8818], device='cuda:0')),\n","              ('module.layer3.1.conv2.output_zero_point',\n","               tensor([-30733.], device='cuda:0')),\n","              ('module.layer3.1.conv2.w_scale', tensor([[[[  70942.0078]]],\n","               \n","               \n","                       [[[  94847.6406]]],\n","               \n","               \n","                       [[[  73362.8906]]],\n","               \n","               \n","                       [[[ 104916.3594]]],\n","               \n","               \n","                       [[[  66865.4688]]],\n","               \n","               \n","                       [[[ 142382.2656]]],\n","               \n","               \n","                       [[[ 108659.9766]]],\n","               \n","               \n","                       [[[  80484.1016]]],\n","               \n","               \n","                       [[[ 105751.5703]]],\n","               \n","               \n","                       [[[  59345.9375]]],\n","               \n","               \n","                       [[[  79563.0859]]],\n","               \n","               \n","                       [[[ 100555.0547]]],\n","               \n","               \n","                       [[[ 273465.0000]]],\n","               \n","               \n","                       [[[  91961.1484]]],\n","               \n","               \n","                       [[[ 102387.6016]]],\n","               \n","               \n","                       [[[ 135783.7344]]],\n","               \n","               \n","                       [[[ 138460.0469]]],\n","               \n","               \n","                       [[[ 127461.2266]]],\n","               \n","               \n","                       [[[ 158276.2812]]],\n","               \n","               \n","                       [[[  98663.7031]]],\n","               \n","               \n","                       [[[  99912.0625]]],\n","               \n","               \n","                       [[[ 392741.3125]]],\n","               \n","               \n","                       [[[ 115531.1484]]],\n","               \n","               \n","                       [[[ 112476.7891]]],\n","               \n","               \n","                       [[[ 128824.1562]]],\n","               \n","               \n","                       [[[ 205857.5625]]],\n","               \n","               \n","                       [[[ 100740.0859]]],\n","               \n","               \n","                       [[[ 197185.5938]]],\n","               \n","               \n","                       [[[ 112105.0078]]],\n","               \n","               \n","                       [[[ 210702.1094]]],\n","               \n","               \n","                       [[[  69946.2891]]],\n","               \n","               \n","                       [[[  71342.2109]]],\n","               \n","               \n","                       [[[ 119271.1953]]],\n","               \n","               \n","                       [[[ 121642.8906]]],\n","               \n","               \n","                       [[[  55754.5078]]],\n","               \n","               \n","                       [[[ 108202.6953]]],\n","               \n","               \n","                       [[[  85487.2266]]],\n","               \n","               \n","                       [[[  83994.7891]]],\n","               \n","               \n","                       [[[ 107993.0625]]],\n","               \n","               \n","                       [[[  95148.0781]]],\n","               \n","               \n","                       [[[ 167616.6250]]],\n","               \n","               \n","                       [[[ 122372.9297]]],\n","               \n","               \n","                       [[[ 131509.0469]]],\n","               \n","               \n","                       [[[ 122109.6719]]],\n","               \n","               \n","                       [[[  45632.9102]]],\n","               \n","               \n","                       [[[ 300530.9062]]],\n","               \n","               \n","                       [[[1495929.1250]]],\n","               \n","               \n","                       [[[  85851.5156]]],\n","               \n","               \n","                       [[[ 102515.5547]]],\n","               \n","               \n","                       [[[ 186512.1562]]],\n","               \n","               \n","                       [[[  75360.6484]]],\n","               \n","               \n","                       [[[ 101559.1562]]],\n","               \n","               \n","                       [[[ 111484.1953]]],\n","               \n","               \n","                       [[[  72031.0078]]],\n","               \n","               \n","                       [[[  61324.9531]]],\n","               \n","               \n","                       [[[ 111149.5938]]],\n","               \n","               \n","                       [[[  83181.4219]]],\n","               \n","               \n","                       [[[ 146560.6719]]],\n","               \n","               \n","                       [[[ 108237.3906]]],\n","               \n","               \n","                       [[[  68945.2188]]],\n","               \n","               \n","                       [[[ 100861.2031]]],\n","               \n","               \n","                       [[[  63098.0508]]],\n","               \n","               \n","                       [[[  85165.5312]]],\n","               \n","               \n","                       [[[ 146063.3438]]]], device='cuda:0')),\n","              ('module.layer3.1.conv2.w_zero_point', tensor([[[[-32933.]]],\n","               \n","               \n","                       [[[-26213.]]],\n","               \n","               \n","                       [[[-36986.]]],\n","               \n","               \n","                       [[[-37043.]]],\n","               \n","               \n","                       [[[-32338.]]],\n","               \n","               \n","                       [[[-32075.]]],\n","               \n","               \n","                       [[[-30414.]]],\n","               \n","               \n","                       [[[-24398.]]],\n","               \n","               \n","                       [[[-36819.]]],\n","               \n","               \n","                       [[[-28322.]]],\n","               \n","               \n","                       [[[-30553.]]],\n","               \n","               \n","                       [[[-31071.]]],\n","               \n","               \n","                       [[[-40578.]]],\n","               \n","               \n","                       [[[-25439.]]],\n","               \n","               \n","                       [[[-24465.]]],\n","               \n","               \n","                       [[[-36797.]]],\n","               \n","               \n","                       [[[-33947.]]],\n","               \n","               \n","                       [[[-32258.]]],\n","               \n","               \n","                       [[[-32385.]]],\n","               \n","               \n","                       [[[-33660.]]],\n","               \n","               \n","                       [[[-30566.]]],\n","               \n","               \n","                       [[[-38278.]]],\n","               \n","               \n","                       [[[-26150.]]],\n","               \n","               \n","                       [[[-26774.]]],\n","               \n","               \n","                       [[[-31099.]]],\n","               \n","               \n","                       [[[-42303.]]],\n","               \n","               \n","                       [[[-28570.]]],\n","               \n","               \n","                       [[[-31805.]]],\n","               \n","               \n","                       [[[-33511.]]],\n","               \n","               \n","                       [[[-40732.]]],\n","               \n","               \n","                       [[[-29059.]]],\n","               \n","               \n","                       [[[-27964.]]],\n","               \n","               \n","                       [[[-32823.]]],\n","               \n","               \n","                       [[[-28595.]]],\n","               \n","               \n","                       [[[-32423.]]],\n","               \n","               \n","                       [[[-30771.]]],\n","               \n","               \n","                       [[[-30213.]]],\n","               \n","               \n","                       [[[-21203.]]],\n","               \n","               \n","                       [[[-29173.]]],\n","               \n","               \n","                       [[[-34417.]]],\n","               \n","               \n","                       [[[-26530.]]],\n","               \n","               \n","                       [[[-31075.]]],\n","               \n","               \n","                       [[[-32583.]]],\n","               \n","               \n","                       [[[-32880.]]],\n","               \n","               \n","                       [[[-15074.]]],\n","               \n","               \n","                       [[[-36438.]]],\n","               \n","               \n","                       [[[-19076.]]],\n","               \n","               \n","                       [[[-23900.]]],\n","               \n","               \n","                       [[[-37349.]]],\n","               \n","               \n","                       [[[-27743.]]],\n","               \n","               \n","                       [[[-32410.]]],\n","               \n","               \n","                       [[[-29565.]]],\n","               \n","               \n","                       [[[-32669.]]],\n","               \n","               \n","                       [[[-29459.]]],\n","               \n","               \n","                       [[[-25549.]]],\n","               \n","               \n","                       [[[-32459.]]],\n","               \n","               \n","                       [[[-29576.]]],\n","               \n","               \n","                       [[[-25494.]]],\n","               \n","               \n","                       [[[-30882.]]],\n","               \n","               \n","                       [[[-29913.]]],\n","               \n","               \n","                       [[[-29806.]]],\n","               \n","               \n","                       [[[-24373.]]],\n","               \n","               \n","                       [[[-27201.]]],\n","               \n","               \n","                       [[[-29530.]]]], device='cuda:0')),\n","              ('module.layer3.1.conv2.fp_bias',\n","               tensor([ 0.4030,  0.0572,  0.7478, -0.1776,  0.4480,  0.3364,  0.6157, -0.1972,\n","                        0.2759,  0.8537,  0.0760,  0.0517,  0.1529, -0.2723, -0.5562,  0.2344,\n","                       -0.1440, -0.2076, -0.1909,  0.0117, -0.2534,  0.2383, -0.0924,  0.1400,\n","                        0.1572,  0.2883,  0.3270,  0.1106,  0.1449,  0.2695,  0.2193,  0.3214,\n","                       -0.1354, -0.0788,  0.8408, -0.0209,  0.0752,  0.3268,  0.5286,  0.7334,\n","                        0.2401,  0.1599, -0.1206,  0.3481, -0.2789,  0.2322, -0.0215,  0.1377,\n","                        0.0045, -0.0019,  0.3009,  0.4957,  0.0472, -0.0166,  1.0126, -0.3167,\n","                        0.6662, -0.1901, -0.0385,  0.3535,  0.1972, -0.2702,  0.0243, -0.1085],\n","                      device='cuda:0')),\n","              ('module.layer3.1.conv2.accum_scale', tensor([[[3.0498e+09]],\n","               \n","                       [[4.0775e+09]],\n","               \n","                       [[3.1539e+09]],\n","               \n","                       [[4.5103e+09]],\n","               \n","                       [[2.8745e+09]],\n","               \n","                       [[6.1210e+09]],\n","               \n","                       [[4.6713e+09]],\n","               \n","                       [[3.4600e+09]],\n","               \n","                       [[4.5462e+09]],\n","               \n","                       [[2.5513e+09]],\n","               \n","                       [[3.4204e+09]],\n","               \n","                       [[4.3228e+09]],\n","               \n","                       [[1.1756e+10]],\n","               \n","                       [[3.9534e+09]],\n","               \n","                       [[4.4016e+09]],\n","               \n","                       [[5.8373e+09]],\n","               \n","                       [[5.9524e+09]],\n","               \n","                       [[5.4795e+09]],\n","               \n","                       [[6.8043e+09]],\n","               \n","                       [[4.2415e+09]],\n","               \n","                       [[4.2952e+09]],\n","               \n","                       [[1.6884e+10]],\n","               \n","                       [[4.9667e+09]],\n","               \n","                       [[4.8354e+09]],\n","               \n","                       [[5.5381e+09]],\n","               \n","                       [[8.8498e+09]],\n","               \n","                       [[4.3308e+09]],\n","               \n","                       [[8.4770e+09]],\n","               \n","                       [[4.8194e+09]],\n","               \n","                       [[9.0580e+09]],\n","               \n","                       [[3.0070e+09]],\n","               \n","                       [[3.0670e+09]],\n","               \n","                       [[5.1274e+09]],\n","               \n","                       [[5.2294e+09]],\n","               \n","                       [[2.3969e+09]],\n","               \n","                       [[4.6516e+09]],\n","               \n","                       [[3.6751e+09]],\n","               \n","                       [[3.6109e+09]],\n","               \n","                       [[4.6426e+09]],\n","               \n","                       [[4.0904e+09]],\n","               \n","                       [[7.2058e+09]],\n","               \n","                       [[5.2608e+09]],\n","               \n","                       [[5.6535e+09]],\n","               \n","                       [[5.2495e+09]],\n","               \n","                       [[1.9618e+09]],\n","               \n","                       [[1.2920e+10]],\n","               \n","                       [[6.4310e+10]],\n","               \n","                       [[3.6907e+09]],\n","               \n","                       [[4.4071e+09]],\n","               \n","                       [[8.0181e+09]],\n","               \n","                       [[3.2397e+09]],\n","               \n","                       [[4.3660e+09]],\n","               \n","                       [[4.7927e+09]],\n","               \n","                       [[3.0966e+09]],\n","               \n","                       [[2.6363e+09]],\n","               \n","                       [[4.7783e+09]],\n","               \n","                       [[3.5760e+09]],\n","               \n","                       [[6.3006e+09]],\n","               \n","                       [[4.6531e+09]],\n","               \n","                       [[2.9639e+09]],\n","               \n","                       [[4.3360e+09]],\n","               \n","                       [[2.7126e+09]],\n","               \n","                       [[3.6613e+09]],\n","               \n","                       [[6.2792e+09]]], device='cuda:0')),\n","              ('module.layer3.1.conv2.is_simulated_quant_weight_shifted',\n","               tensor(False, device='cuda:0')),\n","              ('module.layer3.1.conv2.wrapped_module.weight',\n","               tensor([[[[20608., 34111., 39634.],\n","                         [16256., 28376., 29346.],\n","                         [14950., 23830., 29637.]],\n","               \n","                        [[49242., 52633., 34023.],\n","                         [28981., 35781., 18517.],\n","                         [25576., 33418., 28877.]],\n","               \n","                        [[48641., 31204., 30255.],\n","                         [35180., 27052., 30505.],\n","                         [28708., 33063., 36433.]],\n","               \n","                        ...,\n","               \n","                        [[32795., 37308., 14272.],\n","                         [39618., 34503.,  8458.],\n","                         [25336., 22450., 14738.]],\n","               \n","                        [[31582., 32376., 31341.],\n","                         [15388., 26720., 19178.],\n","                         [32064., 50096., 36304.]],\n","               \n","                        [[33201., 18409., 21659.],\n","                         [25405., 20571., 24301.],\n","                         [18993., 26913., 31105.]]],\n","               \n","               \n","                       [[[18885., 15096., 25397.],\n","                         [22013., 24545., 28583.],\n","                         [17006., 21083., 20253.]],\n","               \n","                        [[21570., 19505., 21265.],\n","                         [21576., 18735., 19356.],\n","                         [17942., 13304., 17735.]],\n","               \n","                        [[26292., 20191., 27271.],\n","                         [28209., 27062., 21201.],\n","                         [11360., 30409., 28208.]],\n","               \n","                        ...,\n","               \n","                        [[18846., 26408., 30173.],\n","                         [ 8076., 23474., 29159.],\n","                         [26678., 33445., 41872.]],\n","               \n","                        [[35905., 33532., 33054.],\n","                         [23693., 24173., 20638.],\n","                         [18524., 24972., 19436.]],\n","               \n","                        [[35409., 32368., 34588.],\n","                         [36155., 29048., 27723.],\n","                         [23797., 30315., 29636.]]],\n","               \n","               \n","                       [[[29430., 28089., 35886.],\n","                         [30427., 27270., 40667.],\n","                         [30255., 31341., 42407.]],\n","               \n","                        [[37900., 36022., 30737.],\n","                         [29544., 29321., 24985.],\n","                         [26570., 29374., 30213.]],\n","               \n","                        [[26411., 30778., 34164.],\n","                         [30331., 37943., 45235.],\n","                         [42777., 45649., 38442.]],\n","               \n","                        ...,\n","               \n","                        [[39956., 41846., 38809.],\n","                         [37476., 37575., 29607.],\n","                         [38091., 40735., 26337.]],\n","               \n","                        [[28870., 35248., 35418.],\n","                         [25056., 35919., 25928.],\n","                         [37192., 40856., 23640.]],\n","               \n","                        [[29911., 42045., 41618.],\n","                         [28661., 44015., 56328.],\n","                         [35885., 36710., 51818.]]],\n","               \n","               \n","                       ...,\n","               \n","               \n","                       [[[20200., 23209., 22038.],\n","                         [24278., 29760., 31533.],\n","                         [26649., 22616., 34469.]],\n","               \n","                        [[40278., 38857., 38005.],\n","                         [29754., 34620., 26893.],\n","                         [20364., 32106., 27697.]],\n","               \n","                        [[31194., 21585., 24707.],\n","                         [33158., 20675., 21061.],\n","                         [24155., 31754., 37576.]],\n","               \n","                        ...,\n","               \n","                        [[21247., 29701., 27651.],\n","                         [21114., 17587., 15881.],\n","                         [28845., 24423., 18599.]],\n","               \n","                        [[27174., 18773., 18715.],\n","                         [25238., 20479., 17713.],\n","                         [25354., 22595., 25769.]],\n","               \n","                        [[30967., 22595., 33060.],\n","                         [22573., 20584., 37575.],\n","                         [16852., 22983., 39183.]]],\n","               \n","               \n","                       [[[44877., 33102., 33661.],\n","                         [34101., 23905., 39534.],\n","                         [24267., 17791., 41794.]],\n","               \n","                        [[44703., 32537., 27612.],\n","                         [36394., 23094., 19976.],\n","                         [23183., 17495., 26803.]],\n","               \n","                        [[ 9415., 26445., 36024.],\n","                         [18104., 32308., 37512.],\n","                         [35894., 37177., 39859.]],\n","               \n","                        ...,\n","               \n","                        [[48213., 40411., 29256.],\n","                         [29708.,  5409., 16453.],\n","                         [23921., 16236., 33363.]],\n","               \n","                        [[16970., 25113., 29937.],\n","                         [24769., 16474., 14098.],\n","                         [46372., 31970., 22339.]],\n","               \n","                        [[34277., 28512., 28891.],\n","                         [35285., 20588., 37353.],\n","                         [37770., 22994., 30855.]]],\n","               \n","               \n","                       [[[14702., 33922., 48708.],\n","                         [24737., 22008., 38162.],\n","                         [28571.,  7992., 30985.]],\n","               \n","                        [[18338., 23094., 27170.],\n","                         [42764., 39107., 37086.],\n","                         [40061., 30836., 34434.]],\n","               \n","                        [[45685., 44823., 19334.],\n","                         [43969., 45993., 34574.],\n","                         [34849., 44885., 45117.]],\n","               \n","                        ...,\n","               \n","                        [[31276.,  3973.,  4028.],\n","                         [28315., 35191., 16367.],\n","                         [16493., 65535., 45612.]],\n","               \n","                        [[31508., 33183., 33393.],\n","                         [36742., 35804., 38274.],\n","                         [23909., 29586., 37171.]],\n","               \n","                        [[30515.,  4037., 10092.],\n","                         [40846., 17653., 18685.],\n","                         [44921., 38544., 48388.]]]], device='cuda:0')),\n","              ('module.layer3.1.conv2.wrapped_module.bias',\n","               tensor([ 1.2292e+09,  2.3340e+08,  2.1475e+09, -8.0126e+08,  1.2878e+09,\n","                        2.0592e+09,  2.1475e+09, -6.8224e+08,  1.2545e+09,  2.1475e+09,\n","                        2.6001e+08,  2.2365e+08,  1.7971e+09, -1.0766e+09, -2.1475e+09,\n","                        1.3682e+09, -8.5688e+08, -1.1377e+09, -1.2988e+09,  4.9658e+07,\n","                       -1.0882e+09,  2.1475e+09, -4.5898e+08,  6.7674e+08,  8.7075e+08,\n","                        2.1475e+09,  1.4164e+09,  9.3726e+08,  6.9852e+08,  2.1475e+09,\n","                        6.5943e+08,  9.8570e+08, -6.9404e+08, -4.1232e+08,  2.0153e+09,\n","                       -9.7423e+07,  2.7650e+08,  1.1802e+09,  2.1475e+09,  2.1475e+09,\n","                        1.7298e+09,  8.4125e+08, -6.8178e+08,  1.8274e+09, -5.4709e+08,\n","                        2.1475e+09, -1.3815e+09,  5.0827e+08,  1.9853e+07, -1.5335e+07,\n","                        9.7470e+08,  2.1475e+09,  2.2625e+08, -5.1513e+07,  2.1475e+09,\n","                       -1.5134e+09,  2.1475e+09, -1.1976e+09, -1.7906e+08,  1.0478e+09,\n","                        8.5523e+08, -7.3302e+08,  8.8921e+07, -6.8148e+08], device='cuda:0')),\n","              ('module.layer3.1.relu2.num_forwards',\n","               tensor([40], device='cuda:0')),\n","              ('module.layer3.1.relu2.force_readjust',\n","               tensor(False, device='cuda:0')),\n","              ('module.layer3.1.relu2.output_scale',\n","               tensor([8835.0479], device='cuda:0')),\n","              ('module.layer3.1.relu2.output_zero_point',\n","               tensor([0.], device='cuda:0')),\n","              ('module.layer3.1.residual_eltwiseadd.num_forwards',\n","               tensor([40], device='cuda:0')),\n","              ('module.layer3.1.residual_eltwiseadd.force_readjust',\n","               tensor(False, device='cuda:0')),\n","              ('module.layer3.1.residual_eltwiseadd.output_scale',\n","               tensor([8835.0479], device='cuda:0')),\n","              ('module.layer3.1.residual_eltwiseadd.output_zero_point',\n","               tensor([0.], device='cuda:0')),\n","              ('module.layer3.2.conv1.num_forwards',\n","               tensor([40], device='cuda:0')),\n","              ('module.layer3.2.conv1.force_readjust',\n","               tensor(False, device='cuda:0')),\n","              ('module.layer3.2.conv1.output_scale',\n","               tensor([53781.4453], device='cuda:0')),\n","              ('module.layer3.2.conv1.output_zero_point',\n","               tensor([0.], device='cuda:0')),\n","              ('module.layer3.2.conv1.w_scale', tensor([[[[ 840879.3750]]],\n","               \n","               \n","                       [[[ 814258.1875]]],\n","               \n","               \n","                       [[[ 743007.3750]]],\n","               \n","               \n","                       [[[1040441.9375]]],\n","               \n","               \n","                       [[[1042800.3750]]],\n","               \n","               \n","                       [[[ 997177.6875]]],\n","               \n","               \n","                       [[[1110062.1250]]],\n","               \n","               \n","                       [[[ 855991.5625]]],\n","               \n","               \n","                       [[[1061992.2500]]],\n","               \n","               \n","                       [[[ 851631.7500]]],\n","               \n","               \n","                       [[[ 682403.0625]]],\n","               \n","               \n","                       [[[ 991712.4375]]],\n","               \n","               \n","                       [[[1081139.8750]]],\n","               \n","               \n","                       [[[ 997685.5000]]],\n","               \n","               \n","                       [[[3051064.7500]]],\n","               \n","               \n","                       [[[ 887945.3750]]],\n","               \n","               \n","                       [[[ 983669.9375]]],\n","               \n","               \n","                       [[[ 853712.5625]]],\n","               \n","               \n","                       [[[1011872.7500]]],\n","               \n","               \n","                       [[[2155389.2500]]],\n","               \n","               \n","                       [[[1288156.3750]]],\n","               \n","               \n","                       [[[ 885816.1250]]],\n","               \n","               \n","                       [[[1374348.8750]]],\n","               \n","               \n","                       [[[ 976943.2500]]],\n","               \n","               \n","                       [[[ 815586.8125]]],\n","               \n","               \n","                       [[[1104474.5000]]],\n","               \n","               \n","                       [[[1503314.2500]]],\n","               \n","               \n","                       [[[ 555780.9375]]],\n","               \n","               \n","                       [[[ 827396.1875]]],\n","               \n","               \n","                       [[[1006823.0625]]],\n","               \n","               \n","                       [[[1440577.8750]]],\n","               \n","               \n","                       [[[1145324.3750]]],\n","               \n","               \n","                       [[[1479855.5000]]],\n","               \n","               \n","                       [[[ 858810.0625]]],\n","               \n","               \n","                       [[[1507910.7500]]],\n","               \n","               \n","                       [[[ 946210.5000]]],\n","               \n","               \n","                       [[[ 765540.1875]]],\n","               \n","               \n","                       [[[1275133.6250]]],\n","               \n","               \n","                       [[[1038843.0000]]],\n","               \n","               \n","                       [[[ 867207.4375]]],\n","               \n","               \n","                       [[[ 554735.2500]]],\n","               \n","               \n","                       [[[ 649314.8750]]],\n","               \n","               \n","                       [[[ 695135.9375]]],\n","               \n","               \n","                       [[[ 912492.1250]]],\n","               \n","               \n","                       [[[1191016.7500]]],\n","               \n","               \n","                       [[[ 866007.7500]]],\n","               \n","               \n","                       [[[ 779011.1875]]],\n","               \n","               \n","                       [[[ 924326.8125]]],\n","               \n","               \n","                       [[[ 966381.0625]]],\n","               \n","               \n","                       [[[ 891711.0000]]],\n","               \n","               \n","                       [[[ 686778.7500]]],\n","               \n","               \n","                       [[[ 697735.5000]]],\n","               \n","               \n","                       [[[ 790663.8125]]],\n","               \n","               \n","                       [[[1146503.6250]]],\n","               \n","               \n","                       [[[ 821298.7500]]],\n","               \n","               \n","                       [[[1086942.7500]]],\n","               \n","               \n","                       [[[ 798648.1875]]],\n","               \n","               \n","                       [[[ 767938.0625]]],\n","               \n","               \n","                       [[[ 771367.8750]]],\n","               \n","               \n","                       [[[1046475.5625]]],\n","               \n","               \n","                       [[[1054771.8750]]],\n","               \n","               \n","                       [[[1076639.5000]]],\n","               \n","               \n","                       [[[ 928753.5000]]],\n","               \n","               \n","                       [[[ 945612.0625]]]], device='cuda:0')),\n","              ('module.layer3.2.conv1.w_zero_point', tensor([[[[-29768.]]],\n","               \n","               \n","                       [[[-32901.]]],\n","               \n","               \n","                       [[[-27953.]]],\n","               \n","               \n","                       [[[-27750.]]],\n","               \n","               \n","                       [[[-32228.]]],\n","               \n","               \n","                       [[[-34987.]]],\n","               \n","               \n","                       [[[-32453.]]],\n","               \n","               \n","                       [[[-30052.]]],\n","               \n","               \n","                       [[[-29220.]]],\n","               \n","               \n","                       [[[-29263.]]],\n","               \n","               \n","                       [[[-35540.]]],\n","               \n","               \n","                       [[[-28650.]]],\n","               \n","               \n","                       [[[-27869.]]],\n","               \n","               \n","                       [[[-27879.]]],\n","               \n","               \n","                       [[[-22853.]]],\n","               \n","               \n","                       [[[-26568.]]],\n","               \n","               \n","                       [[[-35195.]]],\n","               \n","               \n","                       [[[-31454.]]],\n","               \n","               \n","                       [[[-31354.]]],\n","               \n","               \n","                       [[[-27231.]]],\n","               \n","               \n","                       [[[-34139.]]],\n","               \n","               \n","                       [[[-29412.]]],\n","               \n","               \n","                       [[[-27189.]]],\n","               \n","               \n","                       [[[-24788.]]],\n","               \n","               \n","                       [[[-33886.]]],\n","               \n","               \n","                       [[[-27801.]]],\n","               \n","               \n","                       [[[-31995.]]],\n","               \n","               \n","                       [[[-31216.]]],\n","               \n","               \n","                       [[[-34541.]]],\n","               \n","               \n","                       [[[-38257.]]],\n","               \n","               \n","                       [[[-31766.]]],\n","               \n","               \n","                       [[[-27129.]]],\n","               \n","               \n","                       [[[-35040.]]],\n","               \n","               \n","                       [[[-31573.]]],\n","               \n","               \n","                       [[[-32269.]]],\n","               \n","               \n","                       [[[-23305.]]],\n","               \n","               \n","                       [[[-24343.]]],\n","               \n","               \n","                       [[[-27695.]]],\n","               \n","               \n","                       [[[-28802.]]],\n","               \n","               \n","                       [[[-29607.]]],\n","               \n","               \n","                       [[[-28997.]]],\n","               \n","               \n","                       [[[-31283.]]],\n","               \n","               \n","                       [[[-29635.]]],\n","               \n","               \n","                       [[[-31194.]]],\n","               \n","               \n","                       [[[-30944.]]],\n","               \n","               \n","                       [[[-31752.]]],\n","               \n","               \n","                       [[[-28757.]]],\n","               \n","               \n","                       [[[-27137.]]],\n","               \n","               \n","                       [[[-37210.]]],\n","               \n","               \n","                       [[[-24536.]]],\n","               \n","               \n","                       [[[-29713.]]],\n","               \n","               \n","                       [[[-31097.]]],\n","               \n","               \n","                       [[[-29905.]]],\n","               \n","               \n","                       [[[-29490.]]],\n","               \n","               \n","                       [[[-25853.]]],\n","               \n","               \n","                       [[[-33623.]]],\n","               \n","               \n","                       [[[-26106.]]],\n","               \n","               \n","                       [[[-33115.]]],\n","               \n","               \n","                       [[[-29331.]]],\n","               \n","               \n","                       [[[-31168.]]],\n","               \n","               \n","                       [[[-34792.]]],\n","               \n","               \n","                       [[[-32970.]]],\n","               \n","               \n","                       [[[-27695.]]],\n","               \n","               \n","                       [[[-30416.]]]], device='cuda:0')),\n","              ('module.layer3.2.conv1.fp_bias',\n","               tensor([-0.3388, -0.2158, -0.2754, -0.3570,  0.0587,  0.4261,  0.3613, -0.1590,\n","                        0.1134, -0.0039, -0.3000, -0.5024, -0.0249, -0.0773, -0.3444, -0.0224,\n","                        0.0835, -0.2082, -0.4694, -0.3234, -0.3973,  0.1611, -0.2650, -0.2048,\n","                        0.0111, -0.1394,  0.0653, -0.4308,  0.0911, -0.2290, -0.0737, -0.2002,\n","                       -0.3416, -0.7604, -0.3290, -0.1455, -0.2194, -0.0637, -0.2134, -0.2856,\n","                       -0.2453,  0.0012,  0.1843, -0.0747, -0.0016, -0.1557, -0.0147, -0.0842,\n","                        0.0029, -0.2075, -0.0429, -0.1244, -0.1531, -0.0810, -0.2563, -0.3678,\n","                       -0.0808, -0.4053, -0.2112, -0.2587, -0.2455, -0.0929, -0.1123, -0.3790],\n","                      device='cuda:0')),\n","              ('module.layer3.2.conv1.accum_scale', tensor([[[7.4292e+09]],\n","               \n","                       [[7.1940e+09]],\n","               \n","                       [[6.5645e+09]],\n","               \n","                       [[9.1924e+09]],\n","               \n","                       [[9.2132e+09]],\n","               \n","                       [[8.8101e+09]],\n","               \n","                       [[9.8075e+09]],\n","               \n","                       [[7.5627e+09]],\n","               \n","                       [[9.3828e+09]],\n","               \n","                       [[7.5242e+09]],\n","               \n","                       [[6.0291e+09]],\n","               \n","                       [[8.7618e+09]],\n","               \n","                       [[9.5519e+09]],\n","               \n","                       [[8.8146e+09]],\n","               \n","                       [[2.6956e+10]],\n","               \n","                       [[7.8450e+09]],\n","               \n","                       [[8.6908e+09]],\n","               \n","                       [[7.5426e+09]],\n","               \n","                       [[8.9399e+09]],\n","               \n","                       [[1.9043e+10]],\n","               \n","                       [[1.1381e+10]],\n","               \n","                       [[7.8262e+09]],\n","               \n","                       [[1.2142e+10]],\n","               \n","                       [[8.6313e+09]],\n","               \n","                       [[7.2057e+09]],\n","               \n","                       [[9.7581e+09]],\n","               \n","                       [[1.3282e+10]],\n","               \n","                       [[4.9104e+09]],\n","               \n","                       [[7.3101e+09]],\n","               \n","                       [[8.8953e+09]],\n","               \n","                       [[1.2728e+10]],\n","               \n","                       [[1.0119e+10]],\n","               \n","                       [[1.3075e+10]],\n","               \n","                       [[7.5876e+09]],\n","               \n","                       [[1.3322e+10]],\n","               \n","                       [[8.3598e+09]],\n","               \n","                       [[6.7636e+09]],\n","               \n","                       [[1.1266e+10]],\n","               \n","                       [[9.1782e+09]],\n","               \n","                       [[7.6618e+09]],\n","               \n","                       [[4.9011e+09]],\n","               \n","                       [[5.7367e+09]],\n","               \n","                       [[6.1416e+09]],\n","               \n","                       [[8.0619e+09]],\n","               \n","                       [[1.0523e+10]],\n","               \n","                       [[7.6512e+09]],\n","               \n","                       [[6.8826e+09]],\n","               \n","                       [[8.1665e+09]],\n","               \n","                       [[8.5380e+09]],\n","               \n","                       [[7.8783e+09]],\n","               \n","                       [[6.0677e+09]],\n","               \n","                       [[6.1645e+09]],\n","               \n","                       [[6.9856e+09]],\n","               \n","                       [[1.0129e+10]],\n","               \n","                       [[7.2562e+09]],\n","               \n","                       [[9.6032e+09]],\n","               \n","                       [[7.0561e+09]],\n","               \n","                       [[6.7848e+09]],\n","               \n","                       [[6.8151e+09]],\n","               \n","                       [[9.2457e+09]],\n","               \n","                       [[9.3190e+09]],\n","               \n","                       [[9.5122e+09]],\n","               \n","                       [[8.2056e+09]],\n","               \n","                       [[8.3545e+09]]], device='cuda:0')),\n","              ('module.layer3.2.conv1.is_simulated_quant_weight_shifted',\n","               tensor(False, device='cuda:0')),\n","              ('module.layer3.2.conv1.wrapped_module.weight',\n","               tensor([[[[32608., 24190., 32945.],\n","                         [27443., 25184., 23821.],\n","                         [24212., 34508., 20381.]],\n","               \n","                        [[29634., 31908., 40487.],\n","                         [32423., 30037., 32461.],\n","                         [23477., 25465., 30723.]],\n","               \n","                        [[39266., 31164., 45458.],\n","                         [46905., 41259., 31644.],\n","                         [51840., 40513., 27298.]],\n","               \n","                        ...,\n","               \n","                        [[27992., 28113., 30948.],\n","                         [24818., 23531., 27178.],\n","                         [29698., 26283., 24733.]],\n","               \n","                        [[51110., 37877., 32568.],\n","                         [46736., 29821., 30244.],\n","                         [18969., 25602., 44931.]],\n","               \n","                        [[26509., 27137., 53265.],\n","                         [20605., 16417., 22160.],\n","                         [39007., 34708., 21080.]]],\n","               \n","               \n","                       [[[29140., 24225., 16265.],\n","                         [37676., 43807., 14923.],\n","                         [34604., 42298., 24696.]],\n","               \n","                        [[36863., 32901., 47054.],\n","                         [33823., 26918., 29583.],\n","                         [25089., 26305., 26921.]],\n","               \n","                        [[49446., 48081., 25561.],\n","                         [50368., 46790., 42664.],\n","                         [34946., 38075., 29807.]],\n","               \n","                        ...,\n","               \n","                        [[26912., 30733., 32937.],\n","                         [25455., 27711., 31390.],\n","                         [31408., 32234., 30736.]],\n","               \n","                        [[28035., 31408., 38938.],\n","                         [23576., 25691., 40559.],\n","                         [25844., 31689., 23373.]],\n","               \n","                        [[23177., 47532., 37773.],\n","                         [32058., 28913., 37349.],\n","                         [30518., 33055., 40718.]]],\n","               \n","               \n","                       [[[38858., 49096., 33801.],\n","                         [28476., 35382., 33791.],\n","                         [ 6577.,  8942., 20728.]],\n","               \n","                        [[27721., 19719., 22649.],\n","                         [33282., 26379., 27202.],\n","                         [22439., 28408., 24601.]],\n","               \n","                        [[18285., 10123., 23026.],\n","                         [35346., 30270., 40784.],\n","                         [41811., 47432., 46401.]],\n","               \n","                        ...,\n","               \n","                        [[32574., 29286., 28955.],\n","                         [31727., 27734., 27667.],\n","                         [31099., 31469., 29495.]],\n","               \n","                        [[29015., 32148., 40288.],\n","                         [13438.,  2765.,  7118.],\n","                         [19184., 13090., 16432.]],\n","               \n","                        [[41145., 26106., 28089.],\n","                         [36133., 23738., 19960.],\n","                         [31201., 25573., 24575.]]],\n","               \n","               \n","                       ...,\n","               \n","               \n","                       [[[36360., 28800., 19498.],\n","                         [46023., 32007., 33049.],\n","                         [42203., 40769., 38433.]],\n","               \n","                        [[21394., 26070., 36230.],\n","                         [28186., 30878., 26225.],\n","                         [34001., 27206., 24524.]],\n","               \n","                        [[21856., 36455., 51990.],\n","                         [26000., 31268., 29152.],\n","                         [42075., 58057., 43552.]],\n","               \n","                        ...,\n","               \n","                        [[35594., 35586., 34439.],\n","                         [31282., 33538., 31991.],\n","                         [32184., 34912., 33293.]],\n","               \n","                        [[29354., 20082., 23641.],\n","                         [30410., 21634., 27990.],\n","                         [26603., 22937., 42536.]],\n","               \n","                        [[23225., 31399., 32077.],\n","                         [25754., 36681., 45690.],\n","                         [20468., 27929., 36690.]]],\n","               \n","               \n","                       [[[15133., 12380., 26608.],\n","                         [ 8653., 12450., 23166.],\n","                         [ 6730., 11745.,  3624.]],\n","               \n","                        [[13878., 11538., 22313.],\n","                         [14071., 16773., 29945.],\n","                         [20003., 25745., 29476.]],\n","               \n","                        [[ 5401., 14862., 15200.],\n","                         [17109., 27059., 20819.],\n","                         [29501., 37324., 29909.]],\n","               \n","                        ...,\n","               \n","                        [[30124., 22060., 21511.],\n","                         [31025., 26663., 26706.],\n","                         [31512., 31923., 31674.]],\n","               \n","                        [[34307., 14299., 19349.],\n","                         [25416., 10235., 19348.],\n","                         [19815., 14227., 24088.]],\n","               \n","                        [[42931., 39792., 41446.],\n","                         [49509., 44207., 28304.],\n","                         [26485., 27072., 20487.]]],\n","               \n","               \n","                       [[[39587., 31049., 25113.],\n","                         [34930., 26458., 19432.],\n","                         [62254., 59421., 39330.]],\n","               \n","                        [[29810., 24485., 29169.],\n","                         [26378., 28029., 35745.],\n","                         [32436., 38072., 47913.]],\n","               \n","                        [[40923., 44205., 31238.],\n","                         [49911., 39209., 15730.],\n","                         [21715.,  9448., 27283.]],\n","               \n","                        ...,\n","               \n","                        [[25950., 28739., 29807.],\n","                         [28047., 26998., 28940.],\n","                         [33781., 29690., 29091.]],\n","               \n","                        [[18033., 16399., 21767.],\n","                         [22234., 35426., 26467.],\n","                         [13244., 31802., 34080.]],\n","               \n","                        [[34834., 30591., 24686.],\n","                         [21045., 30849., 25616.],\n","                         [ 3703., 12056.,  9505.]]]], device='cuda:0')),\n","              ('module.layer3.2.conv1.wrapped_module.bias',\n","               tensor([-2.1475e+09, -1.5525e+09, -1.8079e+09, -2.1475e+09,  5.4076e+08,\n","                        2.1475e+09,  2.1475e+09, -1.2026e+09,  1.0643e+09, -2.9137e+07,\n","                       -1.8089e+09, -2.1475e+09, -2.3823e+08, -6.8164e+08, -2.1475e+09,\n","                       -1.7566e+08,  7.2583e+08, -1.5703e+09, -2.1475e+09, -2.1475e+09,\n","                       -2.1475e+09,  1.2611e+09, -2.1475e+09, -1.7679e+09,  7.9910e+07,\n","                       -1.3605e+09,  8.6772e+08, -2.1155e+09,  6.6579e+08, -2.0372e+09,\n","                       -9.3786e+08, -2.0257e+09, -2.1475e+09, -2.1475e+09, -2.1475e+09,\n","                       -1.2161e+09, -1.4839e+09, -7.1786e+08, -1.9585e+09, -2.1475e+09,\n","                       -1.2022e+09,  6.9172e+06,  1.1318e+09, -6.0184e+08, -1.6566e+07,\n","                       -1.1914e+09, -1.0101e+08, -6.8721e+08,  2.5106e+07, -1.6348e+09,\n","                       -2.6018e+08, -7.6696e+08, -1.0692e+09, -8.2006e+08, -1.8600e+09,\n","                       -2.1475e+09, -5.7006e+08, -2.1475e+09, -1.4395e+09, -2.1475e+09,\n","                       -2.1475e+09, -8.8344e+08, -9.2127e+08, -2.1475e+09], device='cuda:0')),\n","              ('module.layer3.2.conv2.num_forwards',\n","               tensor([40], device='cuda:0')),\n","              ('module.layer3.2.conv2.force_readjust',\n","               tensor(False, device='cuda:0')),\n","              ('module.layer3.2.conv2.output_scale',\n","               tensor([14105.6045], device='cuda:0')),\n","              ('module.layer3.2.conv2.output_zero_point',\n","               tensor([-33286.], device='cuda:0')),\n","              ('module.layer3.2.conv2.w_scale', tensor([[[[ 110583.0781]]],\n","               \n","               \n","                       [[[  62412.4648]]],\n","               \n","               \n","                       [[[ 105886.4844]]],\n","               \n","               \n","                       [[[  84768.4766]]],\n","               \n","               \n","                       [[[ 118146.1797]]],\n","               \n","               \n","                       [[[  76996.1328]]],\n","               \n","               \n","                       [[[  71613.3047]]],\n","               \n","               \n","                       [[[  99853.0703]]],\n","               \n","               \n","                       [[[  52537.8789]]],\n","               \n","               \n","                       [[[  77301.9062]]],\n","               \n","               \n","                       [[[  66291.5625]]],\n","               \n","               \n","                       [[[  40784.4375]]],\n","               \n","               \n","                       [[[ 225874.3281]]],\n","               \n","               \n","                       [[[  52462.6289]]],\n","               \n","               \n","                       [[[  64279.2695]]],\n","               \n","               \n","                       [[[  85680.6484]]],\n","               \n","               \n","                       [[[ 149350.4062]]],\n","               \n","               \n","                       [[[  94670.5312]]],\n","               \n","               \n","                       [[[  73866.4766]]],\n","               \n","               \n","                       [[[ 116234.4219]]],\n","               \n","               \n","                       [[[  46932.4141]]],\n","               \n","               \n","                       [[[ 323591.2812]]],\n","               \n","               \n","                       [[[  72891.5859]]],\n","               \n","               \n","                       [[[  61258.5391]]],\n","               \n","               \n","                       [[[ 105505.4453]]],\n","               \n","               \n","                       [[[ 103950.9844]]],\n","               \n","               \n","                       [[[  82261.6562]]],\n","               \n","               \n","                       [[[ 116620.9219]]],\n","               \n","               \n","                       [[[  77818.1172]]],\n","               \n","               \n","                       [[[ 310600.2500]]],\n","               \n","               \n","                       [[[  42687.9453]]],\n","               \n","               \n","                       [[[  48275.0195]]],\n","               \n","               \n","                       [[[1701700.1250]]],\n","               \n","               \n","                       [[[ 123733.6328]]],\n","               \n","               \n","                       [[[  56887.3984]]],\n","               \n","               \n","                       [[[  78739.2891]]],\n","               \n","               \n","                       [[[  99007.4609]]],\n","               \n","               \n","                       [[[  64585.1484]]],\n","               \n","               \n","                       [[[  57476.6172]]],\n","               \n","               \n","                       [[[  60522.9844]]],\n","               \n","               \n","                       [[[ 157356.7500]]],\n","               \n","               \n","                       [[[  92679.9609]]],\n","               \n","               \n","                       [[[ 133758.6250]]],\n","               \n","               \n","                       [[[ 134628.9844]]],\n","               \n","               \n","                       [[[ 165298.2500]]],\n","               \n","               \n","                       [[[ 115833.5312]]],\n","               \n","               \n","                       [[[9725169.0000]]],\n","               \n","               \n","                       [[[ 152547.6562]]],\n","               \n","               \n","                       [[[ 103971.2344]]],\n","               \n","               \n","                       [[[ 281836.6562]]],\n","               \n","               \n","                       [[[ 189910.7500]]],\n","               \n","               \n","                       [[[  70207.5859]]],\n","               \n","               \n","                       [[[ 117677.8594]]],\n","               \n","               \n","                       [[[  48277.9062]]],\n","               \n","               \n","                       [[[  81408.4688]]],\n","               \n","               \n","                       [[[ 108953.5938]]],\n","               \n","               \n","                       [[[  77998.0078]]],\n","               \n","               \n","                       [[[  55318.9883]]],\n","               \n","               \n","                       [[[  61308.2539]]],\n","               \n","               \n","                       [[[ 153188.2031]]],\n","               \n","               \n","                       [[[  91767.0859]]],\n","               \n","               \n","                       [[[  53676.9648]]],\n","               \n","               \n","                       [[[  89989.8750]]],\n","               \n","               \n","                       [[[ 611550.9375]]]], device='cuda:0')),\n","              ('module.layer3.2.conv2.w_zero_point', tensor([[[[-33837.]]],\n","               \n","               \n","                       [[[-22989.]]],\n","               \n","               \n","                       [[[-41857.]]],\n","               \n","               \n","                       [[[-31203.]]],\n","               \n","               \n","                       [[[-33798.]]],\n","               \n","               \n","                       [[[-34391.]]],\n","               \n","               \n","                       [[[-31197.]]],\n","               \n","               \n","                       [[[-29898.]]],\n","               \n","               \n","                       [[[-30185.]]],\n","               \n","               \n","                       [[[-38262.]]],\n","               \n","               \n","                       [[[-29071.]]],\n","               \n","               \n","                       [[[-30556.]]],\n","               \n","               \n","                       [[[-28194.]]],\n","               \n","               \n","                       [[[-25605.]]],\n","               \n","               \n","                       [[[-30187.]]],\n","               \n","               \n","                       [[[-36690.]]],\n","               \n","               \n","                       [[[-30557.]]],\n","               \n","               \n","                       [[[-31214.]]],\n","               \n","               \n","                       [[[-26692.]]],\n","               \n","               \n","                       [[[-39234.]]],\n","               \n","               \n","                       [[[-30047.]]],\n","               \n","               \n","                       [[[-31194.]]],\n","               \n","               \n","                       [[[-33674.]]],\n","               \n","               \n","                       [[[-32318.]]],\n","               \n","               \n","                       [[[-33757.]]],\n","               \n","               \n","                       [[[-32763.]]],\n","               \n","               \n","                       [[[-26824.]]],\n","               \n","               \n","                       [[[-29805.]]],\n","               \n","               \n","                       [[[-26098.]]],\n","               \n","               \n","                       [[[-30796.]]],\n","               \n","               \n","                       [[[-25278.]]],\n","               \n","               \n","                       [[[-22304.]]],\n","               \n","               \n","                       [[[-34858.]]],\n","               \n","               \n","                       [[[-30772.]]],\n","               \n","               \n","                       [[[-28361.]]],\n","               \n","               \n","                       [[[-27006.]]],\n","               \n","               \n","                       [[[-35613.]]],\n","               \n","               \n","                       [[[-23545.]]],\n","               \n","               \n","                       [[[-35223.]]],\n","               \n","               \n","                       [[[-34142.]]],\n","               \n","               \n","                       [[[-28297.]]],\n","               \n","               \n","                       [[[-29392.]]],\n","               \n","               \n","                       [[[-34249.]]],\n","               \n","               \n","                       [[[-32397.]]],\n","               \n","               \n","                       [[[-32539.]]],\n","               \n","               \n","                       [[[-36581.]]],\n","               \n","               \n","                       [[[-40380.]]],\n","               \n","               \n","                       [[[-29013.]]],\n","               \n","               \n","                       [[[-34499.]]],\n","               \n","               \n","                       [[[-27102.]]],\n","               \n","               \n","                       [[[-35981.]]],\n","               \n","               \n","                       [[[-26776.]]],\n","               \n","               \n","                       [[[-28779.]]],\n","               \n","               \n","                       [[[-21904.]]],\n","               \n","               \n","                       [[[-33556.]]],\n","               \n","               \n","                       [[[-31919.]]],\n","               \n","               \n","                       [[[-32484.]]],\n","               \n","               \n","                       [[[-34713.]]],\n","               \n","               \n","                       [[[-30595.]]],\n","               \n","               \n","                       [[[-38146.]]],\n","               \n","               \n","                       [[[-35294.]]],\n","               \n","               \n","                       [[[-22735.]]],\n","               \n","               \n","                       [[[-33737.]]],\n","               \n","               \n","                       [[[-35120.]]]], device='cuda:0')),\n","              ('module.layer3.2.conv2.fp_bias',\n","               tensor([-0.2059, -0.2472,  0.2186, -0.0752,  0.1994,  0.1399,  0.1550, -0.1801,\n","                       -0.0773,  0.4704,  0.1039, -0.1053,  0.0391,  0.0027, -0.5230, -0.1828,\n","                       -0.1625,  0.0026,  0.0113,  0.2150, -0.2189,  0.1285,  0.0159,  0.3251,\n","                        0.4370,  0.1244, -0.0622, -0.0730, -0.1323, -0.1336,  0.0135, -0.3554,\n","                       -0.0788, -0.1458,  0.3106, -0.2850,  0.0122, -0.1214,  0.3200,  0.1259,\n","                        0.1324, -0.0735, -0.0719,  0.2313,  0.0082,  0.1164, -0.0086,  0.0419,\n","                       -0.2008,  0.0281, -0.1118,  0.0217, -0.1971,  0.0251,  0.0904, -0.0752,\n","                        0.5737, -0.1405, -0.0754,  0.0359,  0.3031, -0.4865,  0.0746, -0.0312],\n","                      device='cuda:0')),\n","              ('module.layer3.2.conv2.accum_scale', tensor([[[5.9473e+09]],\n","               \n","                       [[3.3566e+09]],\n","               \n","                       [[5.6947e+09]],\n","               \n","                       [[4.5590e+09]],\n","               \n","                       [[6.3541e+09]],\n","               \n","                       [[4.1410e+09]],\n","               \n","                       [[3.8515e+09]],\n","               \n","                       [[5.3702e+09]],\n","               \n","                       [[2.8256e+09]],\n","               \n","                       [[4.1574e+09]],\n","               \n","                       [[3.5653e+09]],\n","               \n","                       [[2.1934e+09]],\n","               \n","                       [[1.2148e+10]],\n","               \n","                       [[2.8215e+09]],\n","               \n","                       [[3.4570e+09]],\n","               \n","                       [[4.6080e+09]],\n","               \n","                       [[8.0323e+09]],\n","               \n","                       [[5.0915e+09]],\n","               \n","                       [[3.9726e+09]],\n","               \n","                       [[6.2513e+09]],\n","               \n","                       [[2.5241e+09]],\n","               \n","                       [[1.7403e+10]],\n","               \n","                       [[3.9202e+09]],\n","               \n","                       [[3.2946e+09]],\n","               \n","                       [[5.6742e+09]],\n","               \n","                       [[5.5906e+09]],\n","               \n","                       [[4.4242e+09]],\n","               \n","                       [[6.2720e+09]],\n","               \n","                       [[4.1852e+09]],\n","               \n","                       [[1.6705e+10]],\n","               \n","                       [[2.2958e+09]],\n","               \n","                       [[2.5963e+09]],\n","               \n","                       [[9.1520e+10]],\n","               \n","                       [[6.6546e+09]],\n","               \n","                       [[3.0595e+09]],\n","               \n","                       [[4.2347e+09]],\n","               \n","                       [[5.3248e+09]],\n","               \n","                       [[3.4735e+09]],\n","               \n","                       [[3.0912e+09]],\n","               \n","                       [[3.2550e+09]],\n","               \n","                       [[8.4629e+09]],\n","               \n","                       [[4.9845e+09]],\n","               \n","                       [[7.1937e+09]],\n","               \n","                       [[7.2405e+09]],\n","               \n","                       [[8.8900e+09]],\n","               \n","                       [[6.2297e+09]],\n","               \n","                       [[5.2303e+11]],\n","               \n","                       [[8.2042e+09]],\n","               \n","                       [[5.5917e+09]],\n","               \n","                       [[1.5158e+10]],\n","               \n","                       [[1.0214e+10]],\n","               \n","                       [[3.7759e+09]],\n","               \n","                       [[6.3289e+09]],\n","               \n","                       [[2.5965e+09]],\n","               \n","                       [[4.3783e+09]],\n","               \n","                       [[5.8597e+09]],\n","               \n","                       [[4.1948e+09]],\n","               \n","                       [[2.9751e+09]],\n","               \n","                       [[3.2972e+09]],\n","               \n","                       [[8.2387e+09]],\n","               \n","                       [[4.9354e+09]],\n","               \n","                       [[2.8868e+09]],\n","               \n","                       [[4.8398e+09]],\n","               \n","                       [[3.2890e+10]]], device='cuda:0')),\n","              ('module.layer3.2.conv2.is_simulated_quant_weight_shifted',\n","               tensor(False, device='cuda:0')),\n","              ('module.layer3.2.conv2.wrapped_module.weight',\n","               tensor([[[[36568., 48261., 44258.],\n","                         [32972., 38651., 36055.],\n","                         [35685., 30095., 25042.]],\n","               \n","                        [[25407., 53684., 55649.],\n","                         [28658., 42797., 44590.],\n","                         [25439., 29760., 32751.]],\n","               \n","                        [[30743., 31033., 27123.],\n","                         [20109., 24223., 23583.],\n","                         [20287., 35449., 40542.]],\n","               \n","                        ...,\n","               \n","                        [[29206., 44234., 43876.],\n","                         [19105., 36408., 36047.],\n","                         [19947., 31891., 29699.]],\n","               \n","                        [[30964., 36387., 33299.],\n","                         [20295., 23015., 31319.],\n","                         [22113., 24489., 38274.]],\n","               \n","                        [[36037., 46580., 65535.],\n","                         [36408., 32176., 39791.],\n","                         [31369., 29673., 35118.]]],\n","               \n","               \n","                       [[[26903., 19290., 19878.],\n","                         [33756., 20321., 20816.],\n","                         [32725., 23978., 26636.]],\n","               \n","                        [[12554., 13600., 17535.],\n","                         [34636., 15558.,  7062.],\n","                         [52306., 47594., 23452.]],\n","               \n","                        [[27639., 27327., 30129.],\n","                         [21670., 10367., 23983.],\n","                         [27687., 18472., 24179.]],\n","               \n","                        ...,\n","               \n","                        [[13251., 19937., 20961.],\n","                         [26640., 25515., 26194.],\n","                         [28114., 23892., 21187.]],\n","               \n","                        [[19397., 20879., 19144.],\n","                         [16627., 22426., 25144.],\n","                         [22550., 24085., 33570.]],\n","               \n","                        [[14770., 18487., 27514.],\n","                         [26148., 18725., 20696.],\n","                         [27143., 30887., 20648.]]],\n","               \n","               \n","                       [[[39088., 32673., 30435.],\n","                         [33168., 34988., 38980.],\n","                         [29086., 27654., 33993.]],\n","               \n","                        [[18948., 41517., 53269.],\n","                         [22003., 48597., 65535.],\n","                         [34914., 48204., 54865.]],\n","               \n","                        [[59395., 44758., 37904.],\n","                         [45191., 32174., 35176.],\n","                         [48025., 46635., 54207.]],\n","               \n","                        ...,\n","               \n","                        [[37778., 40417., 42853.],\n","                         [35124., 36887., 39784.],\n","                         [25928., 31545., 35970.]],\n","               \n","                        [[60864., 38292., 24154.],\n","                         [52001., 43077., 35082.],\n","                         [40146., 41786., 48814.]],\n","               \n","                        [[23175., 37614., 53366.],\n","                         [38399., 46480., 58783.],\n","                         [31230., 37178., 44645.]]],\n","               \n","               \n","                       ...,\n","               \n","               \n","                       [[[27886., 14893., 16029.],\n","                         [39325., 30260., 25738.],\n","                         [33779., 27624., 26379.]],\n","               \n","                        [[16856., 16149., 16331.],\n","                         [17203., 23164., 18216.],\n","                         [17170., 28602., 20912.]],\n","               \n","                        [[23487., 22218., 23048.],\n","                         [27152., 21041., 20737.],\n","                         [20721., 22584., 25494.]],\n","               \n","                        ...,\n","               \n","                        [[36284., 29330., 19657.],\n","                         [25440., 28058., 17964.],\n","                         [19923., 25219., 17439.]],\n","               \n","                        [[47252., 46357., 41059.],\n","                         [43023., 45596., 37486.],\n","                         [20308., 33596., 34316.]],\n","               \n","                        [[14332., 22648., 18108.],\n","                         [29868., 26768., 19514.],\n","                         [34067., 18845., 17716.]]],\n","               \n","               \n","                       [[[27845., 38872., 39192.],\n","                         [21241., 38647., 33594.],\n","                         [32005., 40044., 28635.]],\n","               \n","                        [[30164., 36589., 43842.],\n","                         [44117., 42471., 35275.],\n","                         [37002., 27032., 22595.]],\n","               \n","                        [[36126., 28271., 25040.],\n","                         [43059., 34895., 26528.],\n","                         [42044., 36685., 38032.]],\n","               \n","                        ...,\n","               \n","                        [[42468., 44538., 44586.],\n","                         [43893., 41889., 39156.],\n","                         [30114., 28003., 35104.]],\n","               \n","                        [[35315., 33830., 16930.],\n","                         [40455., 48534., 35620.],\n","                         [40318., 29344., 19287.]],\n","               \n","                        [[44706., 46074., 29030.],\n","                         [41682., 52847., 27571.],\n","                         [24966., 40416., 30786.]]],\n","               \n","               \n","                       [[[32084., 21601., 22722.],\n","                         [32879., 35647., 41567.],\n","                         [31229., 38261., 43585.]],\n","               \n","                        [[55072., 55649., 43427.],\n","                         [30798., 46512., 46657.],\n","                         [29898., 41296., 42744.]],\n","               \n","                        [[32710., 34130., 31089.],\n","                         [31423., 38700., 38580.],\n","                         [38900., 36496., 40970.]],\n","               \n","                        ...,\n","               \n","                        [[37544., 40209., 37262.],\n","                         [43129., 44550., 41325.],\n","                         [47080., 44703., 38463.]],\n","               \n","                        [[47239., 52955., 37513.],\n","                         [47959., 49145., 35525.],\n","                         [49316., 36689., 23026.]],\n","               \n","                        [[31064., 27050., 23209.],\n","                         [48360., 35002., 35322.],\n","                         [41811., 45780., 47127.]]]], device='cuda:0')),\n","              ('module.layer3.2.conv2.wrapped_module.bias',\n","               tensor([-1.2244e+09, -8.2961e+08,  1.2449e+09, -3.4287e+08,  1.2670e+09,\n","                        5.7947e+08,  5.9683e+08, -9.6725e+08, -2.1836e+08,  1.9556e+09,\n","                        3.7059e+08, -2.3091e+08,  4.7450e+08,  7.5797e+06, -1.8079e+09,\n","                       -8.4235e+08, -1.3049e+09,  1.3121e+07,  4.5020e+07,  1.3440e+09,\n","                       -5.5253e+08,  2.1475e+09,  6.2377e+07,  1.0711e+09,  2.1475e+09,\n","                        6.9556e+08, -2.7525e+08, -4.5768e+08, -5.5377e+08, -2.1475e+09,\n","                        3.0969e+07, -9.2283e+08, -2.1475e+09, -9.6994e+08,  9.5013e+08,\n","                       -1.2067e+09,  6.4941e+07, -4.2167e+08,  9.8919e+08,  4.0978e+08,\n","                        1.1204e+09, -3.6627e+08, -5.1746e+08,  1.6747e+09,  7.2734e+07,\n","                        7.2495e+08, -2.1475e+09,  3.4340e+08, -1.1231e+09,  4.2525e+08,\n","                       -1.1415e+09,  8.1858e+07, -1.2473e+09,  6.5055e+07,  3.9568e+08,\n","                       -4.4092e+08,  2.1475e+09, -4.1809e+08, -2.4867e+08,  2.9572e+08,\n","                        1.4957e+09, -1.4045e+09,  3.6119e+08, -1.0257e+09], device='cuda:0')),\n","              ('module.layer3.2.relu2.num_forwards',\n","               tensor([40], device='cuda:0')),\n","              ('module.layer3.2.relu2.force_readjust',\n","               tensor(False, device='cuda:0')),\n","              ('module.layer3.2.relu2.output_scale',\n","               tensor([8325.3242], device='cuda:0')),\n","              ('module.layer3.2.relu2.output_zero_point',\n","               tensor([0.], device='cuda:0')),\n","              ('module.layer3.2.residual_eltwiseadd.num_forwards',\n","               tensor([40], device='cuda:0')),\n","              ('module.layer3.2.residual_eltwiseadd.force_readjust',\n","               tensor(False, device='cuda:0')),\n","              ('module.layer3.2.residual_eltwiseadd.output_scale',\n","               tensor([8325.3242], device='cuda:0')),\n","              ('module.layer3.2.residual_eltwiseadd.output_zero_point',\n","               tensor([0.], device='cuda:0')),\n","              ('module.layer3.3.conv1.num_forwards',\n","               tensor([40], device='cuda:0')),\n","              ('module.layer3.3.conv1.force_readjust',\n","               tensor(False, device='cuda:0')),\n","              ('module.layer3.3.conv1.output_scale',\n","               tensor([57371.3867], device='cuda:0')),\n","              ('module.layer3.3.conv1.output_zero_point',\n","               tensor([0.], device='cuda:0')),\n","              ('module.layer3.3.conv1.w_scale', tensor([[[[ 945072.3750]]],\n","               \n","               \n","                       [[[ 926869.0000]]],\n","               \n","               \n","                       [[[1065061.2500]]],\n","               \n","               \n","                       [[[ 769740.9375]]],\n","               \n","               \n","                       [[[ 694623.0625]]],\n","               \n","               \n","                       [[[ 982549.0625]]],\n","               \n","               \n","                       [[[1089911.0000]]],\n","               \n","               \n","                       [[[ 788637.2500]]],\n","               \n","               \n","                       [[[ 875015.0000]]],\n","               \n","               \n","                       [[[1097101.6250]]],\n","               \n","               \n","                       [[[1251131.8750]]],\n","               \n","               \n","                       [[[1471028.0000]]],\n","               \n","               \n","                       [[[ 956615.4375]]],\n","               \n","               \n","                       [[[ 750601.8125]]],\n","               \n","               \n","                       [[[ 718930.5625]]],\n","               \n","               \n","                       [[[ 719134.6250]]],\n","               \n","               \n","                       [[[1401691.8750]]],\n","               \n","               \n","                       [[[ 770492.8125]]],\n","               \n","               \n","                       [[[ 998859.7500]]],\n","               \n","               \n","                       [[[1191959.3750]]],\n","               \n","               \n","                       [[[ 934800.7500]]],\n","               \n","               \n","                       [[[1135127.8750]]],\n","               \n","               \n","                       [[[1078338.8750]]],\n","               \n","               \n","                       [[[1728441.8750]]],\n","               \n","               \n","                       [[[ 764108.1875]]],\n","               \n","               \n","                       [[[ 879807.8125]]],\n","               \n","               \n","                       [[[ 994981.6875]]],\n","               \n","               \n","                       [[[1311224.7500]]],\n","               \n","               \n","                       [[[ 975690.1250]]],\n","               \n","               \n","                       [[[ 979294.3125]]],\n","               \n","               \n","                       [[[ 550623.8125]]],\n","               \n","               \n","                       [[[ 822245.1875]]],\n","               \n","               \n","                       [[[ 788990.5625]]],\n","               \n","               \n","                       [[[ 938981.3125]]],\n","               \n","               \n","                       [[[1570374.8750]]],\n","               \n","               \n","                       [[[1016098.5625]]],\n","               \n","               \n","                       [[[1063603.6250]]],\n","               \n","               \n","                       [[[1019741.8750]]],\n","               \n","               \n","                       [[[ 912194.4375]]],\n","               \n","               \n","                       [[[ 732740.2500]]],\n","               \n","               \n","                       [[[ 834676.4375]]],\n","               \n","               \n","                       [[[ 990483.5625]]],\n","               \n","               \n","                       [[[ 900457.8750]]],\n","               \n","               \n","                       [[[ 907708.1250]]],\n","               \n","               \n","                       [[[1075539.5000]]],\n","               \n","               \n","                       [[[ 798893.0000]]],\n","               \n","               \n","                       [[[1359840.7500]]],\n","               \n","               \n","                       [[[ 779572.9375]]],\n","               \n","               \n","                       [[[1102479.6250]]],\n","               \n","               \n","                       [[[1674557.0000]]],\n","               \n","               \n","                       [[[1048201.5000]]],\n","               \n","               \n","                       [[[1029687.9375]]],\n","               \n","               \n","                       [[[1128178.1250]]],\n","               \n","               \n","                       [[[ 748038.6250]]],\n","               \n","               \n","                       [[[1926932.3750]]],\n","               \n","               \n","                       [[[ 617780.2500]]],\n","               \n","               \n","                       [[[1213858.0000]]],\n","               \n","               \n","                       [[[1146750.1250]]],\n","               \n","               \n","                       [[[ 981585.1250]]],\n","               \n","               \n","                       [[[ 738410.2500]]],\n","               \n","               \n","                       [[[ 915940.4375]]],\n","               \n","               \n","                       [[[1286750.7500]]],\n","               \n","               \n","                       [[[1018154.0000]]],\n","               \n","               \n","                       [[[1325507.8750]]]], device='cuda:0')),\n","              ('module.layer3.3.conv1.w_zero_point', tensor([[[[-30662.]]],\n","               \n","               \n","                       [[[-31486.]]],\n","               \n","               \n","                       [[[-29804.]]],\n","               \n","               \n","                       [[[-34557.]]],\n","               \n","               \n","                       [[[-24368.]]],\n","               \n","               \n","                       [[[-31303.]]],\n","               \n","               \n","                       [[[-29829.]]],\n","               \n","               \n","                       [[[-26361.]]],\n","               \n","               \n","                       [[[-27502.]]],\n","               \n","               \n","                       [[[-27986.]]],\n","               \n","               \n","                       [[[-27393.]]],\n","               \n","               \n","                       [[[-22881.]]],\n","               \n","               \n","                       [[[-28787.]]],\n","               \n","               \n","                       [[[-28020.]]],\n","               \n","               \n","                       [[[-29117.]]],\n","               \n","               \n","                       [[[-28483.]]],\n","               \n","               \n","                       [[[-26643.]]],\n","               \n","               \n","                       [[[-32259.]]],\n","               \n","               \n","                       [[[-24988.]]],\n","               \n","               \n","                       [[[-24525.]]],\n","               \n","               \n","                       [[[-28435.]]],\n","               \n","               \n","                       [[[-30018.]]],\n","               \n","               \n","                       [[[-35338.]]],\n","               \n","               \n","                       [[[-30950.]]],\n","               \n","               \n","                       [[[-29438.]]],\n","               \n","               \n","                       [[[-31679.]]],\n","               \n","               \n","                       [[[-36833.]]],\n","               \n","               \n","                       [[[-33717.]]],\n","               \n","               \n","                       [[[-28524.]]],\n","               \n","               \n","                       [[[-31967.]]],\n","               \n","               \n","                       [[[-28261.]]],\n","               \n","               \n","                       [[[-34327.]]],\n","               \n","               \n","                       [[[-30712.]]],\n","               \n","               \n","                       [[[-30714.]]],\n","               \n","               \n","                       [[[-24077.]]],\n","               \n","               \n","                       [[[-23746.]]],\n","               \n","               \n","                       [[[-24058.]]],\n","               \n","               \n","                       [[[-31633.]]],\n","               \n","               \n","                       [[[-21865.]]],\n","               \n","               \n","                       [[[-26491.]]],\n","               \n","               \n","                       [[[-25389.]]],\n","               \n","               \n","                       [[[-31417.]]],\n","               \n","               \n","                       [[[-29074.]]],\n","               \n","               \n","                       [[[-34831.]]],\n","               \n","               \n","                       [[[-28923.]]],\n","               \n","               \n","                       [[[-22991.]]],\n","               \n","               \n","                       [[[-32332.]]],\n","               \n","               \n","                       [[[-31131.]]],\n","               \n","               \n","                       [[[-30616.]]],\n","               \n","               \n","                       [[[-27455.]]],\n","               \n","               \n","                       [[[-27993.]]],\n","               \n","               \n","                       [[[-35328.]]],\n","               \n","               \n","                       [[[-28249.]]],\n","               \n","               \n","                       [[[-39823.]]],\n","               \n","               \n","                       [[[-26350.]]],\n","               \n","               \n","                       [[[-28026.]]],\n","               \n","               \n","                       [[[-28590.]]],\n","               \n","               \n","                       [[[-22653.]]],\n","               \n","               \n","                       [[[-24247.]]],\n","               \n","               \n","                       [[[-30987.]]],\n","               \n","               \n","                       [[[-27942.]]],\n","               \n","               \n","                       [[[-35306.]]],\n","               \n","               \n","                       [[[-30591.]]],\n","               \n","               \n","                       [[[-30137.]]]], device='cuda:0')),\n","              ('module.layer3.3.conv1.fp_bias',\n","               tensor([-0.3682, -0.1407, -0.3667, -0.0442, -0.2503, -0.1010, -0.1762, -0.5606,\n","                       -0.0877, -0.1655, -0.2651, -0.5302, -0.2517, -0.4622, -0.2941, -0.2012,\n","                       -0.8060, -0.3055, -0.3999, -0.3193,  0.1920, -0.4377, -0.1739, -0.2451,\n","                       -0.0071, -0.3293,  0.5274, -0.1586, -0.2565, -0.0672, -0.0563, -0.0676,\n","                        0.1023, -0.1386, -0.1668, -0.5481, -0.5388, -0.3834, -0.0365, -0.3284,\n","                       -0.2257, -0.0228, -0.1626, -0.0223, -0.3858, -0.3569, -0.2117,  0.0460,\n","                       -0.4867, -0.0238, -0.1591,  0.0179, -0.3352, -0.1401,  0.0024,  0.2392,\n","                        0.0132, -0.1945,  0.0391, -0.0319, -0.4206,  0.1600, -0.3570, -0.3280],\n","                      device='cuda:0')),\n","              ('module.layer3.3.conv1.accum_scale', tensor([[[7.8680e+09]],\n","               \n","                       [[7.7165e+09]],\n","               \n","                       [[8.8670e+09]],\n","               \n","                       [[6.4083e+09]],\n","               \n","                       [[5.7830e+09]],\n","               \n","                       [[8.1800e+09]],\n","               \n","                       [[9.0739e+09]],\n","               \n","                       [[6.5657e+09]],\n","               \n","                       [[7.2848e+09]],\n","               \n","                       [[9.1337e+09]],\n","               \n","                       [[1.0416e+10]],\n","               \n","                       [[1.2247e+10]],\n","               \n","                       [[7.9641e+09]],\n","               \n","                       [[6.2490e+09]],\n","               \n","                       [[5.9853e+09]],\n","               \n","                       [[5.9870e+09]],\n","               \n","                       [[1.1670e+10]],\n","               \n","                       [[6.4146e+09]],\n","               \n","                       [[8.3158e+09]],\n","               \n","                       [[9.9234e+09]],\n","               \n","                       [[7.7825e+09]],\n","               \n","                       [[9.4503e+09]],\n","               \n","                       [[8.9775e+09]],\n","               \n","                       [[1.4390e+10]],\n","               \n","                       [[6.3614e+09]],\n","               \n","                       [[7.3247e+09]],\n","               \n","                       [[8.2835e+09]],\n","               \n","                       [[1.0916e+10]],\n","               \n","                       [[8.1229e+09]],\n","               \n","                       [[8.1529e+09]],\n","               \n","                       [[4.5841e+09]],\n","               \n","                       [[6.8455e+09]],\n","               \n","                       [[6.5686e+09]],\n","               \n","                       [[7.8173e+09]],\n","               \n","                       [[1.3074e+10]],\n","               \n","                       [[8.4594e+09]],\n","               \n","                       [[8.8548e+09]],\n","               \n","                       [[8.4897e+09]],\n","               \n","                       [[7.5943e+09]],\n","               \n","                       [[6.1003e+09]],\n","               \n","                       [[6.9490e+09]],\n","               \n","                       [[8.2461e+09]],\n","               \n","                       [[7.4966e+09]],\n","               \n","                       [[7.5570e+09]],\n","               \n","                       [[8.9542e+09]],\n","               \n","                       [[6.6510e+09]],\n","               \n","                       [[1.1321e+10]],\n","               \n","                       [[6.4902e+09]],\n","               \n","                       [[9.1785e+09]],\n","               \n","                       [[1.3941e+10]],\n","               \n","                       [[8.7266e+09]],\n","               \n","                       [[8.5725e+09]],\n","               \n","                       [[9.3924e+09]],\n","               \n","                       [[6.2277e+09]],\n","               \n","                       [[1.6042e+10]],\n","               \n","                       [[5.1432e+09]],\n","               \n","                       [[1.0106e+10]],\n","               \n","                       [[9.5471e+09]],\n","               \n","                       [[8.1720e+09]],\n","               \n","                       [[6.1475e+09]],\n","               \n","                       [[7.6255e+09]],\n","               \n","                       [[1.0713e+10]],\n","               \n","                       [[8.4765e+09]],\n","               \n","                       [[1.1035e+10]]], device='cuda:0')),\n","              ('module.layer3.3.conv1.is_simulated_quant_weight_shifted',\n","               tensor(False, device='cuda:0')),\n","              ('module.layer3.3.conv1.wrapped_module.weight',\n","               tensor([[[[45056., 29613., 33075.],\n","                         [33727., 16550., 18905.],\n","                         [21728., 18047., 28843.]],\n","               \n","                        [[35886., 39482., 35681.],\n","                         [29567., 40857., 39469.],\n","                         [29584., 30247., 30817.]],\n","               \n","                        [[25056., 32715., 32885.],\n","                         [30351., 34456., 37661.],\n","                         [37491., 27938., 36310.]],\n","               \n","                        ...,\n","               \n","                        [[28247., 32963., 35772.],\n","                         [25023., 31569., 36854.],\n","                         [25337., 30040., 33333.]],\n","               \n","                        [[29153., 20596., 24474.],\n","                         [34634., 30485., 31896.],\n","                         [45029., 38200., 35091.]],\n","               \n","                        [[40561., 32894., 33446.],\n","                         [36182., 39102., 28006.],\n","                         [37864., 37011., 32983.]]],\n","               \n","               \n","                       [[[39215., 42114., 26866.],\n","                         [23019., 35480., 19654.],\n","                         [16566., 31005., 21016.]],\n","               \n","                        [[31211., 31088., 40451.],\n","                         [36805., 32107., 27378.],\n","                         [36356., 33993., 18767.]],\n","               \n","                        [[28147., 34656., 37096.],\n","                         [15897.,  7376., 27565.],\n","                         [16820., 13690., 33353.]],\n","               \n","                        ...,\n","               \n","                        [[31104., 28674., 31289.],\n","                         [30290., 26851., 27315.],\n","                         [28873., 29465., 29402.]],\n","               \n","                        [[25360., 37840., 53532.],\n","                         [21769., 20480., 47735.],\n","                         [44816., 42841., 42084.]],\n","               \n","                        [[30550., 20801., 19243.],\n","                         [26460., 23729., 11595.],\n","                         [30448., 30295., 19415.]]],\n","               \n","               \n","                       [[[23403., 24484.,  5728.],\n","                         [26294., 23047., 17395.],\n","                         [52138., 24322., 43063.]],\n","               \n","                        [[36564., 36740., 32419.],\n","                         [29075., 30995., 37355.],\n","                         [30340., 36585., 31789.]],\n","               \n","                        [[39934., 29916., 11303.],\n","                         [35169., 32768., 19083.],\n","                         [29544., 24501., 18045.]],\n","               \n","                        ...,\n","               \n","                        [[30752., 28192., 29765.],\n","                         [32225., 27853., 32371.],\n","                         [35858., 34575., 35022.]],\n","               \n","                        [[10841., 31016., 40691.],\n","                         [ 8029., 35306., 50732.],\n","                         [28577., 46656., 46559.]],\n","               \n","                        [[10021., 10855., 28878.],\n","                         [19975., 20310., 32379.],\n","                         [58381., 56582., 42060.]]],\n","               \n","               \n","                       ...,\n","               \n","               \n","                       [[[17552., 26740., 24608.],\n","                         [18148., 26325., 29879.],\n","                         [42715., 32519., 37577.]],\n","               \n","                        [[35139., 33077., 39624.],\n","                         [36403., 27479., 29868.],\n","                         [34946., 27642., 28805.]],\n","               \n","                        [[52248., 39541., 48132.],\n","                         [44421., 39305., 41552.],\n","                         [33281., 41838., 49173.]],\n","               \n","                        ...,\n","               \n","                        [[33517., 31106., 29067.],\n","                         [38088., 37033., 35762.],\n","                         [34585., 31676., 32281.]],\n","               \n","                        [[27840., 28327., 31080.],\n","                         [32200., 18688., 25114.],\n","                         [45920., 21670., 22507.]],\n","               \n","                        [[41691., 19406., 18965.],\n","                         [41679., 14453., 27599.],\n","                         [44355., 28219., 45978.]]],\n","               \n","               \n","                       [[[20639., 28443., 36636.],\n","                         [ 7130., 22132., 37143.],\n","                         [ 6392., 22529., 34539.]],\n","               \n","                        [[22282., 20006., 21065.],\n","                         [35438., 26915., 22700.],\n","                         [30297., 35466., 36210.]],\n","               \n","                        [[27262., 29866., 18596.],\n","                         [43928., 50150., 44632.],\n","                         [65535., 57941., 47746.]],\n","               \n","                        ...,\n","               \n","                        [[35809., 27542., 26302.],\n","                         [41882., 33191., 25816.],\n","                         [37884., 29669., 21401.]],\n","               \n","                        [[47145., 36914., 30716.],\n","                         [45948., 34418., 33554.],\n","                         [38454., 26967., 31909.]],\n","               \n","                        [[50043., 34848., 26319.],\n","                         [57821., 28426., 31193.],\n","                         [33735., 40558., 46580.]]],\n","               \n","               \n","                       [[[16574., 18776., 16263.],\n","                         [20465., 23521., 38813.],\n","                         [24217., 13487., 32682.]],\n","               \n","                        [[34245., 24303., 22529.],\n","                         [47497., 42550., 30638.],\n","                         [42884., 36470., 31517.]],\n","               \n","                        [[38764., 24065., 20258.],\n","                         [24601., 38534., 38447.],\n","                         [31906., 28084., 26607.]],\n","               \n","                        ...,\n","               \n","                        [[30935., 33479., 33329.],\n","                         [27052., 24814., 25358.],\n","                         [28040., 29325., 27017.]],\n","               \n","                        [[29805., 26474., 26107.],\n","                         [23277., 17091., 20522.],\n","                         [40098., 38026., 22840.]],\n","               \n","                        [[42516., 35939., 29271.],\n","                         [41156., 50846., 32466.],\n","                         [36147., 35711., 40684.]]]], device='cuda:0')),\n","              ('module.layer3.3.conv1.wrapped_module.bias',\n","               tensor([-2.1475e+09, -1.0853e+09, -2.1475e+09, -2.8308e+08, -1.4473e+09,\n","                       -8.2619e+08, -1.5988e+09, -2.1475e+09, -6.3882e+08, -1.5113e+09,\n","                       -2.1475e+09, -2.1475e+09, -2.0047e+09, -2.1475e+09, -1.7603e+09,\n","                       -1.2047e+09, -2.1475e+09, -1.9597e+09, -2.1475e+09, -2.1475e+09,\n","                        1.4939e+09, -2.1475e+09, -1.5609e+09, -2.1475e+09, -4.5297e+07,\n","                       -2.1475e+09,  2.1475e+09, -1.7310e+09, -2.0834e+09, -5.4765e+08,\n","                       -2.5801e+08, -4.6251e+08,  6.7195e+08, -1.0833e+09, -2.1475e+09,\n","                       -2.1475e+09, -2.1475e+09, -2.1475e+09, -2.7737e+08, -2.0033e+09,\n","                       -1.5684e+09, -1.8838e+08, -1.2187e+09, -1.6815e+08, -2.1475e+09,\n","                       -2.1475e+09, -2.1475e+09,  2.9866e+08, -2.1475e+09, -3.3133e+08,\n","                       -1.3886e+09,  1.5381e+08, -2.1475e+09, -8.7265e+08,  3.8462e+07,\n","                        1.2300e+09,  1.3375e+08, -1.8570e+09,  3.1982e+08, -1.9595e+08,\n","                       -2.1475e+09,  1.7136e+09, -2.1475e+09, -2.1475e+09], device='cuda:0')),\n","              ('module.layer3.3.conv2.num_forwards',\n","               tensor([40], device='cuda:0')),\n","              ('module.layer3.3.conv2.force_readjust',\n","               tensor(False, device='cuda:0')),\n","              ('module.layer3.3.conv2.output_scale',\n","               tensor([12194.5654], device='cuda:0')),\n","              ('module.layer3.3.conv2.output_zero_point',\n","               tensor([-35587.], device='cuda:0')),\n","              ('module.layer3.3.conv2.w_scale', tensor([[[[  38518.8594]]],\n","               \n","               \n","                       [[[  90614.9844]]],\n","               \n","               \n","                       [[[  82234.5312]]],\n","               \n","               \n","                       [[[  38713.7266]]],\n","               \n","               \n","                       [[[ 110179.9375]]],\n","               \n","               \n","                       [[[  80099.1719]]],\n","               \n","               \n","                       [[[  70693.1875]]],\n","               \n","               \n","                       [[[ 117334.7188]]],\n","               \n","               \n","                       [[[  64340.8711]]],\n","               \n","               \n","                       [[[  62959.1328]]],\n","               \n","               \n","                       [[[  95715.6406]]],\n","               \n","               \n","                       [[[  33669.3438]]],\n","               \n","               \n","                       [[[  76413.4844]]],\n","               \n","               \n","                       [[[  63764.6055]]],\n","               \n","               \n","                       [[[  69685.4453]]],\n","               \n","               \n","                       [[[ 143481.5625]]],\n","               \n","               \n","                       [[[  45980.1953]]],\n","               \n","               \n","                       [[[ 103796.7812]]],\n","               \n","               \n","                       [[[ 108365.5859]]],\n","               \n","               \n","                       [[[ 110453.2188]]],\n","               \n","               \n","                       [[[  95710.0469]]],\n","               \n","               \n","                       [[[ 672128.1875]]],\n","               \n","               \n","                       [[[  86961.1562]]],\n","               \n","               \n","                       [[[  83722.2344]]],\n","               \n","               \n","                       [[[ 173550.0625]]],\n","               \n","               \n","                       [[[ 157733.0156]]],\n","               \n","               \n","                       [[[  77601.0469]]],\n","               \n","               \n","                       [[[ 105492.9453]]],\n","               \n","               \n","                       [[[ 138673.0312]]],\n","               \n","               \n","                       [[[  79064.1328]]],\n","               \n","               \n","                       [[[  95074.3281]]],\n","               \n","               \n","                       [[[  64521.3320]]],\n","               \n","               \n","                       [[[ 129286.9922]]],\n","               \n","               \n","                       [[[ 134206.8281]]],\n","               \n","               \n","                       [[[  66991.5391]]],\n","               \n","               \n","                       [[[  57110.0898]]],\n","               \n","               \n","                       [[[ 109570.0000]]],\n","               \n","               \n","                       [[[  65361.7695]]],\n","               \n","               \n","                       [[[  48028.7070]]],\n","               \n","               \n","                       [[[  57977.0195]]],\n","               \n","               \n","                       [[[  99868.3281]]],\n","               \n","               \n","                       [[[  70643.2969]]],\n","               \n","               \n","                       [[[ 494046.4062]]],\n","               \n","               \n","                       [[[ 134352.8906]]],\n","               \n","               \n","                       [[[ 256466.7500]]],\n","               \n","               \n","                       [[[  94553.1094]]],\n","               \n","               \n","                       [[[8464545.0000]]],\n","               \n","               \n","                       [[[ 398516.9375]]],\n","               \n","               \n","                       [[[  78287.0000]]],\n","               \n","               \n","                       [[[ 309374.4062]]],\n","               \n","               \n","                       [[[  41792.2930]]],\n","               \n","               \n","                       [[[ 119451.5078]]],\n","               \n","               \n","                       [[[  86737.0859]]],\n","               \n","               \n","                       [[[ 111055.9766]]],\n","               \n","               \n","                       [[[ 179950.6094]]],\n","               \n","               \n","                       [[[ 121486.2891]]],\n","               \n","               \n","                       [[[ 150043.8750]]],\n","               \n","               \n","                       [[[  70014.9375]]],\n","               \n","               \n","                       [[[  49174.6719]]],\n","               \n","               \n","                       [[[  59283.8164]]],\n","               \n","               \n","                       [[[  70273.2812]]],\n","               \n","               \n","                       [[[ 158384.8281]]],\n","               \n","               \n","                       [[[ 102646.6719]]],\n","               \n","               \n","                       [[[ 418094.0312]]]], device='cuda:0')),\n","              ('module.layer3.3.conv2.w_zero_point', tensor([[[[-37140.]]],\n","               \n","               \n","                       [[[-29760.]]],\n","               \n","               \n","                       [[[-34700.]]],\n","               \n","               \n","                       [[[-26828.]]],\n","               \n","               \n","                       [[[-36178.]]],\n","               \n","               \n","                       [[[-30832.]]],\n","               \n","               \n","                       [[[-26015.]]],\n","               \n","               \n","                       [[[-29495.]]],\n","               \n","               \n","                       [[[-29625.]]],\n","               \n","               \n","                       [[[-25916.]]],\n","               \n","               \n","                       [[[-37818.]]],\n","               \n","               \n","                       [[[-19958.]]],\n","               \n","               \n","                       [[[-32749.]]],\n","               \n","               \n","                       [[[-24921.]]],\n","               \n","               \n","                       [[[-30588.]]],\n","               \n","               \n","                       [[[-32941.]]],\n","               \n","               \n","                       [[[-30323.]]],\n","               \n","               \n","                       [[[-27967.]]],\n","               \n","               \n","                       [[[-33507.]]],\n","               \n","               \n","                       [[[-28786.]]],\n","               \n","               \n","                       [[[-40313.]]],\n","               \n","               \n","                       [[[-35221.]]],\n","               \n","               \n","                       [[[-36091.]]],\n","               \n","               \n","                       [[[-32686.]]],\n","               \n","               \n","                       [[[-34661.]]],\n","               \n","               \n","                       [[[-36142.]]],\n","               \n","               \n","                       [[[-37686.]]],\n","               \n","               \n","                       [[[-30201.]]],\n","               \n","               \n","                       [[[-33461.]]],\n","               \n","               \n","                       [[[-31800.]]],\n","               \n","               \n","                       [[[-31342.]]],\n","               \n","               \n","                       [[[-30930.]]],\n","               \n","               \n","                       [[[-30635.]]],\n","               \n","               \n","                       [[[-33330.]]],\n","               \n","               \n","                       [[[-28847.]]],\n","               \n","               \n","                       [[[-21653.]]],\n","               \n","               \n","                       [[[-31884.]]],\n","               \n","               \n","                       [[[-27615.]]],\n","               \n","               \n","                       [[[-33571.]]],\n","               \n","               \n","                       [[[-32448.]]],\n","               \n","               \n","                       [[[-37611.]]],\n","               \n","               \n","                       [[[-33910.]]],\n","               \n","               \n","                       [[[-40249.]]],\n","               \n","               \n","                       [[[-41161.]]],\n","               \n","               \n","                       [[[-25635.]]],\n","               \n","               \n","                       [[[-31798.]]],\n","               \n","               \n","                       [[[-36156.]]],\n","               \n","               \n","                       [[[-37535.]]],\n","               \n","               \n","                       [[[-32393.]]],\n","               \n","               \n","                       [[[-33550.]]],\n","               \n","               \n","                       [[[-30820.]]],\n","               \n","               \n","                       [[[-28958.]]],\n","               \n","               \n","                       [[[-32249.]]],\n","               \n","               \n","                       [[[-30681.]]],\n","               \n","               \n","                       [[[-31349.]]],\n","               \n","               \n","                       [[[-39014.]]],\n","               \n","               \n","                       [[[-33462.]]],\n","               \n","               \n","                       [[[-30318.]]],\n","               \n","               \n","                       [[[-26175.]]],\n","               \n","               \n","                       [[[-25045.]]],\n","               \n","               \n","                       [[[-29367.]]],\n","               \n","               \n","                       [[[-29263.]]],\n","               \n","               \n","                       [[[-28758.]]],\n","               \n","               \n","                       [[[-33321.]]]], device='cuda:0')),\n","              ('module.layer3.3.conv2.fp_bias',\n","               tensor([-0.4332, -0.1276,  0.4311,  0.3234,  0.0409,  0.0595, -0.0275, -0.0249,\n","                        0.1238,  0.4257,  0.1737, -0.3459,  0.0529,  0.2112, -0.4575,  0.0386,\n","                       -0.1484,  0.0623, -0.1164, -0.1051,  0.0131, -0.0384, -0.1161,  0.0799,\n","                       -0.0075,  0.1208,  0.2637, -0.0861, -0.1664, -0.0246, -0.1371, -0.0197,\n","                       -0.1343, -0.2693,  0.3239, -0.2847, -0.0511,  0.0513,  0.2001,  0.0482,\n","                        0.0567, -0.0392, -0.1193,  0.4102,  0.0453,  0.1830, -0.0089, -0.0770,\n","                       -0.1311,  0.0545,  0.7579,  0.1150,  0.0031, -0.1330, -0.0098,  0.0432,\n","                        0.2441, -0.4763, -0.3627,  0.0403, -0.0305, -0.1679, -0.0449,  0.0616],\n","                      device='cuda:0')),\n","              ('module.layer3.3.conv2.accum_scale', tensor([[[2.2099e+09]],\n","               \n","                       [[5.1987e+09]],\n","               \n","                       [[4.7179e+09]],\n","               \n","                       [[2.2211e+09]],\n","               \n","                       [[6.3212e+09]],\n","               \n","                       [[4.5954e+09]],\n","               \n","                       [[4.0558e+09]],\n","               \n","                       [[6.7317e+09]],\n","               \n","                       [[3.6913e+09]],\n","               \n","                       [[3.6121e+09]],\n","               \n","                       [[5.4913e+09]],\n","               \n","                       [[1.9317e+09]],\n","               \n","                       [[4.3839e+09]],\n","               \n","                       [[3.6583e+09]],\n","               \n","                       [[3.9980e+09]],\n","               \n","                       [[8.2317e+09]],\n","               \n","                       [[2.6379e+09]],\n","               \n","                       [[5.9550e+09]],\n","               \n","                       [[6.2171e+09]],\n","               \n","                       [[6.3369e+09]],\n","               \n","                       [[5.4910e+09]],\n","               \n","                       [[3.8561e+10]],\n","               \n","                       [[4.9891e+09]],\n","               \n","                       [[4.8033e+09]],\n","               \n","                       [[9.9568e+09]],\n","               \n","                       [[9.0494e+09]],\n","               \n","                       [[4.4521e+09]],\n","               \n","                       [[6.0523e+09]],\n","               \n","                       [[7.9559e+09]],\n","               \n","                       [[4.5360e+09]],\n","               \n","                       [[5.4545e+09]],\n","               \n","                       [[3.7017e+09]],\n","               \n","                       [[7.4174e+09]],\n","               \n","                       [[7.6996e+09]],\n","               \n","                       [[3.8434e+09]],\n","               \n","                       [[3.2765e+09]],\n","               \n","                       [[6.2862e+09]],\n","               \n","                       [[3.7499e+09]],\n","               \n","                       [[2.7555e+09]],\n","               \n","                       [[3.3262e+09]],\n","               \n","                       [[5.7296e+09]],\n","               \n","                       [[4.0529e+09]],\n","               \n","                       [[2.8344e+10]],\n","               \n","                       [[7.7080e+09]],\n","               \n","                       [[1.4714e+10]],\n","               \n","                       [[5.4246e+09]],\n","               \n","                       [[4.8562e+11]],\n","               \n","                       [[2.2863e+10]],\n","               \n","                       [[4.4914e+09]],\n","               \n","                       [[1.7749e+10]],\n","               \n","                       [[2.3977e+09]],\n","               \n","                       [[6.8531e+09]],\n","               \n","                       [[4.9762e+09]],\n","               \n","                       [[6.3714e+09]],\n","               \n","                       [[1.0324e+10]],\n","               \n","                       [[6.9698e+09]],\n","               \n","                       [[8.6082e+09]],\n","               \n","                       [[4.0169e+09]],\n","               \n","                       [[2.8212e+09]],\n","               \n","                       [[3.4012e+09]],\n","               \n","                       [[4.0317e+09]],\n","               \n","                       [[9.0868e+09]],\n","               \n","                       [[5.8890e+09]],\n","               \n","                       [[2.3987e+10]]], device='cuda:0')),\n","              ('module.layer3.3.conv2.is_simulated_quant_weight_shifted',\n","               tensor(False, device='cuda:0')),\n","              ('module.layer3.3.conv2.wrapped_module.weight',\n","               tensor([[[[41581., 33227., 23752.],\n","                         [38327., 31853., 33360.],\n","                         [23131., 25560., 34590.]],\n","               \n","                        [[43955., 40896., 33336.],\n","                         [28664., 28256., 26443.],\n","                         [34238., 27419., 26182.]],\n","               \n","                        [[56803., 52048., 36896.],\n","                         [38239., 40254., 38569.],\n","                         [25046., 35929., 40915.]],\n","               \n","                        ...,\n","               \n","                        [[29417., 31701., 35444.],\n","                         [36134., 37101., 35274.],\n","                         [35824., 35788., 32664.]],\n","               \n","                        [[29957., 34766., 41216.],\n","                         [36572., 35691., 38441.],\n","                         [36986., 30854., 30147.]],\n","               \n","                        [[41220., 33828., 31143.],\n","                         [34634., 26953., 29907.],\n","                         [35746., 32498., 30015.]]],\n","               \n","               \n","                       [[[25848., 17694., 19782.],\n","                         [32484., 29191., 27879.],\n","                         [28106., 33987., 47313.]],\n","               \n","                        [[19523., 15593., 23735.],\n","                         [19424., 22561., 26132.],\n","                         [14883., 28205., 37160.]],\n","               \n","                        [[24064., 25056., 28637.],\n","                         [49260., 32886., 22731.],\n","                         [31703.,  7885.,  9525.]],\n","               \n","                        ...,\n","               \n","                        [[28756., 27917., 22425.],\n","                         [24942., 22858., 18241.],\n","                         [24078., 20556., 24201.]],\n","               \n","                        [[29063., 31518., 23383.],\n","                         [22051., 31145., 33767.],\n","                         [10288., 13789., 32616.]],\n","               \n","                        [[43150., 38510., 34168.],\n","                         [36785., 43384., 39245.],\n","                         [30285., 23561., 22947.]]],\n","               \n","               \n","                       [[[30741., 34373., 28673.],\n","                         [31656., 31500., 35986.],\n","                         [30434., 30060., 35885.]],\n","               \n","                        [[47587., 32576., 28403.],\n","                         [47001., 35701., 34673.],\n","                         [42345., 29591., 35629.]],\n","               \n","                        [[59946., 25744., 20232.],\n","                         [36118., 17354., 19267.],\n","                         [34066., 24897., 18754.]],\n","               \n","                        ...,\n","               \n","                        [[20038., 17099., 17117.],\n","                         [22802., 25734.,  7278.],\n","                         [31530., 28934., 24171.]],\n","               \n","                        [[11442., 21787., 17216.],\n","                         [22552., 18882., 10522.],\n","                         [33079., 28729., 29867.]],\n","               \n","                        [[33266., 27734., 25954.],\n","                         [23006., 23665., 31927.],\n","                         [15277., 22257., 27958.]]],\n","               \n","               \n","                       ...,\n","               \n","               \n","                       [[[13175.,  4961., 13693.],\n","                         [21726., 11590., 18233.],\n","                         [15974., 17984., 28245.]],\n","               \n","                        [[28264., 24474., 24559.],\n","                         [14789., 25648., 28352.],\n","                         [21352., 37397., 33170.]],\n","               \n","                        [[31509., 25713., 28354.],\n","                         [47225., 28951., 29175.],\n","                         [31472., 31768., 19075.]],\n","               \n","                        ...,\n","               \n","                        [[28787., 18595., 16750.],\n","                         [27030., 29295., 24571.],\n","                         [28803., 33013., 32199.]],\n","               \n","                        [[31539., 36317., 28057.],\n","                         [22196., 45897., 54333.],\n","                         [23555., 41599., 53482.]],\n","               \n","                        [[28509., 10343.,  8344.],\n","                         [29357., 19152., 25753.],\n","                         [30261., 25924., 36129.]]],\n","               \n","               \n","                       [[[40857., 38896., 37830.],\n","                         [29518., 23009., 30463.],\n","                         [32894., 28406., 41021.]],\n","               \n","                        [[33940., 15856., 25542.],\n","                         [33589., 33415., 36064.],\n","                         [22666., 28104., 28706.]],\n","               \n","                        [[26350., 23850., 18684.],\n","                         [39534., 38624., 19341.],\n","                         [26627., 31904., 25475.]],\n","               \n","                        ...,\n","               \n","                        [[15983., 19210., 28479.],\n","                         [26422., 23133., 33122.],\n","                         [30058., 27082., 27259.]],\n","               \n","                        [[ 8934.,  9769., 11276.],\n","                         [11926.,  5024., 20214.],\n","                         [13651.,  8635., 23454.]],\n","               \n","                        [[12923., 34091., 34388.],\n","                         [12079., 17296., 18090.],\n","                         [20612., 19038., 24151.]]],\n","               \n","               \n","                       [[[26620., 32781., 54653.],\n","                         [27874., 24014., 28321.],\n","                         [24423., 24130., 21317.]],\n","               \n","                        [[23046., 17453., 28192.],\n","                         [37189., 20348., 22358.],\n","                         [38463., 11465., 12720.]],\n","               \n","                        [[29863., 20937., 27811.],\n","                         [23780.,  7670.,  5011.],\n","                         [40210., 10506., 20605.]],\n","               \n","                        ...,\n","               \n","                        [[31580., 10999., 12210.],\n","                         [28797., 27718., 40895.],\n","                         [29598., 35308., 40617.]],\n","               \n","                        [[32953., 20773., 25617.],\n","                         [40281., 33502., 34138.],\n","                         [30332., 30958., 37011.]],\n","               \n","                        [[24245., 30587., 31337.],\n","                         [21275., 38073., 34287.],\n","                         [23503., 31437., 31202.]]]], device='cuda:0')),\n","              ('module.layer3.3.conv2.wrapped_module.bias',\n","               tensor([-9.5741e+08, -6.6325e+08,  2.0339e+09,  7.1839e+08,  2.5876e+08,\n","                        2.7343e+08, -1.1154e+08, -1.6755e+08,  4.5698e+08,  1.5376e+09,\n","                        9.5367e+08, -6.6823e+08,  2.3173e+08,  7.7262e+08, -1.8291e+09,\n","                        3.1792e+08, -3.9142e+08,  3.7126e+08, -7.2392e+08, -6.6623e+08,\n","                        7.1831e+07, -1.4822e+09, -5.7913e+08,  3.8368e+08, -7.4783e+07,\n","                        1.0931e+09,  1.1742e+09, -5.2098e+08, -1.3240e+09, -1.1177e+08,\n","                       -7.4761e+08, -7.3033e+07, -9.9618e+08, -2.0736e+09,  1.2447e+09,\n","                       -9.3280e+08, -3.2142e+08,  1.9236e+08,  5.5151e+08,  1.6038e+08,\n","                        3.2509e+08, -1.5883e+08, -2.1475e+09,  2.1475e+09,  6.6626e+08,\n","                        9.9244e+08, -2.1475e+09, -1.7615e+09, -5.8882e+08,  9.6811e+08,\n","                        1.8172e+09,  7.8782e+08,  1.5231e+07, -8.4736e+08, -1.0148e+08,\n","                        3.0122e+08,  2.1017e+09, -1.9131e+09, -1.0231e+09,  1.3716e+08,\n","                       -1.2311e+08, -1.5257e+09, -2.6421e+08,  1.4774e+09], device='cuda:0')),\n","              ('module.layer3.3.relu2.num_forwards',\n","               tensor([40], device='cuda:0')),\n","              ('module.layer3.3.relu2.force_readjust',\n","               tensor(False, device='cuda:0')),\n","              ('module.layer3.3.relu2.output_scale',\n","               tensor([7623.4497], device='cuda:0')),\n","              ('module.layer3.3.relu2.output_zero_point',\n","               tensor([0.], device='cuda:0')),\n","              ('module.layer3.3.residual_eltwiseadd.num_forwards',\n","               tensor([40], device='cuda:0')),\n","              ('module.layer3.3.residual_eltwiseadd.force_readjust',\n","               tensor(False, device='cuda:0')),\n","              ('module.layer3.3.residual_eltwiseadd.output_scale',\n","               tensor([7623.4497], device='cuda:0')),\n","              ('module.layer3.3.residual_eltwiseadd.output_zero_point',\n","               tensor([0.], device='cuda:0')),\n","              ('module.layer3.4.conv1.num_forwards',\n","               tensor([40], device='cuda:0')),\n","              ('module.layer3.4.conv1.force_readjust',\n","               tensor(False, device='cuda:0')),\n","              ('module.layer3.4.conv1.output_scale',\n","               tensor([57618.2812], device='cuda:0')),\n","              ('module.layer3.4.conv1.output_zero_point',\n","               tensor([0.], device='cuda:0')),\n","              ('module.layer3.4.conv1.w_scale', tensor([[[[ 899478.1250]]],\n","               \n","               \n","                       [[[ 942820.5000]]],\n","               \n","               \n","                       [[[ 835924.9375]]],\n","               \n","               \n","                       [[[ 683907.5000]]],\n","               \n","               \n","                       [[[ 941636.8125]]],\n","               \n","               \n","                       [[[1204519.0000]]],\n","               \n","               \n","                       [[[ 616736.0000]]],\n","               \n","               \n","                       [[[ 804441.1250]]],\n","               \n","               \n","                       [[[2215623.2500]]],\n","               \n","               \n","                       [[[1014674.8750]]],\n","               \n","               \n","                       [[[1253970.3750]]],\n","               \n","               \n","                       [[[1452653.0000]]],\n","               \n","               \n","                       [[[ 918624.9375]]],\n","               \n","               \n","                       [[[ 636080.1250]]],\n","               \n","               \n","                       [[[1014480.6250]]],\n","               \n","               \n","                       [[[ 948310.8125]]],\n","               \n","               \n","                       [[[ 712872.7500]]],\n","               \n","               \n","                       [[[ 833186.5625]]],\n","               \n","               \n","                       [[[ 869898.3750]]],\n","               \n","               \n","                       [[[ 721912.2500]]],\n","               \n","               \n","                       [[[ 797166.4375]]],\n","               \n","               \n","                       [[[ 775467.1250]]],\n","               \n","               \n","                       [[[ 766475.0625]]],\n","               \n","               \n","                       [[[1054670.6250]]],\n","               \n","               \n","                       [[[ 826191.1875]]],\n","               \n","               \n","                       [[[ 690753.3750]]],\n","               \n","               \n","                       [[[1114844.7500]]],\n","               \n","               \n","                       [[[ 921206.1250]]],\n","               \n","               \n","                       [[[ 600150.2500]]],\n","               \n","               \n","                       [[[ 959418.4375]]],\n","               \n","               \n","                       [[[ 685628.0000]]],\n","               \n","               \n","                       [[[ 744992.3125]]],\n","               \n","               \n","                       [[[ 854486.1875]]],\n","               \n","               \n","                       [[[ 927652.5625]]],\n","               \n","               \n","                       [[[1278119.7500]]],\n","               \n","               \n","                       [[[ 949451.5625]]],\n","               \n","               \n","                       [[[ 874065.8750]]],\n","               \n","               \n","                       [[[ 759220.4375]]],\n","               \n","               \n","                       [[[1039637.3125]]],\n","               \n","               \n","                       [[[ 784167.5000]]],\n","               \n","               \n","                       [[[1167358.6250]]],\n","               \n","               \n","                       [[[ 740222.6250]]],\n","               \n","               \n","                       [[[1015443.7500]]],\n","               \n","               \n","                       [[[1391790.7500]]],\n","               \n","               \n","                       [[[1228219.2500]]],\n","               \n","               \n","                       [[[ 840642.0625]]],\n","               \n","               \n","                       [[[ 817664.2500]]],\n","               \n","               \n","                       [[[ 954682.0000]]],\n","               \n","               \n","                       [[[1188634.3750]]],\n","               \n","               \n","                       [[[1169355.1250]]],\n","               \n","               \n","                       [[[3473783.5000]]],\n","               \n","               \n","                       [[[1185309.2500]]],\n","               \n","               \n","                       [[[1073237.0000]]],\n","               \n","               \n","                       [[[1334330.7500]]],\n","               \n","               \n","                       [[[1161484.2500]]],\n","               \n","               \n","                       [[[ 983445.8750]]],\n","               \n","               \n","                       [[[ 959217.4375]]],\n","               \n","               \n","                       [[[1163298.7500]]],\n","               \n","               \n","                       [[[ 675064.2500]]],\n","               \n","               \n","                       [[[1360542.0000]]],\n","               \n","               \n","                       [[[ 924491.3750]]],\n","               \n","               \n","                       [[[1216653.3750]]],\n","               \n","               \n","                       [[[ 917695.8750]]],\n","               \n","               \n","                       [[[ 979414.1250]]]], device='cuda:0')),\n","              ('module.layer3.4.conv1.w_zero_point', tensor([[[[-29292.]]],\n","               \n","               \n","                       [[[-29055.]]],\n","               \n","               \n","                       [[[-32409.]]],\n","               \n","               \n","                       [[[-30528.]]],\n","               \n","               \n","                       [[[-28165.]]],\n","               \n","               \n","                       [[[-33098.]]],\n","               \n","               \n","                       [[[-24432.]]],\n","               \n","               \n","                       [[[-31714.]]],\n","               \n","               \n","                       [[[-30903.]]],\n","               \n","               \n","                       [[[-31440.]]],\n","               \n","               \n","                       [[[-30284.]]],\n","               \n","               \n","                       [[[-24235.]]],\n","               \n","               \n","                       [[[-32530.]]],\n","               \n","               \n","                       [[[-32761.]]],\n","               \n","               \n","                       [[[-30247.]]],\n","               \n","               \n","                       [[[-33594.]]],\n","               \n","               \n","                       [[[-31369.]]],\n","               \n","               \n","                       [[[-30544.]]],\n","               \n","               \n","                       [[[-30893.]]],\n","               \n","               \n","                       [[[-34845.]]],\n","               \n","               \n","                       [[[-35238.]]],\n","               \n","               \n","                       [[[-29155.]]],\n","               \n","               \n","                       [[[-28748.]]],\n","               \n","               \n","                       [[[-25179.]]],\n","               \n","               \n","                       [[[-24368.]]],\n","               \n","               \n","                       [[[-32876.]]],\n","               \n","               \n","                       [[[-29456.]]],\n","               \n","               \n","                       [[[-34641.]]],\n","               \n","               \n","                       [[[-37016.]]],\n","               \n","               \n","                       [[[-29074.]]],\n","               \n","               \n","                       [[[-37056.]]],\n","               \n","               \n","                       [[[-30303.]]],\n","               \n","               \n","                       [[[-29804.]]],\n","               \n","               \n","                       [[[-27533.]]],\n","               \n","               \n","                       [[[-31860.]]],\n","               \n","               \n","                       [[[-33214.]]],\n","               \n","               \n","                       [[[-37190.]]],\n","               \n","               \n","                       [[[-30630.]]],\n","               \n","               \n","                       [[[-28971.]]],\n","               \n","               \n","                       [[[-26901.]]],\n","               \n","               \n","                       [[[-27745.]]],\n","               \n","               \n","                       [[[-32691.]]],\n","               \n","               \n","                       [[[-25197.]]],\n","               \n","               \n","                       [[[-28067.]]],\n","               \n","               \n","                       [[[-33729.]]],\n","               \n","               \n","                       [[[-27453.]]],\n","               \n","               \n","                       [[[-26275.]]],\n","               \n","               \n","                       [[[-27244.]]],\n","               \n","               \n","                       [[[-34189.]]],\n","               \n","               \n","                       [[[-32389.]]],\n","               \n","               \n","                       [[[-27883.]]],\n","               \n","               \n","                       [[[-28056.]]],\n","               \n","               \n","                       [[[-29822.]]],\n","               \n","               \n","                       [[[-26774.]]],\n","               \n","               \n","                       [[[-33041.]]],\n","               \n","               \n","                       [[[-26727.]]],\n","               \n","               \n","                       [[[-27290.]]],\n","               \n","               \n","                       [[[-30778.]]],\n","               \n","               \n","                       [[[-26755.]]],\n","               \n","               \n","                       [[[-27483.]]],\n","               \n","               \n","                       [[[-30561.]]],\n","               \n","               \n","                       [[[-26215.]]],\n","               \n","               \n","                       [[[-27137.]]],\n","               \n","               \n","                       [[[-34186.]]]], device='cuda:0')),\n","              ('module.layer3.4.conv1.fp_bias',\n","               tensor([ 0.0281,  0.0592, -0.0217, -0.3808, -0.2562, -0.0859,  0.0195, -0.0513,\n","                       -0.1568, -0.2343, -0.1962, -0.2959, -0.2855, -0.2351, -0.0486, -0.1972,\n","                       -0.1806, -0.5252, -0.4962, -0.3040, -0.3126, -0.0707, -0.1191, -0.1374,\n","                        0.0111, -0.2119, -0.2836, -0.1770, -0.3748, -0.0087,  0.0833, -0.3857,\n","                       -0.4539, -0.1601, -0.1864, -0.2435, -0.2898, -0.2661, -0.2470, -0.5460,\n","                       -0.1476, -0.1661, -0.1880, -0.2882, -0.1974, -0.4193, -0.6230,  0.0949,\n","                       -0.0303,  0.0871,  0.0504, -0.2127, -0.2550, -0.2372, -0.2858, -0.2786,\n","                       -0.2513, -0.2163, -0.0584, -0.1543, -0.2130, -0.3508, -0.3467, -0.1953],\n","                      device='cuda:0')),\n","              ('module.layer3.4.conv1.accum_scale', tensor([[[6.8571e+09]],\n","               \n","                       [[7.1875e+09]],\n","               \n","                       [[6.3726e+09]],\n","               \n","                       [[5.2137e+09]],\n","               \n","                       [[7.1785e+09]],\n","               \n","                       [[9.1826e+09]],\n","               \n","                       [[4.7017e+09]],\n","               \n","                       [[6.1326e+09]],\n","               \n","                       [[1.6891e+10]],\n","               \n","                       [[7.7353e+09]],\n","               \n","                       [[9.5596e+09]],\n","               \n","                       [[1.1074e+10]],\n","               \n","                       [[7.0031e+09]],\n","               \n","                       [[4.8491e+09]],\n","               \n","                       [[7.7338e+09]],\n","               \n","                       [[7.2294e+09]],\n","               \n","                       [[5.4345e+09]],\n","               \n","                       [[6.3518e+09]],\n","               \n","                       [[6.6316e+09]],\n","               \n","                       [[5.5035e+09]],\n","               \n","                       [[6.0772e+09]],\n","               \n","                       [[5.9117e+09]],\n","               \n","                       [[5.8432e+09]],\n","               \n","                       [[8.0402e+09]],\n","               \n","                       [[6.2984e+09]],\n","               \n","                       [[5.2659e+09]],\n","               \n","                       [[8.4990e+09]],\n","               \n","                       [[7.0228e+09]],\n","               \n","                       [[4.5752e+09]],\n","               \n","                       [[7.3141e+09]],\n","               \n","                       [[5.2269e+09]],\n","               \n","                       [[5.6794e+09]],\n","               \n","                       [[6.5141e+09]],\n","               \n","                       [[7.0719e+09]],\n","               \n","                       [[9.7437e+09]],\n","               \n","                       [[7.2381e+09]],\n","               \n","                       [[6.6634e+09]],\n","               \n","                       [[5.7879e+09]],\n","               \n","                       [[7.9256e+09]],\n","               \n","                       [[5.9781e+09]],\n","               \n","                       [[8.8993e+09]],\n","               \n","                       [[5.6430e+09]],\n","               \n","                       [[7.7412e+09]],\n","               \n","                       [[1.0610e+10]],\n","               \n","                       [[9.3633e+09]],\n","               \n","                       [[6.4086e+09]],\n","               \n","                       [[6.2334e+09]],\n","               \n","                       [[7.2780e+09]],\n","               \n","                       [[9.0615e+09]],\n","               \n","                       [[8.9145e+09]],\n","               \n","                       [[2.6482e+10]],\n","               \n","                       [[9.0361e+09]],\n","               \n","                       [[8.1818e+09]],\n","               \n","                       [[1.0172e+10]],\n","               \n","                       [[8.8545e+09]],\n","               \n","                       [[7.4973e+09]],\n","               \n","                       [[7.3125e+09]],\n","               \n","                       [[8.8683e+09]],\n","               \n","                       [[5.1463e+09]],\n","               \n","                       [[1.0372e+10]],\n","               \n","                       [[7.0478e+09]],\n","               \n","                       [[9.2751e+09]],\n","               \n","                       [[6.9960e+09]],\n","               \n","                       [[7.4665e+09]]], device='cuda:0')),\n","              ('module.layer3.4.conv1.is_simulated_quant_weight_shifted',\n","               tensor(False, device='cuda:0')),\n","              ('module.layer3.4.conv1.wrapped_module.weight',\n","               tensor([[[[34598., 26786., 25445.],\n","                         [29672., 29892., 18571.],\n","                         [26481., 37192., 26812.]],\n","               \n","                        [[27049., 43478., 34932.],\n","                         [30265., 38972., 26076.],\n","                         [29834., 25103., 15934.]],\n","               \n","                        [[25868., 37112., 47316.],\n","                         [12356., 28675., 44458.],\n","                         [20912., 37022., 37107.]],\n","               \n","                        ...,\n","               \n","                        [[30880., 28162., 31134.],\n","                         [31849., 32905., 34479.],\n","                         [26187., 24467., 30997.]],\n","               \n","                        [[14555., 18795., 20828.],\n","                         [41254., 24730., 14366.],\n","                         [59200., 23395., 10247.]],\n","               \n","                        [[42019., 31840.,  3008.],\n","                         [22346., 17131., 10816.],\n","                         [ 3091., 25086., 22280.]]],\n","               \n","               \n","                       [[[18599., 45075., 65535.],\n","                         [27738., 32525., 33331.],\n","                         [29421., 30842., 20411.]],\n","               \n","                        [[27452., 24324., 21762.],\n","                         [25051., 27162., 31413.],\n","                         [26214., 29899., 29822.]],\n","               \n","                        [[21154., 28963., 28580.],\n","                         [31146., 21332., 22752.],\n","                         [41224., 36277., 33888.]],\n","               \n","                        ...,\n","               \n","                        [[32679., 28418., 25253.],\n","                         [34198., 29792., 26557.],\n","                         [29808., 26496., 28036.]],\n","               \n","                        [[34593., 25558., 29334.],\n","                         [28226., 26732., 36338.],\n","                         [15411., 19822., 32981.]],\n","               \n","                        [[30187., 28181., 31481.],\n","                         [22255., 25942., 15883.],\n","                         [31690., 37804., 30677.]]],\n","               \n","               \n","                       [[[28959., 33984., 33787.],\n","                         [19447., 18988., 23775.],\n","                         [15174.,  4457.,  9967.]],\n","               \n","                        [[29797., 25105., 28384.],\n","                         [23256., 24286., 32397.],\n","                         [33946., 31546., 33069.]],\n","               \n","                        [[34220., 47978., 49106.],\n","                         [15042., 23971., 38074.],\n","                         [26454., 32568., 26401.]],\n","               \n","                        ...,\n","               \n","                        [[30428., 35895., 31341.],\n","                         [40065., 37157., 34677.],\n","                         [39628., 37848., 31096.]],\n","               \n","                        [[40465., 33574., 27661.],\n","                         [54070., 40346., 37264.],\n","                         [49529., 48312., 42250.]],\n","               \n","                        [[25802.,  9873.,  4140.],\n","                         [28042., 13103.,   552.],\n","                         [50727., 30388., 33236.]]],\n","               \n","               \n","                       ...,\n","               \n","               \n","                       [[[19092., 17780., 20687.],\n","                         [13337., 18008., 20860.],\n","                         [ 8535., 15080., 20956.]],\n","               \n","                        [[34247., 28430., 22077.],\n","                         [25650., 16391., 18763.],\n","                         [18228., 16767., 18202.]],\n","               \n","                        [[23539., 28167., 28627.],\n","                         [21532., 17419., 28253.],\n","                         [15170., 16661., 31758.]],\n","               \n","                        ...,\n","               \n","                        [[22659., 27145., 37625.],\n","                         [23624., 24282., 34584.],\n","                         [27243., 28904., 34517.]],\n","               \n","                        [[31135., 28528., 30268.],\n","                         [ 9391., 16939., 23658.],\n","                         [26900., 22564., 18244.]],\n","               \n","                        [[22360.,  3771., 19693.],\n","                         [14382.,     0., 12143.],\n","                         [16238., 15064., 19544.]]],\n","               \n","               \n","                       [[[31098., 33255., 27901.],\n","                         [26667., 30001., 19857.],\n","                         [26862., 27747., 26644.]],\n","               \n","                        [[21004., 30322., 25328.],\n","                         [31627., 29316., 22292.],\n","                         [39668., 31793., 24626.]],\n","               \n","                        [[39515., 39474., 42722.],\n","                         [30819., 30904., 23543.],\n","                         [29406., 34900., 22759.]],\n","               \n","                        ...,\n","               \n","                        [[21912., 29863., 32069.],\n","                         [24711., 24784., 30896.],\n","                         [25848., 22400., 30911.]],\n","               \n","                        [[27352., 26714., 23848.],\n","                         [15220., 17032., 20269.],\n","                         [ 6206., 15922., 23987.]],\n","               \n","                        [[27059., 36162., 29551.],\n","                         [17342., 20070., 13004.],\n","                         [ 8463., 19922., 34311.]]],\n","               \n","               \n","                       [[[32365., 22696., 29671.],\n","                         [19540., 28687., 45637.],\n","                         [23602., 41252., 36830.]],\n","               \n","                        [[30434., 38083., 32144.],\n","                         [29585., 33878., 35973.],\n","                         [42627., 48018., 35573.]],\n","               \n","                        [[37609., 35513., 34907.],\n","                         [41726., 49087., 31413.],\n","                         [61782., 61356., 24565.]],\n","               \n","                        ...,\n","               \n","                        [[37513., 36074., 31395.],\n","                         [37723., 34450., 31715.],\n","                         [27368., 26864., 37174.]],\n","               \n","                        [[34423., 16461., 30084.],\n","                         [24687., 21792., 48488.],\n","                         [38556., 34578., 54577.]],\n","               \n","                        [[24819., 28420., 60533.],\n","                         [20241., 23387., 49192.],\n","                         [34616., 18365., 25027.]]]], device='cuda:0')),\n","              ('module.layer3.4.conv1.wrapped_module.bias',\n","               tensor([ 1.9257e+08,  4.2520e+08, -1.3859e+08, -1.9856e+09, -1.8392e+09,\n","                       -7.8899e+08,  9.1739e+07, -3.1474e+08, -2.1475e+09, -1.8123e+09,\n","                       -1.8754e+09, -2.1475e+09, -1.9990e+09, -1.1401e+09, -3.7623e+08,\n","                       -1.4260e+09, -9.8168e+08, -2.1475e+09, -2.1475e+09, -1.6731e+09,\n","                       -1.8995e+09, -4.1813e+08, -6.9594e+08, -1.1047e+09,  7.0218e+07,\n","                       -1.1160e+09, -2.1475e+09, -1.2434e+09, -1.7148e+09, -6.3594e+07,\n","                        4.3519e+08, -2.1475e+09, -2.1475e+09, -1.1320e+09, -1.8164e+09,\n","                       -1.7625e+09, -1.9309e+09, -1.5404e+09, -1.9577e+09, -2.1475e+09,\n","                       -1.3136e+09, -9.3720e+08, -1.4552e+09, -2.1475e+09, -1.8478e+09,\n","                       -2.1475e+09, -2.1475e+09,  6.9037e+08, -2.7480e+08,  7.7644e+08,\n","                        1.3359e+09, -1.9218e+09, -2.0860e+09, -2.1475e+09, -2.1475e+09,\n","                       -2.0888e+09, -1.8376e+09, -1.9180e+09, -3.0049e+08, -1.6002e+09,\n","                       -1.5014e+09, -2.1475e+09, -2.1475e+09, -1.4584e+09], device='cuda:0')),\n","              ('module.layer3.4.conv2.num_forwards',\n","               tensor([40], device='cuda:0')),\n","              ('module.layer3.4.conv2.force_readjust',\n","               tensor(False, device='cuda:0')),\n","              ('module.layer3.4.conv2.output_scale',\n","               tensor([9636.0684], device='cuda:0')),\n","              ('module.layer3.4.conv2.output_zero_point',\n","               tensor([-36755.], device='cuda:0')),\n","              ('module.layer3.4.conv2.w_scale', tensor([[[[5.0047e+04]]],\n","               \n","               \n","                       [[[9.3853e+04]]],\n","               \n","               \n","                       [[[7.8331e+07]]],\n","               \n","               \n","                       [[[4.6700e+04]]],\n","               \n","               \n","                       [[[1.3528e+05]]],\n","               \n","               \n","                       [[[1.3573e+05]]],\n","               \n","               \n","                       [[[1.2523e+05]]],\n","               \n","               \n","                       [[[3.8451e+05]]],\n","               \n","               \n","                       [[[1.0745e+05]]],\n","               \n","               \n","                       [[[1.0999e+05]]],\n","               \n","               \n","                       [[[5.4766e+04]]],\n","               \n","               \n","                       [[[1.5966e+05]]],\n","               \n","               \n","                       [[[9.6314e+04]]],\n","               \n","               \n","                       [[[2.2102e+05]]],\n","               \n","               \n","                       [[[8.9191e+04]]],\n","               \n","               \n","                       [[[1.2528e+05]]],\n","               \n","               \n","                       [[[1.0260e+05]]],\n","               \n","               \n","                       [[[1.2421e+05]]],\n","               \n","               \n","                       [[[1.6611e+05]]],\n","               \n","               \n","                       [[[7.1649e+04]]],\n","               \n","               \n","                       [[[2.8740e+05]]],\n","               \n","               \n","                       [[[1.0784e+05]]],\n","               \n","               \n","                       [[[9.3796e+04]]],\n","               \n","               \n","                       [[[6.8937e+04]]],\n","               \n","               \n","                       [[[1.4762e+05]]],\n","               \n","               \n","                       [[[1.0748e+05]]],\n","               \n","               \n","                       [[[1.3365e+05]]],\n","               \n","               \n","                       [[[7.3363e+04]]],\n","               \n","               \n","                       [[[7.9728e+04]]],\n","               \n","               \n","                       [[[1.3133e+05]]],\n","               \n","               \n","                       [[[1.6594e+05]]],\n","               \n","               \n","                       [[[7.5076e+04]]],\n","               \n","               \n","                       [[[9.8479e+04]]],\n","               \n","               \n","                       [[[7.5648e+04]]],\n","               \n","               \n","                       [[[2.1212e+05]]],\n","               \n","               \n","                       [[[6.1648e+04]]],\n","               \n","               \n","                       [[[5.5674e+04]]],\n","               \n","               \n","                       [[[5.4658e+04]]],\n","               \n","               \n","                       [[[9.4794e+04]]],\n","               \n","               \n","                       [[[2.7306e+05]]],\n","               \n","               \n","                       [[[9.6070e+04]]],\n","               \n","               \n","                       [[[1.7207e+05]]],\n","               \n","               \n","                       [[[2.0294e+04]]],\n","               \n","               \n","                       [[[2.0748e+05]]],\n","               \n","               \n","                       [[[1.5155e+05]]],\n","               \n","               \n","                       [[[1.0282e+05]]],\n","               \n","               \n","                       [[[1.1467e+07]]],\n","               \n","               \n","                       [[[1.0775e+05]]],\n","               \n","               \n","                       [[[7.6863e+04]]],\n","               \n","               \n","                       [[[3.1917e+05]]],\n","               \n","               \n","                       [[[7.6645e+05]]],\n","               \n","               \n","                       [[[6.2605e+04]]],\n","               \n","               \n","                       [[[1.0071e+05]]],\n","               \n","               \n","                       [[[1.0044e+05]]],\n","               \n","               \n","                       [[[1.1760e+05]]],\n","               \n","               \n","                       [[[1.3714e+05]]],\n","               \n","               \n","                       [[[1.0077e+05]]],\n","               \n","               \n","                       [[[8.5812e+04]]],\n","               \n","               \n","                       [[[7.3571e+04]]],\n","               \n","               \n","                       [[[7.8064e+04]]],\n","               \n","               \n","                       [[[5.6888e+04]]],\n","               \n","               \n","                       [[[1.1051e+05]]],\n","               \n","               \n","                       [[[7.1667e+04]]],\n","               \n","               \n","                       [[[4.3624e+04]]]], device='cuda:0')),\n","              ('module.layer3.4.conv2.w_zero_point', tensor([[[[-31257.]]],\n","               \n","               \n","                       [[[-25849.]]],\n","               \n","               \n","                       [[[-34234.]]],\n","               \n","               \n","                       [[[-31593.]]],\n","               \n","               \n","                       [[[-33220.]]],\n","               \n","               \n","                       [[[-38778.]]],\n","               \n","               \n","                       [[[-32238.]]],\n","               \n","               \n","                       [[[-27829.]]],\n","               \n","               \n","                       [[[-33111.]]],\n","               \n","               \n","                       [[[-27265.]]],\n","               \n","               \n","                       [[[-24351.]]],\n","               \n","               \n","                       [[[-29479.]]],\n","               \n","               \n","                       [[[-30229.]]],\n","               \n","               \n","                       [[[-26448.]]],\n","               \n","               \n","                       [[[-32271.]]],\n","               \n","               \n","                       [[[-36070.]]],\n","               \n","               \n","                       [[[-30852.]]],\n","               \n","               \n","                       [[[-32646.]]],\n","               \n","               \n","                       [[[-32806.]]],\n","               \n","               \n","                       [[[-27629.]]],\n","               \n","               \n","                       [[[-33894.]]],\n","               \n","               \n","                       [[[-37748.]]],\n","               \n","               \n","                       [[[-25732.]]],\n","               \n","               \n","                       [[[-32532.]]],\n","               \n","               \n","                       [[[-37275.]]],\n","               \n","               \n","                       [[[-32952.]]],\n","               \n","               \n","                       [[[-31356.]]],\n","               \n","               \n","                       [[[-32829.]]],\n","               \n","               \n","                       [[[-29846.]]],\n","               \n","               \n","                       [[[-31950.]]],\n","               \n","               \n","                       [[[-31222.]]],\n","               \n","               \n","                       [[[-29745.]]],\n","               \n","               \n","                       [[[-30250.]]],\n","               \n","               \n","                       [[[-24608.]]],\n","               \n","               \n","                       [[[-27852.]]],\n","               \n","               \n","                       [[[-26735.]]],\n","               \n","               \n","                       [[[-31749.]]],\n","               \n","               \n","                       [[[-23514.]]],\n","               \n","               \n","                       [[[-32485.]]],\n","               \n","               \n","                       [[[-33648.]]],\n","               \n","               \n","                       [[[-30599.]]],\n","               \n","               \n","                       [[[-37208.]]],\n","               \n","               \n","                       [[[-33200.]]],\n","               \n","               \n","                       [[[-28596.]]],\n","               \n","               \n","                       [[[-22016.]]],\n","               \n","               \n","                       [[[-37261.]]],\n","               \n","               \n","                       [[[-36348.]]],\n","               \n","               \n","                       [[[-28813.]]],\n","               \n","               \n","                       [[[-32054.]]],\n","               \n","               \n","                       [[[-33667.]]],\n","               \n","               \n","                       [[[-28714.]]],\n","               \n","               \n","                       [[[-27533.]]],\n","               \n","               \n","                       [[[-33095.]]],\n","               \n","               \n","                       [[[-27506.]]],\n","               \n","               \n","                       [[[-32795.]]],\n","               \n","               \n","                       [[[-33144.]]],\n","               \n","               \n","                       [[[-26718.]]],\n","               \n","               \n","                       [[[-33819.]]],\n","               \n","               \n","                       [[[-27065.]]],\n","               \n","               \n","                       [[[-38667.]]],\n","               \n","               \n","                       [[[-30595.]]],\n","               \n","               \n","                       [[[-28044.]]],\n","               \n","               \n","                       [[[-27912.]]],\n","               \n","               \n","                       [[[-31339.]]]], device='cuda:0')),\n","              ('module.layer3.4.conv2.fp_bias',\n","               tensor([ 0.4362, -0.3877, -0.1893,  0.1008, -0.0959, -0.0836,  0.0564, -0.0694,\n","                       -0.2559, -0.1668, -0.4285, -0.1020,  0.0415, -0.0368, -0.5924,  0.0083,\n","                       -0.1761,  0.0064, -0.0811, -0.2730, -0.1443,  0.2292, -0.1381, -0.2571,\n","                       -0.0234,  0.0365, -0.1513, -0.0431, -0.1890,  0.0699, -0.0566, -0.2072,\n","                       -0.0183, -0.3016, -0.1358, -0.3822, -0.1995,  0.0073, -0.0079, -0.1303,\n","                        0.0476, -0.0811,  0.1438, -0.0465, -0.1089,  0.0219, -0.0086, -0.2670,\n","                       -0.0433, -0.0527, -0.4054, -0.1394, -0.1018, -0.0659,  0.0821, -0.0824,\n","                       -0.0376, -0.0609, -0.0475, -0.1982, -0.2405,  0.1148, -0.1415, -0.0392],\n","                      device='cuda:0')),\n","              ('module.layer3.4.conv2.accum_scale', tensor([[[2.8836e+09]],\n","               \n","                       [[5.4077e+09]],\n","               \n","                       [[4.5133e+12]],\n","               \n","                       [[2.6907e+09]],\n","               \n","                       [[7.7947e+09]],\n","               \n","                       [[7.8205e+09]],\n","               \n","                       [[7.2157e+09]],\n","               \n","                       [[2.2155e+10]],\n","               \n","                       [[6.1911e+09]],\n","               \n","                       [[6.3374e+09]],\n","               \n","                       [[3.1555e+09]],\n","               \n","                       [[9.1993e+09]],\n","               \n","                       [[5.5494e+09]],\n","               \n","                       [[1.2735e+10]],\n","               \n","                       [[5.1390e+09]],\n","               \n","                       [[7.2184e+09]],\n","               \n","                       [[5.9119e+09]],\n","               \n","                       [[7.1569e+09]],\n","               \n","                       [[9.5709e+09]],\n","               \n","                       [[4.1283e+09]],\n","               \n","                       [[1.6560e+10]],\n","               \n","                       [[6.2138e+09]],\n","               \n","                       [[5.4043e+09]],\n","               \n","                       [[3.9720e+09]],\n","               \n","                       [[8.5057e+09]],\n","               \n","                       [[6.1926e+09]],\n","               \n","                       [[7.7006e+09]],\n","               \n","                       [[4.2271e+09]],\n","               \n","                       [[4.5938e+09]],\n","               \n","                       [[7.5669e+09]],\n","               \n","                       [[9.5610e+09]],\n","               \n","                       [[4.3257e+09]],\n","               \n","                       [[5.6742e+09]],\n","               \n","                       [[4.3587e+09]],\n","               \n","                       [[1.2222e+10]],\n","               \n","                       [[3.5520e+09]],\n","               \n","                       [[3.2079e+09]],\n","               \n","                       [[3.1493e+09]],\n","               \n","                       [[5.4619e+09]],\n","               \n","                       [[1.5733e+10]],\n","               \n","                       [[5.5354e+09]],\n","               \n","                       [[9.9141e+09]],\n","               \n","                       [[1.1693e+09]],\n","               \n","                       [[1.1955e+10]],\n","               \n","                       [[8.7319e+09]],\n","               \n","                       [[5.9243e+09]],\n","               \n","                       [[6.6071e+11]],\n","               \n","                       [[6.2081e+09]],\n","               \n","                       [[4.4287e+09]],\n","               \n","                       [[1.8390e+10]],\n","               \n","                       [[4.4161e+10]],\n","               \n","                       [[3.6072e+09]],\n","               \n","                       [[5.8028e+09]],\n","               \n","                       [[5.7872e+09]],\n","               \n","                       [[6.7758e+09]],\n","               \n","                       [[7.9017e+09]],\n","               \n","                       [[5.8063e+09]],\n","               \n","                       [[4.9443e+09]],\n","               \n","                       [[4.2390e+09]],\n","               \n","                       [[4.4979e+09]],\n","               \n","                       [[3.2778e+09]],\n","               \n","                       [[6.3672e+09]],\n","               \n","                       [[4.1293e+09]],\n","               \n","                       [[2.5136e+09]]], device='cuda:0')),\n","              ('module.layer3.4.conv2.is_simulated_quant_weight_shifted',\n","               tensor(False, device='cuda:0')),\n","              ('module.layer3.4.conv2.wrapped_module.weight',\n","               tensor([[[[39037., 29660., 24481.],\n","                         [29683., 23641., 25303.],\n","                         [33553., 31656., 29157.]],\n","               \n","                        [[18111., 24085., 15881.],\n","                         [35701., 34392., 25354.],\n","                         [40879., 34387., 37609.]],\n","               \n","                        [[58796., 44641., 23554.],\n","                         [34036., 22261., 24878.],\n","                         [31360., 22614., 27193.]],\n","               \n","                        ...,\n","               \n","                        [[20555., 20481., 21033.],\n","                         [23529., 20164., 26050.],\n","                         [36674., 33381., 29191.]],\n","               \n","                        [[22366., 15130., 23230.],\n","                         [35081., 30948., 38472.],\n","                         [44556., 40025., 38197.]],\n","               \n","                        [[29422., 47211., 50393.],\n","                         [19792., 31466., 31121.],\n","                         [15567., 19378., 15193.]]],\n","               \n","               \n","                       [[[32159., 33740., 29028.],\n","                         [14525., 27022., 36021.],\n","                         [18723., 18610., 19091.]],\n","               \n","                        [[24859., 23555., 21718.],\n","                         [22805., 20638., 22315.],\n","                         [12170., 19994., 29823.]],\n","               \n","                        [[22120., 30452., 27714.],\n","                         [24374., 28586., 35244.],\n","                         [20380., 26163., 33096.]],\n","               \n","                        ...,\n","               \n","                        [[23282., 26483., 26469.],\n","                         [31459., 29082., 24395.],\n","                         [34189., 30046., 30188.]],\n","               \n","                        [[22633., 15639., 26062.],\n","                         [34945., 21709., 16893.],\n","                         [48688., 32052., 24760.]],\n","               \n","                        [[20063., 22932., 28327.],\n","                         [24530., 20404., 17700.],\n","                         [37478., 25466., 27584.]]],\n","               \n","               \n","                       [[[15691., 20543., 18887.],\n","                         [25428., 31655., 18945.],\n","                         [30316., 45965., 29303.]],\n","               \n","                        [[29320., 31676., 28322.],\n","                         [19646., 23532., 22293.],\n","                         [27316., 24367., 30966.]],\n","               \n","                        [[21491., 32879., 28244.],\n","                         [24136., 29684., 21972.],\n","                         [41337., 41378., 26350.]],\n","               \n","                        ...,\n","               \n","                        [[30284., 25186., 38500.],\n","                         [28476., 25716., 36090.],\n","                         [39123., 38571., 42776.]],\n","               \n","                        [[47360., 34061., 42154.],\n","                         [30540., 24159., 29752.],\n","                         [38869., 39977., 42525.]],\n","               \n","                        [[24468., 28052., 45817.],\n","                         [24316., 19598., 29626.],\n","                         [23414., 18942., 27687.]]],\n","               \n","               \n","                       ...,\n","               \n","               \n","                       [[[32378., 31679., 35189.],\n","                         [30716., 22265., 21732.],\n","                         [29212., 17368., 17816.]],\n","               \n","                        [[37094., 26767., 28692.],\n","                         [34210., 21855., 22575.],\n","                         [28609., 23315., 27638.]],\n","               \n","                        [[25374., 27469., 19037.],\n","                         [20531., 21587., 16017.],\n","                         [37802., 26357., 13307.]],\n","               \n","                        ...,\n","               \n","                        [[41012., 31968., 20787.],\n","                         [38411., 26045., 21461.],\n","                         [49543., 36511., 27134.]],\n","               \n","                        [[25594., 23739.,  6515.],\n","                         [18960., 21156.,  4345.],\n","                         [29948., 35998., 23772.]],\n","               \n","                        [[28015., 39404., 52262.],\n","                         [15550., 22584., 28916.],\n","                         [28416., 38466., 32064.]]],\n","               \n","               \n","                       [[[27101., 32854., 33238.],\n","                         [34773., 43064., 34956.],\n","                         [31353., 39901., 37287.]],\n","               \n","                        [[36223., 31838., 27717.],\n","                         [32816., 27944., 10923.],\n","                         [25740., 17937.,  4917.]],\n","               \n","                        [[44159., 28827., 33608.],\n","                         [36268., 21476., 19861.],\n","                         [36994., 35837., 25010.]],\n","               \n","                        ...,\n","               \n","                        [[21579., 17605., 23456.],\n","                         [27866., 28689., 28971.],\n","                         [30391., 29244., 28798.]],\n","               \n","                        [[18077., 25018., 32201.],\n","                         [23734., 30906., 26686.],\n","                         [36232., 39515., 32219.]],\n","               \n","                        [[37513., 45735., 47316.],\n","                         [36751., 41528., 38549.],\n","                         [29802., 26005., 29396.]]],\n","               \n","               \n","                       [[[33535., 35473., 39906.],\n","                         [35464., 58176., 59431.],\n","                         [29145., 45952., 40833.]],\n","               \n","                        [[37182., 32586., 32014.],\n","                         [39519., 24247., 15538.],\n","                         [39482., 18160., 14368.]],\n","               \n","                        [[21729., 23653., 31105.],\n","                         [21449., 16083., 25384.],\n","                         [26656., 23674., 12626.]],\n","               \n","                        ...,\n","               \n","                        [[27647., 20580., 32452.],\n","                         [33011., 24205., 35165.],\n","                         [38222., 35818., 40358.]],\n","               \n","                        [[38477., 34625., 37485.],\n","                         [35365., 25750., 30663.],\n","                         [36044., 23914., 29433.]],\n","               \n","                        [[14749., 24030., 39182.],\n","                         [21080., 32465., 57585.],\n","                         [39633., 35540., 40624.]]]], device='cuda:0')),\n","              ('module.layer3.4.conv2.wrapped_module.bias',\n","               tensor([ 1.2578e+09, -2.0963e+09, -2.1475e+09,  2.7117e+08, -7.4727e+08,\n","                       -6.5346e+08,  4.0664e+08, -1.5383e+09, -1.5842e+09, -1.0570e+09,\n","                       -1.3522e+09, -9.3841e+08,  2.3026e+08, -4.6869e+08, -2.1475e+09,\n","                        5.9784e+07, -1.0410e+09,  4.5863e+07, -7.7653e+08, -1.1269e+09,\n","                       -2.1475e+09,  1.4242e+09, -7.4622e+08, -1.0212e+09, -1.9889e+08,\n","                        2.2598e+08, -1.1650e+09, -1.8223e+08, -8.6830e+08,  5.2862e+08,\n","                       -5.4085e+08, -8.9626e+08, -1.0369e+08, -1.3144e+09, -1.6594e+09,\n","                       -1.3575e+09, -6.3985e+08,  2.3025e+07, -4.2956e+07, -2.0498e+09,\n","                        2.6338e+08, -8.0399e+08,  1.6815e+08, -5.5603e+08, -9.5049e+08,\n","                        1.2973e+08, -2.1475e+09, -1.6577e+09, -1.9197e+08, -9.6914e+08,\n","                       -2.1475e+09, -5.0302e+08, -5.9088e+08, -3.8122e+08,  5.5653e+08,\n","                       -6.5105e+08, -2.1856e+08, -3.0092e+08, -2.0140e+08, -8.9141e+08,\n","                       -7.8845e+08,  7.3068e+08, -5.8432e+08, -9.8636e+07], device='cuda:0')),\n","              ('module.layer3.4.relu2.num_forwards',\n","               tensor([40], device='cuda:0')),\n","              ('module.layer3.4.relu2.force_readjust',\n","               tensor(False, device='cuda:0')),\n","              ('module.layer3.4.relu2.output_scale',\n","               tensor([7303.5151], device='cuda:0')),\n","              ('module.layer3.4.relu2.output_zero_point',\n","               tensor([0.], device='cuda:0')),\n","              ('module.layer3.4.residual_eltwiseadd.num_forwards',\n","               tensor([40], device='cuda:0')),\n","              ('module.layer3.4.residual_eltwiseadd.force_readjust',\n","               tensor(False, device='cuda:0')),\n","              ('module.layer3.4.residual_eltwiseadd.output_scale',\n","               tensor([7303.5151], device='cuda:0')),\n","              ('module.layer3.4.residual_eltwiseadd.output_zero_point',\n","               tensor([0.], device='cuda:0')),\n","              ('module.layer3.5.conv1.num_forwards',\n","               tensor([40], device='cuda:0')),\n","              ('module.layer3.5.conv1.force_readjust',\n","               tensor(False, device='cuda:0')),\n","              ('module.layer3.5.conv1.output_scale',\n","               tensor([56613.0469], device='cuda:0')),\n","              ('module.layer3.5.conv1.output_zero_point',\n","               tensor([0.], device='cuda:0')),\n","              ('module.layer3.5.conv1.w_scale', tensor([[[[  667438.8125]]],\n","               \n","               \n","                       [[[  653329.4375]]],\n","               \n","               \n","                       [[[  689895.1875]]],\n","               \n","               \n","                       [[[  792061.5625]]],\n","               \n","               \n","                       [[[ 1169485.5000]]],\n","               \n","               \n","                       [[[  613796.7500]]],\n","               \n","               \n","                       [[[  830572.6250]]],\n","               \n","               \n","                       [[[91679120.0000]]],\n","               \n","               \n","                       [[[ 1260459.1250]]],\n","               \n","               \n","                       [[[  978941.8125]]],\n","               \n","               \n","                       [[[  791483.5000]]],\n","               \n","               \n","                       [[[  751773.8750]]],\n","               \n","               \n","                       [[[  947492.5625]]],\n","               \n","               \n","                       [[[  966718.9375]]],\n","               \n","               \n","                       [[[ 1386355.7500]]],\n","               \n","               \n","                       [[[ 1414225.8750]]],\n","               \n","               \n","                       [[[  883076.5000]]],\n","               \n","               \n","                       [[[  860635.6250]]],\n","               \n","               \n","                       [[[  736837.6875]]],\n","               \n","               \n","                       [[[  765388.8125]]],\n","               \n","               \n","                       [[[  983069.0000]]],\n","               \n","               \n","                       [[[  856247.0000]]],\n","               \n","               \n","                       [[[ 2542185.7500]]],\n","               \n","               \n","                       [[[  796949.7500]]],\n","               \n","               \n","                       [[[  881001.8125]]],\n","               \n","               \n","                       [[[  696162.6875]]],\n","               \n","               \n","                       [[[  665743.9375]]],\n","               \n","               \n","                       [[[ 1201235.7500]]],\n","               \n","               \n","                       [[[  945364.3125]]],\n","               \n","               \n","                       [[[  948461.3750]]],\n","               \n","               \n","                       [[[  880819.8750]]],\n","               \n","               \n","                       [[[  705855.6250]]],\n","               \n","               \n","                       [[[  707624.0625]]],\n","               \n","               \n","                       [[[ 1208998.8750]]],\n","               \n","               \n","                       [[[  783019.5000]]],\n","               \n","               \n","                       [[[  937943.7500]]],\n","               \n","               \n","                       [[[  729372.8125]]],\n","               \n","               \n","                       [[[  865231.0000]]],\n","               \n","               \n","                       [[[ 1357822.8750]]],\n","               \n","               \n","                       [[[  879967.0625]]],\n","               \n","               \n","                       [[[  736055.1250]]],\n","               \n","               \n","                       [[[  893333.6875]]],\n","               \n","               \n","                       [[[  887410.9375]]],\n","               \n","               \n","                       [[[ 1895931.2500]]],\n","               \n","               \n","                       [[[  792661.1875]]],\n","               \n","               \n","                       [[[  814851.3750]]],\n","               \n","               \n","                       [[[ 1260077.0000]]],\n","               \n","               \n","                       [[[ 1129346.2500]]],\n","               \n","               \n","                       [[[  858933.6250]]],\n","               \n","               \n","                       [[[ 1842339.8750]]],\n","               \n","               \n","                       [[[  765697.3125]]],\n","               \n","               \n","                       [[[ 1427514.8750]]],\n","               \n","               \n","                       [[[  807820.9375]]],\n","               \n","               \n","                       [[[  909080.0000]]],\n","               \n","               \n","                       [[[ 1056022.3750]]],\n","               \n","               \n","                       [[[ 1595723.1250]]],\n","               \n","               \n","                       [[[  791468.1250]]],\n","               \n","               \n","                       [[[ 1960745.0000]]],\n","               \n","               \n","                       [[[  883484.0000]]],\n","               \n","               \n","                       [[[  876648.2500]]],\n","               \n","               \n","                       [[[  667566.6875]]],\n","               \n","               \n","                       [[[  903170.1875]]],\n","               \n","               \n","                       [[[ 2111315.7500]]],\n","               \n","               \n","                       [[[  703985.5625]]]], device='cuda:0')),\n","              ('module.layer3.5.conv1.w_zero_point', tensor([[[[-29266.]]],\n","               \n","               \n","                       [[[-31815.]]],\n","               \n","               \n","                       [[[-22790.]]],\n","               \n","               \n","                       [[[-26893.]]],\n","               \n","               \n","                       [[[-32011.]]],\n","               \n","               \n","                       [[[-26659.]]],\n","               \n","               \n","                       [[[-24657.]]],\n","               \n","               \n","                       [[[-33378.]]],\n","               \n","               \n","                       [[[-31072.]]],\n","               \n","               \n","                       [[[-30026.]]],\n","               \n","               \n","                       [[[-26084.]]],\n","               \n","               \n","                       [[[-26587.]]],\n","               \n","               \n","                       [[[-26841.]]],\n","               \n","               \n","                       [[[-28317.]]],\n","               \n","               \n","                       [[[-28806.]]],\n","               \n","               \n","                       [[[-32038.]]],\n","               \n","               \n","                       [[[-28900.]]],\n","               \n","               \n","                       [[[-28488.]]],\n","               \n","               \n","                       [[[-33190.]]],\n","               \n","               \n","                       [[[-27700.]]],\n","               \n","               \n","                       [[[-28394.]]],\n","               \n","               \n","                       [[[-23957.]]],\n","               \n","               \n","                       [[[-33500.]]],\n","               \n","               \n","                       [[[-24923.]]],\n","               \n","               \n","                       [[[-23799.]]],\n","               \n","               \n","                       [[[-36803.]]],\n","               \n","               \n","                       [[[-35162.]]],\n","               \n","               \n","                       [[[-35597.]]],\n","               \n","               \n","                       [[[-24321.]]],\n","               \n","               \n","                       [[[-22732.]]],\n","               \n","               \n","                       [[[-26021.]]],\n","               \n","               \n","                       [[[-26096.]]],\n","               \n","               \n","                       [[[-28268.]]],\n","               \n","               \n","                       [[[-25448.]]],\n","               \n","               \n","                       [[[-25657.]]],\n","               \n","               \n","                       [[[-29549.]]],\n","               \n","               \n","                       [[[-32640.]]],\n","               \n","               \n","                       [[[-29879.]]],\n","               \n","               \n","                       [[[-30250.]]],\n","               \n","               \n","                       [[[-31829.]]],\n","               \n","               \n","                       [[[-28109.]]],\n","               \n","               \n","                       [[[-25955.]]],\n","               \n","               \n","                       [[[-28627.]]],\n","               \n","               \n","                       [[[-27375.]]],\n","               \n","               \n","                       [[[-23675.]]],\n","               \n","               \n","                       [[[-31422.]]],\n","               \n","               \n","                       [[[-27823.]]],\n","               \n","               \n","                       [[[-32998.]]],\n","               \n","               \n","                       [[[-25699.]]],\n","               \n","               \n","                       [[[-29844.]]],\n","               \n","               \n","                       [[[-27248.]]],\n","               \n","               \n","                       [[[-33125.]]],\n","               \n","               \n","                       [[[-25539.]]],\n","               \n","               \n","                       [[[-31236.]]],\n","               \n","               \n","                       [[[-28057.]]],\n","               \n","               \n","                       [[[-29518.]]],\n","               \n","               \n","                       [[[-26730.]]],\n","               \n","               \n","                       [[[-28469.]]],\n","               \n","               \n","                       [[[-27345.]]],\n","               \n","               \n","                       [[[-28781.]]],\n","               \n","               \n","                       [[[-31271.]]],\n","               \n","               \n","                       [[[-33201.]]],\n","               \n","               \n","                       [[[-29801.]]],\n","               \n","               \n","                       [[[-26421.]]]], device='cuda:0')),\n","              ('module.layer3.5.conv1.fp_bias',\n","               tensor([-0.2421, -0.0781,  0.1405,  0.0821, -0.0612, -0.4580, -0.1070, -0.0279,\n","                       -0.0695, -0.3479, -0.1755, -0.3235, -0.0228, -0.4900, -0.0906, -0.2032,\n","                       -0.3410, -0.1245, -0.1039, -0.1896, -0.2678, -0.2493, -0.1130, -0.0021,\n","                       -0.3444,  0.1694,  0.0226,  0.1957, -0.3563, -0.1862, -0.1338, -0.0554,\n","                       -0.2093,  0.0318, -0.1275,  0.2162, -0.2791,  0.0706, -0.1288, -0.2010,\n","                        0.1370,  0.0899, -0.4615, -0.0756, -0.1868,  0.0305, -0.0162, -0.1262,\n","                       -0.3932, -0.1019, -0.3384, -0.0972, -0.1188, -0.1392, -0.0237, -0.1331,\n","                       -0.4411, -0.1710,  0.2028, -0.0274, -0.3046,  0.3547, -0.2764,  0.3233],\n","                      device='cuda:0')),\n","              ('module.layer3.5.conv1.accum_scale', tensor([[[4.8746e+09]],\n","               \n","                       [[4.7716e+09]],\n","               \n","                       [[5.0387e+09]],\n","               \n","                       [[5.7848e+09]],\n","               \n","                       [[8.5414e+09]],\n","               \n","                       [[4.4829e+09]],\n","               \n","                       [[6.0661e+09]],\n","               \n","                       [[6.6958e+11]],\n","               \n","                       [[9.2058e+09]],\n","               \n","                       [[7.1497e+09]],\n","               \n","                       [[5.7806e+09]],\n","               \n","                       [[5.4906e+09]],\n","               \n","                       [[6.9200e+09]],\n","               \n","                       [[7.0604e+09]],\n","               \n","                       [[1.0125e+10]],\n","               \n","                       [[1.0329e+10]],\n","               \n","                       [[6.4496e+09]],\n","               \n","                       [[6.2857e+09]],\n","               \n","                       [[5.3815e+09]],\n","               \n","                       [[5.5900e+09]],\n","               \n","                       [[7.1799e+09]],\n","               \n","                       [[6.2536e+09]],\n","               \n","                       [[1.8567e+10]],\n","               \n","                       [[5.8205e+09]],\n","               \n","                       [[6.4344e+09]],\n","               \n","                       [[5.0844e+09]],\n","               \n","                       [[4.8623e+09]],\n","               \n","                       [[8.7732e+09]],\n","               \n","                       [[6.9045e+09]],\n","               \n","                       [[6.9271e+09]],\n","               \n","                       [[6.4331e+09]],\n","               \n","                       [[5.1552e+09]],\n","               \n","                       [[5.1681e+09]],\n","               \n","                       [[8.8299e+09]],\n","               \n","                       [[5.7188e+09]],\n","               \n","                       [[6.8503e+09]],\n","               \n","                       [[5.3270e+09]],\n","               \n","                       [[6.3192e+09]],\n","               \n","                       [[9.9169e+09]],\n","               \n","                       [[6.4269e+09]],\n","               \n","                       [[5.3758e+09]],\n","               \n","                       [[6.5245e+09]],\n","               \n","                       [[6.4812e+09]],\n","               \n","                       [[1.3847e+10]],\n","               \n","                       [[5.7892e+09]],\n","               \n","                       [[5.9513e+09]],\n","               \n","                       [[9.2030e+09]],\n","               \n","                       [[8.2482e+09]],\n","               \n","                       [[6.2732e+09]],\n","               \n","                       [[1.3456e+10]],\n","               \n","                       [[5.5923e+09]],\n","               \n","                       [[1.0426e+10]],\n","               \n","                       [[5.8999e+09]],\n","               \n","                       [[6.6395e+09]],\n","               \n","                       [[7.7127e+09]],\n","               \n","                       [[1.1654e+10]],\n","               \n","                       [[5.7805e+09]],\n","               \n","                       [[1.4320e+10]],\n","               \n","                       [[6.4525e+09]],\n","               \n","                       [[6.4026e+09]],\n","               \n","                       [[4.8756e+09]],\n","               \n","                       [[6.5963e+09]],\n","               \n","                       [[1.5420e+10]],\n","               \n","                       [[5.1416e+09]]], device='cuda:0')),\n","              ('module.layer3.5.conv1.is_simulated_quant_weight_shifted',\n","               tensor(False, device='cuda:0')),\n","              ('module.layer3.5.conv1.wrapped_module.weight',\n","               tensor([[[[33974., 26223., 18371.],\n","                         [26672., 37240., 14763.],\n","                         [45026., 39961., 16253.]],\n","               \n","                        [[25756., 22196., 34279.],\n","                         [24715., 27086., 32702.],\n","                         [17400., 33929., 36445.]],\n","               \n","                        [[39002., 26619.,  9556.],\n","                         [47498., 29236., 32647.],\n","                         [23273., 18885., 35847.]],\n","               \n","                        ...,\n","               \n","                        [[22478., 29796., 29866.],\n","                         [28623., 38743., 31431.],\n","                         [27433., 37260., 31733.]],\n","               \n","                        [[19473., 37574., 40164.],\n","                         [39362., 43624., 29827.],\n","                         [ 8556., 13632., 25453.]],\n","               \n","                        [[29906., 27600., 36431.],\n","                         [24191., 38118., 35383.],\n","                         [25277., 32048., 39861.]]],\n","               \n","               \n","                       [[[25904., 28065., 27209.],\n","                         [38926., 30898., 27208.],\n","                         [24291., 46863., 35420.]],\n","               \n","                        [[24168., 25874., 26463.],\n","                         [33036., 30945., 31863.],\n","                         [37360., 32074., 32594.]],\n","               \n","                        [[29399., 35539., 27387.],\n","                         [33647., 34068., 40485.],\n","                         [32178., 35019., 41512.]],\n","               \n","                        ...,\n","               \n","                        [[35509., 33226., 37998.],\n","                         [38560., 37000., 39283.],\n","                         [35429., 30000., 31794.]],\n","               \n","                        [[47072., 55018., 57148.],\n","                         [27324., 44438., 44264.],\n","                         [16816., 28231., 12091.]],\n","               \n","                        [[23642., 24315., 20844.],\n","                         [20532., 21735., 16508.],\n","                         [33008., 31740., 34135.]]],\n","               \n","               \n","                       [[[18637., 10764.,  7153.],\n","                         [32113., 30300.,  5165.],\n","                         [42848., 37132., 32629.]],\n","               \n","                        [[24578., 18650., 22033.],\n","                         [17883., 11939., 16523.],\n","                         [21871., 21272., 14536.]],\n","               \n","                        [[24215., 23768., 29069.],\n","                         [ 8383., 15735., 22081.],\n","                         [ 3857., 10824., 15980.]],\n","               \n","                        ...,\n","               \n","                        [[17662., 16248., 26977.],\n","                         [21483., 18615., 27905.],\n","                         [22683., 18093., 25773.]],\n","               \n","                        [[11084., 10646., 21572.],\n","                         [51958., 29817., 16055.],\n","                         [65535., 33290.,  3033.]],\n","               \n","                        [[54238., 34546.,  4394.],\n","                         [13233., 27953.,  6654.],\n","                         [16245., 18928., 15043.]]],\n","               \n","               \n","                       ...,\n","               \n","               \n","                       [[[33866., 36170., 28275.],\n","                         [28872., 36550., 32980.],\n","                         [41302., 43346., 32838.]],\n","               \n","                        [[27165., 23619., 27689.],\n","                         [27865., 22317., 22669.],\n","                         [28213., 27662., 29564.]],\n","               \n","                        [[26588., 20876., 33216.],\n","                         [37730., 27054., 24805.],\n","                         [31041., 16732., 39301.]],\n","               \n","                        ...,\n","               \n","                        [[37758., 27091., 29996.],\n","                         [35816., 32871., 32399.],\n","                         [30089., 33961., 33482.]],\n","               \n","                        [[25301., 16045., 45597.],\n","                         [36544., 40686., 39672.],\n","                         [39308., 46016., 47147.]],\n","               \n","                        [[25912., 27264., 32978.],\n","                         [20245., 65012., 47632.],\n","                         [18871., 54080., 44849.]]],\n","               \n","               \n","                       [[[28126., 32020., 28953.],\n","                         [25391., 41493., 45852.],\n","                         [55257., 65535., 43894.]],\n","               \n","                        [[29419., 28244., 44078.],\n","                         [23039., 38272., 54892.],\n","                         [35629., 39462., 40383.]],\n","               \n","                        [[15816., 45713., 55985.],\n","                         [14224., 41699., 53160.],\n","                         [ 9901., 34185., 46592.]],\n","               \n","                        ...,\n","               \n","                        [[20067., 25628., 33970.],\n","                         [18033., 24429., 36538.],\n","                         [26253., 30804., 41427.]],\n","               \n","                        [[32969., 25115., 34801.],\n","                         [21737., 16888., 31026.],\n","                         [ 9889., 20025., 27969.]],\n","               \n","                        [[13995., 14035., 20037.],\n","                         [14955., 12174., 32311.],\n","                         [26311., 28625., 33976.]]],\n","               \n","               \n","                       [[[25254., 17122., 24644.],\n","                         [24504., 12089., 21688.],\n","                         [14441.,  8075., 11592.]],\n","               \n","                        [[29869., 31408., 30516.],\n","                         [28415., 32730., 31746.],\n","                         [25684., 26845., 25866.]],\n","               \n","                        [[21215., 25040., 29715.],\n","                         [17766., 33282., 37979.],\n","                         [18296., 35209., 30203.]],\n","               \n","                        ...,\n","               \n","                        [[26427., 21699., 24033.],\n","                         [26814., 22775., 24451.],\n","                         [28652., 23244., 24372.]],\n","               \n","                        [[14875., 25087., 20107.],\n","                         [15796., 22412., 16028.],\n","                         [15986., 24159., 23231.]],\n","               \n","                        [[38715., 24672., 44148.],\n","                         [33087., 30972., 34063.],\n","                         [34608., 28770., 24212.]]]], device='cuda:0')),\n","              ('module.layer3.5.conv1.wrapped_module.bias',\n","               tensor([-1.1804e+09, -3.7245e+08,  7.0772e+08,  4.7483e+08, -5.2263e+08,\n","                       -2.0533e+09, -6.4882e+08, -2.1475e+09, -6.3980e+08, -2.1475e+09,\n","                       -1.0145e+09, -1.7764e+09, -1.5808e+08, -2.1475e+09, -9.1727e+08,\n","                       -2.0991e+09, -2.1475e+09, -7.8272e+08, -5.5887e+08, -1.0601e+09,\n","                       -1.9224e+09, -1.5590e+09, -2.0981e+09, -1.2296e+07, -2.1475e+09,\n","                        8.6125e+08,  1.0969e+08,  1.7170e+09, -2.1475e+09, -1.2902e+09,\n","                       -8.6043e+08, -2.8536e+08, -1.0816e+09,  2.8092e+08, -7.2894e+08,\n","                        1.4811e+09, -1.4867e+09,  4.4590e+08, -1.2769e+09, -1.2915e+09,\n","                        7.3671e+08,  5.8638e+08, -2.1475e+09, -1.0473e+09, -1.0811e+09,\n","                        1.8178e+08, -1.4900e+08, -1.0409e+09, -2.1475e+09, -1.3714e+09,\n","                       -1.8925e+09, -1.0132e+09, -7.0071e+08, -9.2398e+08, -1.8289e+08,\n","                       -1.5516e+09, -2.1475e+09, -2.1475e+09,  1.3085e+09, -1.7563e+08,\n","                       -1.4849e+09,  2.1475e+09, -2.1475e+09,  1.6623e+09], device='cuda:0')),\n","              ('module.layer3.5.conv2.num_forwards',\n","               tensor([40], device='cuda:0')),\n","              ('module.layer3.5.conv2.force_readjust',\n","               tensor(False, device='cuda:0')),\n","              ('module.layer3.5.conv2.output_scale',\n","               tensor([9313.7529], device='cuda:0')),\n","              ('module.layer3.5.conv2.output_zero_point',\n","               tensor([-25436.], device='cuda:0')),\n","              ('module.layer3.5.conv2.w_scale', tensor([[[[202241.9531]]],\n","               \n","               \n","                       [[[ 40242.8281]]],\n","               \n","               \n","                       [[[ 51698.0977]]],\n","               \n","               \n","                       [[[ 53085.8438]]],\n","               \n","               \n","                       [[[ 32229.7793]]],\n","               \n","               \n","                       [[[366721.3750]]],\n","               \n","               \n","                       [[[ 62347.6055]]],\n","               \n","               \n","                       [[[209521.3125]]],\n","               \n","               \n","                       [[[ 74968.7734]]],\n","               \n","               \n","                       [[[ 88824.0938]]],\n","               \n","               \n","                       [[[848555.8750]]],\n","               \n","               \n","                       [[[ 52355.5430]]],\n","               \n","               \n","                       [[[ 65262.8281]]],\n","               \n","               \n","                       [[[ 43840.3477]]],\n","               \n","               \n","                       [[[174190.0000]]],\n","               \n","               \n","                       [[[ 76440.5469]]],\n","               \n","               \n","                       [[[ 60598.3594]]],\n","               \n","               \n","                       [[[101651.9609]]],\n","               \n","               \n","                       [[[ 53490.9570]]],\n","               \n","               \n","                       [[[118845.3438]]],\n","               \n","               \n","                       [[[371021.7812]]],\n","               \n","               \n","                       [[[180247.4844]]],\n","               \n","               \n","                       [[[104161.2266]]],\n","               \n","               \n","                       [[[242954.0781]]],\n","               \n","               \n","                       [[[ 44528.6367]]],\n","               \n","               \n","                       [[[126231.2969]]],\n","               \n","               \n","                       [[[143196.7031]]],\n","               \n","               \n","                       [[[ 84270.7188]]],\n","               \n","               \n","                       [[[ 92261.1172]]],\n","               \n","               \n","                       [[[103225.7656]]],\n","               \n","               \n","                       [[[ 54223.7422]]],\n","               \n","               \n","                       [[[ 79147.5859]]],\n","               \n","               \n","                       [[[100971.7812]]],\n","               \n","               \n","                       [[[ 77938.6484]]],\n","               \n","               \n","                       [[[272318.0312]]],\n","               \n","               \n","                       [[[116191.8047]]],\n","               \n","               \n","                       [[[ 75605.5000]]],\n","               \n","               \n","                       [[[133111.7969]]],\n","               \n","               \n","                       [[[ 64595.0586]]],\n","               \n","               \n","                       [[[ 83652.2109]]],\n","               \n","               \n","                       [[[102861.8516]]],\n","               \n","               \n","                       [[[889779.4375]]],\n","               \n","               \n","                       [[[ 97978.7422]]],\n","               \n","               \n","                       [[[401696.0312]]],\n","               \n","               \n","                       [[[367967.2500]]],\n","               \n","               \n","                       [[[145746.7188]]],\n","               \n","               \n","                       [[[ 52973.7891]]],\n","               \n","               \n","                       [[[ 36828.6680]]],\n","               \n","               \n","                       [[[ 79136.3125]]],\n","               \n","               \n","                       [[[587211.1250]]],\n","               \n","               \n","                       [[[108399.4141]]],\n","               \n","               \n","                       [[[166972.5000]]],\n","               \n","               \n","                       [[[ 43878.2930]]],\n","               \n","               \n","                       [[[205277.5156]]],\n","               \n","               \n","                       [[[405660.7812]]],\n","               \n","               \n","                       [[[ 85506.9375]]],\n","               \n","               \n","                       [[[173038.3750]]],\n","               \n","               \n","                       [[[ 59248.5859]]],\n","               \n","               \n","                       [[[147351.8906]]],\n","               \n","               \n","                       [[[ 84127.7734]]],\n","               \n","               \n","                       [[[ 60323.5977]]],\n","               \n","               \n","                       [[[ 28936.5566]]],\n","               \n","               \n","                       [[[ 87717.1641]]],\n","               \n","               \n","                       [[[ 43475.7031]]]], device='cuda:0')),\n","              ('module.layer3.5.conv2.w_zero_point', tensor([[[[-22897.]]],\n","               \n","               \n","                       [[[-27619.]]],\n","               \n","               \n","                       [[[-32629.]]],\n","               \n","               \n","                       [[[-29002.]]],\n","               \n","               \n","                       [[[-21670.]]],\n","               \n","               \n","                       [[[-31645.]]],\n","               \n","               \n","                       [[[-28392.]]],\n","               \n","               \n","                       [[[-27252.]]],\n","               \n","               \n","                       [[[-27560.]]],\n","               \n","               \n","                       [[[-25870.]]],\n","               \n","               \n","                       [[[-32524.]]],\n","               \n","               \n","                       [[[-28335.]]],\n","               \n","               \n","                       [[[-38259.]]],\n","               \n","               \n","                       [[[-28668.]]],\n","               \n","               \n","                       [[[-26627.]]],\n","               \n","               \n","                       [[[-24285.]]],\n","               \n","               \n","                       [[[-35508.]]],\n","               \n","               \n","                       [[[-31746.]]],\n","               \n","               \n","                       [[[-29552.]]],\n","               \n","               \n","                       [[[-28407.]]],\n","               \n","               \n","                       [[[-33587.]]],\n","               \n","               \n","                       [[[-34265.]]],\n","               \n","               \n","                       [[[-27426.]]],\n","               \n","               \n","                       [[[-40869.]]],\n","               \n","               \n","                       [[[-28937.]]],\n","               \n","               \n","                       [[[-35474.]]],\n","               \n","               \n","                       [[[-35295.]]],\n","               \n","               \n","                       [[[-28604.]]],\n","               \n","               \n","                       [[[-33884.]]],\n","               \n","               \n","                       [[[-29780.]]],\n","               \n","               \n","                       [[[-39836.]]],\n","               \n","               \n","                       [[[-24649.]]],\n","               \n","               \n","                       [[[-27498.]]],\n","               \n","               \n","                       [[[-30548.]]],\n","               \n","               \n","                       [[[-31878.]]],\n","               \n","               \n","                       [[[-37560.]]],\n","               \n","               \n","                       [[[-28430.]]],\n","               \n","               \n","                       [[[-35868.]]],\n","               \n","               \n","                       [[[-32863.]]],\n","               \n","               \n","                       [[[-32268.]]],\n","               \n","               \n","                       [[[-35842.]]],\n","               \n","               \n","                       [[[-32044.]]],\n","               \n","               \n","                       [[[-33951.]]],\n","               \n","               \n","                       [[[-34063.]]],\n","               \n","               \n","                       [[[-34404.]]],\n","               \n","               \n","                       [[[-29455.]]],\n","               \n","               \n","                       [[[-25307.]]],\n","               \n","               \n","                       [[[-28013.]]],\n","               \n","               \n","                       [[[-38564.]]],\n","               \n","               \n","                       [[[-33060.]]],\n","               \n","               \n","                       [[[-30005.]]],\n","               \n","               \n","                       [[[-35303.]]],\n","               \n","               \n","                       [[[-29135.]]],\n","               \n","               \n","                       [[[-35883.]]],\n","               \n","               \n","                       [[[-32560.]]],\n","               \n","               \n","                       [[[-29949.]]],\n","               \n","               \n","                       [[[-34679.]]],\n","               \n","               \n","                       [[[-26482.]]],\n","               \n","               \n","                       [[[-33560.]]],\n","               \n","               \n","                       [[[-36576.]]],\n","               \n","               \n","                       [[[-27037.]]],\n","               \n","               \n","                       [[[-12633.]]],\n","               \n","               \n","                       [[[-35405.]]],\n","               \n","               \n","                       [[[-39176.]]]], device='cuda:0')),\n","              ('module.layer3.5.conv2.fp_bias',\n","               tensor([-0.2179, -0.7575,  0.0059, -0.6007,  0.1979, -0.0687, -0.0384,  0.0300,\n","                       -0.1891, -0.1459, -0.0910, -0.3259, -0.1689,  0.4759, -0.2313,  0.0163,\n","                        0.2572,  0.0421,  0.0735, -0.1273, -0.1875, -0.0052, -0.1973,  0.0287,\n","                       -0.1244,  0.1709, -0.0544, -0.2683, -0.1392,  0.1934,  0.0090, -0.3371,\n","                       -0.1243, -0.2371, -0.0250,  0.0057, -0.2492,  0.2866, -0.0475, -0.0698,\n","                       -0.0507, -0.2286, -0.1862,  0.0251, -0.0405, -0.0571, -1.1059, -0.6912,\n","                       -0.1208,  0.0252, -0.3960,  0.0156,  0.1294, -0.1049,  0.0209, -0.1954,\n","                        0.2125, -0.1858, -0.1488, -0.0234,  0.1882, -0.0098, -0.0272,  0.4460],\n","                      device='cuda:0')),\n","              ('module.layer3.5.conv2.accum_scale', tensor([[[1.1450e+10]],\n","               \n","                       [[2.2783e+09]],\n","               \n","                       [[2.9268e+09]],\n","               \n","                       [[3.0054e+09]],\n","               \n","                       [[1.8246e+09]],\n","               \n","                       [[2.0761e+10]],\n","               \n","                       [[3.5297e+09]],\n","               \n","                       [[1.1862e+10]],\n","               \n","                       [[4.2442e+09]],\n","               \n","                       [[5.0286e+09]],\n","               \n","                       [[4.8039e+10]],\n","               \n","                       [[2.9640e+09]],\n","               \n","                       [[3.6947e+09]],\n","               \n","                       [[2.4819e+09]],\n","               \n","                       [[9.8614e+09]],\n","               \n","                       [[4.3275e+09]],\n","               \n","                       [[3.4307e+09]],\n","               \n","                       [[5.7548e+09]],\n","               \n","                       [[3.0283e+09]],\n","               \n","                       [[6.7282e+09]],\n","               \n","                       [[2.1005e+10]],\n","               \n","                       [[1.0204e+10]],\n","               \n","                       [[5.8969e+09]],\n","               \n","                       [[1.3754e+10]],\n","               \n","                       [[2.5209e+09]],\n","               \n","                       [[7.1463e+09]],\n","               \n","                       [[8.1068e+09]],\n","               \n","                       [[4.7708e+09]],\n","               \n","                       [[5.2232e+09]],\n","               \n","                       [[5.8439e+09]],\n","               \n","                       [[3.0698e+09]],\n","               \n","                       [[4.4808e+09]],\n","               \n","                       [[5.7163e+09]],\n","               \n","                       [[4.4123e+09]],\n","               \n","                       [[1.5417e+10]],\n","               \n","                       [[6.5780e+09]],\n","               \n","                       [[4.2803e+09]],\n","               \n","                       [[7.5359e+09]],\n","               \n","                       [[3.6569e+09]],\n","               \n","                       [[4.7358e+09]],\n","               \n","                       [[5.8233e+09]],\n","               \n","                       [[5.0373e+10]],\n","               \n","                       [[5.5469e+09]],\n","               \n","                       [[2.2741e+10]],\n","               \n","                       [[2.0832e+10]],\n","               \n","                       [[8.2512e+09]],\n","               \n","                       [[2.9990e+09]],\n","               \n","                       [[2.0850e+09]],\n","               \n","                       [[4.4801e+09]],\n","               \n","                       [[3.3244e+10]],\n","               \n","                       [[6.1368e+09]],\n","               \n","                       [[9.4528e+09]],\n","               \n","                       [[2.4841e+09]],\n","               \n","                       [[1.1621e+10]],\n","               \n","                       [[2.2966e+10]],\n","               \n","                       [[4.8408e+09]],\n","               \n","                       [[9.7962e+09]],\n","               \n","                       [[3.3542e+09]],\n","               \n","                       [[8.3420e+09]],\n","               \n","                       [[4.7627e+09]],\n","               \n","                       [[3.4151e+09]],\n","               \n","                       [[1.6382e+09]],\n","               \n","                       [[4.9659e+09]],\n","               \n","                       [[2.4613e+09]]], device='cuda:0')),\n","              ('module.layer3.5.conv2.is_simulated_quant_weight_shifted',\n","               tensor(False, device='cuda:0')),\n","              ('module.layer3.5.conv2.wrapped_module.weight',\n","               tensor([[[[16292., 36259., 57642.],\n","                         [27993., 31620., 24653.],\n","                         [27916., 28515., 17033.]],\n","               \n","                        [[ 7911.,  9628., 17236.],\n","                         [19860., 18814., 28580.],\n","                         [25223., 27784., 22750.]],\n","               \n","                        [[35598., 36164., 27068.],\n","                         [31495., 25898., 19866.],\n","                         [23819., 14320.,  4536.]],\n","               \n","                        ...,\n","               \n","                        [[17219., 16091., 12616.],\n","                         [32662., 23619., 13938.],\n","                         [24732., 15219., 11860.]],\n","               \n","                        [[19443., 24504., 26389.],\n","                         [18036., 16719., 16467.],\n","                         [20066., 19221., 21063.]],\n","               \n","                        [[10558., 15304., 19572.],\n","                         [22872., 28141., 26107.],\n","                         [27604., 28609., 28143.]]],\n","               \n","               \n","                       [[[24602., 28253., 32074.],\n","                         [28647., 31126., 27529.],\n","                         [26956., 14423., 17567.]],\n","               \n","                        [[27331., 27088., 21094.],\n","                         [36646., 27255., 20194.],\n","                         [35826., 16618., 13926.]],\n","               \n","                        [[17002., 24167., 19177.],\n","                         [28918., 34078., 27820.],\n","                         [23173., 15702.,  4852.]],\n","               \n","                        ...,\n","               \n","                        [[24973., 37424., 34588.],\n","                         [15722., 23738., 19863.],\n","                         [29795., 19506., 15646.]],\n","               \n","                        [[32410., 21854., 21627.],\n","                         [45967., 46851., 55750.],\n","                         [26812., 34060., 41553.]],\n","               \n","                        [[26160., 24844., 25780.],\n","                         [30529., 31114., 26723.],\n","                         [25562., 35344., 35628.]]],\n","               \n","               \n","                       [[[32392., 29175., 36452.],\n","                         [26350., 38490., 60583.],\n","                         [22759., 32573., 40209.]],\n","               \n","                        [[31965., 41571., 37752.],\n","                         [24416., 30543., 24333.],\n","                         [18150., 11932., 15666.]],\n","               \n","                        [[30833., 36026., 38017.],\n","                         [29615., 27537., 25269.],\n","                         [31075., 24185., 21786.]],\n","               \n","                        ...,\n","               \n","                        [[37580., 35414., 43274.],\n","                         [40597., 40544., 42696.],\n","                         [52913., 40238., 41556.]],\n","               \n","                        [[41161., 33256., 22601.],\n","                         [40204., 35496., 28505.],\n","                         [29707., 27160., 28908.]],\n","               \n","                        [[44825., 37658., 40135.],\n","                         [28091., 23179., 43281.],\n","                         [25998., 19080., 25507.]]],\n","               \n","               \n","                       ...,\n","               \n","               \n","                       [[[24739., 14213., 18007.],\n","                         [19148., 22576., 24834.],\n","                         [ 5573.,  8972.,    61.]],\n","               \n","                        [[ 5362.,  4596., 11328.],\n","                         [16852., 16699., 16846.],\n","                         [30303., 27486., 19590.]],\n","               \n","                        [[ 6271., 14907., 14869.],\n","                         [10509., 13536.,  8133.],\n","                         [ 9965., 14567., 10045.]],\n","               \n","                        ...,\n","               \n","                        [[10599.,  5137.,  5409.],\n","                         [ 8482.,  7782., 13285.],\n","                         [ 5524., 11848., 21465.]],\n","               \n","                        [[13741., 12693., 10303.],\n","                         [12999., 14954., 13683.],\n","                         [ 7681.,  9445., 10808.]],\n","               \n","                        [[ 8546.,  8402.,  5750.],\n","                         [ 8711.,  8655.,  9282.],\n","                         [12022., 13924., 14266.]]],\n","               \n","               \n","                       [[[40948., 38691., 25327.],\n","                         [29341., 38998., 31109.],\n","                         [20841., 20563., 33260.]],\n","               \n","                        [[50714., 15514., 11107.],\n","                         [47408., 21889., 18579.],\n","                         [22286., 17286., 36754.]],\n","               \n","                        [[31997., 45920., 60793.],\n","                         [18925., 25957., 46351.],\n","                         [11675., 15209., 27839.]],\n","               \n","                        ...,\n","               \n","                        [[39336., 48052., 27360.],\n","                         [50973., 55330., 35553.],\n","                         [52682., 54160., 31726.]],\n","               \n","                        [[24877., 24574., 32816.],\n","                         [37473., 39513., 45816.],\n","                         [36278., 40532., 42351.]],\n","               \n","                        [[36656., 31978., 34075.],\n","                         [32916., 32442., 34418.],\n","                         [36785., 36622., 25082.]]],\n","               \n","               \n","                       [[[48713., 20393., 16345.],\n","                         [40314., 40598., 40811.],\n","                         [49790., 44594., 31555.]],\n","               \n","                        [[44071., 41380., 31034.],\n","                         [41752., 39223., 30100.],\n","                         [24613., 35788., 41867.]],\n","               \n","                        [[41102., 38162., 17882.],\n","                         [38279., 54014., 40809.],\n","                         [37427., 51541., 44612.]],\n","               \n","                        ...,\n","               \n","                        [[40008., 32966., 36375.],\n","                         [31716., 21455., 33134.],\n","                         [42166., 43838., 37714.]],\n","               \n","                        [[49239., 40946., 28744.],\n","                         [38404., 37994., 36138.],\n","                         [35634., 35525., 36574.]],\n","               \n","                        [[29658., 36177., 44566.],\n","                         [30361., 41316., 35299.],\n","                         [37137., 38678., 25020.]]]], device='cuda:0')),\n","              ('module.layer3.5.conv2.wrapped_module.bias',\n","               tensor([-2.1475e+09, -1.7259e+09,  1.7366e+07, -1.8053e+09,  3.6103e+08,\n","                       -1.4270e+09, -1.3556e+08,  3.5638e+08, -8.0244e+08, -7.3382e+08,\n","                       -2.1475e+09, -9.6594e+08, -6.2397e+08,  1.1813e+09, -2.1475e+09,\n","                        7.0558e+07,  8.8231e+08,  2.4254e+08,  2.2267e+08, -8.5671e+08,\n","                       -2.1475e+09, -5.2789e+07, -1.1635e+09,  3.9519e+08, -3.1349e+08,\n","                        1.2216e+09, -4.4095e+08, -1.2798e+09, -7.2721e+08,  1.1305e+09,\n","                        2.7693e+07, -1.5104e+09, -7.1067e+08, -1.0460e+09, -3.8559e+08,\n","                        3.7742e+07, -1.0667e+09,  2.1475e+09, -1.7365e+08, -3.3072e+08,\n","                       -2.9504e+08, -2.1475e+09, -1.0331e+09,  5.7081e+08, -8.4307e+08,\n","                       -4.7083e+08, -2.1475e+09, -1.4411e+09, -5.4110e+08,  8.3776e+08,\n","                       -2.1475e+09,  1.4765e+08,  3.2150e+08, -1.2195e+09,  4.8102e+08,\n","                       -9.4596e+08,  2.0815e+09, -6.2321e+08, -1.2415e+09, -1.1140e+08,\n","                        6.4261e+08, -1.6014e+07, -1.3521e+08,  1.0977e+09], device='cuda:0')),\n","              ('module.layer3.5.relu2.num_forwards',\n","               tensor([40], device='cuda:0')),\n","              ('module.layer3.5.relu2.force_readjust',\n","               tensor(False, device='cuda:0')),\n","              ('module.layer3.5.relu2.output_scale',\n","               tensor([6673.8643], device='cuda:0')),\n","              ('module.layer3.5.relu2.output_zero_point',\n","               tensor([0.], device='cuda:0')),\n","              ('module.layer3.5.residual_eltwiseadd.num_forwards',\n","               tensor([40], device='cuda:0')),\n","              ('module.layer3.5.residual_eltwiseadd.force_readjust',\n","               tensor(False, device='cuda:0')),\n","              ('module.layer3.5.residual_eltwiseadd.output_scale',\n","               tensor([6673.8643], device='cuda:0')),\n","              ('module.layer3.5.residual_eltwiseadd.output_zero_point',\n","               tensor([0.], device='cuda:0')),\n","              ('module.layer3.6.conv1.num_forwards',\n","               tensor([40], device='cuda:0')),\n","              ('module.layer3.6.conv1.force_readjust',\n","               tensor(False, device='cuda:0')),\n","              ('module.layer3.6.conv1.output_scale',\n","               tensor([38243.2891], device='cuda:0')),\n","              ('module.layer3.6.conv1.output_zero_point',\n","               tensor([0.], device='cuda:0')),\n","              ('module.layer3.6.conv1.w_scale', tensor([[[[ 928775.2500]]],\n","               \n","               \n","                       [[[ 894328.0000]]],\n","               \n","               \n","                       [[[ 652519.6250]]],\n","               \n","               \n","                       [[[ 871853.3125]]],\n","               \n","               \n","                       [[[1321869.8750]]],\n","               \n","               \n","                       [[[1446927.8750]]],\n","               \n","               \n","                       [[[1318146.1250]]],\n","               \n","               \n","                       [[[ 656472.3125]]],\n","               \n","               \n","                       [[[1016727.3125]]],\n","               \n","               \n","                       [[[ 614531.7500]]],\n","               \n","               \n","                       [[[ 618265.2500]]],\n","               \n","               \n","                       [[[ 789554.7500]]],\n","               \n","               \n","                       [[[ 697766.8750]]],\n","               \n","               \n","                       [[[ 871049.6250]]],\n","               \n","               \n","                       [[[ 559376.4375]]],\n","               \n","               \n","                       [[[ 810358.5625]]],\n","               \n","               \n","                       [[[ 861731.6875]]],\n","               \n","               \n","                       [[[ 588773.4375]]],\n","               \n","               \n","                       [[[ 705233.5625]]],\n","               \n","               \n","                       [[[1894056.7500]]],\n","               \n","               \n","                       [[[ 887089.1250]]],\n","               \n","               \n","                       [[[1020573.0625]]],\n","               \n","               \n","                       [[[ 524241.1250]]],\n","               \n","               \n","                       [[[ 483449.8750]]],\n","               \n","               \n","                       [[[ 654002.7500]]],\n","               \n","               \n","                       [[[ 641714.1250]]],\n","               \n","               \n","                       [[[ 742104.9375]]],\n","               \n","               \n","                       [[[1427884.3750]]],\n","               \n","               \n","                       [[[1054535.3750]]],\n","               \n","               \n","                       [[[ 818996.6875]]],\n","               \n","               \n","                       [[[ 522410.5312]]],\n","               \n","               \n","                       [[[ 632047.1875]]],\n","               \n","               \n","                       [[[2216120.0000]]],\n","               \n","               \n","                       [[[ 529817.6875]]],\n","               \n","               \n","                       [[[ 929237.8125]]],\n","               \n","               \n","                       [[[1087931.2500]]],\n","               \n","               \n","                       [[[ 838965.7500]]],\n","               \n","               \n","                       [[[ 605904.6875]]],\n","               \n","               \n","                       [[[ 618280.1875]]],\n","               \n","               \n","                       [[[ 632872.1875]]],\n","               \n","               \n","                       [[[1311492.0000]]],\n","               \n","               \n","                       [[[ 764786.7500]]],\n","               \n","               \n","                       [[[ 855791.6250]]],\n","               \n","               \n","                       [[[ 564886.1875]]],\n","               \n","               \n","                       [[[ 802389.8125]]],\n","               \n","               \n","                       [[[ 635597.6875]]],\n","               \n","               \n","                       [[[ 748794.2500]]],\n","               \n","               \n","                       [[[1025966.9375]]],\n","               \n","               \n","                       [[[ 476303.2500]]],\n","               \n","               \n","                       [[[ 616357.0625]]],\n","               \n","               \n","                       [[[ 691617.1250]]],\n","               \n","               \n","                       [[[ 498217.1562]]],\n","               \n","               \n","                       [[[ 720391.4375]]],\n","               \n","               \n","                       [[[1101696.0000]]],\n","               \n","               \n","                       [[[1063729.1250]]],\n","               \n","               \n","                       [[[1103944.2500]]],\n","               \n","               \n","                       [[[1065099.1250]]],\n","               \n","               \n","                       [[[1120490.8750]]],\n","               \n","               \n","                       [[[1001576.8125]]],\n","               \n","               \n","                       [[[ 655514.1250]]],\n","               \n","               \n","                       [[[ 603708.1875]]],\n","               \n","               \n","                       [[[ 629710.0000]]],\n","               \n","               \n","                       [[[ 958303.3750]]],\n","               \n","               \n","                       [[[ 769881.7500]]]], device='cuda:0')),\n","              ('module.layer3.6.conv1.w_zero_point', tensor([[[[-27266.]]],\n","               \n","               \n","                       [[[-27915.]]],\n","               \n","               \n","                       [[[-27099.]]],\n","               \n","               \n","                       [[[-27464.]]],\n","               \n","               \n","                       [[[-29771.]]],\n","               \n","               \n","                       [[[-26104.]]],\n","               \n","               \n","                       [[[-26808.]]],\n","               \n","               \n","                       [[[-25071.]]],\n","               \n","               \n","                       [[[-30265.]]],\n","               \n","               \n","                       [[[-28113.]]],\n","               \n","               \n","                       [[[-27156.]]],\n","               \n","               \n","                       [[[-31208.]]],\n","               \n","               \n","                       [[[-29722.]]],\n","               \n","               \n","                       [[[-25599.]]],\n","               \n","               \n","                       [[[-29249.]]],\n","               \n","               \n","                       [[[-29562.]]],\n","               \n","               \n","                       [[[-34034.]]],\n","               \n","               \n","                       [[[-21822.]]],\n","               \n","               \n","                       [[[-22731.]]],\n","               \n","               \n","                       [[[-27925.]]],\n","               \n","               \n","                       [[[-29148.]]],\n","               \n","               \n","                       [[[-29274.]]],\n","               \n","               \n","                       [[[-28011.]]],\n","               \n","               \n","                       [[[-25813.]]],\n","               \n","               \n","                       [[[-27486.]]],\n","               \n","               \n","                       [[[-29922.]]],\n","               \n","               \n","                       [[[-30355.]]],\n","               \n","               \n","                       [[[-26620.]]],\n","               \n","               \n","                       [[[-32361.]]],\n","               \n","               \n","                       [[[-30431.]]],\n","               \n","               \n","                       [[[-26238.]]],\n","               \n","               \n","                       [[[-28613.]]],\n","               \n","               \n","                       [[[-22592.]]],\n","               \n","               \n","                       [[[-27564.]]],\n","               \n","               \n","                       [[[-29709.]]],\n","               \n","               \n","                       [[[-31198.]]],\n","               \n","               \n","                       [[[-36134.]]],\n","               \n","               \n","                       [[[-33862.]]],\n","               \n","               \n","                       [[[-17792.]]],\n","               \n","               \n","                       [[[-26151.]]],\n","               \n","               \n","                       [[[-31671.]]],\n","               \n","               \n","                       [[[-25905.]]],\n","               \n","               \n","                       [[[-34199.]]],\n","               \n","               \n","                       [[[-29673.]]],\n","               \n","               \n","                       [[[-32138.]]],\n","               \n","               \n","                       [[[-29433.]]],\n","               \n","               \n","                       [[[-30447.]]],\n","               \n","               \n","                       [[[-29906.]]],\n","               \n","               \n","                       [[[-38643.]]],\n","               \n","               \n","                       [[[-24543.]]],\n","               \n","               \n","                       [[[-27396.]]],\n","               \n","               \n","                       [[[-28474.]]],\n","               \n","               \n","                       [[[-21033.]]],\n","               \n","               \n","                       [[[-24849.]]],\n","               \n","               \n","                       [[[-28586.]]],\n","               \n","               \n","                       [[[-29912.]]],\n","               \n","               \n","                       [[[-26957.]]],\n","               \n","               \n","                       [[[-27971.]]],\n","               \n","               \n","                       [[[-31997.]]],\n","               \n","               \n","                       [[[-29478.]]],\n","               \n","               \n","                       [[[-31511.]]],\n","               \n","               \n","                       [[[-27763.]]],\n","               \n","               \n","                       [[[-30615.]]],\n","               \n","               \n","                       [[[-26122.]]]], device='cuda:0')),\n","              ('module.layer3.6.conv1.fp_bias',\n","               tensor([-0.0639, -0.1586, -0.1174, -0.1785, -0.2036, -0.1114, -0.0606, -0.0937,\n","                       -0.2508, -0.3548, -0.1263, -0.1535,  0.0266, -0.1215, -0.1828, -0.2766,\n","                       -0.0923, -0.5072, -0.3017,  0.0420, -0.1552, -0.0576, -0.1898, -0.3873,\n","                       -0.0132, -0.3040, -0.1307, -0.1622,  0.2160, -0.2444, -0.0119, -0.2714,\n","                       -0.0485, -0.0587,  0.0467, -0.3063, -0.0489, -0.3003, -0.3103, -0.1403,\n","                       -0.0727, -0.3094, -0.2159, -0.0764, -0.2862, -0.3549, -0.1253, -0.1990,\n","                       -0.0434, -0.2021, -0.3523, -0.1334, -0.5031, -0.0298, -0.0618,  0.3560,\n","                       -0.4056, -0.3298,  0.2244, -0.1524, -0.1732, -0.1338, -0.0053,  0.2595],\n","                      device='cuda:0')),\n","              ('module.layer3.6.conv1.accum_scale', tensor([[[6.1985e+09]],\n","               \n","                       [[5.9686e+09]],\n","               \n","                       [[4.3548e+09]],\n","               \n","                       [[5.8186e+09]],\n","               \n","                       [[8.8220e+09]],\n","               \n","                       [[9.6566e+09]],\n","               \n","                       [[8.7971e+09]],\n","               \n","                       [[4.3812e+09]],\n","               \n","                       [[6.7855e+09]],\n","               \n","                       [[4.1013e+09]],\n","               \n","                       [[4.1262e+09]],\n","               \n","                       [[5.2694e+09]],\n","               \n","                       [[4.6568e+09]],\n","               \n","                       [[5.8133e+09]],\n","               \n","                       [[3.7332e+09]],\n","               \n","                       [[5.4082e+09]],\n","               \n","                       [[5.7511e+09]],\n","               \n","                       [[3.9294e+09]],\n","               \n","                       [[4.7066e+09]],\n","               \n","                       [[1.2641e+10]],\n","               \n","                       [[5.9203e+09]],\n","               \n","                       [[6.8112e+09]],\n","               \n","                       [[3.4987e+09]],\n","               \n","                       [[3.2265e+09]],\n","               \n","                       [[4.3647e+09]],\n","               \n","                       [[4.2827e+09]],\n","               \n","                       [[4.9527e+09]],\n","               \n","                       [[9.5295e+09]],\n","               \n","                       [[7.0378e+09]],\n","               \n","                       [[5.4659e+09]],\n","               \n","                       [[3.4865e+09]],\n","               \n","                       [[4.2182e+09]],\n","               \n","                       [[1.4790e+10]],\n","               \n","                       [[3.5359e+09]],\n","               \n","                       [[6.2016e+09]],\n","               \n","                       [[7.2607e+09]],\n","               \n","                       [[5.5991e+09]],\n","               \n","                       [[4.0437e+09]],\n","               \n","                       [[4.1263e+09]],\n","               \n","                       [[4.2237e+09]],\n","               \n","                       [[8.7527e+09]],\n","               \n","                       [[5.1041e+09]],\n","               \n","                       [[5.7114e+09]],\n","               \n","                       [[3.7700e+09]],\n","               \n","                       [[5.3550e+09]],\n","               \n","                       [[4.2419e+09]],\n","               \n","                       [[4.9974e+09]],\n","               \n","                       [[6.8472e+09]],\n","               \n","                       [[3.1788e+09]],\n","               \n","                       [[4.1135e+09]],\n","               \n","                       [[4.6158e+09]],\n","               \n","                       [[3.3250e+09]],\n","               \n","                       [[4.8078e+09]],\n","               \n","                       [[7.3526e+09]],\n","               \n","                       [[7.0992e+09]],\n","               \n","                       [[7.3676e+09]],\n","               \n","                       [[7.1083e+09]],\n","               \n","                       [[7.4780e+09]],\n","               \n","                       [[6.6844e+09]],\n","               \n","                       [[4.3748e+09]],\n","               \n","                       [[4.0291e+09]],\n","               \n","                       [[4.2026e+09]],\n","               \n","                       [[6.3956e+09]],\n","               \n","                       [[5.1381e+09]]], device='cuda:0')),\n","              ('module.layer3.6.conv1.is_simulated_quant_weight_shifted',\n","               tensor(False, device='cuda:0')),\n","              ('module.layer3.6.conv1.wrapped_module.weight',\n","               tensor([[[[29368., 26714., 22643.],\n","                         [28837., 20026., 17596.],\n","                         [26227., 13669.,  8512.]],\n","               \n","                        [[42174., 40216., 20483.],\n","                         [33106., 34944., 25583.],\n","                         [27863., 33671., 34389.]],\n","               \n","                        [[32058., 25449., 27136.],\n","                         [30970., 27160., 17834.],\n","                         [53324., 47238., 32061.]],\n","               \n","                        ...,\n","               \n","                        [[19346., 22460., 22703.],\n","                         [18325., 32122., 37866.],\n","                         [21454., 36786., 41484.]],\n","               \n","                        [[20415., 20217., 11674.],\n","                         [16842., 17084., 13260.],\n","                         [11374., 32944., 36288.]],\n","               \n","                        [[38520., 34873., 29846.],\n","                         [30751., 16332., 12564.],\n","                         [29294., 13926., 14592.]]],\n","               \n","               \n","                       [[[27745., 21530., 17490.],\n","                         [29832., 32661., 14111.],\n","                         [36156., 45487.,  9246.]],\n","               \n","                        [[20982., 16992., 19155.],\n","                         [23930., 15920., 27702.],\n","                         [27746., 25470., 31073.]],\n","               \n","                        [[ 5689.,  4359.,  5445.],\n","                         [ 5155., 17662., 19474.],\n","                         [24402., 20731., 31964.]],\n","               \n","                        ...,\n","               \n","                        [[14613., 32542., 41609.],\n","                         [15701., 25972., 26572.],\n","                         [31381., 26849., 23013.]],\n","               \n","                        [[21274., 11624., 12198.],\n","                         [26540., 19066., 22554.],\n","                         [23485., 21660., 11714.]],\n","               \n","                        [[47511., 36205., 34542.],\n","                         [40660., 40748., 23091.],\n","                         [39339., 40371., 21120.]]],\n","               \n","               \n","                       [[[37831., 39029., 39041.],\n","                         [43333., 33738., 19363.],\n","                         [40246., 33414., 26752.]],\n","               \n","                        [[27616., 34000., 39334.],\n","                         [32200., 35665., 35007.],\n","                         [26729., 21212., 22807.]],\n","               \n","                        [[25340.,  9364.,  4243.],\n","                         [47223., 39783., 46898.],\n","                         [23583., 46346., 40251.]],\n","               \n","                        ...,\n","               \n","                        [[29457., 26125., 22983.],\n","                         [17691., 17092., 20542.],\n","                         [11612., 15540., 20901.]],\n","               \n","                        [[25218., 32172., 29049.],\n","                         [20924., 21956., 22177.],\n","                         [20038.,  7849., 10485.]],\n","               \n","                        [[45051., 33430., 23736.],\n","                         [32308., 25387.,  9169.],\n","                         [ 3304.,  2413.,  8680.]]],\n","               \n","               \n","                       ...,\n","               \n","               \n","                       [[[36037., 30174., 27359.],\n","                         [17644., 20513., 19130.],\n","                         [15475.,  9255.,  9493.]],\n","               \n","                        [[28147., 33773., 29839.],\n","                         [24291., 27428., 24720.],\n","                         [31124., 27023., 26619.]],\n","               \n","                        [[33396., 33794., 28566.],\n","                         [19596., 21287., 28249.],\n","                         [22452., 26644., 38861.]],\n","               \n","                        ...,\n","               \n","                        [[33511., 34841., 34266.],\n","                         [29029., 26550., 29927.],\n","                         [30045., 18798., 19887.]],\n","               \n","                        [[25748., 30601., 25870.],\n","                         [39519., 48064., 37844.],\n","                         [29357., 38658., 30633.]],\n","               \n","                        [[12127.,     0., 14169.],\n","                         [15696., 21536., 26265.],\n","                         [41182., 42322., 28570.]]],\n","               \n","               \n","                       [[[21032., 28132., 19385.],\n","                         [25853., 28408., 19605.],\n","                         [19618., 13216., 18651.]],\n","               \n","                        [[16124., 11230., 22968.],\n","                         [30550., 24947., 25846.],\n","                         [24738., 24186., 22547.]],\n","               \n","                        [[40858., 27653., 16287.],\n","                         [30969., 16744., 24540.],\n","                         [17805., 17058., 24425.]],\n","               \n","                        ...,\n","               \n","                        [[27997., 36815., 37274.],\n","                         [39414., 48656., 41469.],\n","                         [35334., 39915., 24578.]],\n","               \n","                        [[26696., 40812., 37215.],\n","                         [25690., 14074., 17685.],\n","                         [20743., 11740., 16664.]],\n","               \n","                        [[34835., 26024., 29272.],\n","                         [27176., 14333., 21612.],\n","                         [24545., 18526., 22224.]]],\n","               \n","               \n","                       [[[25069., 29709., 26615.],\n","                         [20157., 29487., 21386.],\n","                         [ 7767., 27081., 24700.]],\n","               \n","                        [[22693., 14097.,  5086.],\n","                         [22800., 25308., 19547.],\n","                         [11730., 22068., 25474.]],\n","               \n","                        [[24735., 18853., 16226.],\n","                         [36268., 31009., 21376.],\n","                         [37674., 36468., 13993.]],\n","               \n","                        ...,\n","               \n","                        [[21216., 18147., 14770.],\n","                         [25389., 22443., 11952.],\n","                         [22938., 20306., 18393.]],\n","               \n","                        [[25209., 21692., 21326.],\n","                         [15794., 20879., 20156.],\n","                         [ 8834., 12369., 18985.]],\n","               \n","                        [[60157., 33055., 23428.],\n","                         [65535., 39015., 28316.],\n","                         [36928., 36222., 27611.]]]], device='cuda:0')),\n","              ('module.layer3.6.conv1.wrapped_module.bias',\n","               tensor([-3.9586e+08, -9.4663e+08, -5.1122e+08, -1.0389e+09, -1.7965e+09,\n","                       -1.0761e+09, -5.3286e+08, -4.1040e+08, -1.7015e+09, -1.4551e+09,\n","                       -5.2119e+08, -8.0880e+08,  1.2409e+08, -7.0647e+08, -6.8240e+08,\n","                       -1.4960e+09, -5.3067e+08, -1.9928e+09, -1.4201e+09,  5.3048e+08,\n","                       -9.1913e+08, -3.9202e+08, -6.6419e+08, -1.2496e+09, -5.7426e+07,\n","                       -1.3019e+09, -6.4718e+08, -1.5453e+09,  1.5199e+09, -1.3357e+09,\n","                       -4.1528e+07, -1.1449e+09, -7.1790e+08, -2.0768e+08,  2.8931e+08,\n","                       -2.1475e+09, -2.7382e+08, -1.2144e+09, -1.2803e+09, -5.9241e+08,\n","                       -6.3671e+08, -1.5792e+09, -1.2330e+09, -2.8794e+08, -1.5326e+09,\n","                       -1.5055e+09, -6.2610e+08, -1.3629e+09, -1.3794e+08, -8.3127e+08,\n","                       -1.6263e+09, -4.4343e+08, -2.1475e+09, -2.1896e+08, -4.3879e+08,\n","                        2.1475e+09, -2.1475e+09, -2.1475e+09,  1.5000e+09, -6.6664e+08,\n","                       -6.9785e+08, -5.6213e+08, -3.4054e+07,  1.3335e+09], device='cuda:0')),\n","              ('module.layer3.6.conv2.num_forwards',\n","               tensor([40], device='cuda:0')),\n","              ('module.layer3.6.conv2.force_readjust',\n","               tensor(False, device='cuda:0')),\n","              ('module.layer3.6.conv2.output_scale',\n","               tensor([5706.8755], device='cuda:0')),\n","              ('module.layer3.6.conv2.output_zero_point',\n","               tensor([-22449.], device='cuda:0')),\n","              ('module.layer3.6.conv2.w_scale', tensor([[[[  38409.0234]]],\n","               \n","               \n","                       [[[  41870.6055]]],\n","               \n","               \n","                       [[[  59839.5273]]],\n","               \n","               \n","                       [[[  43542.4180]]],\n","               \n","               \n","                       [[[  58129.9570]]],\n","               \n","               \n","                       [[[ 134058.8125]]],\n","               \n","               \n","                       [[[  56853.9375]]],\n","               \n","               \n","                       [[[ 220376.0469]]],\n","               \n","               \n","                       [[[  37827.6172]]],\n","               \n","               \n","                       [[[ 106781.3125]]],\n","               \n","               \n","                       [[[ 130512.5938]]],\n","               \n","               \n","                       [[[  57092.2070]]],\n","               \n","               \n","                       [[[  86793.4453]]],\n","               \n","               \n","                       [[[  62490.0312]]],\n","               \n","               \n","                       [[[  51722.4648]]],\n","               \n","               \n","                       [[[  75934.2578]]],\n","               \n","               \n","                       [[[ 105417.0859]]],\n","               \n","               \n","                       [[[  82577.6016]]],\n","               \n","               \n","                       [[[  77245.2188]]],\n","               \n","               \n","                       [[[  78908.1875]]],\n","               \n","               \n","                       [[[  50036.5781]]],\n","               \n","               \n","                       [[[  82949.0312]]],\n","               \n","               \n","                       [[[ 283493.1250]]],\n","               \n","               \n","                       [[[  76381.8281]]],\n","               \n","               \n","                       [[[  40862.5859]]],\n","               \n","               \n","                       [[[ 107165.8438]]],\n","               \n","               \n","                       [[[  80945.5938]]],\n","               \n","               \n","                       [[[ 129015.5781]]],\n","               \n","               \n","                       [[[ 126025.7891]]],\n","               \n","               \n","                       [[[ 103535.0781]]],\n","               \n","               \n","                       [[[  43302.5273]]],\n","               \n","               \n","                       [[[  94673.1094]]],\n","               \n","               \n","                       [[[  89368.7969]]],\n","               \n","               \n","                       [[[ 164344.4375]]],\n","               \n","               \n","                       [[[ 105447.9922]]],\n","               \n","               \n","                       [[[  73992.9141]]],\n","               \n","               \n","                       [[[  55204.0039]]],\n","               \n","               \n","                       [[[  84260.3203]]],\n","               \n","               \n","                       [[[  47151.3438]]],\n","               \n","               \n","                       [[[  71814.2422]]],\n","               \n","               \n","                       [[[  86348.4141]]],\n","               \n","               \n","                       [[[ 100149.4219]]],\n","               \n","               \n","                       [[[  40581.7500]]],\n","               \n","               \n","                       [[[  97084.1328]]],\n","               \n","               \n","                       [[[ 176477.4844]]],\n","               \n","               \n","                       [[[ 177842.1562]]],\n","               \n","               \n","                       [[[ 337970.0625]]],\n","               \n","               \n","                       [[[  43921.5625]]],\n","               \n","               \n","                       [[[  59659.1641]]],\n","               \n","               \n","                       [[[2231790.7500]]],\n","               \n","               \n","                       [[[  44681.5156]]],\n","               \n","               \n","                       [[[ 252206.1250]]],\n","               \n","               \n","                       [[[  98475.9922]]],\n","               \n","               \n","                       [[[  59171.5508]]],\n","               \n","               \n","                       [[[ 625279.2500]]],\n","               \n","               \n","                       [[[  95122.6953]]],\n","               \n","               \n","                       [[[ 307848.8750]]],\n","               \n","               \n","                       [[[ 111974.5625]]],\n","               \n","               \n","                       [[[  73553.0391]]],\n","               \n","               \n","                       [[[  83032.3906]]],\n","               \n","               \n","                       [[[ 101930.4531]]],\n","               \n","               \n","                       [[[ 163955.6875]]],\n","               \n","               \n","                       [[[  51699.3828]]],\n","               \n","               \n","                       [[[ 138214.0625]]]], device='cuda:0')),\n","              ('module.layer3.6.conv2.w_zero_point', tensor([[[[-27862.]]],\n","               \n","               \n","                       [[[-27084.]]],\n","               \n","               \n","                       [[[-25856.]]],\n","               \n","               \n","                       [[[-25313.]]],\n","               \n","               \n","                       [[[-21866.]]],\n","               \n","               \n","                       [[[-28759.]]],\n","               \n","               \n","                       [[[-26407.]]],\n","               \n","               \n","                       [[[-26059.]]],\n","               \n","               \n","                       [[[-22927.]]],\n","               \n","               \n","                       [[[-29925.]]],\n","               \n","               \n","                       [[[-32482.]]],\n","               \n","               \n","                       [[[-25447.]]],\n","               \n","               \n","                       [[[-29354.]]],\n","               \n","               \n","                       [[[-33543.]]],\n","               \n","               \n","                       [[[-22529.]]],\n","               \n","               \n","                       [[[-32585.]]],\n","               \n","               \n","                       [[[-32382.]]],\n","               \n","               \n","                       [[[-27712.]]],\n","               \n","               \n","                       [[[-29895.]]],\n","               \n","               \n","                       [[[-28422.]]],\n","               \n","               \n","                       [[[-29456.]]],\n","               \n","               \n","                       [[[-27369.]]],\n","               \n","               \n","                       [[[-30988.]]],\n","               \n","               \n","                       [[[-27195.]]],\n","               \n","               \n","                       [[[-23137.]]],\n","               \n","               \n","                       [[[-28082.]]],\n","               \n","               \n","                       [[[-34132.]]],\n","               \n","               \n","                       [[[-31347.]]],\n","               \n","               \n","                       [[[-30930.]]],\n","               \n","               \n","                       [[[-27555.]]],\n","               \n","               \n","                       [[[-28477.]]],\n","               \n","               \n","                       [[[-29069.]]],\n","               \n","               \n","                       [[[-24896.]]],\n","               \n","               \n","                       [[[-36071.]]],\n","               \n","               \n","                       [[[-21613.]]],\n","               \n","               \n","                       [[[-23271.]]],\n","               \n","               \n","                       [[[-26395.]]],\n","               \n","               \n","                       [[[-31033.]]],\n","               \n","               \n","                       [[[-27076.]]],\n","               \n","               \n","                       [[[-28790.]]],\n","               \n","               \n","                       [[[-20059.]]],\n","               \n","               \n","                       [[[-31388.]]],\n","               \n","               \n","                       [[[-28666.]]],\n","               \n","               \n","                       [[[-32388.]]],\n","               \n","               \n","                       [[[-17529.]]],\n","               \n","               \n","                       [[[-34599.]]],\n","               \n","               \n","                       [[[-21077.]]],\n","               \n","               \n","                       [[[-19277.]]],\n","               \n","               \n","                       [[[-28303.]]],\n","               \n","               \n","                       [[[-28023.]]],\n","               \n","               \n","                       [[[-23946.]]],\n","               \n","               \n","                       [[[-29356.]]],\n","               \n","               \n","                       [[[-31502.]]],\n","               \n","               \n","                       [[[-27170.]]],\n","               \n","               \n","                       [[[-33883.]]],\n","               \n","               \n","                       [[[-28586.]]],\n","               \n","               \n","                       [[[-29936.]]],\n","               \n","               \n","                       [[[-28967.]]],\n","               \n","               \n","                       [[[-26160.]]],\n","               \n","               \n","                       [[[-35122.]]],\n","               \n","               \n","                       [[[-34382.]]],\n","               \n","               \n","                       [[[-28601.]]],\n","               \n","               \n","                       [[[-25438.]]],\n","               \n","               \n","                       [[[-23211.]]]], device='cuda:0')),\n","              ('module.layer3.6.conv2.fp_bias',\n","               tensor([-0.1645, -0.5019,  0.3573,  0.0137, -0.3104, -0.2346, -0.2460,  0.0415,\n","                       -0.7425, -0.0976,  0.0583, -0.1467, -0.0418, -0.1442, -0.4395, -0.0910,\n","                       -0.1014, -0.1291, -0.4214,  0.1471, -0.2627, -0.4744,  0.0785, -0.3285,\n","                       -0.6951, -0.2827, -0.2000,  0.1535, -0.2903, -0.1486, -0.2774, -0.2515,\n","                        0.1117, -0.1024, -0.3017, -0.2587, -1.1960,  0.1613, -0.0073, -0.3262,\n","                       -0.3486, -0.1668, -0.8430, -0.0037, -0.0224,  0.0693, -0.2473, -0.6596,\n","                       -0.1305, -0.0090, -0.9160,  0.0145,  0.0835, -0.7019, -0.0281,  0.1888,\n","                       -0.0334, -0.2370, -0.2475,  0.0286,  0.1470,  0.0750, -0.0771, -0.0980],\n","                      device='cuda:0')),\n","              ('module.layer3.6.conv2.accum_scale', tensor([[[1.4689e+09]],\n","               \n","                       [[1.6013e+09]],\n","               \n","                       [[2.2885e+09]],\n","               \n","                       [[1.6652e+09]],\n","               \n","                       [[2.2231e+09]],\n","               \n","                       [[5.1269e+09]],\n","               \n","                       [[2.1743e+09]],\n","               \n","                       [[8.4279e+09]],\n","               \n","                       [[1.4467e+09]],\n","               \n","                       [[4.0837e+09]],\n","               \n","                       [[4.9912e+09]],\n","               \n","                       [[2.1834e+09]],\n","               \n","                       [[3.3193e+09]],\n","               \n","                       [[2.3898e+09]],\n","               \n","                       [[1.9780e+09]],\n","               \n","                       [[2.9040e+09]],\n","               \n","                       [[4.0315e+09]],\n","               \n","                       [[3.1580e+09]],\n","               \n","                       [[2.9541e+09]],\n","               \n","                       [[3.0177e+09]],\n","               \n","                       [[1.9136e+09]],\n","               \n","                       [[3.1722e+09]],\n","               \n","                       [[1.0842e+10]],\n","               \n","                       [[2.9211e+09]],\n","               \n","                       [[1.5627e+09]],\n","               \n","                       [[4.0984e+09]],\n","               \n","                       [[3.0956e+09]],\n","               \n","                       [[4.9340e+09]],\n","               \n","                       [[4.8196e+09]],\n","               \n","                       [[3.9595e+09]],\n","               \n","                       [[1.6560e+09]],\n","               \n","                       [[3.6206e+09]],\n","               \n","                       [[3.4178e+09]],\n","               \n","                       [[6.2851e+09]],\n","               \n","                       [[4.0327e+09]],\n","               \n","                       [[2.8297e+09]],\n","               \n","                       [[2.1112e+09]],\n","               \n","                       [[3.2224e+09]],\n","               \n","                       [[1.8032e+09]],\n","               \n","                       [[2.7464e+09]],\n","               \n","                       [[3.3022e+09]],\n","               \n","                       [[3.8300e+09]],\n","               \n","                       [[1.5520e+09]],\n","               \n","                       [[3.7128e+09]],\n","               \n","                       [[6.7491e+09]],\n","               \n","                       [[6.8013e+09]],\n","               \n","                       [[1.2925e+10]],\n","               \n","                       [[1.6797e+09]],\n","               \n","                       [[2.2816e+09]],\n","               \n","                       [[8.5351e+10]],\n","               \n","                       [[1.7088e+09]],\n","               \n","                       [[9.6452e+09]],\n","               \n","                       [[3.7660e+09]],\n","               \n","                       [[2.2629e+09]],\n","               \n","                       [[2.3913e+10]],\n","               \n","                       [[3.6378e+09]],\n","               \n","                       [[1.1773e+10]],\n","               \n","                       [[4.2823e+09]],\n","               \n","                       [[2.8129e+09]],\n","               \n","                       [[3.1754e+09]],\n","               \n","                       [[3.8982e+09]],\n","               \n","                       [[6.2702e+09]],\n","               \n","                       [[1.9772e+09]],\n","               \n","                       [[5.2858e+09]]], device='cuda:0')),\n","              ('module.layer3.6.conv2.is_simulated_quant_weight_shifted',\n","               tensor(False, device='cuda:0')),\n","              ('module.layer3.6.conv2.wrapped_module.weight',\n","               tensor([[[[24017., 21126., 23203.],\n","                         [21485., 26569., 32411.],\n","                         [23342., 27202., 30384.]],\n","               \n","                        [[20846., 33269., 32770.],\n","                         [21678., 25343., 25278.],\n","                         [27527., 25198., 26091.]],\n","               \n","                        [[20503., 19804., 29619.],\n","                         [22427., 21510., 25182.],\n","                         [25890., 23514., 20263.]],\n","               \n","                        ...,\n","               \n","                        [[21307., 32306., 33951.],\n","                         [15497., 18442., 19059.],\n","                         [15782., 23401., 23287.]],\n","               \n","                        [[31495., 28210., 31168.],\n","                         [27882., 24531., 27310.],\n","                         [31369., 27339., 28992.]],\n","               \n","                        [[25279., 20378., 29811.],\n","                         [24758., 19063., 21893.],\n","                         [26936., 23637., 21029.]]],\n","               \n","               \n","                       [[[35496., 34450., 31578.],\n","                         [37235., 32858., 32726.],\n","                         [37488., 33172., 31118.]],\n","               \n","                        [[28571., 33157., 35377.],\n","                         [21601., 18964., 21319.],\n","                         [12501.,  5953., 13540.]],\n","               \n","                        [[20548., 24158., 25466.],\n","                         [17726., 20833., 26194.],\n","                         [23385., 30493., 31162.]],\n","               \n","                        ...,\n","               \n","                        [[35746., 35438., 32716.],\n","                         [40362., 37880., 31644.],\n","                         [36040., 27761., 25551.]],\n","               \n","                        [[23375., 23970., 20854.],\n","                         [23171., 26563., 23563.],\n","                         [24707., 26455., 25051.]],\n","               \n","                        [[30179., 26246., 17063.],\n","                         [32040., 30925., 26544.],\n","                         [21931., 28655., 27528.]]],\n","               \n","               \n","                       [[[35914., 36548., 42032.],\n","                         [30827., 30369., 34401.],\n","                         [31177., 31682., 33153.]],\n","               \n","                        [[19179., 31503., 38376.],\n","                         [18825., 29125., 38954.],\n","                         [22834., 25086., 36396.]],\n","               \n","                        [[20067., 19313., 22314.],\n","                         [33248., 30038., 27095.],\n","                         [53185., 45131., 37524.]],\n","               \n","                        ...,\n","               \n","                        [[44386., 41806., 33373.],\n","                         [36192., 31284., 27298.],\n","                         [20048., 20108., 26069.]],\n","               \n","                        [[19329., 16637., 22878.],\n","                         [25711., 25087., 31284.],\n","                         [31070., 37442., 41779.]],\n","               \n","                        [[26992., 21559., 26134.],\n","                         [20073., 18496., 21273.],\n","                         [20572., 20785., 24641.]]],\n","               \n","               \n","                       ...,\n","               \n","               \n","                       [[[29194., 29155., 37633.],\n","                         [21735., 17742., 28515.],\n","                         [18530., 19555., 33397.]],\n","               \n","                        [[35222., 32579., 35916.],\n","                         [39163., 30873., 27324.],\n","                         [48313., 38535., 37174.]],\n","               \n","                        [[23813., 35399., 45482.],\n","                         [21415., 30845., 44654.],\n","                         [30508., 23674., 29733.]],\n","               \n","                        ...,\n","               \n","                        [[15499., 20716., 16737.],\n","                         [16363., 23332., 17632.],\n","                         [16332., 14886., 10870.]],\n","               \n","                        [[35070., 41164., 38512.],\n","                         [40266., 45825., 45216.],\n","                         [41557., 50258., 40685.]],\n","               \n","                        [[ 2207.,  4633., 19116.],\n","                         [ 6266.,  4644.,  9920.],\n","                         [13068., 17738., 18324.]]],\n","               \n","               \n","                       [[[30499., 26126., 22105.],\n","                         [27958., 24095., 16083.],\n","                         [23524., 18925., 14127.]],\n","               \n","                        [[30704., 33616., 33092.],\n","                         [30022., 29953., 35976.],\n","                         [24453., 24729., 30827.]],\n","               \n","                        [[25765., 26346., 13866.],\n","                         [13794., 12338., 10805.],\n","                         [16578., 17349., 15646.]],\n","               \n","                        ...,\n","               \n","                        [[11352.,  6243.,  7538.],\n","                         [13761., 11808., 15697.],\n","                         [24008., 26283., 27345.]],\n","               \n","                        [[22760., 22774., 28485.],\n","                         [17031., 18466., 18773.],\n","                         [20610., 21010., 19949.]],\n","               \n","                        [[21239., 19968., 22965.],\n","                         [18097., 13310., 16894.],\n","                         [23260., 18850., 18431.]]],\n","               \n","               \n","                       [[[33951., 22735., 18467.],\n","                         [22844., 14648., 11473.],\n","                         [12752.,  7692.,  9869.]],\n","               \n","                        [[19098., 11416., 23605.],\n","                         [24107., 18024., 27289.],\n","                         [20485., 20858., 22470.]],\n","               \n","                        [[28320., 22454., 33024.],\n","                         [25914., 24137., 25206.],\n","                         [18069., 17533., 15717.]],\n","               \n","                        ...,\n","               \n","                        [[30357., 25844., 23333.],\n","                         [21770., 17667., 17144.],\n","                         [15783., 17220., 15947.]],\n","               \n","                        [[26614., 28343., 22637.],\n","                         [31691., 28462., 25849.],\n","                         [24178., 17227., 19836.]],\n","               \n","                        [[23946., 29533., 28960.],\n","                         [21716., 27577., 36401.],\n","                         [28752., 32095., 40451.]]]], device='cuda:0')),\n","              ('module.layer3.6.conv2.wrapped_module.bias',\n","               tensor([-2.4164e+08, -8.0364e+08,  8.1764e+08,  2.2891e+07, -6.9009e+08,\n","                       -1.2026e+09, -5.3497e+08,  3.4937e+08, -1.0741e+09, -3.9845e+08,\n","                        2.9116e+08, -3.2036e+08, -1.3862e+08, -3.4449e+08, -8.6934e+08,\n","                       -2.6437e+08, -4.0869e+08, -4.0785e+08, -1.2450e+09,  4.4397e+08,\n","                       -5.0267e+08, -1.5048e+09,  8.5067e+08, -9.5956e+08, -1.0862e+09,\n","                       -1.1585e+09, -6.1926e+08,  7.5734e+08, -1.3990e+09, -5.8842e+08,\n","                       -4.5939e+08, -9.1071e+08,  3.8188e+08, -6.4350e+08, -1.2169e+09,\n","                       -7.3205e+08, -2.1475e+09,  5.1968e+08, -1.3172e+07, -8.9576e+08,\n","                       -1.1513e+09, -6.3901e+08, -1.3084e+09, -1.3608e+07, -1.5091e+08,\n","                        4.7162e+08, -2.1475e+09, -1.1079e+09, -2.9774e+08, -7.6748e+08,\n","                       -1.5652e+09,  1.4028e+08,  3.1454e+08, -1.5883e+09, -6.7161e+08,\n","                        6.8676e+08, -3.9293e+08, -1.0148e+09, -6.9632e+08,  9.0958e+07,\n","                        5.7289e+08,  4.7044e+08, -1.5239e+08, -5.1824e+08], device='cuda:0')),\n","              ('module.layer3.6.relu2.num_forwards',\n","               tensor([40], device='cuda:0')),\n","              ('module.layer3.6.relu2.force_readjust',\n","               tensor(False, device='cuda:0')),\n","              ('module.layer3.6.relu2.output_scale',\n","               tensor([4283.1787], device='cuda:0')),\n","              ('module.layer3.6.relu2.output_zero_point',\n","               tensor([0.], device='cuda:0')),\n","              ('module.layer3.6.residual_eltwiseadd.num_forwards',\n","               tensor([40], device='cuda:0')),\n","              ('module.layer3.6.residual_eltwiseadd.force_readjust',\n","               tensor(False, device='cuda:0')),\n","              ('module.layer3.6.residual_eltwiseadd.output_scale',\n","               tensor([4283.1787], device='cuda:0')),\n","              ('module.layer3.6.residual_eltwiseadd.output_zero_point',\n","               tensor([0.], device='cuda:0')),\n","              ('module.layer3.7.conv1.num_forwards',\n","               tensor([40], device='cuda:0')),\n","              ('module.layer3.7.conv1.force_readjust',\n","               tensor(False, device='cuda:0')),\n","              ('module.layer3.7.conv1.output_scale',\n","               tensor([50339.9570], device='cuda:0')),\n","              ('module.layer3.7.conv1.output_zero_point',\n","               tensor([0.], device='cuda:0')),\n","              ('module.layer3.7.conv1.w_scale', tensor([[[[4.3772e+06]]],\n","               \n","               \n","                       [[[1.1944e+06]]],\n","               \n","               \n","                       [[[1.6949e+06]]],\n","               \n","               \n","                       [[[1.8889e+08]]],\n","               \n","               \n","                       [[[1.5057e+06]]],\n","               \n","               \n","                       [[[1.4803e+06]]],\n","               \n","               \n","                       [[[2.2892e+06]]],\n","               \n","               \n","                       [[[2.1454e+06]]],\n","               \n","               \n","                       [[[2.2445e+06]]],\n","               \n","               \n","                       [[[8.6843e+05]]],\n","               \n","               \n","                       [[[1.5911e+06]]],\n","               \n","               \n","                       [[[2.2420e+06]]],\n","               \n","               \n","                       [[[1.1416e+06]]],\n","               \n","               \n","                       [[[3.1299e+06]]],\n","               \n","               \n","                       [[[1.9634e+06]]],\n","               \n","               \n","                       [[[2.2306e+06]]],\n","               \n","               \n","                       [[[2.2429e+06]]],\n","               \n","               \n","                       [[[5.5389e+06]]],\n","               \n","               \n","                       [[[2.3024e+06]]],\n","               \n","               \n","                       [[[1.2467e+06]]],\n","               \n","               \n","                       [[[1.3427e+06]]],\n","               \n","               \n","                       [[[1.2781e+06]]],\n","               \n","               \n","                       [[[2.0861e+06]]],\n","               \n","               \n","                       [[[2.7789e+06]]],\n","               \n","               \n","                       [[[1.3203e+06]]],\n","               \n","               \n","                       [[[1.0502e+06]]],\n","               \n","               \n","                       [[[1.1675e+06]]],\n","               \n","               \n","                       [[[2.8105e+06]]],\n","               \n","               \n","                       [[[2.7030e+06]]],\n","               \n","               \n","                       [[[2.3982e+06]]],\n","               \n","               \n","                       [[[1.9788e+06]]],\n","               \n","               \n","                       [[[2.7516e+06]]],\n","               \n","               \n","                       [[[2.1488e+06]]],\n","               \n","               \n","                       [[[1.3514e+06]]],\n","               \n","               \n","                       [[[2.3115e+06]]],\n","               \n","               \n","                       [[[1.6535e+06]]],\n","               \n","               \n","                       [[[1.7498e+06]]],\n","               \n","               \n","                       [[[1.2206e+06]]],\n","               \n","               \n","                       [[[1.7051e+06]]],\n","               \n","               \n","                       [[[2.7042e+06]]],\n","               \n","               \n","                       [[[1.5387e+06]]],\n","               \n","               \n","                       [[[2.1429e+06]]],\n","               \n","               \n","                       [[[2.5477e+06]]],\n","               \n","               \n","                       [[[2.9887e+06]]],\n","               \n","               \n","                       [[[3.0853e+06]]],\n","               \n","               \n","                       [[[2.2637e+06]]],\n","               \n","               \n","                       [[[1.2911e+06]]],\n","               \n","               \n","                       [[[1.6418e+06]]],\n","               \n","               \n","                       [[[2.2579e+06]]],\n","               \n","               \n","                       [[[1.1970e+06]]],\n","               \n","               \n","                       [[[1.3409e+06]]],\n","               \n","               \n","                       [[[1.7943e+06]]],\n","               \n","               \n","                       [[[1.4193e+06]]],\n","               \n","               \n","                       [[[2.3403e+06]]],\n","               \n","               \n","                       [[[3.3323e+06]]],\n","               \n","               \n","                       [[[2.2976e+06]]],\n","               \n","               \n","                       [[[3.0460e+06]]],\n","               \n","               \n","                       [[[1.9937e+06]]],\n","               \n","               \n","                       [[[1.7698e+06]]],\n","               \n","               \n","                       [[[3.2203e+06]]],\n","               \n","               \n","                       [[[1.3859e+06]]],\n","               \n","               \n","                       [[[2.5257e+06]]],\n","               \n","               \n","                       [[[1.2530e+06]]],\n","               \n","               \n","                       [[[1.6759e+06]]]], device='cuda:0')),\n","              ('module.layer3.7.conv1.w_zero_point', tensor([[[[-28675.]]],\n","               \n","               \n","                       [[[-21244.]]],\n","               \n","               \n","                       [[[-22699.]]],\n","               \n","               \n","                       [[[-24522.]]],\n","               \n","               \n","                       [[[-36361.]]],\n","               \n","               \n","                       [[[-28553.]]],\n","               \n","               \n","                       [[[-28365.]]],\n","               \n","               \n","                       [[[-28612.]]],\n","               \n","               \n","                       [[[-21876.]]],\n","               \n","               \n","                       [[[-26012.]]],\n","               \n","               \n","                       [[[-21792.]]],\n","               \n","               \n","                       [[[-28573.]]],\n","               \n","               \n","                       [[[-25874.]]],\n","               \n","               \n","                       [[[-29131.]]],\n","               \n","               \n","                       [[[-20427.]]],\n","               \n","               \n","                       [[[-26977.]]],\n","               \n","               \n","                       [[[-30935.]]],\n","               \n","               \n","                       [[[-36144.]]],\n","               \n","               \n","                       [[[-31399.]]],\n","               \n","               \n","                       [[[-26733.]]],\n","               \n","               \n","                       [[[-20705.]]],\n","               \n","               \n","                       [[[-21054.]]],\n","               \n","               \n","                       [[[-27477.]]],\n","               \n","               \n","                       [[[-33288.]]],\n","               \n","               \n","                       [[[-31225.]]],\n","               \n","               \n","                       [[[-21912.]]],\n","               \n","               \n","                       [[[-21210.]]],\n","               \n","               \n","                       [[[-29466.]]],\n","               \n","               \n","                       [[[-23629.]]],\n","               \n","               \n","                       [[[-26602.]]],\n","               \n","               \n","                       [[[-28057.]]],\n","               \n","               \n","                       [[[-30678.]]],\n","               \n","               \n","                       [[[-26340.]]],\n","               \n","               \n","                       [[[-25703.]]],\n","               \n","               \n","                       [[[-28261.]]],\n","               \n","               \n","                       [[[-26367.]]],\n","               \n","               \n","                       [[[-30370.]]],\n","               \n","               \n","                       [[[-21407.]]],\n","               \n","               \n","                       [[[-27131.]]],\n","               \n","               \n","                       [[[-22802.]]],\n","               \n","               \n","                       [[[-28705.]]],\n","               \n","               \n","                       [[[-22756.]]],\n","               \n","               \n","                       [[[-31013.]]],\n","               \n","               \n","                       [[[-29539.]]],\n","               \n","               \n","                       [[[-27176.]]],\n","               \n","               \n","                       [[[-27440.]]],\n","               \n","               \n","                       [[[-25463.]]],\n","               \n","               \n","                       [[[-20717.]]],\n","               \n","               \n","                       [[[-24542.]]],\n","               \n","               \n","                       [[[-27172.]]],\n","               \n","               \n","                       [[[-23986.]]],\n","               \n","               \n","                       [[[-27410.]]],\n","               \n","               \n","                       [[[-26115.]]],\n","               \n","               \n","                       [[[-29140.]]],\n","               \n","               \n","                       [[[-28294.]]],\n","               \n","               \n","                       [[[-26498.]]],\n","               \n","               \n","                       [[[-27077.]]],\n","               \n","               \n","                       [[[-24878.]]],\n","               \n","               \n","                       [[[-30992.]]],\n","               \n","               \n","                       [[[-25923.]]],\n","               \n","               \n","                       [[[-26427.]]],\n","               \n","               \n","                       [[[-32711.]]],\n","               \n","               \n","                       [[[-25686.]]],\n","               \n","               \n","                       [[[-24908.]]]], device='cuda:0')),\n","              ('module.layer3.7.conv1.fp_bias',\n","               tensor([-0.0313, -0.1054, -0.1110, -0.0247, -0.0306, -0.1726,  0.1844,  0.0058,\n","                       -0.0391,  0.0114, -0.0282,  0.3042, -0.1371, -0.0203, -0.0455, -0.0640,\n","                       -0.0253,  0.3039,  0.0620, -0.1484, -0.0596,  0.0113, -0.1371,  0.0794,\n","                       -0.0199, -0.1360, -0.0858,  0.2590,  0.0049, -0.0859, -0.1622,  0.3109,\n","                        0.0965, -0.2625, -0.0657, -0.1001,  0.0657, -0.0777, -0.0281, -0.0415,\n","                       -0.0436,  0.1029,  0.0416, -0.1317, -0.1222, -0.0153, -0.1663, -0.2551,\n","                        0.1998,  0.0640, -0.0888, -0.0767, -0.2589, -0.1321, -0.0515,  0.0342,\n","                       -0.0304,  0.0391, -0.2560,  0.1383, -0.0439,  0.3423, -0.1264, -0.1423],\n","                      device='cuda:0')),\n","              ('module.layer3.7.conv1.accum_scale', tensor([[[1.8748e+10]],\n","               \n","                       [[5.1157e+09]],\n","               \n","                       [[7.2596e+09]],\n","               \n","                       [[8.0903e+11]],\n","               \n","                       [[6.4494e+09]],\n","               \n","                       [[6.3406e+09]],\n","               \n","                       [[9.8050e+09]],\n","               \n","                       [[9.1893e+09]],\n","               \n","                       [[9.6135e+09]],\n","               \n","                       [[3.7197e+09]],\n","               \n","                       [[6.8150e+09]],\n","               \n","                       [[9.6031e+09]],\n","               \n","                       [[4.8896e+09]],\n","               \n","                       [[1.3406e+10]],\n","               \n","                       [[8.4098e+09]],\n","               \n","                       [[9.5541e+09]],\n","               \n","                       [[9.6068e+09]],\n","               \n","                       [[2.3724e+10]],\n","               \n","                       [[9.8614e+09]],\n","               \n","                       [[5.3396e+09]],\n","               \n","                       [[5.7508e+09]],\n","               \n","                       [[5.4744e+09]],\n","               \n","                       [[8.9350e+09]],\n","               \n","                       [[1.1902e+10]],\n","               \n","                       [[5.6551e+09]],\n","               \n","                       [[4.4980e+09]],\n","               \n","                       [[5.0007e+09]],\n","               \n","                       [[1.2038e+10]],\n","               \n","                       [[1.1577e+10]],\n","               \n","                       [[1.0272e+10]],\n","               \n","                       [[8.4757e+09]],\n","               \n","                       [[1.1786e+10]],\n","               \n","                       [[9.2039e+09]],\n","               \n","                       [[5.7881e+09]],\n","               \n","                       [[9.9008e+09]],\n","               \n","                       [[7.0820e+09]],\n","               \n","                       [[7.4947e+09]],\n","               \n","                       [[5.2280e+09]],\n","               \n","                       [[7.3033e+09]],\n","               \n","                       [[1.1582e+10]],\n","               \n","                       [[6.5907e+09]],\n","               \n","                       [[9.1786e+09]],\n","               \n","                       [[1.0912e+10]],\n","               \n","                       [[1.2801e+10]],\n","               \n","                       [[1.3215e+10]],\n","               \n","                       [[9.6958e+09]],\n","               \n","                       [[5.5302e+09]],\n","               \n","                       [[7.0321e+09]],\n","               \n","                       [[9.6709e+09]],\n","               \n","                       [[5.1270e+09]],\n","               \n","                       [[5.7435e+09]],\n","               \n","                       [[7.6854e+09]],\n","               \n","                       [[6.0793e+09]],\n","               \n","                       [[1.0024e+10]],\n","               \n","                       [[1.4273e+10]],\n","               \n","                       [[9.8411e+09]],\n","               \n","                       [[1.3046e+10]],\n","               \n","                       [[8.5394e+09]],\n","               \n","                       [[7.5802e+09]],\n","               \n","                       [[1.3793e+10]],\n","               \n","                       [[5.9361e+09]],\n","               \n","                       [[1.0818e+10]],\n","               \n","                       [[5.3669e+09]],\n","               \n","                       [[7.1782e+09]]], device='cuda:0')),\n","              ('module.layer3.7.conv1.is_simulated_quant_weight_shifted',\n","               tensor(False, device='cuda:0')),\n","              ('module.layer3.7.conv1.wrapped_module.weight',\n","               tensor([[[[17907., 38339., 53480.],\n","                         [34304., 30780., 36378.],\n","                         [25504., 33307., 29919.]],\n","               \n","                        [[29031., 28650., 24577.],\n","                         [17023., 22399., 23860.],\n","                         [21831., 23331., 25791.]],\n","               \n","                        [[17956., 15783., 18861.],\n","                         [17697., 16208., 18995.],\n","                         [23481., 20769., 18850.]],\n","               \n","                        ...,\n","               \n","                        [[24520., 21641., 22510.],\n","                         [26726., 28957., 32704.],\n","                         [27169., 28826., 30448.]],\n","               \n","                        [[45210., 42388., 38823.],\n","                         [36262., 41566., 51613.],\n","                         [24530., 27151., 37269.]],\n","               \n","                        [[ 9992., 39792., 48734.],\n","                         [23476., 36979., 41286.],\n","                         [25687., 24651., 25160.]]],\n","               \n","               \n","                       [[[16738., 28086., 27246.],\n","                         [11805., 12556., 17061.],\n","                         [21357., 13920., 18695.]],\n","               \n","                        [[11441., 29828., 45469.],\n","                         [12278., 14580., 21203.],\n","                         [21908., 17719., 15444.]],\n","               \n","                        [[36580., 25336., 11126.],\n","                         [26428., 26504., 17740.],\n","                         [12419., 17579., 22635.]],\n","               \n","                        ...,\n","               \n","                        [[25237., 30450., 29091.],\n","                         [29674., 30670., 34812.],\n","                         [23838., 23570., 26762.]],\n","               \n","                        [[23729., 17886., 19055.],\n","                         [32556., 14567.,  9716.],\n","                         [23093., 24111., 23476.]],\n","               \n","                        [[ 7661., 16720., 58200.],\n","                         [ 3242.,  4213., 65535.],\n","                         [18440., 20079., 65051.]]],\n","               \n","               \n","                       [[[11374., 15657., 25147.],\n","                         [14572., 19862., 27995.],\n","                         [11277., 32856., 46304.]],\n","               \n","                        [[22807., 14177.,  5767.],\n","                         [24219., 18688.,  7970.],\n","                         [24766., 26101., 20306.]],\n","               \n","                        [[25640., 17612., 16352.],\n","                         [20938., 16150.,  9374.],\n","                         [12560., 18726., 10699.]],\n","               \n","                        ...,\n","               \n","                        [[14312., 19481., 33988.],\n","                         [12345., 17074., 26405.],\n","                         [ 4961.,  2493.,  9223.]],\n","               \n","                        [[12459., 14216., 23252.],\n","                         [32583., 30488., 29032.],\n","                         [57816., 60827., 51635.]],\n","               \n","                        [[53327., 59145., 65535.],\n","                         [48009., 45659., 47916.],\n","                         [25009., 26001., 27181.]]],\n","               \n","               \n","                       ...,\n","               \n","               \n","                       [[[32513., 28863., 19385.],\n","                         [22898., 28593., 18068.],\n","                         [21569., 26080., 13266.]],\n","               \n","                        [[19296., 26662., 22812.],\n","                         [18856., 28754., 29880.],\n","                         [23575., 26773., 26673.]],\n","               \n","                        [[32470., 25876., 37074.],\n","                         [30874., 30797., 34525.],\n","                         [34518., 29308., 34486.]],\n","               \n","                        ...,\n","               \n","                        [[13100., 13936., 14522.],\n","                         [16473., 19876., 22537.],\n","                         [20661., 26729., 28048.]],\n","               \n","                        [[25201., 25204., 28852.],\n","                         [22888., 31604., 32311.],\n","                         [19519., 36578., 30721.]],\n","               \n","                        [[25821., 44988., 41211.],\n","                         [26849., 41684., 50012.],\n","                         [24946., 27285., 45591.]]],\n","               \n","               \n","                       [[[31614., 26894., 27958.],\n","                         [21723., 28926., 29616.],\n","                         [ 4107., 10746., 14438.]],\n","               \n","                        [[27744., 23368., 27072.],\n","                         [34671., 25584., 22316.],\n","                         [17507., 14130., 21944.]],\n","               \n","                        [[ 8845., 11819., 19236.],\n","                         [19633., 10808., 16969.],\n","                         [23923., 17977., 25357.]],\n","               \n","                        ...,\n","               \n","                        [[28395., 29733., 29942.],\n","                         [26477., 27812., 28876.],\n","                         [20304., 15480., 18525.]],\n","               \n","                        [[17243., 22113., 23909.],\n","                         [27509., 27272., 16624.],\n","                         [31260., 21401., 12361.]],\n","               \n","                        [[13378.,  6549., 16636.],\n","                         [14867.,  9235.,  6274.],\n","                         [43240., 52853., 25934.]]],\n","               \n","               \n","                       [[[42254., 33328., 23861.],\n","                         [45240., 29655., 20961.],\n","                         [18112., 10735., 10131.]],\n","               \n","                        [[26893., 26770., 26350.],\n","                         [26871., 24063., 20617.],\n","                         [25002., 25116., 23887.]],\n","               \n","                        [[17138., 19760., 12630.],\n","                         [30532., 24625., 20345.],\n","                         [31672., 27499., 31313.]],\n","               \n","                        ...,\n","               \n","                        [[27508., 28808., 26235.],\n","                         [24476., 24789., 24261.],\n","                         [24179., 26772., 27066.]],\n","               \n","                        [[48717., 45355., 46834.],\n","                         [26754., 29072., 37529.],\n","                         [11099., 12204., 16111.]],\n","               \n","                        [[22695., 23217., 16256.],\n","                         [25231., 29539., 29391.],\n","                         [20825., 24828., 28678.]]]], device='cuda:0')),\n","              ('module.layer3.7.conv1.wrapped_module.bias',\n","               tensor([-5.8617e+08, -5.3914e+08, -8.0602e+08, -2.1475e+09, -1.9721e+08,\n","                       -1.0947e+09,  1.8078e+09,  5.2915e+07, -3.7549e+08,  4.2482e+07,\n","                       -1.9190e+08,  2.1475e+09, -6.7059e+08, -2.7157e+08, -3.8305e+08,\n","                       -6.1100e+08, -2.4329e+08,  2.1475e+09,  6.1103e+08, -7.9239e+08,\n","                       -3.4252e+08,  6.1804e+07, -1.2246e+09,  9.4517e+08, -1.1241e+08,\n","                       -6.1163e+08, -4.2891e+08,  2.1475e+09,  5.6314e+07, -8.8283e+08,\n","                       -1.3745e+09,  2.1475e+09,  8.8840e+08, -1.5192e+09, -6.5050e+08,\n","                       -7.0879e+08,  4.9209e+08, -4.0632e+08, -2.0486e+08, -4.8099e+08,\n","                       -2.8707e+08,  9.4460e+08,  4.5433e+08, -1.6860e+09, -1.6153e+09,\n","                       -1.4798e+08, -9.1990e+08, -1.7936e+09,  1.9326e+09,  3.2820e+08,\n","                       -5.0998e+08, -5.8929e+08, -1.5738e+09, -1.3238e+09, -7.3474e+08,\n","                        3.3634e+08, -3.9693e+08,  3.3347e+08, -1.9405e+09,  1.9080e+09,\n","                       -2.6058e+08,  2.1475e+09, -6.7858e+08, -1.0212e+09], device='cuda:0')),\n","              ('module.layer3.7.conv2.num_forwards',\n","               tensor([40], device='cuda:0')),\n","              ('module.layer3.7.conv2.force_readjust',\n","               tensor(False, device='cuda:0')),\n","              ('module.layer3.7.conv2.output_scale',\n","               tensor([8069.2710], device='cuda:0')),\n","              ('module.layer3.7.conv2.output_zero_point',\n","               tensor([-21351.], device='cuda:0')),\n","              ('module.layer3.7.conv2.w_scale', tensor([[[[  44138.6992]]],\n","               \n","               \n","                       [[[ 109558.7656]]],\n","               \n","               \n","                       [[[  55821.6367]]],\n","               \n","               \n","                       [[[ 282373.2188]]],\n","               \n","               \n","                       [[[ 125834.0703]]],\n","               \n","               \n","                       [[[ 196781.0625]]],\n","               \n","               \n","                       [[[ 137950.7656]]],\n","               \n","               \n","                       [[[ 336435.4688]]],\n","               \n","               \n","                       [[[  66431.8203]]],\n","               \n","               \n","                       [[[ 159624.0469]]],\n","               \n","               \n","                       [[[  84437.6094]]],\n","               \n","               \n","                       [[[ 343059.4688]]],\n","               \n","               \n","                       [[[  76423.1328]]],\n","               \n","               \n","                       [[[  54203.7266]]],\n","               \n","               \n","                       [[[ 152070.7656]]],\n","               \n","               \n","                       [[[  68569.2422]]],\n","               \n","               \n","                       [[[  50120.5547]]],\n","               \n","               \n","                       [[[ 215328.6250]]],\n","               \n","               \n","                       [[[  81694.2656]]],\n","               \n","               \n","                       [[[ 150575.5469]]],\n","               \n","               \n","                       [[[ 115200.2188]]],\n","               \n","               \n","                       [[[ 164996.0938]]],\n","               \n","               \n","                       [[[ 147301.0156]]],\n","               \n","               \n","                       [[[ 107924.9766]]],\n","               \n","               \n","                       [[[  72360.2266]]],\n","               \n","               \n","                       [[[ 114321.3438]]],\n","               \n","               \n","                       [[[  86533.0625]]],\n","               \n","               \n","                       [[[ 192068.4688]]],\n","               \n","               \n","                       [[[ 131799.2344]]],\n","               \n","               \n","                       [[[ 170234.8281]]],\n","               \n","               \n","                       [[[ 142101.4375]]],\n","               \n","               \n","                       [[[ 191360.7031]]],\n","               \n","               \n","                       [[[ 124444.9297]]],\n","               \n","               \n","                       [[[ 253283.4219]]],\n","               \n","               \n","                       [[[ 129344.8438]]],\n","               \n","               \n","                       [[[ 168215.1406]]],\n","               \n","               \n","                       [[[ 135271.2812]]],\n","               \n","               \n","                       [[[ 102165.7500]]],\n","               \n","               \n","                       [[[  57974.8516]]],\n","               \n","               \n","                       [[[ 145142.4844]]],\n","               \n","               \n","                       [[[ 142603.9219]]],\n","               \n","               \n","                       [[[ 110423.7734]]],\n","               \n","               \n","                       [[[ 146651.8594]]],\n","               \n","               \n","                       [[[  86302.6016]]],\n","               \n","               \n","                       [[[ 849452.7500]]],\n","               \n","               \n","                       [[[ 246496.8438]]],\n","               \n","               \n","                       [[[ 281997.9375]]],\n","               \n","               \n","                       [[[ 223538.5781]]],\n","               \n","               \n","                       [[[ 144312.6875]]],\n","               \n","               \n","                       [[[1137076.7500]]],\n","               \n","               \n","                       [[[  79661.3125]]],\n","               \n","               \n","                       [[[ 155820.4219]]],\n","               \n","               \n","                       [[[  53655.6289]]],\n","               \n","               \n","                       [[[ 133124.4219]]],\n","               \n","               \n","                       [[[ 824331.9375]]],\n","               \n","               \n","                       [[[ 113135.7812]]],\n","               \n","               \n","                       [[[ 248516.9375]]],\n","               \n","               \n","                       [[[ 110056.0625]]],\n","               \n","               \n","                       [[[  95917.3047]]],\n","               \n","               \n","                       [[[ 120283.7500]]],\n","               \n","               \n","                       [[[  81681.0703]]],\n","               \n","               \n","                       [[[ 176053.7031]]],\n","               \n","               \n","                       [[[  78012.4297]]],\n","               \n","               \n","                       [[[  53754.2891]]]], device='cuda:0')),\n","              ('module.layer3.7.conv2.w_zero_point', tensor([[[[-20250.]]],\n","               \n","               \n","                       [[[-31733.]]],\n","               \n","               \n","                       [[[-19018.]]],\n","               \n","               \n","                       [[[-28071.]]],\n","               \n","               \n","                       [[[-24034.]]],\n","               \n","               \n","                       [[[-33298.]]],\n","               \n","               \n","                       [[[-36034.]]],\n","               \n","               \n","                       [[[-36418.]]],\n","               \n","               \n","                       [[[-22080.]]],\n","               \n","               \n","                       [[[-23765.]]],\n","               \n","               \n","                       [[[-41088.]]],\n","               \n","               \n","                       [[[-23818.]]],\n","               \n","               \n","                       [[[-35650.]]],\n","               \n","               \n","                       [[[-21933.]]],\n","               \n","               \n","                       [[[-27903.]]],\n","               \n","               \n","                       [[[-22816.]]],\n","               \n","               \n","                       [[[-23686.]]],\n","               \n","               \n","                       [[[-32647.]]],\n","               \n","               \n","                       [[[-28136.]]],\n","               \n","               \n","                       [[[-29386.]]],\n","               \n","               \n","                       [[[-32056.]]],\n","               \n","               \n","                       [[[-28480.]]],\n","               \n","               \n","                       [[[-29980.]]],\n","               \n","               \n","                       [[[-43655.]]],\n","               \n","               \n","                       [[[-29776.]]],\n","               \n","               \n","                       [[[-24018.]]],\n","               \n","               \n","                       [[[-35118.]]],\n","               \n","               \n","                       [[[-30774.]]],\n","               \n","               \n","                       [[[-22724.]]],\n","               \n","               \n","                       [[[-32879.]]],\n","               \n","               \n","                       [[[-35927.]]],\n","               \n","               \n","                       [[[-22058.]]],\n","               \n","               \n","                       [[[-32391.]]],\n","               \n","               \n","                       [[[-32054.]]],\n","               \n","               \n","                       [[[-20026.]]],\n","               \n","               \n","                       [[[-23408.]]],\n","               \n","               \n","                       [[[-38218.]]],\n","               \n","               \n","                       [[[-30139.]]],\n","               \n","               \n","                       [[[-24021.]]],\n","               \n","               \n","                       [[[-26073.]]],\n","               \n","               \n","                       [[[-28302.]]],\n","               \n","               \n","                       [[[-21401.]]],\n","               \n","               \n","                       [[[-32289.]]],\n","               \n","               \n","                       [[[-23320.]]],\n","               \n","               \n","                       [[[-21242.]]],\n","               \n","               \n","                       [[[-32663.]]],\n","               \n","               \n","                       [[[-33981.]]],\n","               \n","               \n","                       [[[-28230.]]],\n","               \n","               \n","                       [[[-32586.]]],\n","               \n","               \n","                       [[[-33103.]]],\n","               \n","               \n","                       [[[-30094.]]],\n","               \n","               \n","                       [[[-23113.]]],\n","               \n","               \n","                       [[[-25347.]]],\n","               \n","               \n","                       [[[-25110.]]],\n","               \n","               \n","                       [[[-40772.]]],\n","               \n","               \n","                       [[[-24522.]]],\n","               \n","               \n","                       [[[-32441.]]],\n","               \n","               \n","                       [[[-22300.]]],\n","               \n","               \n","                       [[[-24524.]]],\n","               \n","               \n","                       [[[-31441.]]],\n","               \n","               \n","                       [[[-27408.]]],\n","               \n","               \n","                       [[[-22755.]]],\n","               \n","               \n","                       [[[-29417.]]],\n","               \n","               \n","                       [[[-19404.]]]], device='cuda:0')),\n","              ('module.layer3.7.conv2.fp_bias',\n","               tensor([ 0.2048,  0.4032, -0.8588, -0.1518,  0.3428,  0.2586,  0.8078,  0.2184,\n","                       -0.3362, -0.1526,  0.0841, -0.1999,  0.3261, -0.4162,  0.0466,  0.0954,\n","                       -0.2865,  0.0722, -0.2951,  0.3124,  0.2698, -0.2092,  0.0194,  0.7213,\n","                       -0.0968,  0.0219,  1.1313,  0.2237,  0.0631,  0.2349,  0.2427, -0.2088,\n","                        0.3004, -0.0245, -0.6136,  0.1897,  0.3101,  0.1313, -0.6758,  0.1905,\n","                       -0.1277, -0.0657,  0.0471, -0.3930, -0.0382,  0.1870,  0.0211, -0.0154,\n","                        0.1685,  0.0587,  0.2975, -0.2818, -0.1782,  0.3070, -0.0078, -0.2794,\n","                        0.1333, -0.0109,  0.0909,  0.1268, -0.2341,  0.0901,  0.3701, -0.0862],\n","                      device='cuda:0')),\n","              ('module.layer3.7.conv2.accum_scale', tensor([[[2.2219e+09]],\n","               \n","                       [[5.5152e+09]],\n","               \n","                       [[2.8101e+09]],\n","               \n","                       [[1.4215e+10]],\n","               \n","                       [[6.3345e+09]],\n","               \n","                       [[9.9060e+09]],\n","               \n","                       [[6.9444e+09]],\n","               \n","                       [[1.6936e+10]],\n","               \n","                       [[3.3442e+09]],\n","               \n","                       [[8.0355e+09]],\n","               \n","                       [[4.2506e+09]],\n","               \n","                       [[1.7270e+10]],\n","               \n","                       [[3.8471e+09]],\n","               \n","                       [[2.7286e+09]],\n","               \n","                       [[7.6552e+09]],\n","               \n","                       [[3.4518e+09]],\n","               \n","                       [[2.5231e+09]],\n","               \n","                       [[1.0840e+10]],\n","               \n","                       [[4.1125e+09]],\n","               \n","                       [[7.5800e+09]],\n","               \n","                       [[5.7992e+09]],\n","               \n","                       [[8.3059e+09]],\n","               \n","                       [[7.4151e+09]],\n","               \n","                       [[5.4329e+09]],\n","               \n","                       [[3.6426e+09]],\n","               \n","                       [[5.7549e+09]],\n","               \n","                       [[4.3561e+09]],\n","               \n","                       [[9.6687e+09]],\n","               \n","                       [[6.6348e+09]],\n","               \n","                       [[8.5696e+09]],\n","               \n","                       [[7.1534e+09]],\n","               \n","                       [[9.6331e+09]],\n","               \n","                       [[6.2646e+09]],\n","               \n","                       [[1.2750e+10]],\n","               \n","                       [[6.5112e+09]],\n","               \n","                       [[8.4679e+09]],\n","               \n","                       [[6.8096e+09]],\n","               \n","                       [[5.1430e+09]],\n","               \n","                       [[2.9185e+09]],\n","               \n","                       [[7.3065e+09]],\n","               \n","                       [[7.1787e+09]],\n","               \n","                       [[5.5587e+09]],\n","               \n","                       [[7.3824e+09]],\n","               \n","                       [[4.3445e+09]],\n","               \n","                       [[4.2761e+10]],\n","               \n","                       [[1.2409e+10]],\n","               \n","                       [[1.4196e+10]],\n","               \n","                       [[1.1253e+10]],\n","               \n","                       [[7.2647e+09]],\n","               \n","                       [[5.7240e+10]],\n","               \n","                       [[4.0101e+09]],\n","               \n","                       [[7.8440e+09]],\n","               \n","                       [[2.7010e+09]],\n","               \n","                       [[6.7015e+09]],\n","               \n","                       [[4.1497e+10]],\n","               \n","                       [[5.6953e+09]],\n","               \n","                       [[1.2510e+10]],\n","               \n","                       [[5.5402e+09]],\n","               \n","                       [[4.8285e+09]],\n","               \n","                       [[6.0551e+09]],\n","               \n","                       [[4.1118e+09]],\n","               \n","                       [[8.8625e+09]],\n","               \n","                       [[3.9271e+09]],\n","               \n","                       [[2.7060e+09]]], device='cuda:0')),\n","              ('module.layer3.7.conv2.is_simulated_quant_weight_shifted',\n","               tensor(False, device='cuda:0')),\n","              ('module.layer3.7.conv2.wrapped_module.weight',\n","               tensor([[[[18021., 14384., 13583.],\n","                         [24588., 19579., 14272.],\n","                         [29494., 24830., 20252.]],\n","               \n","                        [[21829., 19607., 17457.],\n","                         [26646., 27017., 27271.],\n","                         [26121., 28283., 24447.]],\n","               \n","                        [[21667., 15912., 14119.],\n","                         [22331., 20719., 21177.],\n","                         [20803., 21279., 19931.]],\n","               \n","                        ...,\n","               \n","                        [[ 7989.,  7052., 19239.],\n","                         [ 2489.,   787., 10515.],\n","                         [11721., 10316.,  9490.]],\n","               \n","                        [[22387., 25909., 26704.],\n","                         [17098., 19495., 21804.],\n","                         [17980., 20442., 22081.]],\n","               \n","                        [[10022., 15594., 12645.],\n","                         [17872., 19356., 15383.],\n","                         [19311., 24613., 20314.]]],\n","               \n","               \n","                       [[[27491., 25185., 24397.],\n","                         [27134., 24958., 23990.],\n","                         [27796., 27591., 26646.]],\n","               \n","                        [[32032., 30177., 29572.],\n","                         [40060., 37520., 39107.],\n","                         [42054., 42885., 45499.]],\n","               \n","                        [[26848., 26198., 25205.],\n","                         [21538., 24143., 22213.],\n","                         [10378.,  9937.,  8788.]],\n","               \n","                        ...,\n","               \n","                        [[30373., 22651., 33773.],\n","                         [19112.,  8248., 22283.],\n","                         [38277., 24959., 29600.]],\n","               \n","                        [[50166., 47456., 45506.],\n","                         [54324., 60398., 63872.],\n","                         [37605., 41789., 46816.]],\n","               \n","                        [[31375., 30051., 28375.],\n","                         [32435., 31813., 29457.],\n","                         [35474., 35426., 31698.]]],\n","               \n","               \n","                       [[[17848., 16791., 15739.],\n","                         [19498., 18935., 18129.],\n","                         [18099., 18729., 18170.]],\n","               \n","                        [[10148.,  8429.,     0.],\n","                         [16794., 15877., 16401.],\n","                         [30103., 29458., 31352.]],\n","               \n","                        [[10608., 12761., 12277.],\n","                         [12894., 14222., 16022.],\n","                         [ 9666.,  8208., 11616.]],\n","               \n","                        ...,\n","               \n","                        [[20964., 15488., 24267.],\n","                         [15356., 10770., 16907.],\n","                         [ 5436.,  1688.,  7125.]],\n","               \n","                        [[17534., 13798., 10733.],\n","                         [25169., 19623., 19973.],\n","                         [39945., 34300., 31284.]],\n","               \n","                        [[13939., 13291., 13254.],\n","                         [11080., 11146., 10576.],\n","                         [11713.,  8618.,  5815.]]],\n","               \n","               \n","                       ...,\n","               \n","               \n","                       [[[23092., 18834., 17035.],\n","                         [23010., 19586., 15855.],\n","                         [25362., 21053., 16396.]],\n","               \n","                        [[33787., 19242., 27018.],\n","                         [39063., 24949., 26954.],\n","                         [39529., 23557., 22607.]],\n","               \n","                        [[18595., 20870., 21193.],\n","                         [20683., 17485., 17541.],\n","                         [25628., 21661., 18901.]],\n","               \n","                        ...,\n","               \n","                        [[15209., 24061., 30238.],\n","                         [ 6460., 10427., 17826.],\n","                         [17811., 17415., 24520.]],\n","               \n","                        [[12671., 21022., 27879.],\n","                         [ 9447., 13342., 12565.],\n","                         [ 9987., 10811., 10308.]],\n","               \n","                        [[18378., 24494., 25017.],\n","                         [14044., 20325., 22877.],\n","                         [14526., 22624., 26188.]]],\n","               \n","               \n","                       [[[23838., 22153., 27486.],\n","                         [33166., 34735., 34646.],\n","                         [36619., 39959., 38383.]],\n","               \n","                        [[31176., 40996., 39593.],\n","                         [27997., 34487., 23127.],\n","                         [10320., 10292., 10201.]],\n","               \n","                        [[38229., 38274., 34993.],\n","                         [41133., 45117., 43387.],\n","                         [35080., 40103., 40501.]],\n","               \n","                        ...,\n","               \n","                        [[22523., 10044., 14681.],\n","                         [24408., 12393., 22927.],\n","                         [35603., 22023., 31681.]],\n","               \n","                        [[17386.,  9059.,  9887.],\n","                         [ 8648.,  1154.,     0.],\n","                         [ 9330., 12846., 13610.]],\n","               \n","                        [[17864., 16294., 15211.],\n","                         [28824., 34014., 42371.],\n","                         [38696., 54778., 65535.]]],\n","               \n","               \n","                       [[[22850., 22352., 20270.],\n","                         [19787., 20542., 20190.],\n","                         [21297., 22067., 22165.]],\n","               \n","                        [[50166., 23450.,  8386.],\n","                         [45692., 45125., 16705.],\n","                         [37131., 38754., 14690.]],\n","               \n","                        [[21018., 19199., 21410.],\n","                         [10571., 23630., 33857.],\n","                         [14784., 28392., 35722.]],\n","               \n","                        ...,\n","               \n","                        [[24972., 16101., 29794.],\n","                         [15966.,  5219., 19943.],\n","                         [16474.,  7725., 22014.]],\n","               \n","                        [[28467., 30839., 30454.],\n","                         [23083., 25744., 24163.],\n","                         [22618., 20864., 20405.]],\n","               \n","                        [[16899., 22556., 19593.],\n","                         [11580., 21874., 13956.],\n","                         [24765., 27626., 15044.]]]], device='cuda:0')),\n","              ('module.layer3.7.conv2.wrapped_module.bias',\n","               tensor([ 4.5509e+08,  2.1475e+09, -2.1475e+09, -2.1475e+09,  2.1475e+09,\n","                        2.1475e+09,  2.1475e+09,  2.1475e+09, -1.1243e+09, -1.2258e+09,\n","                        3.5749e+08, -2.1475e+09,  1.2547e+09, -1.1356e+09,  3.5702e+08,\n","                        3.2943e+08, -7.2274e+08,  7.8272e+08, -1.2134e+09,  2.1475e+09,\n","                        1.5648e+09, -1.7374e+09,  1.4419e+08,  2.1475e+09, -3.5254e+08,\n","                        1.2601e+08,  2.1475e+09,  2.1475e+09,  4.1838e+08,  2.0126e+09,\n","                        1.7363e+09, -2.0111e+09,  1.8816e+09, -3.1179e+08, -2.1475e+09,\n","                        1.6062e+09,  2.1118e+09,  6.7538e+08, -1.9723e+09,  1.3920e+09,\n","                       -9.1666e+08, -3.6546e+08,  3.4779e+08, -1.7073e+09, -1.6328e+09,\n","                        2.1475e+09,  2.9895e+08, -1.7293e+08,  1.2241e+09,  2.1475e+09,\n","                        1.1932e+09, -2.1475e+09, -4.8135e+08,  2.0573e+09, -3.2337e+08,\n","                       -1.5914e+09,  1.6673e+09, -6.0153e+07,  4.3884e+08,  7.6796e+08,\n","                       -9.6267e+08,  7.9839e+08,  1.4536e+09, -2.3326e+08], device='cuda:0')),\n","              ('module.layer3.7.relu2.num_forwards',\n","               tensor([40], device='cuda:0')),\n","              ('module.layer3.7.relu2.force_readjust',\n","               tensor(False, device='cuda:0')),\n","              ('module.layer3.7.relu2.output_scale',\n","               tensor([3485.1147], device='cuda:0')),\n","              ('module.layer3.7.relu2.output_zero_point',\n","               tensor([0.], device='cuda:0')),\n","              ('module.layer3.7.residual_eltwiseadd.num_forwards',\n","               tensor([40], device='cuda:0')),\n","              ('module.layer3.7.residual_eltwiseadd.force_readjust',\n","               tensor(False, device='cuda:0')),\n","              ('module.layer3.7.residual_eltwiseadd.output_scale',\n","               tensor([3485.1147], device='cuda:0')),\n","              ('module.layer3.7.residual_eltwiseadd.output_zero_point',\n","               tensor([0.], device='cuda:0')),\n","              ('module.layer3.8.conv1.num_forwards',\n","               tensor([40], device='cuda:0')),\n","              ('module.layer3.8.conv1.force_readjust',\n","               tensor(False, device='cuda:0')),\n","              ('module.layer3.8.conv1.output_scale',\n","               tensor([63862.1602], device='cuda:0')),\n","              ('module.layer3.8.conv1.output_zero_point',\n","               tensor([0.], device='cuda:0')),\n","              ('module.layer3.8.conv1.w_scale', tensor([[[[4642472.0000]]],\n","               \n","               \n","                       [[[7917881.5000]]],\n","               \n","               \n","                       [[[4849263.0000]]],\n","               \n","               \n","                       [[[5950412.5000]]],\n","               \n","               \n","                       [[[4445694.0000]]],\n","               \n","               \n","                       [[[3994438.7500]]],\n","               \n","               \n","                       [[[5168030.0000]]],\n","               \n","               \n","                       [[[5322729.5000]]],\n","               \n","               \n","                       [[[4837669.5000]]],\n","               \n","               \n","                       [[[3893783.0000]]],\n","               \n","               \n","                       [[[2449091.0000]]],\n","               \n","               \n","                       [[[5492771.0000]]],\n","               \n","               \n","                       [[[4854007.0000]]],\n","               \n","               \n","                       [[[8321098.5000]]],\n","               \n","               \n","                       [[[2168618.5000]]],\n","               \n","               \n","                       [[[3267045.2500]]],\n","               \n","               \n","                       [[[4618218.0000]]],\n","               \n","               \n","                       [[[6050688.5000]]],\n","               \n","               \n","                       [[[3038730.5000]]],\n","               \n","               \n","                       [[[1703076.3750]]],\n","               \n","               \n","                       [[[4145220.5000]]],\n","               \n","               \n","                       [[[2785116.5000]]],\n","               \n","               \n","                       [[[2305230.2500]]],\n","               \n","               \n","                       [[[3310189.5000]]],\n","               \n","               \n","                       [[[3082798.5000]]],\n","               \n","               \n","                       [[[3594438.7500]]],\n","               \n","               \n","                       [[[2100352.5000]]],\n","               \n","               \n","                       [[[2188324.2500]]],\n","               \n","               \n","                       [[[4403051.5000]]],\n","               \n","               \n","                       [[[4210746.5000]]],\n","               \n","               \n","                       [[[4926420.0000]]],\n","               \n","               \n","                       [[[3381594.0000]]],\n","               \n","               \n","                       [[[1599923.8750]]],\n","               \n","               \n","                       [[[6610167.0000]]],\n","               \n","               \n","                       [[[3389815.2500]]],\n","               \n","               \n","                       [[[3512333.0000]]],\n","               \n","               \n","                       [[[4235694.5000]]],\n","               \n","               \n","                       [[[5349231.5000]]],\n","               \n","               \n","                       [[[2150844.0000]]],\n","               \n","               \n","                       [[[4915641.5000]]],\n","               \n","               \n","                       [[[4111216.0000]]],\n","               \n","               \n","                       [[[2813423.7500]]],\n","               \n","               \n","                       [[[3048461.7500]]],\n","               \n","               \n","                       [[[2366569.7500]]],\n","               \n","               \n","                       [[[4748436.5000]]],\n","               \n","               \n","                       [[[3393484.7500]]],\n","               \n","               \n","                       [[[2641797.2500]]],\n","               \n","               \n","                       [[[2747717.0000]]],\n","               \n","               \n","                       [[[3174907.7500]]],\n","               \n","               \n","                       [[[4772381.5000]]],\n","               \n","               \n","                       [[[2416965.7500]]],\n","               \n","               \n","                       [[[3824495.0000]]],\n","               \n","               \n","                       [[[4252108.0000]]],\n","               \n","               \n","                       [[[3222701.0000]]],\n","               \n","               \n","                       [[[5451303.0000]]],\n","               \n","               \n","                       [[[4532186.0000]]],\n","               \n","               \n","                       [[[5231114.5000]]],\n","               \n","               \n","                       [[[3123842.7500]]],\n","               \n","               \n","                       [[[1585049.3750]]],\n","               \n","               \n","                       [[[5426970.0000]]],\n","               \n","               \n","                       [[[6648773.0000]]],\n","               \n","               \n","                       [[[4540337.0000]]],\n","               \n","               \n","                       [[[4637311.0000]]],\n","               \n","               \n","                       [[[3980520.2500]]]], device='cuda:0')),\n","              ('module.layer3.8.conv1.w_zero_point', tensor([[[[-31209.]]],\n","               \n","               \n","                       [[[-40889.]]],\n","               \n","               \n","                       [[[-35809.]]],\n","               \n","               \n","                       [[[-39710.]]],\n","               \n","               \n","                       [[[-29372.]]],\n","               \n","               \n","                       [[[-21416.]]],\n","               \n","               \n","                       [[[-31486.]]],\n","               \n","               \n","                       [[[-31316.]]],\n","               \n","               \n","                       [[[-24946.]]],\n","               \n","               \n","                       [[[-24507.]]],\n","               \n","               \n","                       [[[-18714.]]],\n","               \n","               \n","                       [[[-28491.]]],\n","               \n","               \n","                       [[[-26359.]]],\n","               \n","               \n","                       [[[-34538.]]],\n","               \n","               \n","                       [[[-19235.]]],\n","               \n","               \n","                       [[[-23334.]]],\n","               \n","               \n","                       [[[-30355.]]],\n","               \n","               \n","                       [[[-24980.]]],\n","               \n","               \n","                       [[[-19184.]]],\n","               \n","               \n","                       [[[-24496.]]],\n","               \n","               \n","                       [[[-21651.]]],\n","               \n","               \n","                       [[[-32333.]]],\n","               \n","               \n","                       [[[-21568.]]],\n","               \n","               \n","                       [[[-25796.]]],\n","               \n","               \n","                       [[[-24075.]]],\n","               \n","               \n","                       [[[-30932.]]],\n","               \n","               \n","                       [[[-31522.]]],\n","               \n","               \n","                       [[[-23680.]]],\n","               \n","               \n","                       [[[-27359.]]],\n","               \n","               \n","                       [[[-27371.]]],\n","               \n","               \n","                       [[[-29965.]]],\n","               \n","               \n","                       [[[-23958.]]],\n","               \n","               \n","                       [[[-21037.]]],\n","               \n","               \n","                       [[[-23585.]]],\n","               \n","               \n","                       [[[-26450.]]],\n","               \n","               \n","                       [[[-22765.]]],\n","               \n","               \n","                       [[[-24139.]]],\n","               \n","               \n","                       [[[-32608.]]],\n","               \n","               \n","                       [[[-19043.]]],\n","               \n","               \n","                       [[[-25097.]]],\n","               \n","               \n","                       [[[-32589.]]],\n","               \n","               \n","                       [[[-27837.]]],\n","               \n","               \n","                       [[[-23408.]]],\n","               \n","               \n","                       [[[-29178.]]],\n","               \n","               \n","                       [[[-34588.]]],\n","               \n","               \n","                       [[[-25916.]]],\n","               \n","               \n","                       [[[-21524.]]],\n","               \n","               \n","                       [[[-20526.]]],\n","               \n","               \n","                       [[[-25760.]]],\n","               \n","               \n","                       [[[-27594.]]],\n","               \n","               \n","                       [[[-29225.]]],\n","               \n","               \n","                       [[[-35395.]]],\n","               \n","               \n","                       [[[-26269.]]],\n","               \n","               \n","                       [[[-23888.]]],\n","               \n","               \n","                       [[[-20184.]]],\n","               \n","               \n","                       [[[-31575.]]],\n","               \n","               \n","                       [[[-28285.]]],\n","               \n","               \n","                       [[[-34899.]]],\n","               \n","               \n","                       [[[-22394.]]],\n","               \n","               \n","                       [[[-25663.]]],\n","               \n","               \n","                       [[[-34441.]]],\n","               \n","               \n","                       [[[-22606.]]],\n","               \n","               \n","                       [[[-35937.]]],\n","               \n","               \n","                       [[[-33400.]]]], device='cuda:0')),\n","              ('module.layer3.8.conv1.fp_bias',\n","               tensor([ 0.1747,  0.2082,  0.2661,  0.1903,  0.1028, -0.1064,  0.2414,  0.0681,\n","                        0.0449, -0.1080, -0.1051,  0.1799, -0.0794,  0.2072, -0.0921,  0.0074,\n","                       -0.0013, -0.0546,  0.1833, -0.0505, -0.2758,  0.0620, -0.0804, -0.0280,\n","                        0.0689,  0.0235, -0.0144,  0.0388,  0.0131,  0.2219,  0.1321, -0.0909,\n","                        0.0514,  0.0081, -0.0029, -0.0294, -0.0282,  0.1405, -0.0914, -0.0115,\n","                        0.2809, -0.0897, -0.1800,  0.1784,  0.3077,  0.0234, -0.0828, -0.0538,\n","                       -0.1445, -0.0256, -0.1615,  0.1817,  0.1238,  0.0108,  0.0404,  0.0625,\n","                       -0.1515,  0.1363, -0.0756, -0.0011,  0.2078, -0.0568,  0.3332,  0.2600],\n","                      device='cuda:0')),\n","              ('module.layer3.8.conv1.accum_scale', tensor([[[1.6180e+10]],\n","               \n","                       [[2.7595e+10]],\n","               \n","                       [[1.6900e+10]],\n","               \n","                       [[2.0738e+10]],\n","               \n","                       [[1.5494e+10]],\n","               \n","                       [[1.3921e+10]],\n","               \n","                       [[1.8011e+10]],\n","               \n","                       [[1.8550e+10]],\n","               \n","                       [[1.6860e+10]],\n","               \n","                       [[1.3570e+10]],\n","               \n","                       [[8.5354e+09]],\n","               \n","                       [[1.9143e+10]],\n","               \n","                       [[1.6917e+10]],\n","               \n","                       [[2.9000e+10]],\n","               \n","                       [[7.5579e+09]],\n","               \n","                       [[1.1386e+10]],\n","               \n","                       [[1.6095e+10]],\n","               \n","                       [[2.1087e+10]],\n","               \n","                       [[1.0590e+10]],\n","               \n","                       [[5.9354e+09]],\n","               \n","                       [[1.4447e+10]],\n","               \n","                       [[9.7065e+09]],\n","               \n","                       [[8.0340e+09]],\n","               \n","                       [[1.1536e+10]],\n","               \n","                       [[1.0744e+10]],\n","               \n","                       [[1.2527e+10]],\n","               \n","                       [[7.3200e+09]],\n","               \n","                       [[7.6266e+09]],\n","               \n","                       [[1.5345e+10]],\n","               \n","                       [[1.4675e+10]],\n","               \n","                       [[1.7169e+10]],\n","               \n","                       [[1.1785e+10]],\n","               \n","                       [[5.5759e+09]],\n","               \n","                       [[2.3037e+10]],\n","               \n","                       [[1.1814e+10]],\n","               \n","                       [[1.2241e+10]],\n","               \n","                       [[1.4762e+10]],\n","               \n","                       [[1.8643e+10]],\n","               \n","                       [[7.4959e+09]],\n","               \n","                       [[1.7132e+10]],\n","               \n","                       [[1.4328e+10]],\n","               \n","                       [[9.8051e+09]],\n","               \n","                       [[1.0624e+10]],\n","               \n","                       [[8.2478e+09]],\n","               \n","                       [[1.6549e+10]],\n","               \n","                       [[1.1827e+10]],\n","               \n","                       [[9.2070e+09]],\n","               \n","                       [[9.5761e+09]],\n","               \n","                       [[1.1065e+10]],\n","               \n","                       [[1.6632e+10]],\n","               \n","                       [[8.4234e+09]],\n","               \n","                       [[1.3329e+10]],\n","               \n","                       [[1.4819e+10]],\n","               \n","                       [[1.1231e+10]],\n","               \n","                       [[1.8998e+10]],\n","               \n","                       [[1.5795e+10]],\n","               \n","                       [[1.8231e+10]],\n","               \n","                       [[1.0887e+10]],\n","               \n","                       [[5.5241e+09]],\n","               \n","                       [[1.8914e+10]],\n","               \n","                       [[2.3172e+10]],\n","               \n","                       [[1.5824e+10]],\n","               \n","                       [[1.6162e+10]],\n","               \n","                       [[1.3873e+10]]], device='cuda:0')),\n","              ('module.layer3.8.conv1.is_simulated_quant_weight_shifted',\n","               tensor(False, device='cuda:0')),\n","              ('module.layer3.8.conv1.wrapped_module.weight',\n","               tensor([[[[37921., 32317., 28070.],\n","                         [32425., 26897., 25614.],\n","                         [22119., 23389., 22611.]],\n","               \n","                        [[31663., 38173., 35890.],\n","                         [40237., 46943., 33405.],\n","                         [26358., 36867., 33241.]],\n","               \n","                        [[37716., 40095., 36745.],\n","                         [41598., 43825., 39242.],\n","                         [38595., 45140., 49113.]],\n","               \n","                        ...,\n","               \n","                        [[22468., 22304., 20425.],\n","                         [24353., 32328., 32249.],\n","                         [30078., 39469., 38737.]],\n","               \n","                        [[19316., 15791., 13960.],\n","                         [10694., 10342., 10263.],\n","                         [21191., 16408.,  9990.]],\n","               \n","                        [[46235., 42723., 43300.],\n","                         [42641., 38538., 27795.],\n","                         [44870., 42095., 35157.]]],\n","               \n","               \n","                       [[[32063., 35066., 21769.],\n","                         [36742., 44119., 36492.],\n","                         [29840., 34891., 29550.]],\n","               \n","                        [[42427., 47658., 36742.],\n","                         [43980., 43641., 36707.],\n","                         [40264., 46500., 48594.]],\n","               \n","                        [[59384., 45240., 42560.],\n","                         [60058., 41668., 33501.],\n","                         [54219., 38754., 39827.]],\n","               \n","                        ...,\n","               \n","                        [[31035., 32823., 31068.],\n","                         [36111., 36790., 34755.],\n","                         [43797., 41445., 39305.]],\n","               \n","                        [[24872., 25746., 24069.],\n","                         [18807., 22655., 18139.],\n","                         [21279., 22862., 31800.]],\n","               \n","                        [[31936., 36180., 30255.],\n","                         [37632., 34527., 36179.],\n","                         [40424., 34735., 33521.]]],\n","               \n","               \n","                       [[[ 9459., 13196., 11677.],\n","                         [24719., 32404., 34595.],\n","                         [23177., 44875., 58550.]],\n","               \n","                        [[21460., 20421.,  9089.],\n","                         [16118., 20176., 13100.],\n","                         [10200., 11884., 13630.]],\n","               \n","                        [[46201., 41662., 41669.],\n","                         [48429., 48808., 50462.],\n","                         [20667., 18748., 25903.]],\n","               \n","                        ...,\n","               \n","                        [[35547., 41950., 37634.],\n","                         [33501., 41098., 41270.],\n","                         [29263., 35560., 38556.]],\n","               \n","                        [[22098., 29543., 36920.],\n","                         [30204., 40286., 46195.],\n","                         [27503., 32144., 34483.]],\n","               \n","                        [[23135., 23494., 34333.],\n","                         [37211., 40028., 41312.],\n","                         [36202., 39960., 39871.]]],\n","               \n","               \n","                       ...,\n","               \n","               \n","                       [[[11008.,  6253., 20321.],\n","                         [35966., 37417., 40250.],\n","                         [33226., 40834., 35772.]],\n","               \n","                        [[22999., 19269., 10102.],\n","                         [19815., 19012., 17205.],\n","                         [19649., 20914., 24547.]],\n","               \n","                        [[28476., 20419., 13448.],\n","                         [47248., 48705., 31623.],\n","                         [24026., 28955., 21534.]],\n","               \n","                        ...,\n","               \n","                        [[27567., 29576., 35837.],\n","                         [20252., 21458., 27102.],\n","                         [17020., 18495., 23737.]],\n","               \n","                        [[21800., 16974., 13470.],\n","                         [ 6336.,  5375.,  8838.],\n","                         [    0.,  1550., 13998.]],\n","               \n","                        [[ 7267.,  5078.,  2810.],\n","                         [11010.,  6201., 14140.],\n","                         [21475., 11616., 24376.]]],\n","               \n","               \n","                       [[[38171., 54127., 61149.],\n","                         [20308., 14423., 19247.],\n","                         [28083., 19828., 12250.]],\n","               \n","                        [[22969., 26045., 22059.],\n","                         [24154., 28157., 26372.],\n","                         [29587., 29728., 28565.]],\n","               \n","                        [[ 9824., 18550., 17219.],\n","                         [ 2500., 12990., 12878.],\n","                         [ 2031.,  8744., 11156.]],\n","               \n","                        ...,\n","               \n","                        [[33433., 32075., 28491.],\n","                         [29408., 31607., 27408.],\n","                         [25508., 29247., 29366.]],\n","               \n","                        [[12939., 11382., 12659.],\n","                         [22710., 28084., 21584.],\n","                         [25108., 34707., 24291.]],\n","               \n","                        [[51657., 48226., 43509.],\n","                         [38911., 38643., 27932.],\n","                         [42168., 44428., 30067.]]],\n","               \n","               \n","                       [[[16162., 16423., 15033.],\n","                         [25045., 29743., 28071.],\n","                         [25155., 32374., 37974.]],\n","               \n","                        [[32901., 24963., 15624.],\n","                         [20353., 16915., 13195.],\n","                         [24960., 25769., 24246.]],\n","               \n","                        [[45154., 39472., 26779.],\n","                         [57093., 43187., 29399.],\n","                         [53597., 42575., 31061.]],\n","               \n","                        ...,\n","               \n","                        [[40966., 46480., 46068.],\n","                         [38839., 44619., 45176.],\n","                         [32913., 37474., 42278.]],\n","               \n","                        [[47902., 40687., 29787.],\n","                         [44903., 37685., 34007.],\n","                         [33414., 30974., 31751.]],\n","               \n","                        [[23234., 25374., 16296.],\n","                         [16230., 23490., 19541.],\n","                         [ 7953., 17924., 22344.]]]], device='cuda:0')),\n","              ('module.layer3.8.conv1.wrapped_module.bias',\n","               tensor([ 2.1475e+09,  2.1475e+09,  2.1475e+09,  2.1475e+09,  1.5933e+09,\n","                       -1.4816e+09,  2.1475e+09,  1.2639e+09,  7.5783e+08, -1.4657e+09,\n","                       -8.9737e+08,  2.1475e+09, -1.3427e+09,  2.1475e+09, -6.9619e+08,\n","                        8.4181e+07, -2.0515e+07, -1.1519e+09,  1.9412e+09, -2.9987e+08,\n","                       -2.1475e+09,  6.0143e+08, -6.4555e+08, -3.2334e+08,  7.4003e+08,\n","                        2.9446e+08, -1.0540e+08,  2.9581e+08,  2.0095e+08,  2.1475e+09,\n","                        2.1475e+09, -1.0714e+09,  2.8680e+08,  1.8676e+08, -3.3727e+07,\n","                       -3.5955e+08, -4.1596e+08,  2.1475e+09, -6.8491e+08, -1.9727e+08,\n","                        2.1475e+09, -8.7980e+08, -1.9120e+09,  1.4716e+09,  2.1475e+09,\n","                        2.7719e+08, -7.6257e+08, -5.1565e+08, -1.5991e+09, -4.2528e+08,\n","                       -1.3604e+09,  2.1475e+09,  1.8340e+09,  1.2171e+08,  7.6842e+08,\n","                        9.8747e+08, -2.1475e+09,  1.4844e+09, -4.1766e+08, -2.1106e+07,\n","                        2.1475e+09, -8.9883e+08,  2.1475e+09,  2.1475e+09], device='cuda:0')),\n","              ('module.layer3.8.conv2.num_forwards',\n","               tensor([40], device='cuda:0')),\n","              ('module.layer3.8.conv2.force_readjust',\n","               tensor(False, device='cuda:0')),\n","              ('module.layer3.8.conv2.output_scale',\n","               tensor([8528.9678], device='cuda:0')),\n","              ('module.layer3.8.conv2.output_zero_point',\n","               tensor([-21078.], device='cuda:0')),\n","              ('module.layer3.8.conv2.w_scale', tensor([[[[  92520.1172]]],\n","               \n","               \n","                       [[[ 101452.8281]]],\n","               \n","               \n","                       [[[  41910.5508]]],\n","               \n","               \n","                       [[[  87909.9609]]],\n","               \n","               \n","                       [[[  61113.3047]]],\n","               \n","               \n","                       [[[  79963.5625]]],\n","               \n","               \n","                       [[[ 148508.9531]]],\n","               \n","               \n","                       [[[ 552255.9375]]],\n","               \n","               \n","                       [[[ 218796.7031]]],\n","               \n","               \n","                       [[[ 452390.0000]]],\n","               \n","               \n","                       [[[  82580.0703]]],\n","               \n","               \n","                       [[[ 197473.9062]]],\n","               \n","               \n","                       [[[  68813.0703]]],\n","               \n","               \n","                       [[[ 104166.5781]]],\n","               \n","               \n","                       [[[ 161838.0781]]],\n","               \n","               \n","                       [[[ 119001.5312]]],\n","               \n","               \n","                       [[[1950115.5000]]],\n","               \n","               \n","                       [[[ 158869.2344]]],\n","               \n","               \n","                       [[[ 214485.7812]]],\n","               \n","               \n","                       [[[ 167332.6875]]],\n","               \n","               \n","                       [[[ 106413.3438]]],\n","               \n","               \n","                       [[[ 271988.3750]]],\n","               \n","               \n","                       [[[ 195219.2969]]],\n","               \n","               \n","                       [[[ 192610.0469]]],\n","               \n","               \n","                       [[[  72521.6875]]],\n","               \n","               \n","                       [[[ 144922.5000]]],\n","               \n","               \n","                       [[[ 166725.0000]]],\n","               \n","               \n","                       [[[ 155418.2969]]],\n","               \n","               \n","                       [[[ 226125.4375]]],\n","               \n","               \n","                       [[[ 139237.3750]]],\n","               \n","               \n","                       [[[ 401653.0938]]],\n","               \n","               \n","                       [[[ 570716.9375]]],\n","               \n","               \n","                       [[[ 140526.5000]]],\n","               \n","               \n","                       [[[ 617567.6250]]],\n","               \n","               \n","                       [[[ 491183.0000]]],\n","               \n","               \n","                       [[[ 243402.7031]]],\n","               \n","               \n","                       [[[ 161452.5625]]],\n","               \n","               \n","                       [[[ 194457.4375]]],\n","               \n","               \n","                       [[[ 174787.0469]]],\n","               \n","               \n","                       [[[ 126958.7422]]],\n","               \n","               \n","                       [[[ 112757.5078]]],\n","               \n","               \n","                       [[[ 193516.1406]]],\n","               \n","               \n","                       [[[ 113549.0234]]],\n","               \n","               \n","                       [[[ 235360.4844]]],\n","               \n","               \n","                       [[[2041468.7500]]],\n","               \n","               \n","                       [[[ 346867.1875]]],\n","               \n","               \n","                       [[[ 670064.7500]]],\n","               \n","               \n","                       [[[1100367.3750]]],\n","               \n","               \n","                       [[[ 147812.4219]]],\n","               \n","               \n","                       [[[1287326.6250]]],\n","               \n","               \n","                       [[[ 189017.2969]]],\n","               \n","               \n","                       [[[ 912048.9375]]],\n","               \n","               \n","                       [[[ 162837.0938]]],\n","               \n","               \n","                       [[[ 182346.2500]]],\n","               \n","               \n","                       [[[1865622.7500]]],\n","               \n","               \n","                       [[[ 445408.6875]]],\n","               \n","               \n","                       [[[ 648017.5000]]],\n","               \n","               \n","                       [[[ 113647.7500]]],\n","               \n","               \n","                       [[[  70041.1250]]],\n","               \n","               \n","                       [[[ 107272.6875]]],\n","               \n","               \n","                       [[[ 236009.4219]]],\n","               \n","               \n","                       [[[ 250519.9219]]],\n","               \n","               \n","                       [[[ 191357.3594]]],\n","               \n","               \n","                       [[[ 167430.1406]]]], device='cuda:0')),\n","              ('module.layer3.8.conv2.w_zero_point', tensor([[[[-29332.]]],\n","               \n","               \n","                       [[[-41507.]]],\n","               \n","               \n","                       [[[-26607.]]],\n","               \n","               \n","                       [[[-34040.]]],\n","               \n","               \n","                       [[[-25283.]]],\n","               \n","               \n","                       [[[-34206.]]],\n","               \n","               \n","                       [[[-30952.]]],\n","               \n","               \n","                       [[[-24737.]]],\n","               \n","               \n","                       [[[-39047.]]],\n","               \n","               \n","                       [[[-27910.]]],\n","               \n","               \n","                       [[[-24384.]]],\n","               \n","               \n","                       [[[-29239.]]],\n","               \n","               \n","                       [[[-23118.]]],\n","               \n","               \n","                       [[[-34832.]]],\n","               \n","               \n","                       [[[-39100.]]],\n","               \n","               \n","                       [[[-25681.]]],\n","               \n","               \n","                       [[[-36248.]]],\n","               \n","               \n","                       [[[-20149.]]],\n","               \n","               \n","                       [[[-29680.]]],\n","               \n","               \n","                       [[[-24973.]]],\n","               \n","               \n","                       [[[-31458.]]],\n","               \n","               \n","                       [[[-28604.]]],\n","               \n","               \n","                       [[[-34824.]]],\n","               \n","               \n","                       [[[-29028.]]],\n","               \n","               \n","                       [[[-34077.]]],\n","               \n","               \n","                       [[[-33963.]]],\n","               \n","               \n","                       [[[-28752.]]],\n","               \n","               \n","                       [[[-27449.]]],\n","               \n","               \n","                       [[[-29985.]]],\n","               \n","               \n","                       [[[-32592.]]],\n","               \n","               \n","                       [[[-23645.]]],\n","               \n","               \n","                       [[[-26938.]]],\n","               \n","               \n","                       [[[-26188.]]],\n","               \n","               \n","                       [[[-26617.]]],\n","               \n","               \n","                       [[[-20682.]]],\n","               \n","               \n","                       [[[-37266.]]],\n","               \n","               \n","                       [[[-34877.]]],\n","               \n","               \n","                       [[[-30546.]]],\n","               \n","               \n","                       [[[-30900.]]],\n","               \n","               \n","                       [[[-35978.]]],\n","               \n","               \n","                       [[[-28303.]]],\n","               \n","               \n","                       [[[-24808.]]],\n","               \n","               \n","                       [[[-24819.]]],\n","               \n","               \n","                       [[[-31965.]]],\n","               \n","               \n","                       [[[-29614.]]],\n","               \n","               \n","                       [[[-31532.]]],\n","               \n","               \n","                       [[[-36436.]]],\n","               \n","               \n","                       [[[-29025.]]],\n","               \n","               \n","                       [[[-30182.]]],\n","               \n","               \n","                       [[[-28670.]]],\n","               \n","               \n","                       [[[-29164.]]],\n","               \n","               \n","                       [[[-32705.]]],\n","               \n","               \n","                       [[[-23038.]]],\n","               \n","               \n","                       [[[-31870.]]],\n","               \n","               \n","                       [[[-32226.]]],\n","               \n","               \n","                       [[[-31708.]]],\n","               \n","               \n","                       [[[-27041.]]],\n","               \n","               \n","                       [[[-28826.]]],\n","               \n","               \n","                       [[[-23249.]]],\n","               \n","               \n","                       [[[-20295.]]],\n","               \n","               \n","                       [[[-35745.]]],\n","               \n","               \n","                       [[[-24489.]]],\n","               \n","               \n","                       [[[-29746.]]],\n","               \n","               \n","                       [[[-30152.]]]], device='cuda:0')),\n","              ('module.layer3.8.conv2.fp_bias',\n","               tensor([ 8.1727e-01,  8.5649e-01, -8.4451e-01,  7.0041e-01,  4.4967e-01,\n","                        6.7411e-01,  6.0290e-01,  1.2894e-02,  4.3725e-01, -1.3663e-04,\n","                       -1.3134e-01,  8.2572e-02,  6.1982e-02,  2.5464e-01,  5.0888e-01,\n","                        3.9109e-01, -1.5843e-01, -1.4457e-01,  4.1171e-02,  3.7240e-01,\n","                        2.4342e-02,  3.4995e-02, -7.6947e-02,  1.6564e-01,  8.6376e-01,\n","                        4.0951e-01,  2.3556e-01,  2.9943e-01,  1.0196e-01,  7.1574e-02,\n","                       -1.1360e-02, -5.2575e-02,  1.7855e-01, -6.5539e-02, -1.7127e-01,\n","                        4.9062e-02,  4.4079e-01,  8.3113e-02,  1.4252e-02,  3.2113e-01,\n","                        2.5253e-01, -2.6794e-02,  3.2971e-01,  2.2469e-01,  1.5501e-02,\n","                       -8.1888e-02,  1.4668e-01, -1.2635e-01,  8.4136e-02,  3.1103e-02,\n","                        1.6736e-01, -3.4224e-02,  2.2126e-02,  4.4411e-01, -6.3725e-02,\n","                       -9.5593e-02, -9.9483e-02,  3.5902e-01,  4.7350e-01, -4.6346e-02,\n","                       -1.6203e-01, -2.9086e-02,  1.3863e-01, -6.1095e-02], device='cuda:0')),\n","              ('module.layer3.8.conv2.accum_scale', tensor([[[5.9085e+09]],\n","               \n","                       [[6.4790e+09]],\n","               \n","                       [[2.6765e+09]],\n","               \n","                       [[5.6141e+09]],\n","               \n","                       [[3.9028e+09]],\n","               \n","                       [[5.1066e+09]],\n","               \n","                       [[9.4841e+09]],\n","               \n","                       [[3.5268e+10]],\n","               \n","                       [[1.3973e+10]],\n","               \n","                       [[2.8891e+10]],\n","               \n","                       [[5.2737e+09]],\n","               \n","                       [[1.2611e+10]],\n","               \n","                       [[4.3946e+09]],\n","               \n","                       [[6.6523e+09]],\n","               \n","                       [[1.0335e+10]],\n","               \n","                       [[7.5997e+09]],\n","               \n","                       [[1.2454e+11]],\n","               \n","                       [[1.0146e+10]],\n","               \n","                       [[1.3698e+10]],\n","               \n","                       [[1.0686e+10]],\n","               \n","                       [[6.7958e+09]],\n","               \n","                       [[1.7370e+10]],\n","               \n","                       [[1.2467e+10]],\n","               \n","                       [[1.2300e+10]],\n","               \n","                       [[4.6314e+09]],\n","               \n","                       [[9.2551e+09]],\n","               \n","                       [[1.0647e+10]],\n","               \n","                       [[9.9253e+09]],\n","               \n","                       [[1.4441e+10]],\n","               \n","                       [[8.8920e+09]],\n","               \n","                       [[2.5650e+10]],\n","               \n","                       [[3.6447e+10]],\n","               \n","                       [[8.9743e+09]],\n","               \n","                       [[3.9439e+10]],\n","               \n","                       [[3.1368e+10]],\n","               \n","                       [[1.5544e+10]],\n","               \n","                       [[1.0311e+10]],\n","               \n","                       [[1.2418e+10]],\n","               \n","                       [[1.1162e+10]],\n","               \n","                       [[8.1079e+09]],\n","               \n","                       [[7.2009e+09]],\n","               \n","                       [[1.2358e+10]],\n","               \n","                       [[7.2515e+09]],\n","               \n","                       [[1.5031e+10]],\n","               \n","                       [[1.3037e+11]],\n","               \n","                       [[2.2152e+10]],\n","               \n","                       [[4.2792e+10]],\n","               \n","                       [[7.0272e+10]],\n","               \n","                       [[9.4396e+09]],\n","               \n","                       [[8.2211e+10]],\n","               \n","                       [[1.2071e+10]],\n","               \n","                       [[5.8245e+10]],\n","               \n","                       [[1.0399e+10]],\n","               \n","                       [[1.1645e+10]],\n","               \n","                       [[1.1914e+11]],\n","               \n","                       [[2.8445e+10]],\n","               \n","                       [[4.1384e+10]],\n","               \n","                       [[7.2578e+09]],\n","               \n","                       [[4.4730e+09]],\n","               \n","                       [[6.8507e+09]],\n","               \n","                       [[1.5072e+10]],\n","               \n","                       [[1.5999e+10]],\n","               \n","                       [[1.2220e+10]],\n","               \n","                       [[1.0692e+10]]], device='cuda:0')),\n","              ('module.layer3.8.conv2.is_simulated_quant_weight_shifted',\n","               tensor(False, device='cuda:0')),\n","              ('module.layer3.8.conv2.wrapped_module.weight',\n","               tensor([[[[25103., 23171., 22822.],\n","                         [20856., 17490., 20515.],\n","                         [27512., 24217., 26030.]],\n","               \n","                        [[26867., 22700., 26657.],\n","                         [21346., 15435., 22040.],\n","                         [25975., 20598., 25408.]],\n","               \n","                        [[53707., 36777., 38309.],\n","                         [36563., 16011., 23627.],\n","                         [35826., 17721., 26751.]],\n","               \n","                        ...,\n","               \n","                        [[29350., 30428., 29094.],\n","                         [26709., 28094., 29356.],\n","                         [26097., 27010., 31211.]],\n","               \n","                        [[34384., 29501., 38514.],\n","                         [22572., 12915., 24290.],\n","                         [38579., 30958., 39001.]],\n","               \n","                        [[18928., 15608., 19583.],\n","                         [12700.,  7044., 13221.],\n","                         [20827., 15037., 18314.]]],\n","               \n","               \n","                       [[[40375., 34829., 38294.],\n","                         [37509., 32131., 37417.],\n","                         [46413., 41404., 42309.]],\n","               \n","                        [[42046., 40127., 45851.],\n","                         [37374., 37048., 45528.],\n","                         [39700., 37899., 44551.]],\n","               \n","                        [[19867., 13697., 24725.],\n","                         [ 7904.,     0.,  9086.],\n","                         [21592., 16420., 22361.]],\n","               \n","                        ...,\n","               \n","                        [[38268., 37211., 34789.],\n","                         [42579., 42184., 37970.],\n","                         [50979., 49138., 39029.]],\n","               \n","                        [[45741., 36647., 46093.],\n","                         [33707., 20374., 30445.],\n","                         [30900., 16111., 24749.]],\n","               \n","                        [[35327., 34901., 44123.],\n","                         [32567., 29487., 38877.],\n","                         [41460., 37885., 42132.]]],\n","               \n","               \n","                       [[[38049., 42584., 41626.],\n","                         [34007., 35338., 35271.],\n","                         [30090., 33044., 29631.]],\n","               \n","                        [[31300., 33319., 32628.],\n","                         [29939., 31318., 30401.],\n","                         [25494., 28989., 27581.]],\n","               \n","                        [[35002., 34613., 40959.],\n","                         [27165., 25129., 35070.],\n","                         [27710., 29585., 34607.]],\n","               \n","                        ...,\n","               \n","                        [[32209., 31126., 32159.],\n","                         [23598., 19328., 23155.],\n","                         [31390., 32747., 33092.]],\n","               \n","                        [[22262., 17247., 19944.],\n","                         [11353.,  9529., 12621.],\n","                         [    0.,  2503.,  6372.]],\n","               \n","                        [[28984., 35350., 35415.],\n","                         [27638., 36586., 35701.],\n","                         [24813., 31758., 31159.]]],\n","               \n","               \n","                       ...,\n","               \n","               \n","                       [[[16636., 18085., 22764.],\n","                         [11983., 12507., 16271.],\n","                         [13111., 14087., 15916.]],\n","               \n","                        [[15832., 16486., 20877.],\n","                         [14317., 14398., 19516.],\n","                         [21004., 20457., 24982.]],\n","               \n","                        [[17244., 14902., 19034.],\n","                         [20480., 16760., 19808.],\n","                         [31417., 23753., 20934.]],\n","               \n","                        ...,\n","               \n","                        [[21844., 22730., 25827.],\n","                         [22145., 23226., 25204.],\n","                         [19600., 22606., 21784.]],\n","               \n","                        [[24364., 23714., 27932.],\n","                         [22675., 22434., 30338.],\n","                         [32341., 34725., 45650.]],\n","               \n","                        [[33550., 33604., 40693.],\n","                         [38984., 37570., 41737.],\n","                         [47418., 46859., 48034.]]],\n","               \n","               \n","                       [[[22675., 24926., 27899.],\n","                         [20212., 18808., 18764.],\n","                         [28296., 26260., 25331.]],\n","               \n","                        [[31340., 28138., 28936.],\n","                         [24017., 19000., 20252.],\n","                         [28060., 23646., 25875.]],\n","               \n","                        [[65535., 63136., 64130.],\n","                         [42678., 36943., 39208.],\n","                         [35614., 28602., 31854.]],\n","               \n","                        ...,\n","               \n","                        [[23181., 18962., 13450.],\n","                         [16368., 13121., 11135.],\n","                         [18333., 18941., 21043.]],\n","               \n","                        [[24164., 16184., 26005.],\n","                         [18769.,  8211., 17957.],\n","                         [27203., 21044., 27613.]],\n","               \n","                        [[18327., 17035., 23588.],\n","                         [10400.,  6427., 12322.],\n","                         [17089.,  9774., 14544.]]],\n","               \n","               \n","                       [[[32865., 30720., 34692.],\n","                         [28406., 24972., 29205.],\n","                         [32854., 26693., 30548.]],\n","               \n","                        [[32792., 29443., 31739.],\n","                         [29502., 24419., 25610.],\n","                         [29334., 24204., 25935.]],\n","               \n","                        [[32342., 22686., 22554.],\n","                         [24037., 10519., 17316.],\n","                         [27368., 13590., 25672.]],\n","               \n","                        ...,\n","               \n","                        [[36399., 30075., 32691.],\n","                         [33000., 27332., 28884.],\n","                         [24518., 20877., 25413.]],\n","               \n","                        [[34552., 32732., 44281.],\n","                         [29065., 26079., 38240.],\n","                         [45097., 43215., 58218.]],\n","               \n","                        [[19595., 17143., 20850.],\n","                         [19708., 20830., 23399.],\n","                         [11993., 11938., 13873.]]]], device='cuda:0')),\n","              ('module.layer3.8.conv2.wrapped_module.bias',\n","               tensor([ 2.1475e+09,  2.1475e+09, -2.1475e+09,  2.1475e+09,  1.7550e+09,\n","                        2.1475e+09,  2.1475e+09,  4.5475e+08,  2.1475e+09, -3.9473e+06,\n","                       -6.9265e+08,  1.0413e+09,  2.7238e+08,  1.6939e+09,  2.1475e+09,\n","                        2.1475e+09, -2.1475e+09, -1.4668e+09,  5.6393e+08,  2.1475e+09,\n","                        1.6542e+08,  6.0785e+08, -9.5931e+08,  2.0374e+09,  2.1475e+09,\n","                        2.1475e+09,  2.1475e+09,  2.1475e+09,  1.4723e+09,  6.3644e+08,\n","                       -2.9139e+08, -1.9162e+09,  1.6023e+09, -2.1475e+09, -2.1475e+09,\n","                        7.6263e+08,  2.1475e+09,  1.0321e+09,  1.5908e+08,  2.1475e+09,\n","                        1.8185e+09, -3.3113e+08,  2.1475e+09,  2.1475e+09,  2.0209e+09,\n","                       -1.8140e+09,  2.1475e+09, -2.1475e+09,  7.9422e+08,  2.1475e+09,\n","                        2.0202e+09, -1.9934e+09,  2.3009e+08,  2.1475e+09, -2.1475e+09,\n","                       -2.1475e+09, -2.1475e+09,  2.1475e+09,  2.1180e+09, -3.1750e+08,\n","                       -2.1475e+09, -4.6534e+08,  1.6941e+09, -6.5325e+08], device='cuda:0')),\n","              ('module.layer3.8.relu2.num_forwards',\n","               tensor([40], device='cuda:0')),\n","              ('module.layer3.8.relu2.force_readjust',\n","               tensor(False, device='cuda:0')),\n","              ('module.layer3.8.relu2.output_scale',\n","               tensor([2972.4727], device='cuda:0')),\n","              ('module.layer3.8.relu2.output_zero_point',\n","               tensor([0.], device='cuda:0')),\n","              ('module.layer3.8.residual_eltwiseadd.num_forwards',\n","               tensor([40], device='cuda:0')),\n","              ('module.layer3.8.residual_eltwiseadd.force_readjust',\n","               tensor(False, device='cuda:0')),\n","              ('module.layer3.8.residual_eltwiseadd.output_scale',\n","               tensor([2972.4727], device='cuda:0')),\n","              ('module.layer3.8.residual_eltwiseadd.output_zero_point',\n","               tensor([0.], device='cuda:0')),\n","              ('module.avgpool.num_forwards', tensor([40], device='cuda:0')),\n","              ('module.avgpool.force_readjust',\n","               tensor(False, device='cuda:0')),\n","              ('module.avgpool.output_scale',\n","               tensor([16548.5020], device='cuda:0')),\n","              ('module.avgpool.output_zero_point',\n","               tensor([0.], device='cuda:0')),\n","              ('module.fc.num_forwards', tensor([40], device='cuda:0')),\n","              ('module.fc.force_readjust', tensor(False, device='cuda:0')),\n","              ('module.fc.output_scale', tensor([2485.2639], device='cuda:0')),\n","              ('module.fc.output_zero_point',\n","               tensor([-18567.], device='cuda:0')),\n","              ('module.fc.w_scale', tensor([[27505.5117],\n","                       [26372.2422],\n","                       [25472.3789],\n","                       [31819.7656],\n","                       [26080.6406],\n","                       [23201.2344],\n","                       [27528.9043],\n","                       [27581.5742],\n","                       [24097.7930],\n","                       [23911.3008]], device='cuda:0')),\n","              ('module.fc.w_zero_point', tensor([[-26618.],\n","                       [-19325.],\n","                       [-30651.],\n","                       [-22127.],\n","                       [-20578.],\n","                       [-17756.],\n","                       [-21631.],\n","                       [-20407.],\n","                       [-22664.],\n","                       [-15241.]], device='cuda:0')),\n","              ('module.fc.fp_bias',\n","               tensor([ 0.0103, -0.4491,  0.2737,  0.4109,  0.1017, -0.1730,  0.1324, -0.0055,\n","                       -0.2107, -0.0913], device='cuda:0')),\n","              ('module.fc.accum_scale',\n","               tensor([4.5518e+08, 4.3642e+08, 4.2153e+08, 5.2657e+08, 4.3160e+08, 3.8395e+08,\n","                       4.5556e+08, 4.5643e+08, 3.9878e+08, 3.9570e+08], device='cuda:0')),\n","              ('module.fc.is_simulated_quant_weight_shifted',\n","               tensor(False, device='cuda:0')),\n","              ('module.fc.wrapped_module.weight',\n","               tensor([[3.3400e+03, 1.5006e+04, 2.5819e+04, 9.5400e+02, 4.7026e+04, 5.0039e+04,\n","                        2.8544e+04, 2.9585e+04, 1.9385e+04, 2.3320e+04, 3.6146e+04, 2.6203e+04,\n","                        4.0618e+04, 1.7964e+04, 1.7653e+04, 3.8708e+04, 2.2835e+04, 3.8859e+04,\n","                        1.8625e+04, 2.9668e+04, 1.2103e+04, 1.8783e+04, 1.9459e+04, 4.6783e+04,\n","                        5.0053e+04, 9.1070e+03, 3.3847e+04, 1.8406e+04, 1.9837e+04, 2.4483e+04,\n","                        2.1306e+04, 1.8400e+04, 3.9788e+04, 2.7760e+04, 2.5228e+04, 2.3033e+04,\n","                        5.3463e+04, 1.8328e+04, 5.8710e+03, 4.9906e+04, 3.5474e+04, 3.7321e+04,\n","                        1.8189e+04, 2.1570e+03, 2.5305e+04, 2.7458e+04, 2.7952e+04, 2.7727e+04,\n","                        1.5442e+04, 2.8123e+04, 6.5535e+04, 1.9983e+04, 0.0000e+00, 2.8661e+04,\n","                        2.7368e+04, 2.1340e+04, 2.7873e+04, 2.4912e+04, 2.0014e+04, 4.4443e+04,\n","                        1.8930e+04, 3.2245e+04, 3.5245e+04, 1.4977e+04],\n","                       [8.0920e+03, 1.3334e+04, 6.5535e+04, 6.5940e+03, 1.6155e+04, 3.2040e+04,\n","                        1.0720e+04, 1.7790e+04, 1.0727e+04, 1.4525e+04, 5.7590e+04, 1.7802e+04,\n","                        2.6290e+04, 1.9628e+04, 1.6520e+04, 3.4160e+03, 1.2014e+04, 3.2124e+04,\n","                        2.1140e+04, 4.4520e+03, 2.5144e+04, 2.1298e+04, 3.4387e+04, 2.4217e+04,\n","                        0.0000e+00, 1.2869e+04, 9.7170e+03, 2.5933e+04, 1.5198e+04, 9.9030e+03,\n","                        3.5447e+04, 1.4803e+04, 2.8625e+04, 2.0532e+04, 8.4480e+03, 3.1672e+04,\n","                        1.7068e+04, 1.6453e+04, 6.0207e+04, 6.3700e+03, 2.4892e+04, 2.1296e+04,\n","                        1.7252e+04, 5.1650e+03, 2.0151e+04, 1.9457e+04, 2.3207e+04, 1.5944e+04,\n","                        2.3591e+04, 2.0821e+04, 4.4850e+03, 1.7983e+04, 4.4080e+03, 7.4580e+03,\n","                        1.7553e+04, 3.2350e+04, 1.8167e+04, 1.4373e+04, 1.3463e+04, 2.8215e+04,\n","                        2.1556e+04, 8.6140e+03, 7.1400e+03, 1.3718e+04],\n","                       [1.8412e+04, 2.3689e+04, 1.4101e+04, 5.1200e+04, 4.4635e+04, 1.6862e+04,\n","                        1.9736e+04, 3.2855e+04, 2.0039e+04, 2.4429e+04, 2.4830e+04, 2.4623e+04,\n","                        0.0000e+00, 1.2331e+04, 4.7890e+04, 9.4210e+03, 1.8604e+04, 2.9448e+04,\n","                        4.8081e+04, 1.7515e+04, 1.4105e+04, 2.8172e+04, 2.9756e+04, 2.0177e+04,\n","                        3.5060e+04, 4.0820e+04, 2.4862e+04, 3.1695e+04, 4.7867e+04, 4.2912e+04,\n","                        1.6181e+04, 4.8241e+04, 3.9323e+04, 2.7378e+04, 3.4336e+04, 3.4104e+04,\n","                        1.2948e+04, 2.0060e+04, 3.5987e+04, 3.0093e+04, 3.9402e+04, 4.8707e+04,\n","                        2.4245e+04, 4.6598e+04, 2.8175e+04, 2.9413e+04, 2.5757e+04, 6.5535e+04,\n","                        2.9792e+04, 2.9817e+04, 6.3317e+04, 3.3813e+04, 4.1974e+04, 2.7416e+04,\n","                        2.8455e+04, 4.1200e+04, 2.6448e+04, 3.6100e+04, 3.9242e+04, 4.0333e+04,\n","                        2.7225e+04, 4.4320e+04, 3.9106e+04, 5.2265e+04],\n","                       [1.0253e+04, 1.2340e+03, 7.2310e+03, 3.2401e+04, 1.1309e+04, 1.1477e+04,\n","                        2.7983e+04, 2.7220e+04, 2.8200e+04, 2.3146e+04, 1.7050e+03, 5.6131e+04,\n","                        4.1119e+04, 1.6575e+04, 5.4400e+02, 5.7964e+04, 2.6424e+04, 3.3705e+04,\n","                        2.6294e+04, 2.6681e+04, 2.7381e+04, 3.6832e+04, 7.4950e+03, 1.2101e+04,\n","                        0.0000e+00, 1.3709e+04, 2.9613e+04, 3.0855e+04, 1.6625e+04, 3.5008e+04,\n","                        8.7490e+03, 6.9110e+03, 1.9062e+04, 3.1325e+04, 2.1655e+04, 1.5374e+04,\n","                        2.7550e+03, 4.2490e+04, 1.8688e+04, 3.1534e+04, 8.8850e+03, 2.4306e+04,\n","                        1.7830e+03, 3.2254e+04, 2.2899e+04, 2.9935e+04, 1.0821e+04, 1.0190e+04,\n","                        3.0559e+04, 2.1641e+04, 4.3780e+03, 3.0630e+04, 6.5535e+04, 2.7090e+03,\n","                        2.3340e+04, 4.6865e+04, 3.2367e+04, 2.3610e+04, 2.8720e+04, 3.8196e+04,\n","                        5.8091e+04, 3.6006e+04, 2.9107e+04, 4.5370e+03],\n","                       [5.9281e+04, 6.6390e+03, 3.2950e+03, 4.8106e+04, 4.9329e+04, 1.6246e+04,\n","                        3.9133e+04, 1.8877e+04, 5.0040e+03, 1.8355e+04, 2.2304e+04, 2.3161e+04,\n","                        1.3286e+04, 6.5535e+04, 2.4988e+04, 9.0470e+03, 1.6488e+04, 1.3494e+04,\n","                        9.3780e+03, 3.7374e+04, 3.8660e+03, 1.2189e+04, 1.9662e+04, 1.9376e+04,\n","                        1.1204e+04, 3.6761e+04, 1.7837e+04, 2.3610e+04, 1.8226e+04, 6.1450e+03,\n","                        1.6492e+04, 2.2851e+04, 0.0000e+00, 1.8706e+04, 2.0828e+04, 1.1355e+04,\n","                        2.2879e+04, 1.3142e+04, 9.5070e+03, 3.9130e+04, 1.6223e+04, 2.2517e+04,\n","                        1.3435e+04, 3.4682e+04, 1.9685e+04, 2.3450e+04, 1.9847e+04, 1.2926e+04,\n","                        1.2678e+04, 2.0217e+04, 4.4080e+03, 1.6189e+04, 2.6952e+04, 3.5336e+04,\n","                        1.7202e+04, 1.6817e+04, 2.3561e+04, 2.7227e+04, 9.0760e+03, 6.0810e+03,\n","                        2.2869e+04, 2.2859e+04, 3.5208e+04, 7.5150e+03],\n","                       [3.3662e+04, 0.0000e+00, 3.7980e+03, 2.0612e+04, 1.0886e+04, 6.2060e+03,\n","                        2.1216e+04, 1.7449e+04, 8.4420e+03, 2.5059e+04, 1.4818e+04, 4.2750e+03,\n","                        3.3060e+04, 1.7307e+04, 2.9190e+04, 3.5878e+04, 4.9760e+04, 1.9753e+04,\n","                        4.1220e+04, 1.8135e+04, 1.9373e+04, 2.5490e+04, 2.2107e+04, 1.0045e+04,\n","                        2.8990e+03, 1.6060e+04, 2.4500e+04, 1.5444e+04, 1.5682e+04, 3.3518e+04,\n","                        1.5870e+04, 2.6573e+04, 1.7953e+04, 2.6850e+04, 2.1649e+04, 8.7200e+03,\n","                        1.2791e+04, 1.8690e+04, 8.0400e+03, 2.6800e+03, 2.5010e+03, 1.0290e+04,\n","                        6.5535e+04, 8.1330e+03, 1.5099e+04, 1.0724e+04, 2.5630e+04, 1.2860e+04,\n","                        2.8092e+04, 1.8075e+04, 8.7490e+03, 1.2825e+04, 2.7689e+04, 1.0796e+04,\n","                        2.0753e+04, 4.8660e+03, 1.8972e+04, 1.0162e+04, 1.8787e+04, 7.6230e+03,\n","                        2.0285e+04, 7.2900e+03, 3.7988e+04, 3.0660e+04],\n","                       [1.2833e+04, 6.5535e+04, 8.0590e+03, 0.0000e+00, 1.0857e+04, 4.8200e+03,\n","                        5.1544e+04, 2.6079e+04, 2.8544e+04, 2.6734e+04, 1.0300e+04, 2.0964e+04,\n","                        2.4978e+04, 1.2333e+04, 1.7000e+04, 1.1937e+04, 1.5719e+04, 1.2671e+04,\n","                        2.9663e+04, 2.0497e+04, 1.1558e+04, 2.0750e+03, 1.6722e+04, 2.7019e+04,\n","                        6.9570e+03, 3.8433e+04, 3.1987e+04, 3.7550e+04, 2.9837e+04, 1.7817e+04,\n","                        5.8639e+04, 1.8303e+04, 1.6339e+04, 1.2982e+04, 1.9063e+04, 3.2347e+04,\n","                        1.7359e+04, 1.0750e+03, 2.7372e+04, 2.6877e+04, 4.7980e+03, 1.7433e+04,\n","                        1.6230e+04, 3.4023e+04, 2.0731e+04, 1.8768e+04, 2.6654e+04, 1.5211e+04,\n","                        3.7436e+04, 2.1489e+04, 3.1962e+04, 2.1364e+04, 3.1730e+04, 2.0702e+04,\n","                        2.2315e+04, 1.8501e+04, 2.3070e+04, 1.1779e+04, 5.2596e+04, 1.4569e+04,\n","                        1.5325e+04, 2.9081e+04, 6.8800e+02, 1.5471e+04],\n","                       [6.5535e+04, 1.9571e+04, 2.7420e+03, 1.9211e+04, 5.1300e+03, 1.5595e+04,\n","                        0.0000e+00, 1.5322e+04, 6.0889e+04, 1.3789e+04, 2.5910e+03, 1.6778e+04,\n","                        2.3277e+04, 1.8400e+04, 3.5984e+04, 3.2144e+04, 1.3671e+04, 1.6726e+04,\n","                        2.6310e+03, 1.6452e+04, 2.4239e+04, 3.8139e+04, 1.6906e+04, 1.0955e+04,\n","                        1.7529e+04, 1.8417e+04, 5.8230e+03, 7.1200e+03, 1.6753e+04, 3.0036e+04,\n","                        1.2506e+04, 1.9810e+04, 9.6170e+03, 2.1531e+04, 1.7456e+04, 4.7260e+03,\n","                        5.7749e+04, 1.9374e+04, 3.6482e+04, 1.0167e+04, 3.2166e+04, 1.4745e+04,\n","                        8.4470e+03, 1.6869e+04, 1.5018e+04, 2.3803e+04, 2.1382e+04, 1.7275e+04,\n","                        9.9400e+03, 1.8953e+04, 1.3546e+04, 1.1094e+04, 1.5430e+04, 2.1086e+04,\n","                        2.2563e+04, 1.2669e+04, 1.8397e+04, 4.1241e+04, 2.0615e+04, 1.4273e+04,\n","                        5.0820e+03, 5.0970e+03, 1.6498e+04, 4.4619e+04],\n","                       [5.2190e+03, 3.3768e+04, 1.5164e+04, 2.1192e+04, 1.3940e+04, 4.1352e+04,\n","                        1.5940e+04, 2.1967e+04, 2.0439e+04, 2.0078e+04, 3.7847e+04, 1.9564e+04,\n","                        0.0000e+00, 1.9862e+04, 1.9273e+04, 3.1620e+03, 3.0186e+04, 1.5771e+04,\n","                        1.2119e+04, 2.6613e+04, 6.5535e+04, 1.4347e+04, 2.1166e+04, 3.8439e+04,\n","                        4.4024e+04, 1.0147e+04, 3.8335e+04, 1.7556e+04, 2.2202e+04, 1.6497e+04,\n","                        1.9268e+04, 2.3658e+04, 3.3586e+04, 2.2245e+04, 1.7380e+04, 5.0184e+04,\n","                        1.4368e+04, 3.9133e+04, 1.4610e+04, 1.4123e+04, 2.7707e+04, 1.6330e+04,\n","                        2.0959e+04, 1.7306e+04, 3.2418e+04, 2.7806e+04, 1.9304e+04, 2.2331e+04,\n","                        1.4773e+04, 2.4115e+04, 7.2310e+03, 2.1803e+04, 1.0676e+04, 4.7481e+04,\n","                        2.2102e+04, 2.1521e+04, 1.9899e+04, 2.6175e+04, 1.4883e+04, 2.0823e+04,\n","                        1.2869e+04, 2.7461e+04, 9.5100e+03, 8.2540e+03],\n","                       [3.7000e+01, 3.5636e+04, 6.5535e+04, 1.5187e+04, 7.3580e+03, 2.0416e+04,\n","                        5.0030e+03, 1.1278e+04, 1.9713e+04, 2.5940e+04, 4.7260e+03, 1.5408e+04,\n","                        1.9248e+04, 1.5692e+04, 3.6700e+03, 2.1681e+04, 7.5000e+03, 7.6610e+03,\n","                        6.0420e+03, 1.9714e+04, 1.0711e+04, 2.1106e+04, 2.4801e+04, 7.5640e+03,\n","                        4.2814e+04, 1.9532e+04, 1.1310e+03, 1.1223e+04, 1.3660e+04, 2.5200e+03,\n","                        1.2622e+04, 1.2658e+04, 1.1284e+04, 8.6030e+03, 2.8995e+04, 3.7280e+03,\n","                        7.6880e+03, 2.7958e+04, 3.0110e+03, 1.1523e+04, 2.3342e+04, 6.3220e+03,\n","                        1.9790e+04, 2.1387e+04, 1.6703e+04, 8.7470e+03, 1.4330e+04, 1.4232e+04,\n","                        1.5331e+04, 1.3672e+04, 1.3919e+04, 3.1144e+04, 0.0000e+00, 1.1097e+04,\n","                        1.5449e+04, 6.8380e+03, 1.0670e+04, 3.7210e+03, 3.4140e+03, 7.5410e+03,\n","                        1.9848e+04, 7.5340e+03, 5.9720e+03, 2.0727e+04]], device='cuda:0')),\n","              ('module.fc.wrapped_module.bias',\n","               tensor([ 4.6950e+06, -1.9600e+08,  1.1536e+08,  2.1639e+08,  4.3894e+07,\n","                       -6.6432e+07,  6.0323e+07, -2.5193e+06, -8.4009e+07, -3.6124e+07],\n","                      device='cuda:0'))])}"]},"metadata":{"tags":[]},"execution_count":23}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"sJFYDbF51Kot","executionInfo":{"elapsed":2931,"status":"error","timestamp":1607492270865,"user":{"displayName":"Jeremy Wang","photoUrl":"","userId":"16277065741529505083"},"user_tz":300},"outputId":"26ed7319-754f-45f1-a20e-eea92aeefb23"},"source":["quantizer.model.load_state_dict(Checkpoint[\"state_dict\"])"],"execution_count":null,"outputs":[{"output_type":"error","ename":"RuntimeError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)","\u001b[0;32m<ipython-input-15-70351c2ab47a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mCheckpoint\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpather\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mquantizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mCheckpoint\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"state_dict\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mload_state_dict\u001b[0;34m(self, state_dict, strict)\u001b[0m\n\u001b[1;32m    837\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merror_msgs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    838\u001b[0m             raise RuntimeError('Error(s) in loading state_dict for {}:\\n\\t{}'.format(\n\u001b[0;32m--> 839\u001b[0;31m                                self.__class__.__name__, \"\\n\\t\".join(error_msgs)))\n\u001b[0m\u001b[1;32m    840\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_IncompatibleKeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmissing_keys\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0munexpected_keys\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    841\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mRuntimeError\u001b[0m: Error(s) in loading state_dict for DataParallel:\n\tsize mismatch for module.conv1.w_scale: copying a param with shape torch.Size([16, 1, 1, 1]) from checkpoint, the shape in current model is torch.Size([1]).\n\tsize mismatch for module.conv1.w_zero_point: copying a param with shape torch.Size([16, 1, 1, 1]) from checkpoint, the shape in current model is torch.Size([1]).\n\tsize mismatch for module.conv1.accum_scale: copying a param with shape torch.Size([16, 1, 1]) from checkpoint, the shape in current model is torch.Size([1]).\n\tsize mismatch for module.layer1.0.conv1.w_scale: copying a param with shape torch.Size([16, 1, 1, 1]) from checkpoint, the shape in current model is torch.Size([1]).\n\tsize mismatch for module.layer1.0.conv1.w_zero_point: copying a param with shape torch.Size([16, 1, 1, 1]) from checkpoint, the shape in current model is torch.Size([1]).\n\tsize mismatch for module.layer1.0.conv1.accum_scale: copying a param with shape torch.Size([16, 1, 1]) from checkpoint, the shape in current model is torch.Size([1]).\n\tsize mismatch for module.layer1.0.conv2.w_scale: copying a param with shape torch.Size([16, 1, 1, 1]) from checkpoint, the shape in current model is torch.Size([1]).\n\tsize mismatch for module.layer1.0.conv2.w_zero_point: copying a param with shape torch.Size([16, 1, 1, 1]) from checkpoint, the shape in current model is torch.Size([1]).\n\tsize mismatch for module.layer1.0.conv2.accum_scale: copying a param with shape torch.Size([16, 1, 1]) from checkpoint, the shape in current model is torch.Size([1]).\n\tsize mismatch for module.layer1.1.conv1.w_scale: copying a param with shape torch.Size([16, 1, 1, 1]) from checkpoint, the shape in current model is torch.Size([1]).\n\tsize mismatch for module.layer1.1.conv1.w_zero_point: copying a param with shape torch.Size([16, 1, 1, 1]) from checkpoint, the shape in current model is torch.Size([1]).\n\tsize mismatch for module.layer1.1.conv1.accum_scale: copying a param with shape torch.Size([16, 1, 1]) from checkpoint, the shape in current model is torch.Size([1]).\n\tsize mismatch for module.layer1.1.conv2.w_scale: copying a param with shape torch.Size([16, 1, 1, 1]) from checkpoint, the shape in current model is torch.Size([1]).\n\tsize mismatch for module.layer1.1.conv2.w_zero_point: copying a param with shape torch.Size([16, 1, 1, 1]) from checkpoint, the shape in current model is torch.Size([1]).\n\tsize mismatch for module.layer1.1.conv2.accum_scale: copying a param with shape torch.Size([16, 1, 1]) from checkpoint, the shape in current model is torch.Size([1]).\n\tsize mismatch for module.layer1.2.conv1.w_scale: copying a param with shape torch.Size([16, 1, 1, 1]) from checkpoint, the shape in current model is torch.Size([1]).\n\tsize mismatch for module.layer1.2.conv1.w_zero_point: copying a param with shape torch.Size([16, 1, 1, 1]) from checkpoint, the shape in current model is torch.Size([1]).\n\tsize mismatch for module.layer1.2.conv1.accum_scale: copying a param with shape torch.Size([16, 1, 1]) from checkpoint, the shape in current model is torch.Size([1]).\n\tsize mismatch for module.layer1.2.conv2.w_scale: copying a param with shape torch.Size([16, 1, 1, 1]) from checkpoint, the shape in current model is torch.Size([1]).\n\tsize mismatch for module.layer1.2.conv2.w_zero_point: copying a param with shape torch.Size([16, 1, 1, 1]) from checkpoint, the shape in current model is torch.Size([1]).\n\tsize mismatch for module.layer1.2.conv2.accum_scale: copying a param with shape torch.Size([16, 1, 1]) from checkpoint, the shape in current model is torch.Size([1]).\n\tsize mismatch for module.layer1.3.conv1.w_scale: copying a param with shape torch.Size([16, 1, 1, 1]) from checkpoint, the shape in current model is torch.Size([1]).\n\tsize mismatch for module.layer1.3.conv1.w_zero_point: copying a param with shape torch.Size([16, 1, 1, 1]) from checkpoint, the shape in current model is torch.Size([1]).\n\tsize mismatch for module.layer1.3.conv1.accum_scale: copying a param with shape torch.Size([16, 1, 1]) from checkpoint, the shape in current model is torch.Size([1]).\n\tsize mismatch for module.layer1.3.conv2.w_scale: copying a param with shape torch.Size([16, 1, 1, 1]) from checkpoint, the shape in current model is torch.Size([1]).\n\tsize mismatch for module.layer1.3.conv2.w_zero_point: copying a param with shape torch.Size([16, 1, 1, 1]) from checkpoint, the shape in current model is torch.Size([1]).\n\tsize mismatch for module.layer1.3.conv2.accum_scale: copying a param with shape torch.Size([16, 1, 1]) from checkpoint, the shape in current model is torch.Size([1]).\n\tsize mismatch for module.layer1.4.conv1.w_scale: copying a param with shape torch.Size([16, 1, 1, 1]) from checkpoint, the shape in current model is torch.Size([1]).\n\tsize mismatch for module.layer1.4.conv1.w_zero_point: copying a param with shape torch.Size([16, 1, 1, 1]) from checkpoint, the shape in current model is torch.Size([1]).\n\tsize mismatch for module.layer1.4.conv1.accum_scale: copying a param with shape torch.Size([16, 1, 1]) from checkpoint, the shape in current model is torch.Size([1]).\n\tsize mismatch for module.layer1.4.conv2.w_scale: copying a param with shape torch.Size([16, 1, 1, 1]) from checkpoint, the shape in current model is torch.Size([1]).\n\tsize mismatch for module.layer1.4.conv2.w_zero_point: copying a param with shape torch.Size([16, 1, 1, 1]) from checkpoint, the shape in current model is torch.Size([1]).\n\tsize mismatch for module.layer1.4.conv2.accum_scale: copying a param with shape torch.Size([16, 1, 1]) from checkpoint, the shape in current model is torch.Size([1]).\n\tsize mismatch for module.layer1.5.conv1.w_scale: copying a param with shape torch.Size([16, 1, 1, 1]) from checkpoint, the shape in current model is torch.Size([1]).\n\tsize mismatch for module.layer1.5.conv1.w_zero_point: copying a param with shape torch.Size([16, 1, 1, 1]) from checkpoint, the shape in current model is torch.Size([1]).\n\tsize mismatch for module.layer1.5.conv1.accum_scale: copying a param with shape torch.Size([16, 1, 1]) from checkpoint, the shape in current model is torch.Size([1]).\n\tsize mismatch for module.layer1.5.conv2.w_scale: copying a param with shape torch.Size([16, 1, 1, 1]) from checkpoint, the shape in current model is torch.Size([1]).\n\tsize mismatch for module.layer1.5.conv2.w_zero_point: copying a param with shape torch.Size([16, 1, 1, 1]) from checkpoint, the shape in current model is torch.Size([1]).\n\tsize mismatch for module.layer1.5.conv2.accum_scale: copying a param with shape torch.Size([16, 1, 1]) from checkpoint, the shape in current model is torch.Size([1]).\n\tsize mismatch for module.layer1.6.conv1.w_scale: copying a param with shape torch.Size([16, 1, 1, 1]) from checkpoint, the shape in current model is torch.Size([1]).\n\tsize mismatch for module.layer1.6.conv1.w_zero_point: copying a param with shape torch.Size([16, 1, 1, 1]) from checkpoint, the shape in current model is torch.Size([1]).\n\tsize mismatch for module.layer1.6.conv1.accum_scale: copying a param with shape torch.Size([16, 1, 1]) from checkpoint, the shape in current model is torch.Size([1]).\n\tsize mismatch for module.layer1.6.conv2.w_scale: copying a param with shape torch.Size([16, 1, 1, 1]) from checkpoint, the shape in current model is torch.Size([1]).\n\tsize mismatch for module.layer1.6.conv2.w_zero_point: copying a param with shape torch.Size([16, 1, 1, 1]) from checkpoint, the shape in current model is torch.Size([1]).\n\tsize mismatch for module.layer1.6.conv2.accum_scale: copying a param with shape torch.Size([16, 1, 1]) from checkpoint, the shape in current model is torch.Size([1]).\n\tsize mismatch for module.layer1.7.conv1.w_scale: copying a param with shape torch.Size([16, 1, 1, 1]) from checkpoint, the shape in current model is torch.Size([1]).\n\tsize mismatch for module.layer1.7.conv1.w_zero_point: copying a param with shape torch.Size([16, 1, 1, 1]) from checkpoint, the shape in current model is torch.Size([1]).\n\tsize mismatch for module.layer1.7.conv1.accum_scale: copying a param with shape torch.Size([16, 1, 1]) from checkpoint, the shape in current model is torch.Size([1]).\n\tsize mismatch for module.layer1.7.conv2.w_scale: copying a param with shape torch.Size([16, 1, 1, 1]) from checkpoint, the shape in current model is torch.Size([1]).\n\tsize mismatch for module.layer1.7.conv2.w_zero_point: copying a param with shape torch.Size([16, 1, 1, 1]) from checkpoint, the shape in current model is torch.Size([1]).\n\tsize mismatch for module.layer1.7.conv2.accum_scale: copying a param with shape torch.Size([16, 1, 1]) from checkpoint, the shape in current model is torch.Size([1]).\n\tsize mismatch for module.layer1.8.conv1.w_scale: copying a param with shape torch.Size([16, 1, 1, 1]) from checkpoint, the shape in current model is torch.Size([1]).\n\tsize mismatch for module.layer1.8.conv1.w_zero_point: copying a param with shape torch.Size([16, 1, 1, 1]) from checkpoint, the shape in current model is torch.Size([1]).\n\tsize mismatch for module.layer1.8.conv1.accum_scale: copying a param with shape torch.Size([16, 1, 1]) from checkpoint, the shape in current model is torch.Size([1]).\n\tsize mismatch for module.layer1.8.conv2.w_scale: copying a param with shape torch.Size([16, 1, 1, 1]) from checkpoint, the shape in current model is torch.Size([1]).\n\tsize mismatch for module.layer1.8.conv2.w_zero_point: copying a param with shape torch.Size([16, 1, 1, 1]) from checkpoint, the shape in current model is torch.Size([1]).\n\tsize mismatch for module.layer1.8.conv2.accum_scale: copying a param with shape torch.Size([16, 1, 1]) from checkpoint, the shape in current model is torch.Size([1]).\n\tsize mismatch for module.layer2.0.conv1.w_scale: copying a param with shape torch.Size([32, 1, 1, 1]) from checkpoint, the shape in current model is torch.Size([1]).\n\tsize mismatch for module.layer2.0.conv1.w_zero_point: copying a param with shape torch.Size([32, 1, 1, 1]) from checkpoint, the shape in current model is torch.Size([1]).\n\tsize mismatch for module.layer2.0.conv1.accum_scale: copying a param with shape torch.Size([32, 1, 1]) from checkpoint, the shape in current model is torch.Size([1]).\n\tsize mismatch for module.layer2.0.conv2.w_scale: copying a param with shape torch.Size([32, 1, 1, 1]) from checkpoint, the shape in current model is torch.Size([1]).\n\tsize mismatch for module.layer2.0.conv2.w_zero_point: copying a param with shape torch.Size([32, 1, 1, 1]) from checkpoint, the shape in current model is torch.Size([1]).\n\tsize mismatch for module.layer2.0.conv2.accum_scale: copying a param with shape torch.Size([32, 1, 1]) from checkpoint, the shape in current model is torch.Size([1]).\n\tsize mismatch for module.layer2.0.downsample.0.w_scale: copying a param with shape torch.Size([32, 1, 1, 1]) from checkpoint, the shape in current model is torch.Size([1]).\n\tsize mismatch for module.layer2.0.downsample.0.w_zero_point: copying a param with shape torch.Size([32, 1, 1, 1]) from checkpoint, the shape in current model is torch.Size([1]).\n\tsize mismatch for module.layer2.0.downsample.0.accum_scale: copying a param with shape torch.Size([32, 1, 1]) from checkpoint, the shape in current model is torch.Size([1]).\n\tsize mismatch for module.layer2.1.conv1.w_scale: copying a param with shape torch.Size([32, 1, 1, 1]) from checkpoint, the shape in current model is torch.Size([1]).\n\tsize mismatch for module.layer2.1.conv1.w_zero_point: copying a param with shape torch.Size([32, 1, 1, 1]) from checkpoint, the shape in current model is torch.Size([1]).\n\tsize mismatch for module.layer2.1.conv1.accum_scale: copying a param with shape torch.Size([32, 1, 1]) from checkpoint, the shape in current model is torch.Size([1]).\n\tsize mismatch for module.layer2.1.conv2.w_scale: copying a param with shape torch.Size([32, 1, 1, 1]) from checkpoint, the shape in current model is torch.Size([1]).\n\tsize mismatch for module.layer2.1.conv2.w_zero_point: copying a param with shape torch.Size([32, 1, 1, 1]) from checkpoint, the shape in current model is torch.Size([1]).\n\tsize mismatch for module.layer2.1.conv2.accum_scale: copying a param with shape torch.Size([32, 1, 1]) from checkpoint, the shape in current model is torch.Size([1]).\n\tsize mismatch for module.layer2.2.conv1.w_scale: copying a param with shape torch.Size([32, 1, 1, 1]) from checkpoint, the shape in current model is torch.Size([1]).\n\tsize mismatch for module.layer2.2.conv1.w_zero_point: copying a param with shape torch.Size([32, 1, 1, 1]) from checkpoint, the shape in current model is torch.Size([1]).\n\tsize mismatch for module.layer2.2.conv1.accum_scale: copying a param with shape torch.Size([32, 1, 1]) from checkpoint, the shape in current model is torch.Size([1]).\n\tsize mismatch for module.layer2.2.conv2.w_scale: copying a param with shape torch.Size([32, 1, 1, 1]) from checkpoint, the shape in current model is torch.Size([1]).\n\tsize mismatch for module.layer2.2.conv2.w_zero_point: copying a param with shape torch.Size([32, 1, 1, 1]) from checkpoint, the shape in current model is torch.Size([1]).\n\tsize mismatch for module.layer2.2.conv2.accum_scale: copying a param with shape torch.Size([32, 1, 1]) from checkpoint, the shape in current model is torch.Size([1]).\n\tsize mismatch for module.layer2.3.conv1.w_scale: copying a param with shape torch.Size([32, 1, 1, 1]) from checkpoint, the shape in current model is torch.Size([1]).\n\tsize mismatch for module.layer2.3.conv1.w_zero_point: copying a param with shape torch.Size([32, 1, 1, 1]) from checkpoint, the shape in current model is torch.Size([1]).\n\tsize mismatch for module.layer2.3.conv1.accum_scale: copying a param with shape torch.Size([32, 1, 1]) from checkpoint, the shape in current model is torch.Size([1]).\n\tsize mismatch for module.layer2.3.conv2.w_scale: copying a param with shape torch.Size([32, 1, 1, 1]) from checkpoint, the shape in current model is torch.Size([1]).\n\tsize mismatch for module.layer2.3.conv2.w_zero_point: copying a param with shape torch.Size([32, 1, 1, 1]) from checkpoint, the shape in current model is torch.Size([1]).\n\tsize mismatch for module.layer2.3.conv2.accum_scale: copying a param with shape torch.Size([32, 1, 1]) from checkpoint, the shape in current model is torch.Size([1]).\n\tsize mismatch for module.layer2.4.conv1.w_scale: copying a param with shape torch.Size([32, 1, 1, 1]) from checkpoint, the shape in current model is torch.Size([1]).\n\tsize mismatch for module.layer2.4.conv1.w_zero_point: copying a param with shape torch.Size([32, 1, 1, 1]) from checkpoint, the shape in current model is torch.Size([1]).\n\tsize mismatch for module.layer2.4.conv1.accum_scale: copying a param with shape torch.Size([32, 1, 1]) from checkpoint, the shape in current model is torch.Size([1]).\n\tsize mismatch for module.layer2.4.conv2.w_scale: copying a param with shape torch.Size([32, 1, 1, 1]) from checkpoint, the shape in current model is torch.Size([1]).\n\tsize mismatch for module.layer2.4.conv2.w_zero_point: copying a param with shape torch.Size([32, 1, 1, 1]) from checkpoint, the shape in current model is torch.Size([1]).\n\tsize mismatch for module.layer2.4.conv2.accum_scale: copying a param with shape torch.Size([32, 1, 1]) from checkpoint, the shape in current model is torch.Size([1]).\n\tsize mismatch for module.layer2.5.conv1.w_scale: copying a param with shape torch.Size([32, 1, 1, 1]) from checkpoint, the shape in current model is torch.Size([1]).\n\tsize mismatch for module.layer2.5.conv1.w_zero_point: copying a param with shape torch.Size([32, 1, 1, 1]) from checkpoint, the shape in current model is torch.Size([1]).\n\tsize mismatch for module.layer2.5.conv1.accum_scale: copying a param with shape torch.Size([32, 1, 1]) from checkpoint, the shape in current model is torch.Size([1]).\n\tsize mismatch for module.layer2.5.conv2.w_scale: copying a param with shape torch.Size([32, 1, 1, 1]) from checkpoint, the shape in current model is torch.Size([1]).\n\tsize mismatch for module.layer2.5.conv2.w_zero_point: copying a param with shape torch.Size([32, 1, 1, 1]) from checkpoint, the shape in current model is torch.Size([1]).\n\tsize mismatch for module.layer2.5.conv2.accum_scale: copying a param with shape torch.Size([32, 1, 1]) from checkpoint, the shape in current model is torch.Size([1]).\n\tsize mismatch for module.layer2.6.conv1.w_scale: copying a param with shape torch.Size([32, 1, 1, 1]) from checkpoint, the shape in current model is torch.Size([1]).\n\tsize mismatch for module.layer2.6.conv1.w_zero_point: copying a param with shape torch.Size([32, 1, 1, 1]) from checkpoint, the shape in current model is torch.Size([1]).\n\tsize mismatch for module.layer2.6.conv1.accum_scale: copying a param with shape torch.Size([32, 1, 1]) from checkpoint, the shape in current model is torch.Size([1]).\n\tsize mismatch for module.layer2.6.conv2.w_scale: copying a param with shape torch.Size([32, 1, 1, 1]) from checkpoint, the shape in current model is torch.Size([1]).\n\tsize mismatch for module.layer2.6.conv2.w_zero_point: copying a param with shape torch.Size([32, 1, 1, 1]) from checkpoint, the shape in current model is torch.Size([1]).\n\tsize mismatch for module.layer2.6.conv2.accum_scale: copying a param with shape torch.Size([32, 1, 1]) from checkpoint, the shape in current model is torch.Size([1]).\n\tsize mismatch for module.layer2.7.conv1.w_scale: copying a param with shape torch.Size([32, 1, 1, 1]) from checkpoint, the shape in current model is torch.Size([1]).\n\tsize mismatch for module.layer2.7.conv1.w_zero_point: copying a param with shape torch.Size([32, 1, 1, 1]) from checkpoint, the shape in current model is torch.Size([1]).\n\tsize mismatch for module.layer2.7.conv1.accum_scale: copying a param with shape torch.Size([32, 1, 1]) from checkpoint, the shape in current model is torch.Size([1]).\n\tsize mismatch for module.layer2.7.conv2.w_scale: copying a param with shape torch.Size([32, 1, 1, 1]) from checkpoint, the shape in current model is torch.Size([1]).\n\tsize mismatch for module.layer2.7.conv2.w_zero_point: copying a param with shape torch.Size([32, 1, 1, 1]) from checkpoint, the shape in current model is torch.Size([1]).\n\tsize mismatch for module.layer2.7.conv2.accum_scale: copying a param with shape torch.Size([32, 1, 1]) from checkpoint, the shape in current model is torch.Size([1]).\n\tsize mismatch for module.layer2.8.conv1.w_scale: copying a param with shape torch.Size([32, 1, 1, 1]) from checkpoint, the shape in current model is torch.Size([1]).\n\tsize mismatch for module.layer2.8.conv1.w_zero_point: copying a param with shape torch.Size([32, 1, 1, 1]) from checkpoint, the shape in current model is torch.Size([1]).\n\tsize mismatch for module.layer2.8.conv1.accum_scale: copying a param with shape torch.Size([32, 1, 1]) from checkpoint, the shape in current model is torch.Size([1]).\n\tsize mismatch for module.layer2.8.conv2.w_scale: copying a param with shape torch.Size([32, 1, 1, 1]) from checkpoint, the shape in current model is torch.Size([1]).\n\tsize mismatch for module.layer2.8.conv2.w_zero_point: copying a param with shape torch.Size([32, 1, 1, 1]) from checkpoint, the shape in current model is torch.Size([1]).\n\tsize mismatch for module.layer2.8.conv2.accum_scale: copying a param with shape torch.Size([32, 1, 1]) from checkpoint, the shape in current model is torch.Size([1]).\n\tsize mismatch for module.layer3.0.conv1.w_scale: copying a param with shape torch.Size([64, 1, 1, 1]) from checkpoint, the shape in current model is torch.Size([1]).\n\tsize mismatch for module.layer3.0.conv1.w_zero_point: copying a param with shape torch.Size([64, 1, 1, 1]) from checkpoint, the shape in current model is torch.Size([1]).\n\tsize mismatch for module.layer3.0.conv1.accum_scale: copying a param with shape torch.Size([64, 1, 1]) from checkpoint, the shape in current model is torch.Size([1]).\n\tsize mismatch for module.layer3.0.conv2.w_scale: copying a param with shape torch.Size([64, 1, 1, 1]) from checkpoint, the shape in current model is torch.Size([1]).\n\tsize mismatch for module.layer3.0.conv2.w_zero_point: copying a param with shape torch.Size([64, 1, 1, 1]) from checkpoint, the shape in current model is torch.Size([1]).\n\tsize mismatch for module.layer3.0.conv2.accum_scale: copying a param with shape torch.Size([64, 1, 1]) from checkpoint, the shape in current model is torch.Size([1]).\n\tsize mismatch for module.layer3.0.downsample.0.w_scale: copying a param with shape torch.Size([64, 1, 1, 1]) from checkpoint, the shape in current model is torch.Size([1]).\n\tsize mismatch for module.layer3.0.downsample.0.w_zero_point: copying a param with shape torch.Size([64, 1, 1, 1]) from checkpoint, the shape in current model is torch.Size([1]).\n\tsize mismatch for module.layer3.0.downsample.0.accum_scale: copying a param with shape torch.Size([64, 1, 1]) from checkpoint, the shape in current model is torch.Size([1]).\n\tsize mismatch for module.layer3.1.conv1.w_scale: copying a param with shape torch.Size([64, 1, 1, 1]) from checkpoint, the shape in current model is torch.Size([1]).\n\tsize mismatch for module.layer3.1.conv1.w_zero_point: copying a param with shape torch.Size([64, 1, 1, 1]) from checkpoint, the shape in current model is torch.Size([1]).\n\tsize mismatch for module.layer3.1.conv1.accum_scale: copying a param with shape torch.Size([64, 1, 1]) from checkpoint, the shape in current model is torch.Size([1]).\n\tsize mismatch for module.layer3.1.conv2.w_scale: copying a param with shape torch.Size([64, 1, 1, 1]) from checkpoint, the shape in current model is torch.Size([1]).\n\tsize mismatch for module.layer3.1.conv2.w_zero_point: copying a param with shape torch.Size([64, 1, 1, 1]) from checkpoint, the shape in current model is torch.Size([1]).\n\tsize mismatch for module.layer3.1.conv2.accum_scale: copying a param with shape torch.Size([64, 1, 1]) from checkpoint, the shape in current model is torch.Size([1]).\n\tsize mismatch for module.layer3.2.conv1.w_scale: copying a param with shape torch.Size([64, 1, 1, 1]) from checkpoint, the shape in current model is torch.Size([1]).\n\tsize mismatch for module.layer3.2.conv1.w_zero_point: copying a param with shape torch.Size([64, 1, 1, 1]) from checkpoint, the shape in current model is torch.Size([1]).\n\tsize mismatch for module.layer3.2.conv1.accum_scale: copying a param with shape torch.Size([64, 1, 1]) from checkpoint, the shape in current model is torch.Size([1]).\n\tsize mismatch for module.layer3.2.conv2.w_scale: copying a param with shape torch.Size([64, 1, 1, 1]) from checkpoint, the shape in current model is torch.Size([1]).\n\tsize mismatch for module.layer3.2.conv2.w_zero_point: copying a param with shape torch.Size([64, 1, 1, 1]) from checkpoint, the shape in current model is torch.Size([1]).\n\tsize mismatch for module.layer3.2.conv2.accum_scale: copying a param with shape torch.Size([64, 1, 1]) from checkpoint, the shape in current model is torch.Size([1]).\n\tsize mismatch for module.layer3.3.conv1.w_scale: copying a param with shape torch.Size([64, 1, 1, 1]) from checkpoint, the shape in current model is torch.Size([1]).\n\tsize mismatch for module.layer3.3.conv1.w_zero_point: copying a param with shape torch.Size([64, 1, 1, 1]) from checkpoint, the shape in current model is torch.Size([1]).\n\tsize mismatch for module.layer3.3.conv1.accum_scale: copying a param with shape torch.Size([64, 1, 1]) from checkpoint, the shape in current model is torch.Size([1]).\n\tsize mismatch for module.layer3.3.conv2.w_scale: copying a param with shape torch.Size([64, 1, 1, 1]) from checkpoint, the shape in current model is torch.Size([1]).\n\tsize mismatch for module.layer3.3.conv2.w_zero_point: copying a param with shape torch.Size([64, 1, 1, 1]) from checkpoint, the shape in current model is torch.Size([1]).\n\tsize mismatch for module.layer3.3.conv2.accum_scale: copying a param with shape torch.Size([64, 1, 1]) from checkpoint, the shape in current model is torch.Size([1]).\n\tsize mismatch for module.layer3.4.conv1.w_scale: copying a param with shape torch.Size([64, 1, 1, 1]) from checkpoint, the shape in current model is torch.Size([1]).\n\tsize mismatch for module.layer3.4.conv1.w_zero_point: copying a param with shape torch.Size([64, 1, 1, 1]) from checkpoint, the shape in current model is torch.Size([1]).\n\tsize mismatch for module.layer3.4.conv1.accum_scale: copying a param with shape torch.Size([64, 1, 1]) from checkpoint, the shape in current model is torch.Size([1]).\n\tsize mismatch for module.layer3.4.conv2.w_scale: copying a param with shape torch.Size([64, 1, 1, 1]) from checkpoint, the shape in current model is torch.Size([1]).\n\tsize mismatch for module.layer3.4.conv2.w_zero_point: copying a param with shape torch.Size([64, 1, 1, 1]) from checkpoint, the shape in current model is torch.Size([1]).\n\tsize mismatch for module.layer3.4.conv2.accum_scale: copying a param with shape torch.Size([64, 1, 1]) from checkpoint, the shape in current model is torch.Size([1]).\n\tsize mismatch for module.layer3.5.conv1.w_scale: copying a param with shape torch.Size([64, 1, 1, 1]) from checkpoint, the shape in current model is torch.Size([1]).\n\tsize mismatch for module.layer3.5.conv1.w_zero_point: copying a param with shape torch.Size([64, 1, 1, 1]) from checkpoint, the shape in current model is torch.Size([1]).\n\tsize mismatch for module.layer3.5.conv1.accum_scale: copying a param with shape torch.Size([64, 1, 1]) from checkpoint, the shape in current model is torch.Size([1]).\n\tsize mismatch for module.layer3.5.conv2.w_scale: copying a param with shape torch.Size([64, 1, 1, 1]) from checkpoint, the shape in current model is torch.Size([1]).\n\tsize mismatch for module.layer3.5.conv2.w_zero_point: copying a param with shape torch.Size([64, 1, 1, 1]) from checkpoint, the shape in current model is torch.Size([1]).\n\tsize mismatch for module.layer3.5.conv2.accum_scale: copying a param with shape torch.Size([64, 1, 1]) from checkpoint, the shape in current model is torch.Size([1]).\n\tsize mismatch for module.layer3.6.conv1.w_scale: copying a param with shape torch.Size([64, 1, 1, 1]) from checkpoint, the shape in current model is torch.Size([1]).\n\tsize mismatch for module.layer3.6.conv1.w_zero_point: copying a param with shape torch.Size([64, 1, 1, 1]) from checkpoint, the shape in current model is torch.Size([1]).\n\tsize mismatch for module.layer3.6.conv1.accum_scale: copying a param with shape torch.Size([64, 1, 1]) from checkpoint, the shape in current model is torch.Size([1]).\n\tsize mismatch for module.layer3.6.conv2.w_scale: copying a param with shape torch.Size([64, 1, 1, 1]) from checkpoint, the shape in current model is torch.Size([1]).\n\tsize mismatch for module.layer3.6.conv2.w_zero_point: copying a param with shape torch.Size([64, 1, 1, 1]) from checkpoint, the shape in current model is torch.Size([1]).\n\tsize mismatch for module.layer3.6.conv2.accum_scale: copying a param with shape torch.Size([64, 1, 1]) from checkpoint, the shape in current model is torch.Size([1]).\n\tsize mismatch for module.layer3.7.conv1.w_scale: copying a param with shape torch.Size([64, 1, 1, 1]) from checkpoint, the shape in current model is torch.Size([1]).\n\tsize mismatch for module.layer3.7.conv1.w_zero_point: copying a param with shape torch.Size([64, 1, 1, 1]) from checkpoint, the shape in current model is torch.Size([1]).\n\tsize mismatch for module.layer3.7.conv1.accum_scale: copying a param with shape torch.Size([64, 1, 1]) from checkpoint, the shape in current model is torch.Size([1]).\n\tsize mismatch for module.layer3.7.conv2.w_scale: copying a param with shape torch.Size([64, 1, 1, 1]) from checkpoint, the shape in current model is torch.Size([1]).\n\tsize mismatch for module.layer3.7.conv2.w_zero_point: copying a param with shape torch.Size([64, 1, 1, 1]) from checkpoint, the shape in current model is torch.Size([1]).\n\tsize mismatch for module.layer3.7.conv2.accum_scale: copying a param with shape torch.Size([64, 1, 1]) from checkpoint, the shape in current model is torch.Size([1]).\n\tsize mismatch for module.layer3.8.conv1.w_scale: copying a param with shape torch.Size([64, 1, 1, 1]) from checkpoint, the shape in current model is torch.Size([1]).\n\tsize mismatch for module.layer3.8.conv1.w_zero_point: copying a param with shape torch.Size([64, 1, 1, 1]) from checkpoint, the shape in current model is torch.Size([1]).\n\tsize mismatch for module.layer3.8.conv1.accum_scale: copying a param with shape torch.Size([64, 1, 1]) from checkpoint, the shape in current model is torch.Size([1]).\n\tsize mismatch for module.layer3.8.conv2.w_scale: copying a param with shape torch.Size([64, 1, 1, 1]) from checkpoint, the shape in current model is torch.Size([1]).\n\tsize mismatch for module.layer3.8.conv2.w_zero_point: copying a param with shape torch.Size([64, 1, 1, 1]) from checkpoint, the shape in current model is torch.Size([1]).\n\tsize mismatch for module.layer3.8.conv2.accum_scale: copying a param with shape torch.Size([64, 1, 1]) from checkpoint, the shape in current model is torch.Size([1]).\n\tsize mismatch for module.fc.w_scale: copying a param with shape torch.Size([10, 1]) from checkpoint, the shape in current model is torch.Size([1]).\n\tsize mismatch for module.fc.w_zero_point: copying a param with shape torch.Size([10, 1]) from checkpoint, the shape in current model is torch.Size([1]).\n\tsize mismatch for module.fc.accum_scale: copying a param with shape torch.Size([10]) from checkpoint, the shape in current model is torch.Size([1])."]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":380},"id":"O7ibkQFJpaKe","executionInfo":{"elapsed":5061,"status":"error","timestamp":1607470696863,"user":{"displayName":"Jeremy Wang","photoUrl":"","userId":"16277065741529505083"},"user_tz":300},"outputId":"2b31a66c-15c0-4111-a155-841e12a64743"},"source":["# Here we trigger the conversion via the Quantizer instance. Later on we show another way which does not\n","# require the quantizer\n","pyt_model = quantizer.convert_to_pytorch(dummy_input)\n","\n","# Note that the converted model is automatically moved to the CPU, regardless\n","# of the device of the Distiller model\n","print('Distiller model device:', distiller.model_device(quantizer.model))\n","print('PyTorch model device:', distiller.model_device(pyt_model))"],"execution_count":null,"outputs":[{"output_type":"error","ename":"AssertionError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)","\u001b[0;32m<ipython-input-33-bc550f6f1a7d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Here we trigger the conversion via the Quantizer instance. Later on we show another way which does not\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m# require the quantizer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mpyt_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mquantizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert_to_pytorch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdummy_input\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# Note that the converted model is automatically moved to the CPU, regardless\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/content/distiller/distiller/quantization/range_linear.py\u001b[0m in \u001b[0;36mconvert_to_pytorch\u001b[0;34m(self, dummy_input, backend)\u001b[0m\n\u001b[1;32m   2167\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Must call prepare_model before attempting to convert to PyTorch\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2168\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2169\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mpytqc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert_distiller_ptq_model_to_pytorch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdummy_input\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbackend\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbackend\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2170\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2171\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/content/distiller/distiller/quantization/pytorch_quant_conversion.py\u001b[0m in \u001b[0;36mconvert_distiller_ptq_model_to_pytorch\u001b[0;34m(model, dummy_input, backend)\u001b[0m\n\u001b[1;32m    316\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    317\u001b[0m     \u001b[0;31m# First pass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 318\u001b[0;31m     \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_ptq_convert_pass_replace_range_linear_wrappers\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    319\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    320\u001b[0m     \u001b[0;31m# Second pass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/content/distiller/distiller/quantization/pytorch_quant_conversion.py\u001b[0m in \u001b[0;36m_ptq_convert_pass_replace_range_linear_wrappers\u001b[0;34m(module)\u001b[0m\n\u001b[1;32m    155\u001b[0m         \u001b[0mnew_m\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mm\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    156\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdistiller\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mquantization\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRangeLinearQuantWrapper\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 157\u001b[0;31m             \u001b[0mnew_m\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_pytorch_quant\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mneed_reduce_range\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput_quant_settings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mquant_mode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mquint8\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    158\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    159\u001b[0m             requires_quantized_inputs = not (isinstance(new_m, nn.Sequential) and\n","\u001b[0;32m/content/distiller/distiller/quantization/range_linear.py\u001b[0m in \u001b[0;36mto_pytorch_quant\u001b[0;34m(self, reduce_range)\u001b[0m\n\u001b[1;32m    674\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mto_pytorch_quant\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduce_range\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    675\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput_quant_settings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_bits\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m8\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 676\u001b[0;31m             \u001b[0;34m'Conversion to PyTorch PTQ supported only for 8-bit quantization'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    677\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpreset_act_stats\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Conversion to PyTorch PTQ supported only for PTQ wrappers with activation stats'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    678\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_convert_to_pytorch_quant\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreduce_range\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mAssertionError\u001b[0m: Conversion to PyTorch PTQ supported only for 8-bit quantization"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":328},"id":"hMGWizw2pKhw","executionInfo":{"elapsed":1201,"status":"error","timestamp":1607470664427,"user":{"displayName":"Jeremy Wang","photoUrl":"","userId":"16277065741529505083"},"user_tz":300},"outputId":"b97ef700-dcb8-4b6e-8e51-202a89bc3ab3"},"source":["test(pyt_model)"],"execution_count":null,"outputs":[{"output_type":"error","ename":"RuntimeError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)","\u001b[0;32m<ipython-input-31-a835af64b055>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpyt_model\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m<ipython-input-17-59bedcd16e59>\u001b[0m in \u001b[0;36mtest\u001b[0;34m(net)\u001b[0m\n\u001b[1;32m    108\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mbatch_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtestLoader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    109\u001b[0m             \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'cuda'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'cuda'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 110\u001b[0;31m             \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    111\u001b[0m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m             \u001b[0mtest_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    539\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    540\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 541\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    542\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    543\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/content/distiller/distiller/quantization/pytorch_quant_conversion.py\u001b[0m in \u001b[0;36mpatched_forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    186\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mpatch_model_output_dequant\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mpatched_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 188\u001b[0;31m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    189\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput_dequant\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    190\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/content/distiller/distiller/models/cifar10/resnet_cifar.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    136\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    137\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 138\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    139\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbn1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    140\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    539\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    540\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 541\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    542\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    543\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/content/distiller/distiller/quantization/pytorch_quant_conversion.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, *inputs)\u001b[0m\n\u001b[1;32m    438\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    439\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 440\u001b[0;31m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mquant\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    441\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrapped\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    442\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    539\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    540\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 541\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    542\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    543\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/content/distiller/distiller/quantization/pytorch_quant_conversion.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, *inputs)\u001b[0m\n\u001b[1;32m    425\u001b[0m                 \u001b[0;32massert\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Trying to quantize a non-Tensor object'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    426\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mitem\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_quantized\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 427\u001b[0;31m                     \u001b[0mitem\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mquantizers\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx_str\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    428\u001b[0m             \u001b[0mq_inputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    429\u001b[0m         \u001b[0;31m# return q_inputs[0] if len(q_inputs) == 1 else tuple(q_inputs)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    539\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    540\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 541\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    542\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    543\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/quantized/modules/linear.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m     37\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m         return torch.quantize_per_tensor(X, float(self.scale),\n\u001b[0;32m---> 39\u001b[0;31m                                          int(self.zero_point), self.dtype)\n\u001b[0m\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mstaticmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mRuntimeError\u001b[0m: No function is registered for schema aten::quantize_per_tensor(Tensor self, float scale, int zero_point, ScalarType dtype) -> Tensor on tensor type CUDATensorId; available functions are CPUTensorId, VariableTensorId"]}]},{"cell_type":"markdown","metadata":{"id":"r9uTC5m5D-_-"},"source":["# API Conversion"]},{"cell_type":"code","metadata":{"id":"kAsXEDRLqU3L"},"source":["# Quantization\n","# pather = \"/content/drive/MyDrive/CS6787 - Final Project/Google Colab Scripts/Quantization Models/Resnet56_cifar10_post_train_2_8bit/quantized_checkpoint.pth.tar\"\n","# pather = \"/content/drive/MyDrive/CS6787 - Final Project/Google Colab Scripts/Quantization Models/Resnet56_cifar10_post_train_2_4bit/quantized_checkpoint.pth.tar\"\n","# pather = \"/content/drive/MyDrive/CS6787 - Final Project/Google Colab Scripts/Quantization Models/Resnet56_cifar10_post_train_2/quantized_checkpoint.pth.tar\"\n","# pather = \"/content/drive/MyDrive/CS6787 - Final Project/Google Colab Scripts/Quantization Models/Resnet56_cifar10_post_train_2_10bit/quantized_checkpoint.pth.tar\"\n","# pather = \"/content/drive/MyDrive/CS6787 - Final Project/Google Colab Scripts/Quantization Models/Resnet56_cifar10_post_train_2_12bit/quantized_checkpoint.pth.tar\"\n","pather = \"/content/drive/MyDrive/CS6787 - Final Project/Google Colab Scripts/Quantization Models/Resnet56_cifar10_post_train_2_16bit/quantized_checkpoint.pth.tar\""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"7TrV3g6gOhes"},"source":["# Quantization + Retraining\n","# pather = \"/content/drive/MyDrive/CS6787 - Final Project/Google Colab Scripts/Quantization Models/Resnet56_cifat10_post_train+retraining_8bit/esterov=True_best.pth.tar\"\n","# pather = \"/content/drive/MyDrive/CS6787 - Final Project/Google Colab Scripts/Quantization Models/Resnet56_cifat10_post_train+retraining_10bit/esterov=True_best.pth.tar\""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"sGThLtPm9t2I"},"source":["# Load Checkpoint\n","model = distiller.models.create_model(False, \"cifar10\", \"resnet56_cifar\", True, None)\n","model = distiller.apputils.load_lean_checkpoint(model, pather)\n","dummy_input = distiller.get_dummy_input(input_shape=model.input_shape)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":356},"id":"qx1gEPVjiylu","executionInfo":{"elapsed":480,"status":"error","timestamp":1607469605191,"user":{"displayName":"Jeremy Wang","photoUrl":"","userId":"16277065741529505083"},"user_tz":300},"outputId":"0d0e8329-cbd6-411c-c427-a725fcf70819"},"source":["# # Load Checkpoint\n","# model = distiller.models.create_model(False, \"cifar10\", \"resnet56_cifar\", True, None)\n","# dummy_input = distiller.get_dummy_input(input_shape=model.input_shape)\n","# # quantizer = quant.PostTrainLinearQuantizer.from_args(model, args)\n","# model.prepare_model(dummy_input)\n","# # model = distiller.apputils.load_lean_checkpoint(model, pather)\n","# # dummy_input = distiller.get_dummy_input(input_shape=model.input_shape)"],"execution_count":null,"outputs":[{"output_type":"error","ename":"AttributeError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","\u001b[0;32m<ipython-input-25-692fca86c4bf>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mdummy_input\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdistiller\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_dummy_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_shape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# quantizer = quant.PostTrainLinearQuantizer.from_args(model, args)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprepare_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdummy_input\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;31m# model = distiller.apputils.load_lean_checkpoint(model, pather)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m# dummy_input = distiller.get_dummy_input(input_shape=model.input_shape)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m    583\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mmodules\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    584\u001b[0m         raise AttributeError(\"'{}' object has no attribute '{}'\".format(\n\u001b[0;32m--> 585\u001b[0;31m             type(self).__name__, name))\n\u001b[0m\u001b[1;32m    586\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    587\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__setattr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mAttributeError\u001b[0m: 'DataParallel' object has no attribute 'prepare_model'"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":362},"id":"KO3osG4v985_","executionInfo":{"elapsed":497,"status":"error","timestamp":1607469617809,"user":{"displayName":"Jeremy Wang","photoUrl":"","userId":"16277065741529505083"},"user_tz":300},"outputId":"41e30ee6-ed37-4cb6-b75f-787a2440e381"},"source":["# Convert and Evaluate\n","model_pyt_model = distiller.quantization.convert_distiller_ptq_model_to_pytorch(model, dummy_input)\n","# Run evaluation\n","test(model_pyt_model)"],"execution_count":null,"outputs":[{"output_type":"error","ename":"AssertionError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)","\u001b[0;32m<ipython-input-27-280630cb7a5e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Convert and Evaluate\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mmodel_pyt_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdistiller\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mquantization\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert_distiller_ptq_model_to_pytorch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdummy_input\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;31m# Run evaluation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_pyt_model\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/content/distiller/distiller/quantization/pytorch_quant_conversion.py\u001b[0m in \u001b[0;36mconvert_distiller_ptq_model_to_pytorch\u001b[0;34m(model, dummy_input, backend)\u001b[0m\n\u001b[1;32m    316\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    317\u001b[0m     \u001b[0;31m# First pass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 318\u001b[0;31m     \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_ptq_convert_pass_replace_range_linear_wrappers\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    319\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    320\u001b[0m     \u001b[0;31m# Second pass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/content/distiller/distiller/quantization/pytorch_quant_conversion.py\u001b[0m in \u001b[0;36m_ptq_convert_pass_replace_range_linear_wrappers\u001b[0;34m(module)\u001b[0m\n\u001b[1;32m    155\u001b[0m         \u001b[0mnew_m\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mm\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    156\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdistiller\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mquantization\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRangeLinearQuantWrapper\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 157\u001b[0;31m             \u001b[0mnew_m\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_pytorch_quant\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mneed_reduce_range\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput_quant_settings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mquant_mode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mquint8\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    158\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    159\u001b[0m             requires_quantized_inputs = not (isinstance(new_m, nn.Sequential) and\n","\u001b[0;32m/content/distiller/distiller/quantization/range_linear.py\u001b[0m in \u001b[0;36mto_pytorch_quant\u001b[0;34m(self, reduce_range)\u001b[0m\n\u001b[1;32m    674\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mto_pytorch_quant\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduce_range\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    675\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput_quant_settings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_bits\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m8\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 676\u001b[0;31m             \u001b[0;34m'Conversion to PyTorch PTQ supported only for 8-bit quantization'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    677\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpreset_act_stats\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Conversion to PyTorch PTQ supported only for PTQ wrappers with activation stats'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    678\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_convert_to_pytorch_quant\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreduce_range\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mAssertionError\u001b[0m: Conversion to PyTorch PTQ supported only for 8-bit quantization"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":328},"id":"e83J4TtWF5Zm","executionInfo":{"elapsed":741,"status":"error","timestamp":1607460198960,"user":{"displayName":"Jeremy Wang","photoUrl":"","userId":"16277065741529505083"},"user_tz":300},"outputId":"b1f2a67e-4597-4e87-ce4d-66fac178f170"},"source":["computeSize(model_pyt_model)"],"execution_count":null,"outputs":[{"output_type":"error","ename":"RuntimeError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)","\u001b[0;32m<ipython-input-12-7f3b2ce95601>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mcomputeSize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_pyt_model\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m<ipython-input-9-2123549a1d3d>\u001b[0m in \u001b[0;36mcomputeSize\u001b[0;34m(model)\u001b[0m\n\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mcomputeSize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m   \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"./curModel\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m   \u001b[0msize\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetsize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"./curModel\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m   \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mremove\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"./curModel\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(obj, f, pickle_module, pickle_protocol)\u001b[0m\n\u001b[1;32m    258\u001b[0m         \u001b[0;34m>>\u001b[0m\u001b[0;34m>\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    259\u001b[0m     \"\"\"\n\u001b[0;32m--> 260\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_with_file_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"wb\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0m_save\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpickle_module\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpickle_protocol\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    261\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    262\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36m_with_file_like\u001b[0;34m(f, mode, body)\u001b[0m\n\u001b[1;32m    183\u001b[0m         \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    184\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 185\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mbody\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    186\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mnew_fd\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(f)\u001b[0m\n\u001b[1;32m    258\u001b[0m         \u001b[0;34m>>\u001b[0m\u001b[0;34m>\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    259\u001b[0m     \"\"\"\n\u001b[0;32m--> 260\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_with_file_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"wb\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0m_save\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpickle_module\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpickle_protocol\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    261\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    262\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36m_save\u001b[0;34m(obj, f, pickle_module, pickle_protocol)\u001b[0m\n\u001b[1;32m    330\u001b[0m     \u001b[0mpickler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpickle_module\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPickler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprotocol\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpickle_protocol\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    331\u001b[0m     \u001b[0mpickler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpersistent_id\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpersistent_id\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 332\u001b[0;31m     \u001b[0mpickler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    333\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    334\u001b[0m     \u001b[0mserialized_storage_keys\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mserialized_storages\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/quantized/modules/conv.py\u001b[0m in \u001b[0;36m__getstate__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__getstate__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    150\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_scripting\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 151\u001b[0;31m             raise RuntimeError('torch.save() is not currently supported for quantized modules.'\n\u001b[0m\u001b[1;32m    152\u001b[0m                                \u001b[0;34m' See https://github.com/pytorch/pytorch/issues/24045.'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    153\u001b[0m                                ' Please use state_dict or torch.jit serialization.')\n","\u001b[0;31mRuntimeError\u001b[0m: torch.save() is not currently supported for quantized modules. See https://github.com/pytorch/pytorch/issues/24045. Please use state_dict or torch.jit serialization."]}]},{"cell_type":"markdown","metadata":{"id":"DSGpHfKtlwTK"},"source":["# Ignore"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":356},"id":"6dvQU4RlEwrK","executionInfo":{"elapsed":362,"status":"error","timestamp":1607401093249,"user":{"displayName":"Jeremy Wang","photoUrl":"","userId":"16277065741529505083"},"user_tz":300},"outputId":"dced2b83-f90e-41e5-abcd-a57a0e37430f"},"source":["model = distiller.models.create_model(False, \"cifar10\", \"resnet56_cifar\", True, None)\n","# entry = removeModule(torch.load(\"/content/drive/MyDrive/Colab Notebooks/6787 Notebooks/Google Colab Scripts/baseOneShot/best.pth.tar\")\n","# entry = removeModule(torch.load(pather))\n","# model = distiller.models.create_model(False, \"cifar10\", \"resnet56_cifar\", True, None)\n","# Load the file\n","# model.load_state_dict(entry[\"state_dict\"])\n","print(computeStateSizes(model.state_dict(), True))\n","print(computeStateSizes(model.state_dict(), False))\n","entry = torch.load(\"../drive/MyDrive/CS6787 - Final Project/Google Colab Scripts/Pruning Models/Element Pruning/Direct Pruning/best.pth.tar\", map_location=torch.device('cpu'))\n","startTime = time.time()\n","finalAcc = test(model)\n","finalTime = time.time() - startTime\n","stats = computeStatistics(model)\n","# stats[\"Name\"] = entry.name\n","# stats[\"Time\"] = finalTime\n","# results.append(stats)\n","\n","# df = pd.DataFrame(results)\n","\n","stats"],"execution_count":null,"outputs":[{"output_type":"error","ename":"RuntimeError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)","\u001b[0;32m<ipython-input-34-9f44dface884>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# Load the file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m# model.load_state_dict(entry[\"state_dict\"])\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcomputeStateSizes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcomputeStateSizes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mentry\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"../drive/MyDrive/CS6787 - Final Project/Google Colab Scripts/Pruning Models/Element Pruning/Direct Pruning/best.pth.tar\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmap_location\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'cpu'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-24-23c844b6b510>\u001b[0m in \u001b[0;36mcomputeStateSizes\u001b[0;34m(state_dict, compressed)\u001b[0m\n\u001b[1;32m     42\u001b[0m       \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"denseTensor\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m       \u001b[0msparse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_sparse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m       \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msparse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindices\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"sparseTensorIndices\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m       \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msparse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"sparseTensorValues\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m       \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msparse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"sparseTensorSize\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mRuntimeError\u001b[0m: Cannot get indices on an uncoalesced tensor, please call .coalesce() first"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"oIcLG9j0GmTD","executionInfo":{"elapsed":269,"status":"ok","timestamp":1606120303186,"user":{"displayName":"Mueed Ur Rehman","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ghj9YH2JuHnytMBXOrP5AZ7UD35ohiAMKjIFnTh=s64","userId":"03998776733547559393"},"user_tz":300},"outputId":"f3931964-f56c-480a-c2ab-6102c8baa9aa"},"source":["print(baseParameters, baseTrainParameters, baseSize)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["855770 855770 3.41556453704834\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"EPeW_cVuIX8L"},"source":[""]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":234},"id":"Cuf52TjxWhGr","executionInfo":{"elapsed":1023,"status":"error","timestamp":1607401144031,"user":{"displayName":"Jeremy Wang","photoUrl":"","userId":"16277065741529505083"},"user_tz":300},"outputId":"4c47e479-dd7c-464c-f8a8-a32df1ce8003"},"source":["modelDirectory = \"/content/drive/MyDrive/CS6787 - Final Project/Google Colab Scripts/Quantization Models/Post-Training Quantization 02/quantized_checkpoint.pth.tar\"\n","\n","results = []\n","# for entry in os.scandir(modelDirectory):\n","model = distiller.models.create_model(False, \"cifar10\", \"resnet56_cifar\", True, None)\n","#load the file\n","torch.load(modelDirectory)\n","model.load_state_dict(entry[\"state_dict\"])\n","startTime = time.time()\n","finalAcc = test(model)\n","finalTime = time.time() - startTime\n","stats = computeStatistics(model)\n","stats[\"Name\"] = entry.name\n","stats[\"Time\"] = finalTime\n","results.append(stats)\n","\n","df = pd.DataFrame(results)\n","\n","save_dir = \".\"\n","df.to_csv(save_dir)"],"execution_count":null,"outputs":[{"output_type":"error","ename":"TypeError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-37-19e3be6f6d1e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m#load the file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodelDirectory\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodelDirectory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"state_dict\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0mstartTime\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mfinalAcc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mTypeError\u001b[0m: string indices must be integers"]}]},{"cell_type":"code","metadata":{"id":"9tVgIHF1LCdG"},"source":[""],"execution_count":null,"outputs":[]}]}