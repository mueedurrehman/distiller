version: 1
pruners:
  pruner1:
    class: SensitivityPruner
    sensitivities:
      'module.conv1.weight': 0.88
      'module.layer1.0.conv1.weight': 0.96
      'module.layer1.0.conv2.weight': 1.18
      'module.layer1.1.conv1.weight': 0.81
      'module.layer1.1.conv2.weight': 1.03
      'module.layer1.2.conv1.weight': 0.88
      'module.layer1.2.conv2.weight': 1.25
      'module.layer1.3.conv1.weight': 1.1
      'module.layer1.3.conv2.weight': 1.32
      'module.layer1.4.conv1.weight': 0.74
      'module.layer1.4.conv2.weight': 1.25
      'module.layer1.5.conv1.weight': 0.81
      'module.layer1.5.conv2.weight': 1.1
      'module.layer1.6.conv1.weight': 0.88
      'module.layer1.6.conv2.weight': 0.81
      'module.layer1.7.conv1.weight': 0.66
      'module.layer1.7.conv2.weight': 0.74
      'module.layer1.8.conv1.weight': 0.66
      'module.layer1.8.conv2.weight': 0.51
      'module.layer2.0.conv1.weight': 0.29
      'module.layer2.0.conv2.weight': 0.59
      'module.layer2.0.downsample.0.weight': 0.22
      'module.layer2.1.conv1.weight': 0.81
      'module.layer2.1.conv2.weight': 0.74
      'module.layer2.2.conv1.weight': 0.37
      'module.layer2.2.conv2.weight': 1.03
      'module.layer2.3.conv1.weight': 0.44
      'module.layer2.3.conv2.weight': 0.74
      'module.layer2.4.conv1.weight': 0.22
      'module.layer2.4.conv2.weight': 0.81
      'module.layer2.5.conv1.weight': 0.29
      'module.layer2.5.conv2.weight': 0.66
      'module.layer2.6.conv1.weight': 0.44
      'module.layer2.6.conv2.weight': 0.88
      'module.layer2.7.conv1.weight': 0.51
      'module.layer2.7.conv2.weight': 0.74
      'module.layer2.8.conv1.weight': 0.37
      'module.layer2.8.conv2.weight': 0.96
      'module.layer3.0.conv1.weight': 0.29
      'module.layer3.0.conv2.weight': 0.81
      'module.layer3.0.downsample.0.weight': 0.51
      'module.layer3.1.conv1.weight': 0.51
      'module.layer3.1.conv2.weight': 0.59
      'module.layer3.2.conv1.weight': 1.03
      'module.layer3.2.conv2.weight': 1.25
      'module.layer3.3.conv1.weight': 0.59
      'module.layer3.3.conv2.weight': 0.96
      'module.layer3.4.conv1.weight': 0.96
      'module.layer3.4.conv2.weight': 0.96
      'module.layer3.5.conv1.weight': 0.81
      'module.layer3.5.conv2.weight': 1.18
      'module.layer3.6.conv1.weight': 0.59
      'module.layer3.6.conv2.weight': 0.88
      'module.layer3.7.conv1.weight': 0.15
      'module.layer3.7.conv2.weight': 1.1
      'module.layer3.8.conv1.weight': 0.81
      'module.layer3.8.conv2.weight': 0.74
      'module.fc.weight': 0.51


lr_schedulers:
  multiLR:
    class: MultiStepMultiGammaLR
    gammas:
    - 1
    - 0.85
    - 0.85
    - 0.85
    - 0.85
    - 0.85
    - 0.85
    - 0.85
    - 0.85
    - 0.85
    - 0.85
    - 0.85
    - 0.85
    - 0.85
    - 0.85
    - 0.85
    - 0.85
    - 0.85
    - 0.85
    - 0.85
    - 18.06
    - 0.85
    - 0.85
    - 0.85
    - 0.85
    - 0.85
    - 0.85
    - 0.85
    - 0.85
    - 0.85
    - 0.85
    - 0.85
    - 0.85
    - 0.85
    - 0.85
    - 0.85
    - 0.85
    - 0.85
    - 0.85
    - 0.85
    - 18.06
    - 0.85
    - 0.85
    - 0.85
    - 0.85
    - 0.85
    - 0.85
    - 0.85
    - 0.85
    - 0.85
    - 0.85
    - 0.85
    - 0.85
    - 0.85
    - 0.85
    - 0.85
    - 0.85
    - 0.85
    - 0.85
    - 0.85
    - 18.06
    - 0.85
    - 0.85
    - 0.85
    - 0.85
    - 0.85
    - 0.85
    - 0.85
    - 0.85
    - 0.85
    - 0.85
    - 0.85
    - 0.85
    - 0.85
    - 0.85
    - 0.85
    - 0.85
    - 0.85
    - 0.85
    - 0.85
    last_epoch: -1
    milestones:
    - 0
    - 1
    - 2
    - 3
    - 4
    - 5
    - 6
    - 7
    - 8
    - 9
    - 10
    - 11
    - 12
    - 13
    - 14
    - 15
    - 16
    - 17
    - 18
    - 19
    - 20
    - 21
    - 22
    - 23
    - 24
    - 25
    - 26
    - 27
    - 28
    - 29
    - 30
    - 31
    - 32
    - 33
    - 34
    - 35
    - 36
    - 37
    - 38
    - 39
    - 40
    - 41
    - 42
    - 43
    - 44
    - 45
    - 46
    - 47
    - 48
    - 49
    - 50
    - 51
    - 52
    - 53
    - 54
    - 55
    - 56
    - 57
    - 58
    - 59
    - 60
    - 61
    - 62
    - 63
    - 64
    - 65
    - 66
    - 67
    - 68
    - 69
    - 70
    - 71
    - 72
    - 73
    - 74
    - 75
    - 76
    - 77
    - 78
    - 79

policies:
  - pruner:
      instance_name : 'pruner1'
    starting_epoch: 0
    ending_epoch: 65
    frequency: 20
  - lr_scheduler:
      instance_name: multiLR
    starting_epoch: 0
    ending_epoch: 85
    frequency: 1
lr_schedulers:
  multiLR:
    class: MultiStepMultiGammaLR
    gammas:
    - 1
    - 0.85
    - 0.85
    - 0.85
    - 0.85
    - 0.85
    - 0.85
    - 0.85
    - 0.85
    - 0.85
    - 0.85
    - 0.85
    - 0.85
    - 0.85
    - 0.85
    - 0.85
    - 0.85
    - 0.85
    - 0.85
    - 0.85
    - 18.06
    - 0.85
    - 0.85
    - 0.85
    - 0.85
    - 0.85
    - 0.85
    - 0.85
    - 0.85
    - 0.85
    - 0.85
    - 0.85
    - 0.85
    - 0.85
    - 0.85
    - 0.85
    - 0.85
    - 0.85
    - 0.85
    - 0.85
    - 18.06
    - 0.85
    - 0.85
    - 0.85
    - 0.85
    - 0.85
    - 0.85
    - 0.85
    - 0.85
    - 0.85
    - 0.85
    - 0.85
    - 0.85
    - 0.85
    - 0.85
    - 0.85
    - 0.85
    - 0.85
    - 0.85
    - 0.85
    - 18.06
    - 0.85
    - 0.85
    - 0.85
    - 0.85
    - 0.85
    - 0.85
    - 0.85
    - 0.85
    - 0.85
    - 0.85
    - 0.85
    - 0.85
    - 0.85
    - 0.85
    - 0.85
    - 0.85
    - 0.85
    - 0.85
    - 0.85
    last_epoch: -1
    milestones:
    - 0
    - 1
    - 2
    - 3
    - 4
    - 5
    - 6
    - 7
    - 8
    - 9
    - 10
    - 11
    - 12
    - 13
    - 14
    - 15
    - 16
    - 17
    - 18
    - 19
    - 20
    - 21
    - 22
    - 23
    - 24
    - 25
    - 26
    - 27
    - 28
    - 29
    - 30
    - 31
    - 32
    - 33
    - 34
    - 35
    - 36
    - 37
    - 38
    - 39
    - 40
    - 41
    - 42
    - 43
    - 44
    - 45
    - 46
    - 47
    - 48
    - 49
    - 50
    - 51
    - 52
    - 53
    - 54
    - 55
    - 56
    - 57
    - 58
    - 59
    - 60
    - 61
    - 62
    - 63
    - 64
    - 65
    - 66
    - 67
    - 68
    - 69
    - 70
    - 71
    - 72
    - 73
    - 74
    - 75
    - 76
    - 77
    - 78
    - 79

policies:
  - pruner:
      instance_name : 'pruner1'
    starting_epoch: 0
    ending_epoch: 65
    frequency: 20
  - lr_scheduler:
      instance_name: multiLR
    starting_epoch: 0
    ending_epoch: 85
    frequency: 1